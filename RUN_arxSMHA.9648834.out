Mon 27 Jun 2022 05:42:52 PM CEST
r30n7.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
Using backend: pytorch

===== ARXIV_NEW =====

Namespace(DATASET='arxiv_new', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=20, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=4096, LEARNING_RATE=0.001, WEIGHT_DECAY=1e-06, INCEPTION_LAYERS=1, INCEPTION_UNITS=512, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.2, NODE_DROPOUT=0.2, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=5, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5139251947402954
coalesce scoo: 1.717e-05
convert to csr_matrix: 0.02439
calc min-max per row: 0.03358
vectorization: 0.02047
Normalization Time: 0.0928
DOT_PRODUCT
Attention Filter (n=1166243): 0.934 +\- 0.049 [0.563-1.000]
Total Transformation Time: 6.0218
Epoch 20:, Train 0.6497, Val 0.6230, Test 0.5672
Epoch 40:, Train 0.7059, Val 0.6277, Test 0.5740
Epoch 60:, Train 0.7481, Val 0.6246, Test 0.5660
Epoch 80:, Train 0.7827, Val 0.6215, Test 0.5515
Epoch 100:, Train 0.8081, Val 0.6256, Test 0.5619
Epoch 120:, Train 0.8259, Val 0.6268, Test 0.5633
Epoch 140:, Train 0.8388, Val 0.6234, Test 0.5582
Epoch 160:, Train 0.8537, Val 0.6171, Test 0.5519
Epoch 180:, Train 0.8645, Val 0.6194, Test 0.5587
Epoch 200:, Train 0.8714, Val 0.6214, Test 0.5588
Epoch 220:, Train 0.8795, Val 0.6227, Test 0.5570
Epoch 240:, Train 0.8849, Val 0.6190, Test 0.5554
Epoch 260:, Train 0.8881, Val 0.6166, Test 0.5469
Epoch 280:, Train 0.8951, Val 0.6193, Test 0.5600
Epoch 300:, Train 0.8964, Val 0.6176, Test 0.5546
BEST: Epoch 40, Train 0.7059, Val 0.6277, Test 0.5740

RUN #1: seed=4
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5025953054428101
coalesce scoo: 1.192e-05
convert to csr_matrix: 0.02529
calc min-max per row: 0.03351
vectorization: 0.02035
Normalization Time: 0.0928
DOT_PRODUCT
Attention Filter (n=1166243): 0.930 +\- 0.053 [0.569-1.000]
Total Transformation Time: 5.9671
Epoch 20:, Train 0.6504, Val 0.6242, Test 0.5735
Epoch 40:, Train 0.7034, Val 0.6297, Test 0.5705
Epoch 60:, Train 0.7460, Val 0.6260, Test 0.5691
Epoch 80:, Train 0.7810, Val 0.6247, Test 0.5558
Epoch 100:, Train 0.8049, Val 0.6219, Test 0.5554
Epoch 120:, Train 0.8284, Val 0.6235, Test 0.5575
Epoch 140:, Train 0.8426, Val 0.6238, Test 0.5562
Epoch 160:, Train 0.8496, Val 0.6212, Test 0.5520
Epoch 180:, Train 0.8585, Val 0.6199, Test 0.5561
Epoch 200:, Train 0.8743, Val 0.6210, Test 0.5568
Epoch 220:, Train 0.8762, Val 0.6206, Test 0.5516
Epoch 240:, Train 0.8849, Val 0.6190, Test 0.5538
Epoch 260:, Train 0.8878, Val 0.6214, Test 0.5555
Epoch 280:, Train 0.8964, Val 0.6193, Test 0.5551
Epoch 300:, Train 0.8990, Val 0.6173, Test 0.5488
BEST: Epoch 40, Train 0.7034, Val 0.6297, Test 0.5705

RUN #2: seed=8
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.491199254989624
coalesce scoo: 1.335e-05
convert to csr_matrix: 0.02381
calc min-max per row: 0.03351
vectorization: 0.02061
Normalization Time: 0.0932
DOT_PRODUCT
Attention Filter (n=1166243): 0.924 +\- 0.056 [0.536-1.000]
Total Transformation Time: 6.0141
Epoch 20:, Train 0.6518, Val 0.6206, Test 0.5697
Epoch 40:, Train 0.7045, Val 0.6259, Test 0.5678
Epoch 60:, Train 0.7434, Val 0.6291, Test 0.5734
Epoch 80:, Train 0.7807, Val 0.6243, Test 0.5612
Epoch 100:, Train 0.8080, Val 0.6269, Test 0.5665
Epoch 120:, Train 0.8237, Val 0.6238, Test 0.5565
Epoch 140:, Train 0.8391, Val 0.6225, Test 0.5632
Epoch 160:, Train 0.8539, Val 0.6223, Test 0.5584
Epoch 180:, Train 0.8661, Val 0.6211, Test 0.5596
Epoch 200:, Train 0.8738, Val 0.6200, Test 0.5563
Epoch 220:, Train 0.8788, Val 0.6178, Test 0.5514
Epoch 240:, Train 0.8827, Val 0.6173, Test 0.5568
Epoch 260:, Train 0.8901, Val 0.6186, Test 0.5534
Epoch 280:, Train 0.8989, Val 0.6208, Test 0.5546
Epoch 300:, Train 0.8999, Val 0.6189, Test 0.5537
BEST: Epoch 60, Train 0.7434, Val 0.6291, Test 0.5734

RUN #3: seed=42
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4875534474849701
coalesce scoo: 1.216e-05
convert to csr_matrix: 0.02374
calc min-max per row: 0.03358
vectorization: 0.02079
Normalization Time: 0.0931
DOT_PRODUCT
Attention Filter (n=1166243): 0.927 +\- 0.055 [0.507-1.000]
Total Transformation Time: 5.9107
Epoch 20:, Train 0.6473, Val 0.6198, Test 0.5684
Epoch 40:, Train 0.7031, Val 0.6290, Test 0.5687
Epoch 60:, Train 0.7488, Val 0.6309, Test 0.5735
Epoch 80:, Train 0.7807, Val 0.6290, Test 0.5674
Epoch 100:, Train 0.8066, Val 0.6245, Test 0.5652
Epoch 120:, Train 0.8272, Val 0.6252, Test 0.5592
Epoch 140:, Train 0.8438, Val 0.6247, Test 0.5595
Epoch 160:, Train 0.8514, Val 0.6246, Test 0.5570
Epoch 180:, Train 0.8619, Val 0.6224, Test 0.5613
Epoch 200:, Train 0.8751, Val 0.6196, Test 0.5521
Epoch 220:, Train 0.8790, Val 0.6253, Test 0.5633
Epoch 240:, Train 0.8885, Val 0.6193, Test 0.5509
Epoch 260:, Train 0.8927, Val 0.6171, Test 0.5507
Epoch 280:, Train 0.8994, Val 0.6192, Test 0.5523
Epoch 300:, Train 0.8995, Val 0.6212, Test 0.5559
BEST: Epoch 60, Train 0.7488, Val 0.6309, Test 0.5735

RUN #4: seed=64
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.544205904006958
coalesce scoo: 1.192e-05
convert to csr_matrix: 0.02397
calc min-max per row: 0.03342
vectorization: 0.02041
Normalization Time: 0.0929
DOT_PRODUCT
Attention Filter (n=1166243): 0.929 +\- 0.052 [0.512-1.000]
Total Transformation Time: 5.8842
Epoch 20:, Train 0.6492, Val 0.6214, Test 0.5739
Epoch 40:, Train 0.7028, Val 0.6279, Test 0.5759
Epoch 60:, Train 0.7498, Val 0.6270, Test 0.5679
Epoch 80:, Train 0.7825, Val 0.6281, Test 0.5680
Epoch 100:, Train 0.8054, Val 0.6240, Test 0.5582
Epoch 120:, Train 0.8284, Val 0.6229, Test 0.5574
Epoch 140:, Train 0.8425, Val 0.6235, Test 0.5626
Epoch 160:, Train 0.8495, Val 0.6198, Test 0.5540
Epoch 180:, Train 0.8646, Val 0.6211, Test 0.5595
Epoch 200:, Train 0.8736, Val 0.6238, Test 0.5642
Epoch 220:, Train 0.8776, Val 0.6223, Test 0.5586
Epoch 240:, Train 0.8828, Val 0.6203, Test 0.5575
Epoch 260:, Train 0.8895, Val 0.6182, Test 0.5535
Epoch 280:, Train 0.8947, Val 0.6209, Test 0.5560
Epoch 300:, Train 0.9009, Val 0.6199, Test 0.5576
BEST: Epoch 80, Train 0.7825, Val 0.6281, Test 0.5680

RUN #5: seed=128
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5031800270080566
coalesce scoo: 1.192e-05
convert to csr_matrix: 0.02338
calc min-max per row: 0.03348
vectorization: 0.02037
Normalization Time: 0.0917
DOT_PRODUCT
Attention Filter (n=1166243): 0.918 +\- 0.064 [0.530-1.000]
Total Transformation Time: 5.9438
Epoch 20:, Train 0.6488, Val 0.6192, Test 0.5671
Epoch 40:, Train 0.7048, Val 0.6256, Test 0.5683
Epoch 60:, Train 0.7431, Val 0.6255, Test 0.5649
Epoch 80:, Train 0.7788, Val 0.6290, Test 0.5670
Epoch 100:, Train 0.8042, Val 0.6252, Test 0.5646
Epoch 120:, Train 0.8219, Val 0.6207, Test 0.5546
Epoch 140:, Train 0.8383, Val 0.6222, Test 0.5587
Epoch 160:, Train 0.8503, Val 0.6228, Test 0.5595
Epoch 180:, Train 0.8619, Val 0.6222, Test 0.5565
Epoch 200:, Train 0.8684, Val 0.6198, Test 0.5496
Epoch 220:, Train 0.8782, Val 0.6196, Test 0.5514
Epoch 240:, Train 0.8860, Val 0.6221, Test 0.5571
Epoch 260:, Train 0.8884, Val 0.6191, Test 0.5536
Epoch 280:, Train 0.8942, Val 0.6189, Test 0.5569
Epoch 300:, Train 0.8955, Val 0.6173, Test 0.5527
BEST: Epoch 80, Train 0.7788, Val 0.6290, Test 0.5670

RUN #6: seed=256
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4769839346408844
coalesce scoo: 1.264e-05
convert to csr_matrix: 0.02355
calc min-max per row: 0.03359
vectorization: 0.02038
Normalization Time: 0.0931
DOT_PRODUCT
Attention Filter (n=1166243): 0.937 +\- 0.048 [0.556-1.000]
Total Transformation Time: 5.9144
Epoch 20:, Train 0.6511, Val 0.6217, Test 0.5740
Epoch 40:, Train 0.7047, Val 0.6271, Test 0.5708
Epoch 60:, Train 0.7456, Val 0.6207, Test 0.5585
Epoch 80:, Train 0.7800, Val 0.6274, Test 0.5705
Epoch 100:, Train 0.8035, Val 0.6231, Test 0.5638
Epoch 120:, Train 0.8245, Val 0.6227, Test 0.5624
Epoch 140:, Train 0.8382, Val 0.6210, Test 0.5567
Epoch 160:, Train 0.8522, Val 0.6193, Test 0.5531
Epoch 180:, Train 0.8601, Val 0.6176, Test 0.5501
Epoch 200:, Train 0.8691, Val 0.6210, Test 0.5578
Epoch 220:, Train 0.8769, Val 0.6199, Test 0.5542
Epoch 240:, Train 0.8845, Val 0.6197, Test 0.5540
Epoch 260:, Train 0.8858, Val 0.6178, Test 0.5495
Epoch 280:, Train 0.8958, Val 0.6178, Test 0.5508
Epoch 300:, Train 0.9016, Val 0.6177, Test 0.5511
BEST: Epoch 80, Train 0.7800, Val 0.6274, Test 0.5705

RUN #7: seed=512
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4966272711753845
coalesce scoo: 8.821e-06
convert to csr_matrix: 0.02356
calc min-max per row: 0.03358
vectorization: 0.02039
Normalization Time: 0.0933
DOT_PRODUCT
Attention Filter (n=1166243): 0.928 +\- 0.057 [0.520-1.000]
Total Transformation Time: 5.9170
Epoch 20:, Train 0.6476, Val 0.6198, Test 0.5658
Epoch 40:, Train 0.7032, Val 0.6287, Test 0.5743
Epoch 60:, Train 0.7475, Val 0.6267, Test 0.5707
Epoch 80:, Train 0.7784, Val 0.6247, Test 0.5637
Epoch 100:, Train 0.8052, Val 0.6214, Test 0.5562
Epoch 120:, Train 0.8248, Val 0.6251, Test 0.5629
Epoch 140:, Train 0.8363, Val 0.6198, Test 0.5551
Epoch 160:, Train 0.8536, Val 0.6210, Test 0.5563
Epoch 180:, Train 0.8619, Val 0.6212, Test 0.5541
Epoch 200:, Train 0.8705, Val 0.6179, Test 0.5505
Epoch 220:, Train 0.8749, Val 0.6191, Test 0.5519
Epoch 240:, Train 0.8840, Val 0.6165, Test 0.5475
Epoch 260:, Train 0.8895, Val 0.6205, Test 0.5526
Epoch 280:, Train 0.8931, Val 0.6206, Test 0.5542
Epoch 300:, Train 0.8980, Val 0.6204, Test 0.5550
BEST: Epoch 40, Train 0.7032, Val 0.6287, Test 0.5743

RUN #8: seed=1024
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4767032563686371
coalesce scoo: 8.821e-06
convert to csr_matrix: 0.02338
calc min-max per row: 0.03355
vectorization: 0.02069
Normalization Time: 0.0908
DOT_PRODUCT
Attention Filter (n=1166243): 0.928 +\- 0.054 [0.568-1.000]
Total Transformation Time: 5.9224
Epoch 20:, Train 0.6509, Val 0.6216, Test 0.5683
Epoch 40:, Train 0.7052, Val 0.6282, Test 0.5787
Epoch 60:, Train 0.7465, Val 0.6276, Test 0.5705
Epoch 80:, Train 0.7782, Val 0.6240, Test 0.5634
Epoch 100:, Train 0.8057, Val 0.6242, Test 0.5614
Epoch 120:, Train 0.8245, Val 0.6231, Test 0.5616
Epoch 140:, Train 0.8422, Val 0.6225, Test 0.5583
Epoch 160:, Train 0.8503, Val 0.6202, Test 0.5543
Epoch 180:, Train 0.8603, Val 0.6235, Test 0.5563
Epoch 200:, Train 0.8712, Val 0.6183, Test 0.5529
Epoch 220:, Train 0.8765, Val 0.6233, Test 0.5615
Epoch 240:, Train 0.8824, Val 0.6240, Test 0.5592
Epoch 260:, Train 0.8848, Val 0.6203, Test 0.5530
Epoch 280:, Train 0.8968, Val 0.6208, Test 0.5533
Epoch 300:, Train 0.8970, Val 0.6224, Test 0.5568
BEST: Epoch 40, Train 0.7052, Val 0.6282, Test 0.5787

RUN #9: seed=2048
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.47441917657852173
coalesce scoo: 8.583e-06
convert to csr_matrix: 0.02326
calc min-max per row: 0.03349
vectorization: 0.02033
Normalization Time: 0.0919
DOT_PRODUCT
Attention Filter (n=1166243): 0.931 +\- 0.052 [0.537-1.000]
Total Transformation Time: 5.9855
Epoch 20:, Train 0.6478, Val 0.6219, Test 0.5713
Epoch 40:, Train 0.7030, Val 0.6284, Test 0.5668
Epoch 60:, Train 0.7454, Val 0.6297, Test 0.5709
Epoch 80:, Train 0.7831, Val 0.6270, Test 0.5612
Epoch 100:, Train 0.8056, Val 0.6273, Test 0.5612
Epoch 120:, Train 0.8247, Val 0.6251, Test 0.5573
Epoch 140:, Train 0.8415, Val 0.6285, Test 0.5659
Epoch 160:, Train 0.8523, Val 0.6238, Test 0.5525
Epoch 180:, Train 0.8657, Val 0.6249, Test 0.5582
Epoch 200:, Train 0.8728, Val 0.6226, Test 0.5578
Epoch 220:, Train 0.8805, Val 0.6216, Test 0.5574
Epoch 240:, Train 0.8848, Val 0.6211, Test 0.5567
Epoch 260:, Train 0.8890, Val 0.6178, Test 0.5459
Epoch 280:, Train 0.8917, Val 0.6220, Test 0.5550
Epoch 300:, Train 0.8984, Val 0.6185, Test 0.5496
BEST: Epoch 60, Train 0.7454, Val 0.6297, Test 0.5709




==================================================
Model Parameters: 1270317

Avg. Filter Time (s): 5.1531 +/- 0.0406
Avg. Preaggregation Time (s): 5.9481 +/- 0.0445
Avg. Training Time (epoch) (s): 0.9495 +/- 0.0807
Avg. Inference Time (s): 0.0402 +/- 0.0017

Avg. Training Acc: 0.7397 +/- 0.0318
Avg. Validation Acc: 0.6288 +/- 0.0010
Avg. Test Acc: 0.5721 +/- 0.0032

==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 0 hours 52 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
