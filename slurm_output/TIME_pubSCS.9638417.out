Wed 22 Jun 2022 10:05:26 AM CEST
r30n1.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
Using backend: pytorch

===== PUBMED =====

Namespace(DATASET='pubmed', ATTN_FILTER='cosine', EPOCHS=300, EVAL_EVERY=20, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=256, LEARNING_RATE=0.001, WEIGHT_DECAY=1e-07, INCEPTION_LAYERS=2, INCEPTION_UNITS=512, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.3, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, ATTN_HEADS=2, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
For-Loop Times: 0.0005+\-0.0132 [0.0004-3.9228]
Normalization Time: 0.4720
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
61.729827880859375
Epoch 20:, Train 0.9963, Val 0.9140, Test 0.8940
Epoch 40:, Train 0.9999, Val 0.9120, Test 0.8920
Epoch 60:, Train 0.9999, Val 0.9160, Test 0.9000
Epoch 80:, Train 1.0000, Val 0.8980, Test 0.8900
Epoch 100:, Train 0.9999, Val 0.9080, Test 0.8870
Epoch 120:, Train 1.0000, Val 0.9100, Test 0.8950
Epoch 140:, Train 1.0000, Val 0.8960, Test 0.8970
Epoch 160:, Train 1.0000, Val 0.9020, Test 0.8940
Epoch 180:, Train 1.0000, Val 0.8920, Test 0.8930
Epoch 200:, Train 1.0000, Val 0.9100, Test 0.8920
Epoch 220:, Train 1.0000, Val 0.8960, Test 0.8920
Epoch 240:, Train 1.0000, Val 0.9020, Test 0.8920
Epoch 260:, Train 1.0000, Val 0.8980, Test 0.8890
Epoch 280:, Train 1.0000, Val 0.8980, Test 0.8930
Epoch 300:, Train 1.0000, Val 0.8980, Test 0.8850
BEST: Epoch 60, Train 0.9999, Val 0.9160, Test 0.9000

RUN #1: seed=4
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0032]
Normalization Time: 0.0233
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.457178115844727
Epoch 20:, Train 0.9970, Val 0.9120, Test 0.8970
Epoch 40:, Train 0.9999, Val 0.9080, Test 0.9030
Epoch 60:, Train 0.9998, Val 0.9140, Test 0.9000
Epoch 80:, Train 1.0000, Val 0.9080, Test 0.8980
Epoch 100:, Train 1.0000, Val 0.9080, Test 0.8940
Epoch 120:, Train 1.0000, Val 0.8980, Test 0.9030
Epoch 140:, Train 1.0000, Val 0.9020, Test 0.8970
Epoch 160:, Train 1.0000, Val 0.9120, Test 0.8990
Epoch 180:, Train 1.0000, Val 0.8960, Test 0.9030
Epoch 200:, Train 1.0000, Val 0.8940, Test 0.8990
Epoch 220:, Train 1.0000, Val 0.8900, Test 0.8980
Epoch 240:, Train 1.0000, Val 0.9100, Test 0.8940
Epoch 260:, Train 1.0000, Val 0.9020, Test 0.8950
Epoch 280:, Train 1.0000, Val 0.9020, Test 0.8950
Epoch 300:, Train 1.0000, Val 0.9020, Test 0.8900
BEST: Epoch 60, Train 0.9998, Val 0.9140, Test 0.9000

RUN #2: seed=8
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0036]
Normalization Time: 0.0390
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.67246413230896
Epoch 20:, Train 0.9971, Val 0.9180, Test 0.9060
Epoch 40:, Train 0.9998, Val 0.9060, Test 0.8990
Epoch 60:, Train 1.0000, Val 0.9060, Test 0.9000
Epoch 80:, Train 1.0000, Val 0.9060, Test 0.8980
Epoch 100:, Train 1.0000, Val 0.9060, Test 0.8930
Epoch 120:, Train 1.0000, Val 0.9020, Test 0.8960
Epoch 140:, Train 1.0000, Val 0.9040, Test 0.8900
Epoch 160:, Train 1.0000, Val 0.9100, Test 0.8880
Epoch 180:, Train 1.0000, Val 0.9080, Test 0.8980
Epoch 200:, Train 1.0000, Val 0.9080, Test 0.8920
Epoch 220:, Train 1.0000, Val 0.9040, Test 0.8940
Epoch 240:, Train 1.0000, Val 0.9040, Test 0.8940
Epoch 260:, Train 1.0000, Val 0.9000, Test 0.8910
Epoch 280:, Train 1.0000, Val 0.9000, Test 0.8880
Epoch 300:, Train 1.0000, Val 0.9040, Test 0.8960
BEST: Epoch 20, Train 0.9971, Val 0.9180, Test 0.9060

RUN #3: seed=42
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0040]
Normalization Time: 0.0274
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.205920696258545
Epoch 20:, Train 0.9966, Val 0.9080, Test 0.9030
Epoch 40:, Train 0.9998, Val 0.9060, Test 0.8960
Epoch 60:, Train 1.0000, Val 0.9160, Test 0.8970
Epoch 80:, Train 1.0000, Val 0.9060, Test 0.8950
Epoch 100:, Train 1.0000, Val 0.8920, Test 0.8920
Epoch 120:, Train 1.0000, Val 0.9060, Test 0.8850
Epoch 140:, Train 1.0000, Val 0.9020, Test 0.8890
Epoch 160:, Train 1.0000, Val 0.9000, Test 0.8940
Epoch 180:, Train 1.0000, Val 0.9140, Test 0.8910
Epoch 200:, Train 1.0000, Val 0.9000, Test 0.8930
Epoch 220:, Train 1.0000, Val 0.8940, Test 0.8950
Epoch 240:, Train 1.0000, Val 0.8980, Test 0.8910
Epoch 260:, Train 1.0000, Val 0.9040, Test 0.8860
Epoch 280:, Train 1.0000, Val 0.9000, Test 0.8850
Epoch 300:, Train 1.0000, Val 0.9100, Test 0.8970
BEST: Epoch 60, Train 1.0000, Val 0.9160, Test 0.8970

RUN #4: seed=64
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0032]
Normalization Time: 0.0284
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.332895278930664
Epoch 20:, Train 0.9964, Val 0.9020, Test 0.8940
Epoch 40:, Train 0.9998, Val 0.9080, Test 0.9100
Epoch 60:, Train 1.0000, Val 0.9120, Test 0.9050
Epoch 80:, Train 1.0000, Val 0.9020, Test 0.8960
Epoch 100:, Train 0.9999, Val 0.8860, Test 0.9010
Epoch 120:, Train 1.0000, Val 0.8980, Test 0.8920
Epoch 140:, Train 1.0000, Val 0.9080, Test 0.8930
Epoch 160:, Train 1.0000, Val 0.9000, Test 0.8960
Epoch 180:, Train 1.0000, Val 0.8860, Test 0.8910
Epoch 200:, Train 1.0000, Val 0.9000, Test 0.8910
Epoch 220:, Train 1.0000, Val 0.8900, Test 0.8920
Epoch 240:, Train 1.0000, Val 0.8960, Test 0.8890
Epoch 260:, Train 1.0000, Val 0.9060, Test 0.8910
Epoch 280:, Train 1.0000, Val 0.9060, Test 0.8920
Epoch 300:, Train 1.0000, Val 0.8980, Test 0.8840
BEST: Epoch 60, Train 1.0000, Val 0.9120, Test 0.9050

RUN #5: seed=128
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0032]
Normalization Time: 0.0298
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.29978370666504
Epoch 20:, Train 0.9981, Val 0.9180, Test 0.9020
Epoch 40:, Train 0.9999, Val 0.9120, Test 0.8980
Epoch 60:, Train 1.0000, Val 0.9080, Test 0.9000
Epoch 80:, Train 1.0000, Val 0.9080, Test 0.8980
Epoch 100:, Train 1.0000, Val 0.8940, Test 0.8960
Epoch 120:, Train 1.0000, Val 0.9000, Test 0.9030
Epoch 140:, Train 1.0000, Val 0.9060, Test 0.9000
Epoch 160:, Train 1.0000, Val 0.8940, Test 0.8940
Epoch 180:, Train 1.0000, Val 0.8920, Test 0.8910
Epoch 200:, Train 1.0000, Val 0.8980, Test 0.8930
Epoch 220:, Train 1.0000, Val 0.8940, Test 0.8950
Epoch 240:, Train 1.0000, Val 0.8920, Test 0.8930
Epoch 260:, Train 1.0000, Val 0.8940, Test 0.8870
Epoch 280:, Train 1.0000, Val 0.8840, Test 0.8870
Epoch 300:, Train 1.0000, Val 0.9020, Test 0.8950
BEST: Epoch 20, Train 0.9981, Val 0.9180, Test 0.9020

RUN #6: seed=256
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0031]
Normalization Time: 0.0310
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.423804759979248
Epoch 20:, Train 0.9960, Val 0.9180, Test 0.8980
Epoch 40:, Train 0.9999, Val 0.9120, Test 0.8860
Epoch 60:, Train 1.0000, Val 0.9200, Test 0.8940
Epoch 80:, Train 0.9999, Val 0.9120, Test 0.8990
Epoch 100:, Train 1.0000, Val 0.9060, Test 0.8910
Epoch 120:, Train 1.0000, Val 0.9000, Test 0.8940
Epoch 140:, Train 1.0000, Val 0.9140, Test 0.8940
Epoch 160:, Train 1.0000, Val 0.8940, Test 0.8860
Epoch 180:, Train 0.9999, Val 0.8900, Test 0.8900
Epoch 200:, Train 1.0000, Val 0.8960, Test 0.8910
Epoch 220:, Train 1.0000, Val 0.9040, Test 0.8940
Epoch 240:, Train 1.0000, Val 0.8960, Test 0.8910
Epoch 260:, Train 1.0000, Val 0.9040, Test 0.8950
Epoch 280:, Train 1.0000, Val 0.9000, Test 0.8930
Epoch 300:, Train 1.0000, Val 0.8940, Test 0.8960
BEST: Epoch 60, Train 1.0000, Val 0.9200, Test 0.8940

RUN #7: seed=512
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0042]
Normalization Time: 0.0310
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.390304803848267
Epoch 20:, Train 0.9971, Val 0.9180, Test 0.9010
Epoch 40:, Train 0.9998, Val 0.9100, Test 0.8970
Epoch 60:, Train 0.9999, Val 0.9060, Test 0.9010
Epoch 80:, Train 0.9999, Val 0.9080, Test 0.8950
Epoch 100:, Train 1.0000, Val 0.9120, Test 0.8950
Epoch 120:, Train 1.0000, Val 0.8980, Test 0.8910
Epoch 140:, Train 1.0000, Val 0.9060, Test 0.8940
Epoch 160:, Train 1.0000, Val 0.9000, Test 0.8910
Epoch 180:, Train 1.0000, Val 0.8900, Test 0.8890
Epoch 200:, Train 1.0000, Val 0.8980, Test 0.8990
Epoch 220:, Train 1.0000, Val 0.9020, Test 0.9000
Epoch 240:, Train 1.0000, Val 0.9020, Test 0.9030
Epoch 260:, Train 1.0000, Val 0.8960, Test 0.8960
Epoch 280:, Train 1.0000, Val 0.9080, Test 0.8910
Epoch 300:, Train 1.0000, Val 0.9020, Test 0.8980
BEST: Epoch 20, Train 0.9971, Val 0.9180, Test 0.9010

RUN #8: seed=1024
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0031]
Normalization Time: 0.0249
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.389441967010498
Epoch 20:, Train 0.9978, Val 0.9080, Test 0.8990
Epoch 40:, Train 0.9996, Val 0.9080, Test 0.8920
Epoch 60:, Train 0.9999, Val 0.9100, Test 0.9040
Epoch 80:, Train 1.0000, Val 0.8980, Test 0.9010
Epoch 100:, Train 1.0000, Val 0.9160, Test 0.8940
Epoch 120:, Train 1.0000, Val 0.9120, Test 0.8900
Epoch 140:, Train 1.0000, Val 0.9120, Test 0.8930
Epoch 160:, Train 1.0000, Val 0.9120, Test 0.8890
Epoch 180:, Train 1.0000, Val 0.9080, Test 0.8930
Epoch 200:, Train 1.0000, Val 0.9120, Test 0.8900
Epoch 220:, Train 1.0000, Val 0.9120, Test 0.8850
Epoch 240:, Train 1.0000, Val 0.9040, Test 0.8960
Epoch 260:, Train 1.0000, Val 0.9000, Test 0.8830
Epoch 280:, Train 1.0000, Val 0.8900, Test 0.8920
Epoch 300:, Train 1.0000, Val 0.9160, Test 0.8950
BEST: Epoch 100, Train 1.0000, Val 0.9160, Test 0.8940

RUN #9: seed=2048
For-Loop Times: 0.0002+\-0.0000 [0.0002-0.0032]
Normalization Time: 0.0310
COSINE
Attention Filter (n=88570): 0.605 +\- 0.307 [0.001-1.000]
20.443623542785645
Epoch 20:, Train 0.9958, Val 0.9060, Test 0.8950
Epoch 40:, Train 1.0000, Val 0.9020, Test 0.8930
Epoch 60:, Train 1.0000, Val 0.9020, Test 0.9000
Epoch 80:, Train 1.0000, Val 0.9080, Test 0.8810
Epoch 100:, Train 1.0000, Val 0.9040, Test 0.8900
Epoch 120:, Train 1.0000, Val 0.8960, Test 0.8970
Epoch 140:, Train 1.0000, Val 0.9020, Test 0.8940
Epoch 160:, Train 1.0000, Val 0.8960, Test 0.8940
Epoch 180:, Train 1.0000, Val 0.9080, Test 0.8900
Epoch 200:, Train 1.0000, Val 0.8940, Test 0.8900
Epoch 220:, Train 1.0000, Val 0.9020, Test 0.8920
Epoch 240:, Train 0.9999, Val 0.9000, Test 0.8870
Epoch 260:, Train 1.0000, Val 0.9000, Test 0.8960
Epoch 280:, Train 1.0000, Val 0.9040, Test 0.8970
Epoch 300:, Train 1.0000, Val 0.9040, Test 0.8880
BEST: Epoch 80, Train 1.0000, Val 0.9080, Test 0.8810




==================================================
Model Parameters: 2613768

Avg. Preaggregation Time (s): 24.5345 +/- 12.3990
Avg. Training Time (epoch) (s): 1.0578 +/- 0.0955
Avg. Inference Time (s): 0.0981 +/- 0.0039

Avg. Training Acc: 0.9992 +/- 0.0012
Avg. Validation Acc: 0.9156 +/- 0.0033
Avg. Test Acc: 0.8980 +/- 0.0068

==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 0 hours 58 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
