Thu 16 Jun 2022 04:35:29 AM CEST
r32n1.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: products
method: bayes
model: SIGNff_SHA
iterations: 100
run_trial: false
config: SIGNff_SHA.yaml
train_file: hps_SIGNff_DPA.py
project_name: sffSHA_products
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  ATTN_HEADS:
    value: 1
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 2048
    - 4096
    - 8192
    - 16384
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  DATASET:
    value: products
  DPA_NORMALIZATION:
    values:
    - 0
    - 1
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  TRANSFORMATION:
    value: dot_product
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff_DPA.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220616_043652-17zuqu9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-spaceship-15
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/17zuqu9j
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-16 04:37:00,422 - wandb.wandb_agent - INFO - Running runs: []
2022-06-16 04:37:00,679 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:37:00,679 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 04:37:00,687 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 04:37:05,700 - wandb.wandb_agent - INFO - Running runs: ['zonp1e16']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220616_043704-zonp1e16
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-1
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/zonp1e16
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k0_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36433
wandb:    train_loss 2.69659
wandb: training_time 1.36323
wandb:        val_f1 0.35948
wandb:      val_loss 2.70788
wandb: 
wandb: Synced rural-sweep-1: https://wandb.ai/jah377/sffSHA_products/runs/zonp1e16
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_043704-zonp1e16/logs
2022-06-16 11:28:05,922 - wandb.wandb_agent - INFO - Cleaning up finished run: zonp1e16
2022-06-16 11:28:06,332 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:28:06,333 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 11:28:06,342 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 11:28:11,355 - wandb.wandb_agent - INFO - Running runs: ['377sdeli']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220616_112811-377sdeli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-2
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/377sdeli
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k2_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36012
wandb:    train_loss 3.36042
wandb: training_time 1.39996
wandb:        val_f1 0.3666
wandb:      val_loss 3.323
wandb: 
wandb: Synced logical-sweep-2: https://wandb.ai/jah377/sffSHA_products/runs/377sdeli
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_112811-377sdeli/logs
2022-06-16 18:16:57,433 - wandb.wandb_agent - INFO - Cleaning up finished run: 377sdeli
2022-06-16 18:16:57,866 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:16:57,866 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 18:16:57,874 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 18:17:02,886 - wandb.wandb_agent - INFO - Running runs: ['dahhqjqh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220616_181703-dahhqjqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-3
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/dahhqjqh
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k3_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.73607
wandb:    train_loss 1.15649
wandb: training_time 1.47785
wandb:        val_f1 0.73041
wandb:      val_loss 1.17853
wandb: 
wandb: Synced young-sweep-3: https://wandb.ai/jah377/sffSHA_products/runs/dahhqjqh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_181703-dahhqjqh/logs
2022-06-17 01:06:05,934 - wandb.wandb_agent - INFO - Cleaning up finished run: dahhqjqh
2022-06-17 01:06:06,317 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 01:06:06,318 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-17 01:06:06,326 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-17 01:06:11,340 - wandb.wandb_agent - INFO - Running runs: ['dyhnaaa9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220617_010612-dyhnaaa9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-4
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/dyhnaaa9
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k4_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.06234
wandb:    train_loss 3.80743
wandb: training_time 1.63268
wandb:        val_f1 0.06045
wandb:      val_loss 3.8146
wandb: 
wandb: Synced honest-sweep-4: https://wandb.ai/jah377/sffSHA_products/runs/dyhnaaa9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_010612-dyhnaaa9/logs
2022-06-17 08:01:25,767 - wandb.wandb_agent - INFO - Cleaning up finished run: dyhnaaa9
2022-06-17 08:01:26,247 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 08:01:26,248 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 08:01:26,255 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 08:01:31,266 - wandb.wandb_agent - INFO - Running runs: ['t40pw3nt']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220617_080131-t40pw3nt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-5
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/t40pw3nt
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30836
wandb:    train_loss 2.59564
wandb: training_time 2.31532
wandb:        val_f1 0.30834
wandb:      val_loss 2.62156
wandb: 
wandb: Synced sweet-sweep-5: https://wandb.ai/jah377/sffSHA_products/runs/t40pw3nt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_080131-t40pw3nt/logs
2022-06-17 08:22:20,809 - wandb.wandb_agent - INFO - Cleaning up finished run: t40pw3nt
2022-06-17 08:22:21,188 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 08:22:21,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-17 08:22:21,195 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-17 08:22:26,208 - wandb.wandb_agent - INFO - Running runs: ['hm8zwv9z']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220617_082226-hm8zwv9z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-6
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/hm8zwv9z
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k5_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.05381
wandb:    train_loss 3.81401
wandb: training_time 1.73481
wandb:        val_f1 0.05404
wandb:      val_loss 3.82342
wandb: 
wandb: Synced solar-sweep-6: https://wandb.ai/jah377/sffSHA_products/runs/hm8zwv9z
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_082226-hm8zwv9z/logs
2022-06-17 15:19:31,358 - wandb.wandb_agent - INFO - Cleaning up finished run: hm8zwv9z
2022-06-17 15:19:31,758 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 15:19:31,759 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-17 15:19:31,766 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-17 15:19:36,778 - wandb.wandb_agent - INFO - Running runs: ['gjdy6ip2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220617_151937-gjdy6ip2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-7
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/gjdy6ip2
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64536
wandb:    train_loss 1.47676
wandb: training_time 1.48795
wandb:        val_f1 0.63947
wandb:      val_loss 1.50582
wandb: 
wandb: Synced feasible-sweep-7: https://wandb.ai/jah377/sffSHA_products/runs/gjdy6ip2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_151937-gjdy6ip2/logs
2022-06-17 15:35:47,283 - wandb.wandb_agent - INFO - Cleaning up finished run: gjdy6ip2
2022-06-17 15:35:47,729 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 15:35:47,730 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 15:35:47,737 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 15:35:52,751 - wandb.wandb_agent - INFO - Running runs: ['6wzexmcn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220617_153552-6wzexmcn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-8
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/6wzexmcn
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k0_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.77933
wandb:    train_loss 0.76481
wandb: training_time 1.36634
wandb:        val_f1 0.74951
wandb:      val_loss 0.87147
wandb: 
wandb: Synced bright-sweep-8: https://wandb.ai/jah377/sffSHA_products/runs/6wzexmcn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_153552-6wzexmcn/logs
2022-06-17 22:32:47,022 - wandb.wandb_agent - INFO - Cleaning up finished run: 6wzexmcn
2022-06-17 22:32:47,397 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 22:32:47,398 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-17 22:32:47,404 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-17 22:32:52,418 - wandb.wandb_agent - INFO - Running runs: ['l4xz1ery']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220617_223252-l4xz1ery
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-9
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/l4xz1ery
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k4_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60589
wandb:    train_loss 1.80591
wandb: training_time 2.26929
wandb:        val_f1 0.59873
wandb:      val_loss 1.84207
wandb: 
wandb: Synced flowing-sweep-9: https://wandb.ai/jah377/sffSHA_products/runs/l4xz1ery
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_223252-l4xz1ery/logs
2022-06-18 05:32:53,798 - wandb.wandb_agent - INFO - Cleaning up finished run: l4xz1ery
2022-06-18 05:32:54,136 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 05:32:54,136 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-18 05:32:54,141 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-18 05:32:59,150 - wandb.wandb_agent - INFO - Running runs: ['08wrjg10']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_053259-08wrjg10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-10
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/08wrjg10
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.84909
wandb:    train_loss 0.55082
wandb: training_time 1.73167
wandb:        val_f1 0.82344
wandb:      val_loss 0.64677
wandb: 
wandb: Synced confused-sweep-10: https://wandb.ai/jah377/sffSHA_products/runs/08wrjg10
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_053259-08wrjg10/logs
2022-06-18 05:51:27,807 - wandb.wandb_agent - INFO - Cleaning up finished run: 08wrjg10
2022-06-18 05:51:28,162 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 05:51:28,162 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-18 05:51:28,172 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 05:51:33,182 - wandb.wandb_agent - INFO - Running runs: ['z8yh30yx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_055133-z8yh30yx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-11
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/z8yh30yx
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k1_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3794
wandb:    train_loss 12084.93132
wandb: training_time 1.47961
wandb:        val_f1 0.38425
wandb:      val_loss 12534.75689
wandb: 
wandb: Synced exalted-sweep-11: https://wandb.ai/jah377/sffSHA_products/runs/z8yh30yx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_055133-z8yh30yx/logs
2022-06-18 12:53:19,533 - wandb.wandb_agent - INFO - Cleaning up finished run: z8yh30yx
2022-06-18 12:53:19,876 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 12:53:19,877 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-18 12:53:19,885 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
2022-06-18 12:53:24,898 - wandb.wandb_agent - INFO - Running runs: ['opwlh9l0']
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_125327-opwlh9l0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-12
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/opwlh9l0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k5_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56173
wandb:    train_loss 3.10448
wandb: training_time 2.37418
wandb:        val_f1 0.56585
wandb:      val_loss 3.08111
wandb: 
wandb: Synced crisp-sweep-12: https://wandb.ai/jah377/sffSHA_products/runs/opwlh9l0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_125327-opwlh9l0/logs
2022-06-18 19:55:07,575 - wandb.wandb_agent - INFO - Cleaning up finished run: opwlh9l0
2022-06-18 19:55:07,911 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 19:55:07,911 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-18 19:55:07,921 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 19:55:12,934 - wandb.wandb_agent - INFO - Running runs: ['564vjc0f']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_195513-564vjc0f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-13
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/564vjc0f
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.13633
wandb:    train_loss 3.75151
wandb: training_time 1.69728
wandb:        val_f1 0.14643
wandb:      val_loss 3.74967
wandb: 
wandb: Synced rosy-sweep-13: https://wandb.ai/jah377/sffSHA_products/runs/564vjc0f
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_195513-564vjc0f/logs
2022-06-18 20:12:51,540 - wandb.wandb_agent - INFO - Cleaning up finished run: 564vjc0f
2022-06-18 20:12:51,888 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 20:12:51,889 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-18 20:12:51,896 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-18 20:12:56,909 - wandb.wandb_agent - INFO - Running runs: ['ihpxrmtl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_201257-ihpxrmtl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-14
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ihpxrmtl
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60219
wandb:    train_loss 2.86423
wandb: training_time 3.67258
wandb:        val_f1 0.60171
wandb:      val_loss 2.85833
wandb: 
wandb: Synced visionary-sweep-14: https://wandb.ai/jah377/sffSHA_products/runs/ihpxrmtl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_201257-ihpxrmtl/logs
2022-06-18 20:44:12,346 - wandb.wandb_agent - INFO - Cleaning up finished run: ihpxrmtl
2022-06-18 20:44:12,684 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 20:44:12,685 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-18 20:44:12,693 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-18 20:44:17,706 - wandb.wandb_agent - INFO - Running runs: ['hyrekc0o']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_204417-hyrekc0o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-15
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/hyrekc0o
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40723
wandb:    train_loss 3.18965
wandb: training_time 1.58353
wandb:        val_f1 0.40389
wandb:      val_loss 3.20311
wandb: 
wandb: Synced sage-sweep-15: https://wandb.ai/jah377/sffSHA_products/runs/hyrekc0o
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_204417-hyrekc0o/logs
2022-06-18 21:01:39,326 - wandb.wandb_agent - INFO - Cleaning up finished run: hyrekc0o
2022-06-18 21:01:39,752 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 21:01:39,753 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-18 21:01:39,762 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 21:01:44,774 - wandb.wandb_agent - INFO - Running runs: ['hsfamre2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_210145-hsfamre2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-16
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/hsfamre2
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5473
wandb:    train_loss 1.77238
wandb: training_time 2.69257
wandb:        val_f1 0.55301
wandb:      val_loss 1.74351
wandb: 
wandb: Synced fresh-sweep-16: https://wandb.ai/jah377/sffSHA_products/runs/hsfamre2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_210145-hsfamre2/logs
2022-06-18 21:25:43,449 - wandb.wandb_agent - INFO - Cleaning up finished run: hsfamre2
2022-06-18 21:25:43,830 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 21:25:43,830 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-18 21:25:43,838 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 21:25:48,851 - wandb.wandb_agent - INFO - Running runs: ['ceimzg3w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_212548-ceimzg3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-17
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ceimzg3w
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42396
wandb:    train_loss 2.99633
wandb: training_time 2.31881
wandb:        val_f1 0.42153
wandb:      val_loss 3.00381
wandb: 
wandb: Synced golden-sweep-17: https://wandb.ai/jah377/sffSHA_products/runs/ceimzg3w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_212548-ceimzg3w/logs
2022-06-18 21:47:07,046 - wandb.wandb_agent - INFO - Cleaning up finished run: ceimzg3w
2022-06-18 21:47:07,440 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 21:47:07,440 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-18 21:47:07,447 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-18 21:47:12,461 - wandb.wandb_agent - INFO - Running runs: ['z92veect']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_214712-z92veect
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-18
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/z92veect
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.70522
wandb:    train_loss 1.20409
wandb: training_time 2.38533
wandb:        val_f1 0.70602
wandb:      val_loss 1.19744
wandb: 
wandb: Synced daily-sweep-18: https://wandb.ai/jah377/sffSHA_products/runs/z92veect
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_214712-z92veect/logs
2022-06-18 22:09:12,330 - wandb.wandb_agent - INFO - Cleaning up finished run: z92veect
2022-06-18 22:09:12,669 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 22:09:12,670 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-18 22:09:12,676 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 22:09:17,690 - wandb.wandb_agent - INFO - Running runs: ['na5x524j']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_220916-na5x524j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-19
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/na5x524j
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.22344
wandb:    train_loss 3.70921
wandb: training_time 1.64107
wandb:        val_f1 0.22285
wandb:      val_loss 3.71688
wandb: 
wandb: Synced iconic-sweep-19: https://wandb.ai/jah377/sffSHA_products/runs/na5x524j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_220916-na5x524j/logs
2022-06-18 22:27:45,316 - wandb.wandb_agent - INFO - Cleaning up finished run: na5x524j
2022-06-18 22:27:45,684 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 22:27:45,685 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-18 22:27:45,694 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-18 22:27:50,708 - wandb.wandb_agent - INFO - Running runs: ['e6u4c7lf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_222750-e6u4c7lf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-20
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/e6u4c7lf
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17971
wandb:    train_loss 3.73896
wandb: training_time 1.92813
wandb:        val_f1 0.17814
wandb:      val_loss 3.74191
wandb: 
wandb: Synced still-sweep-20: https://wandb.ai/jah377/sffSHA_products/runs/e6u4c7lf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_222750-e6u4c7lf/logs
2022-06-18 22:47:31,285 - wandb.wandb_agent - INFO - Cleaning up finished run: e6u4c7lf
2022-06-18 22:47:31,653 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 22:47:31,654 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-18 22:47:31,661 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-18 22:47:36,674 - wandb.wandb_agent - INFO - Running runs: ['5jn8q4rf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_224736-5jn8q4rf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-21
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/5jn8q4rf
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65981
wandb:    train_loss 1.63168
wandb: training_time 1.89128
wandb:        val_f1 0.6543
wandb:      val_loss 1.63242
wandb: 
wandb: Synced desert-sweep-21: https://wandb.ai/jah377/sffSHA_products/runs/5jn8q4rf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_224736-5jn8q4rf/logs
2022-06-18 23:06:59,946 - wandb.wandb_agent - INFO - Cleaning up finished run: 5jn8q4rf
2022-06-18 23:07:00,273 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 23:07:00,273 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-18 23:07:00,281 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-18 23:07:05,295 - wandb.wandb_agent - INFO - Running runs: ['co3bq6jc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_230705-co3bq6jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-22
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/co3bq6jc
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.00922
wandb:    train_loss 3.82079
wandb: training_time 1.45455
wandb:        val_f1 0.0091
wandb:      val_loss 3.82165
wandb: 
wandb: Synced genial-sweep-22: https://wandb.ai/jah377/sffSHA_products/runs/co3bq6jc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_230705-co3bq6jc/logs
2022-06-18 23:22:59,866 - wandb.wandb_agent - INFO - Cleaning up finished run: co3bq6jc
2022-06-18 23:23:00,268 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 23:23:00,269 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-18 23:23:00,278 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-18 23:23:05,290 - wandb.wandb_agent - INFO - Running runs: ['84q5vtvs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220618_232305-84q5vtvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-23
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/84q5vtvs
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k1_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.18181
wandb:    train_loss 3.47735
wandb: training_time 1.81969
wandb:        val_f1 0.18358
wandb:      val_loss 3.47409
wandb: 
wandb: Synced sunny-sweep-23: https://wandb.ai/jah377/sffSHA_products/runs/84q5vtvs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_232305-84q5vtvs/logs
2022-06-19 06:19:09,691 - wandb.wandb_agent - INFO - Cleaning up finished run: 84q5vtvs
2022-06-19 06:19:10,065 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 06:19:10,065 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 06:19:10,072 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 06:19:15,086 - wandb.wandb_agent - INFO - Running runs: ['guzoc0kw']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_061914-guzoc0kw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-24
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/guzoc0kw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.2739
wandb:    train_loss 3.63555
wandb: training_time 1.79374
wandb:        val_f1 0.2734
wandb:      val_loss 3.64018
wandb: 
wandb: Synced azure-sweep-24: https://wandb.ai/jah377/sffSHA_products/runs/guzoc0kw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_061914-guzoc0kw/logs
2022-06-19 06:37:33,006 - wandb.wandb_agent - INFO - Cleaning up finished run: guzoc0kw
2022-06-19 06:37:33,491 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 06:37:33,492 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-19 06:37:33,498 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 06:37:38,510 - wandb.wandb_agent - INFO - Running runs: ['d2179rz0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_063738-d2179rz0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-25
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/d2179rz0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47218
wandb:    train_loss 1.78958
wandb: training_time 3.12367
wandb:        val_f1 0.47799
wandb:      val_loss 1.77341
wandb: 
wandb: Synced ancient-sweep-25: https://wandb.ai/jah377/sffSHA_products/runs/d2179rz0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_063738-d2179rz0/logs
2022-06-19 07:04:33,261 - wandb.wandb_agent - INFO - Cleaning up finished run: d2179rz0
2022-06-19 07:04:33,672 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:04:33,672 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-19 07:04:33,681 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 07:04:38,694 - wandb.wandb_agent - INFO - Running runs: ['d49yayil']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_070439-d49yayil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-26
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/d49yayil
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.02005
wandb:    train_loss 3.83807
wandb: training_time 1.66559
wandb:        val_f1 0.01933
wandb:      val_loss 3.83855
wandb: 
wandb: Synced curious-sweep-26: https://wandb.ai/jah377/sffSHA_products/runs/d49yayil
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_070439-d49yayil/logs
2022-06-19 07:21:41,488 - wandb.wandb_agent - INFO - Cleaning up finished run: d49yayil
2022-06-19 07:21:41,845 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:21:41,846 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-19 07:21:41,854 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 07:21:46,867 - wandb.wandb_agent - INFO - Running runs: ['c7r0j2fh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_072147-c7r0j2fh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-27
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/c7r0j2fh
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04152
wandb:    train_loss 3.80106
wandb: training_time 1.42984
wandb:        val_f1 0.04308
wandb:      val_loss 3.80088
wandb: 
wandb: Synced decent-sweep-27: https://wandb.ai/jah377/sffSHA_products/runs/c7r0j2fh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_072147-c7r0j2fh/logs
2022-06-19 07:37:40,834 - wandb.wandb_agent - INFO - Cleaning up finished run: c7r0j2fh
2022-06-19 07:37:41,205 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:37:41,206 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-19 07:37:41,212 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 07:37:46,226 - wandb.wandb_agent - INFO - Running runs: ['wvg7ju84']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_073745-wvg7ju84
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-28
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/wvg7ju84
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.21175
wandb:    train_loss 3.62643
wandb: training_time 1.93405
wandb:        val_f1 0.21784
wandb:      val_loss 3.61973
wandb: 
wandb: Synced mild-sweep-28: https://wandb.ai/jah377/sffSHA_products/runs/wvg7ju84
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_073745-wvg7ju84/logs
2022-06-19 07:56:25,358 - wandb.wandb_agent - INFO - Cleaning up finished run: wvg7ju84
2022-06-19 07:56:25,826 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:56:25,827 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-19 07:56:25,834 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 07:56:30,846 - wandb.wandb_agent - INFO - Running runs: ['2mqmayyt']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_075630-2mqmayyt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-29
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/2mqmayyt
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.14621
wandb:    train_loss 3.70494
wandb: training_time 1.67813
wandb:        val_f1 0.16059
wandb:      val_loss 3.69397
wandb: 
wandb: Synced pretty-sweep-29: https://wandb.ai/jah377/sffSHA_products/runs/2mqmayyt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_075630-2mqmayyt/logs
2022-06-19 08:13:56,838 - wandb.wandb_agent - INFO - Cleaning up finished run: 2mqmayyt
2022-06-19 08:13:57,406 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 08:13:57,407 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 08:13:57,414 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 08:14:02,426 - wandb.wandb_agent - INFO - Running runs: ['hdpn67m8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_081402-hdpn67m8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-30
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/hdpn67m8
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.28201
wandb:    train_loss 3.65641
wandb: training_time 1.71789
wandb:        val_f1 0.27658
wandb:      val_loss 3.66489
wandb: 
wandb: Synced desert-sweep-30: https://wandb.ai/jah377/sffSHA_products/runs/hdpn67m8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_081402-hdpn67m8/logs
2022-06-19 08:31:14,941 - wandb.wandb_agent - INFO - Cleaning up finished run: hdpn67m8
2022-06-19 08:31:15,425 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 08:31:15,425 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-19 08:31:15,431 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 08:31:20,445 - wandb.wandb_agent - INFO - Running runs: ['6k4pcgws']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_083120-6k4pcgws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-31
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/6k4pcgws
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.07791
wandb:    train_loss 3.79915
wandb: training_time 1.77588
wandb:        val_f1 0.07443
wandb:      val_loss 3.79971
wandb: 
wandb: Synced dandy-sweep-31: https://wandb.ai/jah377/sffSHA_products/runs/6k4pcgws
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_083120-6k4pcgws/logs
2022-06-19 08:50:24,644 - wandb.wandb_agent - INFO - Cleaning up finished run: 6k4pcgws
2022-06-19 08:50:25,000 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 08:50:25,001 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-19 08:50:25,009 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 08:50:30,022 - wandb.wandb_agent - INFO - Running runs: ['sdbw3g7z']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_085030-sdbw3g7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-32
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/sdbw3g7z
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.11512
wandb:    train_loss 3.77022
wandb: training_time 1.69505
wandb:        val_f1 0.11965
wandb:      val_loss 3.77096
wandb: 
wandb: Synced dazzling-sweep-32: https://wandb.ai/jah377/sffSHA_products/runs/sdbw3g7z
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_085030-sdbw3g7z/logs
2022-06-19 09:08:55,232 - wandb.wandb_agent - INFO - Cleaning up finished run: sdbw3g7z
2022-06-19 09:08:55,635 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 09:08:55,636 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-19 09:08:55,643 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 09:09:00,654 - wandb.wandb_agent - INFO - Running runs: ['6tuztmv2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_090900-6tuztmv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-33
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/6tuztmv2
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.69074
wandb:    train_loss 1.18127
wandb: training_time 1.97389
wandb:        val_f1 0.68301
wandb:      val_loss 1.22151
wandb: 
wandb: Synced feasible-sweep-33: https://wandb.ai/jah377/sffSHA_products/runs/6tuztmv2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_090900-6tuztmv2/logs
2022-06-19 09:28:41,386 - wandb.wandb_agent - INFO - Cleaning up finished run: 6tuztmv2
2022-06-19 09:28:41,814 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 09:28:41,814 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-19 09:28:41,821 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 09:28:46,834 - wandb.wandb_agent - INFO - Running runs: ['gzazit4k']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_092847-gzazit4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-34
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/gzazit4k
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.08033
wandb:    train_loss 3.79527
wandb: training_time 1.768
wandb:        val_f1 0.07708
wandb:      val_loss 3.79553
wandb: 
wandb: Synced spring-sweep-34: https://wandb.ai/jah377/sffSHA_products/runs/gzazit4k
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_092847-gzazit4k/logs
2022-06-19 09:47:50,886 - wandb.wandb_agent - INFO - Cleaning up finished run: gzazit4k
2022-06-19 09:47:51,326 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 09:47:51,327 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 09:47:51,335 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 09:47:56,346 - wandb.wandb_agent - INFO - Running runs: ['j1kzc70j']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_094755-j1kzc70j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-35
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/j1kzc70j
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.32964
wandb:    train_loss 3.55391
wandb: training_time 1.99552
wandb:        val_f1 0.32556
wandb:      val_loss 3.56408
wandb: 
wandb: Synced absurd-sweep-35: https://wandb.ai/jah377/sffSHA_products/runs/j1kzc70j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_094755-j1kzc70j/logs
2022-06-19 10:07:10,914 - wandb.wandb_agent - INFO - Cleaning up finished run: j1kzc70j
2022-06-19 10:07:11,339 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 10:07:11,339 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 10:07:11,346 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 10:07:16,358 - wandb.wandb_agent - INFO - Running runs: ['j9jejpiu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_100716-j9jejpiu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-36
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/j9jejpiu
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.32741
wandb:    train_loss 3.43054
wandb: training_time 1.75318
wandb:        val_f1 0.3193
wandb:      val_loss 3.4402
wandb: 
wandb: Synced crimson-sweep-36: https://wandb.ai/jah377/sffSHA_products/runs/j9jejpiu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_100716-j9jejpiu/logs
2022-06-19 10:25:35,717 - wandb.wandb_agent - INFO - Cleaning up finished run: j9jejpiu
2022-06-19 10:25:36,151 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 10:25:36,151 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 10:25:36,160 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 10:25:41,174 - wandb.wandb_agent - INFO - Running runs: ['bf5k69fp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_102541-bf5k69fp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-37
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/bf5k69fp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1981
wandb:    train_loss 3.70214
wandb: training_time 1.81148
wandb:        val_f1 0.20141
wandb:      val_loss 3.70808
wandb: 
wandb: Synced stoic-sweep-37: https://wandb.ai/jah377/sffSHA_products/runs/bf5k69fp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_102541-bf5k69fp/logs
2022-06-19 10:44:15,074 - wandb.wandb_agent - INFO - Cleaning up finished run: bf5k69fp
2022-06-19 10:44:15,557 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 10:44:15,557 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-19 10:44:15,565 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 10:44:20,578 - wandb.wandb_agent - INFO - Running runs: ['shv4u3ql']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_104420-shv4u3ql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-38
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/shv4u3ql
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.13125
wandb:    train_loss 3.75499
wandb: training_time 1.93213
wandb:        val_f1 0.12748
wandb:      val_loss 3.75836
wandb: 
wandb: Synced chocolate-sweep-38: https://wandb.ai/jah377/sffSHA_products/runs/shv4u3ql
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_104420-shv4u3ql/logs
2022-06-19 11:05:03,534 - wandb.wandb_agent - INFO - Cleaning up finished run: shv4u3ql
2022-06-19 11:05:04,152 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:05:04,152 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 11:05:04,159 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 11:05:09,173 - wandb.wandb_agent - INFO - Running runs: ['rdl8vsfz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_110509-rdl8vsfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-39
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/rdl8vsfz
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.2973
wandb:    train_loss 3.46063
wandb: training_time 1.54529
wandb:        val_f1 0.29441
wandb:      val_loss 3.46954
wandb: 
wandb: Synced winter-sweep-39: https://wandb.ai/jah377/sffSHA_products/runs/rdl8vsfz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_110509-rdl8vsfz/logs
2022-06-19 11:22:52,399 - wandb.wandb_agent - INFO - Cleaning up finished run: rdl8vsfz
2022-06-19 11:22:52,813 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:22:52,814 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-19 11:22:52,822 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 11:22:57,835 - wandb.wandb_agent - INFO - Running runs: ['4k2auzt8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_112258-4k2auzt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-40
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/4k2auzt8
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.78915
wandb:    train_loss 0.97301
wandb: training_time 1.73666
wandb:        val_f1 0.78234
wandb:      val_loss 0.9829
wandb: 
wandb: Synced gentle-sweep-40: https://wandb.ai/jah377/sffSHA_products/runs/4k2auzt8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_112258-4k2auzt8/logs
2022-06-19 11:42:02,992 - wandb.wandb_agent - INFO - Cleaning up finished run: 4k2auzt8
2022-06-19 11:42:03,460 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:42:03,461 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-19 11:42:03,467 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 11:42:08,481 - wandb.wandb_agent - INFO - Running runs: ['tds8xtpm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_114208-tds8xtpm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-41
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/tds8xtpm
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.66785
wandb:    train_loss 1.01579
wandb: training_time 2.13043
wandb:        val_f1 0.65987
wandb:      val_loss 1.04591
wandb: 
wandb: Synced jumping-sweep-41: https://wandb.ai/jah377/sffSHA_products/runs/tds8xtpm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_114208-tds8xtpm/logs
2022-06-19 12:03:18,814 - wandb.wandb_agent - INFO - Cleaning up finished run: tds8xtpm
2022-06-19 12:03:19,393 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:03:19,394 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 12:03:19,402 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 12:03:24,415 - wandb.wandb_agent - INFO - Running runs: ['68tch0pw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_120324-68tch0pw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-42
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/68tch0pw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.16307
wandb:    train_loss 3.67027
wandb: training_time 1.47811
wandb:        val_f1 0.1627
wandb:      val_loss 3.67823
wandb: 
wandb: Synced unique-sweep-42: https://wandb.ai/jah377/sffSHA_products/runs/68tch0pw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_120324-68tch0pw/logs
2022-06-19 12:19:28,354 - wandb.wandb_agent - INFO - Cleaning up finished run: 68tch0pw
2022-06-19 12:19:28,771 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:19:28,771 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-19 12:19:28,778 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 12:19:33,792 - wandb.wandb_agent - INFO - Running runs: ['ra1yip05']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_121933-ra1yip05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-43
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ra1yip05
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.24329
wandb:    train_loss 3.63843
wandb: training_time 2.01116
wandb:        val_f1 0.24423
wandb:      val_loss 3.64283
wandb: 
wandb: Synced earnest-sweep-43: https://wandb.ai/jah377/sffSHA_products/runs/ra1yip05
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_121933-ra1yip05/logs
2022-06-19 12:39:27,045 - wandb.wandb_agent - INFO - Cleaning up finished run: ra1yip05
2022-06-19 12:39:27,667 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:39:27,668 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-19 12:39:27,677 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 12:39:32,690 - wandb.wandb_agent - INFO - Running runs: ['a9wuyv5x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_123932-a9wuyv5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-44
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/a9wuyv5x
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53199
wandb:    train_loss 2.55089
wandb: training_time 1.7032
wandb:        val_f1 0.53274
wandb:      val_loss 2.56979
wandb: 
wandb: Synced trim-sweep-44: https://wandb.ai/jah377/sffSHA_products/runs/a9wuyv5x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_123932-a9wuyv5x/logs
2022-06-19 12:56:38,421 - wandb.wandb_agent - INFO - Cleaning up finished run: a9wuyv5x
2022-06-19 12:56:38,971 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:56:38,971 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-19 12:56:38,978 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 12:56:43,992 - wandb.wandb_agent - INFO - Running runs: ['tje0gifa']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_125644-tje0gifa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-45
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/tje0gifa
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54531
wandb:    train_loss 2.87249
wandb: training_time 1.89687
wandb:        val_f1 0.54424
wandb:      val_loss 2.87514
wandb: 
wandb: Synced summer-sweep-45: https://wandb.ai/jah377/sffSHA_products/runs/tje0gifa
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_125644-tje0gifa/logs
2022-06-19 13:16:18,365 - wandb.wandb_agent - INFO - Cleaning up finished run: tje0gifa
2022-06-19 13:16:18,773 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:16:18,773 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-19 13:16:18,780 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 13:16:23,790 - wandb.wandb_agent - INFO - Running runs: ['97l5mvq6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_131623-97l5mvq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-46
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/97l5mvq6
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.75026
wandb:    train_loss 0.93047
wandb: training_time 2.65416
wandb:        val_f1 0.74071
wandb:      val_loss 0.97313
wandb: 
wandb: Synced northern-sweep-46: https://wandb.ai/jah377/sffSHA_products/runs/97l5mvq6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_131623-97l5mvq6/logs
2022-06-19 13:41:31,974 - wandb.wandb_agent - INFO - Cleaning up finished run: 97l5mvq6
2022-06-19 13:41:32,545 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:41:32,545 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-19 13:41:32,552 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 13:41:37,562 - wandb.wandb_agent - INFO - Running runs: ['9lu2an2f']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_134136-9lu2an2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-47
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/9lu2an2f
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.05776
wandb:    train_loss 3.78928
wandb: training_time 1.35086
wandb:        val_f1 0.0548
wandb:      val_loss 3.79121
wandb: 
wandb: Synced wild-sweep-47: https://wandb.ai/jah377/sffSHA_products/runs/9lu2an2f
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_134136-9lu2an2f/logs
2022-06-19 13:56:39,450 - wandb.wandb_agent - INFO - Cleaning up finished run: 9lu2an2f
2022-06-19 13:56:39,893 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:56:39,894 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-19 13:56:39,900 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 13:56:44,914 - wandb.wandb_agent - INFO - Running runs: ['13im0638']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_135645-13im0638
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-48
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/13im0638
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04147
wandb:    train_loss 3.80975
wandb: training_time 1.37601
wandb:        val_f1 0.04087
wandb:      val_loss 3.81398
wandb: 
wandb: Synced quiet-sweep-48: https://wandb.ai/jah377/sffSHA_products/runs/13im0638
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_135645-13im0638/logs
2022-06-19 14:11:56,982 - wandb.wandb_agent - INFO - Cleaning up finished run: 13im0638
2022-06-19 14:11:57,502 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:11:57,503 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-19 14:11:57,510 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 14:12:02,522 - wandb.wandb_agent - INFO - Running runs: ['ypwo0xpp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_141202-ypwo0xpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-49
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ypwo0xpp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.44057
wandb:    train_loss 3.07406
wandb: training_time 1.35814
wandb:        val_f1 0.43003
wandb:      val_loss 3.10443
wandb: 
wandb: Synced drawn-sweep-49: https://wandb.ai/jah377/sffSHA_products/runs/ypwo0xpp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_141202-ypwo0xpp/logs
2022-06-19 14:27:20,167 - wandb.wandb_agent - INFO - Cleaning up finished run: ypwo0xpp
2022-06-19 14:27:20,607 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:27:20,607 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-19 14:27:20,614 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 14:27:25,626 - wandb.wandb_agent - INFO - Running runs: ['yatw93ff']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_142725-yatw93ff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-50
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/yatw93ff
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.19436
wandb:    train_loss 3.67096
wandb: training_time 1.94079
wandb:        val_f1 0.19274
wandb:      val_loss 3.67823
wandb: 
wandb: Synced amber-sweep-50: https://wandb.ai/jah377/sffSHA_products/runs/yatw93ff
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_142725-yatw93ff/logs
2022-06-19 14:46:34,688 - wandb.wandb_agent - INFO - Cleaning up finished run: yatw93ff
2022-06-19 14:46:35,117 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:46:35,118 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-19 14:46:35,125 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 14:46:40,138 - wandb.wandb_agent - INFO - Running runs: ['ff35088v']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_144640-ff35088v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-51
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ff35088v
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.03438
wandb:    train_loss 3.80909
wandb: training_time 1.64022
wandb:        val_f1 0.03164
wandb:      val_loss 3.81281
wandb: 
wandb: Synced rosy-sweep-51: https://wandb.ai/jah377/sffSHA_products/runs/ff35088v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_144640-ff35088v/logs
2022-06-19 15:04:54,425 - wandb.wandb_agent - INFO - Cleaning up finished run: ff35088v
2022-06-19 15:04:54,866 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:04:54,867 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-19 15:04:54,871 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 15:04:59,882 - wandb.wandb_agent - INFO - Running runs: ['kih2j39d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_150500-kih2j39d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-52
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/kih2j39d
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60757
wandb:    train_loss 1.41135
wandb: training_time 2.01177
wandb:        val_f1 0.60255
wandb:      val_loss 1.44507
wandb: 
wandb: Synced twilight-sweep-52: https://wandb.ai/jah377/sffSHA_products/runs/kih2j39d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_150500-kih2j39d/logs
2022-06-19 15:23:48,993 - wandb.wandb_agent - INFO - Cleaning up finished run: kih2j39d
2022-06-19 15:23:49,439 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:23:49,440 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-19 15:23:49,447 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 15:23:54,461 - wandb.wandb_agent - INFO - Running runs: ['3ljod3d4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_152354-3ljod3d4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-53
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/3ljod3d4
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k2_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54527
wandb:    train_loss 2.57057
wandb: training_time 2.15278
wandb:        val_f1 0.54401
wandb:      val_loss 2.5999
wandb: 
wandb: Synced quiet-sweep-53: https://wandb.ai/jah377/sffSHA_products/runs/3ljod3d4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_152354-3ljod3d4/logs
2022-06-19 22:24:15,631 - wandb.wandb_agent - INFO - Cleaning up finished run: 3ljod3d4
2022-06-19 22:24:16,242 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:24:16,242 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-19 22:24:16,251 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 22:24:21,262 - wandb.wandb_agent - INFO - Running runs: ['ftivz4xq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_222421-ftivz4xq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-54
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ftivz4xq
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3293
wandb:    train_loss 3.39602
wandb: training_time 2.40898
wandb:        val_f1 0.32795
wandb:      val_loss 3.41372
wandb: 
wandb: Synced whole-sweep-54: https://wandb.ai/jah377/sffSHA_products/runs/ftivz4xq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_222421-ftivz4xq/logs
2022-06-19 22:47:28,057 - wandb.wandb_agent - INFO - Cleaning up finished run: ftivz4xq
2022-06-19 22:47:28,503 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:47:28,504 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-19 22:47:28,510 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 22:47:33,522 - wandb.wandb_agent - INFO - Running runs: ['02i4pwk0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_224733-02i4pwk0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-55
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/02i4pwk0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.22869
wandb:    train_loss 3.74984
wandb: training_time 1.5407
wandb:        val_f1 0.22717
wandb:      val_loss 3.75713
wandb: 
wandb: Synced volcanic-sweep-55: https://wandb.ai/jah377/sffSHA_products/runs/02i4pwk0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_224733-02i4pwk0/logs
2022-06-19 23:04:12,317 - wandb.wandb_agent - INFO - Cleaning up finished run: 02i4pwk0
2022-06-19 23:04:17,136 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:04:17,136 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-19 23:04:17,145 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 23:04:22,158 - wandb.wandb_agent - INFO - Running runs: ['jw65vinu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_230422-jw65vinu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-56
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/jw65vinu
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04556
wandb:    train_loss 3.84898
wandb: training_time 1.57597
wandb:        val_f1 0.04674
wandb:      val_loss 3.85001
wandb: 
wandb: Synced lunar-sweep-56: https://wandb.ai/jah377/sffSHA_products/runs/jw65vinu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_230422-jw65vinu/logs
2022-06-19 23:22:19,726 - wandb.wandb_agent - INFO - Cleaning up finished run: jw65vinu
2022-06-19 23:22:20,171 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:22:20,172 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-19 23:22:20,181 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 23:22:25,194 - wandb.wandb_agent - INFO - Running runs: ['voud89vz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_232225-voud89vz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-57
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/voud89vz
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04275
wandb:    train_loss 3.84214
wandb: training_time 1.50743
wandb:        val_f1 0.04275
wandb:      val_loss 3.84226
wandb: 
wandb: Synced valiant-sweep-57: https://wandb.ai/jah377/sffSHA_products/runs/voud89vz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_232225-voud89vz/logs
2022-06-19 23:39:30,811 - wandb.wandb_agent - INFO - Cleaning up finished run: voud89vz
2022-06-19 23:39:31,291 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:39:31,291 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-19 23:39:31,298 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 23:39:36,312 - wandb.wandb_agent - INFO - Running runs: ['qjrjtal0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_233936-qjrjtal0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-58
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/qjrjtal0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 51
wandb:      train_f1 0.17541
wandb:    train_loss 3.78944
wandb: training_time 1.4268
wandb:        val_f1 0.17178
wandb:      val_loss 3.79194
wandb: 
wandb: Synced ruby-sweep-58: https://wandb.ai/jah377/sffSHA_products/runs/qjrjtal0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_233936-qjrjtal0/logs
2022-06-19 23:42:31,446 - wandb.wandb_agent - INFO - Cleaning up finished run: qjrjtal0
2022-06-19 23:42:32,096 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:42:32,097 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-19 23:42:32,107 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 23:42:37,118 - wandb.wandb_agent - INFO - Running runs: ['t4s2zjl8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_234237-t4s2zjl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-59
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/t4s2zjl8
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.02607
wandb:    train_loss 3.85865
wandb: training_time 1.44161
wandb:        val_f1 0.02556
wandb:      val_loss 3.85716
wandb: 
wandb: Synced flowing-sweep-59: https://wandb.ai/jah377/sffSHA_products/runs/t4s2zjl8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_234237-t4s2zjl8/logs
2022-06-19 23:58:42,744 - wandb.wandb_agent - INFO - Cleaning up finished run: t4s2zjl8
2022-06-19 23:58:43,150 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:58:43,150 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-19 23:58:43,154 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 23:58:48,166 - wandb.wandb_agent - INFO - Running runs: ['w1caqswe']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220619_235848-w1caqswe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-60
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/w1caqswe
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36829
wandb:    train_loss 3.56265
wandb: training_time 2.52023
wandb:        val_f1 0.37477
wandb:      val_loss 3.54215
wandb: 
wandb: Synced grateful-sweep-60: https://wandb.ai/jah377/sffSHA_products/runs/w1caqswe
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_235848-w1caqswe/logs
2022-06-20 00:20:06,564 - wandb.wandb_agent - INFO - Cleaning up finished run: w1caqswe
2022-06-20 00:20:09,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:20:09,878 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-20 00:20:09,886 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 00:20:14,899 - wandb.wandb_agent - INFO - Running runs: ['bxsgwq3m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_002015-bxsgwq3m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-61
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/bxsgwq3m
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.18461
wandb:    train_loss 3.6891
wandb: training_time 1.71003
wandb:        val_f1 0.18386
wandb:      val_loss 3.69419
wandb: 
wandb: Synced trim-sweep-61: https://wandb.ai/jah377/sffSHA_products/runs/bxsgwq3m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_002015-bxsgwq3m/logs
2022-06-20 00:39:03,061 - wandb.wandb_agent - INFO - Cleaning up finished run: bxsgwq3m
2022-06-20 00:39:03,648 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:39:03,648 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-20 00:39:03,657 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 00:39:08,671 - wandb.wandb_agent - INFO - Running runs: ['fucp79mr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_003908-fucp79mr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-62
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/fucp79mr
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39113
wandb:    train_loss 3.28388
wandb: training_time 1.49966
wandb:        val_f1 0.38288
wandb:      val_loss 3.2992
wandb: 
wandb: Synced woven-sweep-62: https://wandb.ai/jah377/sffSHA_products/runs/fucp79mr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_003908-fucp79mr/logs
2022-06-20 00:55:48,928 - wandb.wandb_agent - INFO - Cleaning up finished run: fucp79mr
2022-06-20 00:55:49,390 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:55:49,391 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 00:55:49,399 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 00:55:54,410 - wandb.wandb_agent - INFO - Running runs: ['b3taojww']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_005554-b3taojww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-63
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/b3taojww
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.03484
wandb:    train_loss 3.82582
wandb: training_time 1.79056
wandb:        val_f1 0.03425
wandb:      val_loss 3.82445
wandb: 
wandb: Synced classic-sweep-63: https://wandb.ai/jah377/sffSHA_products/runs/b3taojww
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_005554-b3taojww/logs
2022-06-20 01:15:09,590 - wandb.wandb_agent - INFO - Cleaning up finished run: b3taojww
2022-06-20 01:15:12,980 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:15:12,981 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 01:15:12,988 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 01:15:18,002 - wandb.wandb_agent - INFO - Running runs: ['56qp5jtp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_011518-56qp5jtp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-64
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/56qp5jtp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30836
wandb:    train_loss 3.74281
wandb: training_time 2.03405
wandb:        val_f1 0.30834
wandb:      val_loss 3.74278
wandb: 
wandb: Synced playful-sweep-64: https://wandb.ai/jah377/sffSHA_products/runs/56qp5jtp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_011518-56qp5jtp/logs
2022-06-20 01:35:18,263 - wandb.wandb_agent - INFO - Cleaning up finished run: 56qp5jtp
2022-06-20 01:35:19,023 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:35:19,023 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 01:35:19,030 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 01:35:24,045 - wandb.wandb_agent - INFO - Running runs: ['n1naf0e4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_013524-n1naf0e4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-65
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/n1naf0e4
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.34566
wandb:    train_loss 2.65077
wandb: training_time 2.08405
wandb:        val_f1 0.34245
wandb:      val_loss 2.66573
wandb: 
wandb: Synced ruby-sweep-65: https://wandb.ai/jah377/sffSHA_products/runs/n1naf0e4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_013524-n1naf0e4/logs
2022-06-20 01:56:06,771 - wandb.wandb_agent - INFO - Cleaning up finished run: n1naf0e4
2022-06-20 01:56:14,331 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:56:14,332 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-20 01:56:14,341 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 01:56:19,354 - wandb.wandb_agent - INFO - Running runs: ['ibsd9922']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_015619-ibsd9922
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-66
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ibsd9922
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.0428
wandb:    train_loss 3.85031
wandb: training_time 1.56243
wandb:        val_f1 0.04092
wandb:      val_loss 3.84839
wandb: 
wandb: Synced worldly-sweep-66: https://wandb.ai/jah377/sffSHA_products/runs/ibsd9922
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_015619-ibsd9922/logs
2022-06-20 02:14:05,646 - wandb.wandb_agent - INFO - Cleaning up finished run: ibsd9922
2022-06-20 02:14:06,300 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:14:06,300 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-20 02:14:06,308 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 02:14:11,322 - wandb.wandb_agent - INFO - Running runs: ['fmffvale']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_021411-fmffvale
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-67
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/fmffvale
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.25495
wandb:    train_loss 3.61655
wandb: training_time 1.72375
wandb:        val_f1 0.25166
wandb:      val_loss 3.6292
wandb: 
wandb: Synced glamorous-sweep-67: https://wandb.ai/jah377/sffSHA_products/runs/fmffvale
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_021411-fmffvale/logs
2022-06-20 02:30:34,930 - wandb.wandb_agent - INFO - Cleaning up finished run: fmffvale
2022-06-20 02:30:35,957 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:30:35,957 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 02:30:35,965 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 02:30:40,980 - wandb.wandb_agent - INFO - Running runs: ['zhivhdoc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_023041-zhivhdoc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-68
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/zhivhdoc
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51854
wandb:    train_loss 2.30804
wandb: training_time 2.06181
wandb:        val_f1 0.51957
wandb:      val_loss 2.30754
wandb: 
wandb: Synced brisk-sweep-68: https://wandb.ai/jah377/sffSHA_products/runs/zhivhdoc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_023041-zhivhdoc/logs
2022-06-20 02:51:12,845 - wandb.wandb_agent - INFO - Cleaning up finished run: zhivhdoc
2022-06-20 02:51:13,439 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:51:13,439 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 02:51:13,447 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 02:51:18,458 - wandb.wandb_agent - INFO - Running runs: ['ldt8108o']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_025118-ldt8108o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-69
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ldt8108o
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30836
wandb:    train_loss 3.55227
wandb: training_time 1.92764
wandb:        val_f1 0.30834
wandb:      val_loss 3.55511
wandb: 
wandb: Synced firm-sweep-69: https://wandb.ai/jah377/sffSHA_products/runs/ldt8108o
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_025118-ldt8108o/logs
2022-06-20 03:11:11,925 - wandb.wandb_agent - INFO - Cleaning up finished run: ldt8108o
2022-06-20 03:11:12,403 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:11:12,403 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-20 03:11:12,410 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 03:11:17,424 - wandb.wandb_agent - INFO - Running runs: ['fvbnrde9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_031117-fvbnrde9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-70
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/fvbnrde9
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.28702
wandb:    train_loss 3.35012
wandb: training_time 2.18811
wandb:        val_f1 0.28139
wandb:      val_loss 3.3618
wandb: 
wandb: Synced vocal-sweep-70: https://wandb.ai/jah377/sffSHA_products/runs/fvbnrde9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_031117-fvbnrde9/logs
2022-06-20 03:32:49,076 - wandb.wandb_agent - INFO - Cleaning up finished run: fvbnrde9
2022-06-20 03:32:49,501 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:32:49,502 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-20 03:32:49,508 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 03:32:54,522 - wandb.wandb_agent - INFO - Running runs: ['o3xdrotp']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_033253-o3xdrotp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-71
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/o3xdrotp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.24995
wandb:    train_loss 3.43528
wandb: training_time 1.89787
wandb:        val_f1 0.2482
wandb:      val_loss 3.4427
wandb: 
wandb: Synced light-sweep-71: https://wandb.ai/jah377/sffSHA_products/runs/o3xdrotp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_033253-o3xdrotp/logs
2022-06-20 03:53:20,627 - wandb.wandb_agent - INFO - Cleaning up finished run: o3xdrotp
2022-06-20 03:53:21,155 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:53:21,155 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-20 03:53:21,165 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 03:53:26,178 - wandb.wandb_agent - INFO - Running runs: ['cr8e274b']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_035325-cr8e274b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-72
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/cr8e274b
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.02305
wandb:    train_loss 3.82952
wandb: training_time 1.29058
wandb:        val_f1 0.02052
wandb:      val_loss 3.83179
wandb: 
wandb: Synced absurd-sweep-72: https://wandb.ai/jah377/sffSHA_products/runs/cr8e274b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_035325-cr8e274b/logs
2022-06-20 04:08:28,370 - wandb.wandb_agent - INFO - Cleaning up finished run: cr8e274b
2022-06-20 04:08:28,916 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:08:28,917 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-20 04:08:28,924 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 04:08:33,938 - wandb.wandb_agent - INFO - Running runs: ['x3wnf2n3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_040834-x3wnf2n3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-73
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/x3wnf2n3
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65078
wandb:    train_loss 1.24096
wandb: training_time 1.62795
wandb:        val_f1 0.64614
wandb:      val_loss 1.26923
wandb: 
wandb: Synced divine-sweep-73: https://wandb.ai/jah377/sffSHA_products/runs/x3wnf2n3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_040834-x3wnf2n3/logs
2022-06-20 04:24:51,389 - wandb.wandb_agent - INFO - Cleaning up finished run: x3wnf2n3
2022-06-20 04:24:51,842 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:24:51,842 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-20 04:24:51,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 04:24:56,863 - wandb.wandb_agent - INFO - Running runs: ['ko4954hz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_042457-ko4954hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-74
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/ko4954hz
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1001
wandb:    train_loss 3.86562
wandb: training_time 1.52388
wandb:        val_f1 0.10007
wandb:      val_loss 3.8682
wandb: 
wandb: Synced ethereal-sweep-74: https://wandb.ai/jah377/sffSHA_products/runs/ko4954hz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_042457-ko4954hz/logs
2022-06-20 04:41:36,542 - wandb.wandb_agent - INFO - Cleaning up finished run: ko4954hz
2022-06-20 04:41:44,234 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:41:44,234 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-20 04:41:44,243 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 04:41:49,256 - wandb.wandb_agent - INFO - Running runs: ['jxcr5zjq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_044149-jxcr5zjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-75
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/jxcr5zjq
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.02158
wandb:    train_loss 3.82505
wandb: training_time 1.4772
wandb:        val_f1 0.02055
wandb:      val_loss 3.82586
wandb: 
wandb: Synced dulcet-sweep-75: https://wandb.ai/jah377/sffSHA_products/runs/jxcr5zjq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_044149-jxcr5zjq/logs
2022-06-20 04:58:24,168 - wandb.wandb_agent - INFO - Cleaning up finished run: jxcr5zjq
2022-06-20 04:58:24,594 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:58:24,595 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-20 04:58:24,603 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 04:58:29,614 - wandb.wandb_agent - INFO - Running runs: ['4qrby7tk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_045829-4qrby7tk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-76
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/4qrby7tk
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38574
wandb:    train_loss 3.36391
wandb: training_time 2.64008
wandb:        val_f1 0.38341
wandb:      val_loss 3.37936
wandb: 
wandb: Synced rosy-sweep-76: https://wandb.ai/jah377/sffSHA_products/runs/4qrby7tk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_045829-4qrby7tk/logs
2022-06-20 05:23:20,819 - wandb.wandb_agent - INFO - Cleaning up finished run: 4qrby7tk
2022-06-20 05:23:21,803 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:23:21,804 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-20 05:23:21,811 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 05:23:26,822 - wandb.wandb_agent - INFO - Running runs: ['uhoetjgx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_052327-uhoetjgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-77
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/uhoetjgx
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.32565
wandb:    train_loss 3.22456
wandb: training_time 2.15599
wandb:        val_f1 0.32353
wandb:      val_loss 3.23553
wandb: 
wandb: Synced clear-sweep-77: https://wandb.ai/jah377/sffSHA_products/runs/uhoetjgx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_052327-uhoetjgx/logs
2022-06-20 05:43:33,885 - wandb.wandb_agent - INFO - Cleaning up finished run: uhoetjgx
2022-06-20 05:43:34,656 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:43:34,656 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-20 05:43:34,663 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 05:43:39,674 - wandb.wandb_agent - INFO - Running runs: ['9bo9njmp']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_054338-9bo9njmp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-78
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/9bo9njmp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88772
wandb:    train_loss 0.39066
wandb: training_time 2.65091
wandb:        val_f1 0.87308
wandb:      val_loss 0.47031
wandb: 
wandb: Synced crisp-sweep-78: https://wandb.ai/jah377/sffSHA_products/runs/9bo9njmp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_054338-9bo9njmp/logs
2022-06-20 06:08:18,616 - wandb.wandb_agent - INFO - Cleaning up finished run: 9bo9njmp
2022-06-20 06:08:19,111 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:08:19,111 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-20 06:08:19,118 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 06:08:24,133 - wandb.wandb_agent - INFO - Running runs: ['vef9boj0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_060824-vef9boj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-79
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/vef9boj0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26971
wandb:    train_loss 3.55391
wandb: training_time 2.17589
wandb:        val_f1 0.27561
wandb:      val_loss 3.55457
wandb: 
wandb: Synced hopeful-sweep-79: https://wandb.ai/jah377/sffSHA_products/runs/vef9boj0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_060824-vef9boj0/logs
2022-06-20 06:28:06,595 - wandb.wandb_agent - INFO - Cleaning up finished run: vef9boj0
2022-06-20 06:28:08,586 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:28:08,586 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-20 06:28:08,594 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 06:28:13,608 - wandb.wandb_agent - INFO - Running runs: ['mywllsnv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_062813-mywllsnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-80
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/mywllsnv
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40129
wandb:    train_loss 3.26226
wandb: training_time 2.1435
wandb:        val_f1 0.39806
wandb:      val_loss 3.2837
wandb: 
wandb: Synced flowing-sweep-80: https://wandb.ai/jah377/sffSHA_products/runs/mywllsnv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_062813-mywllsnv/logs
2022-06-20 06:49:25,392 - wandb.wandb_agent - INFO - Cleaning up finished run: mywllsnv
2022-06-20 06:49:25,919 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:49:25,919 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-20 06:49:25,926 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 06:49:30,938 - wandb.wandb_agent - INFO - Running runs: ['sbyysi6b']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_064929-sbyysi6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-81
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/sbyysi6b
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.28159
wandb:    train_loss 3.6123
wandb: training_time 2.08697
wandb:        val_f1 0.28126
wandb:      val_loss 3.62232
wandb: 
wandb: Synced rich-sweep-81: https://wandb.ai/jah377/sffSHA_products/runs/sbyysi6b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_064929-sbyysi6b/logs
2022-06-20 07:10:29,116 - wandb.wandb_agent - INFO - Cleaning up finished run: sbyysi6b
2022-06-20 07:10:29,596 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:10:29,596 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-20 07:10:29,601 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 07:10:34,614 - wandb.wandb_agent - INFO - Running runs: ['uh8ukgyp']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_071034-uh8ukgyp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-82
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/uh8ukgyp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.02096
wandb:    train_loss 3.82515
wandb: training_time 1.38583
wandb:        val_f1 0.02294
wandb:      val_loss 3.82538
wandb: 
wandb: Synced solar-sweep-82: https://wandb.ai/jah377/sffSHA_products/runs/uh8ukgyp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_071034-uh8ukgyp/logs
2022-06-20 07:26:13,402 - wandb.wandb_agent - INFO - Cleaning up finished run: uh8ukgyp
2022-06-20 07:26:13,887 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:26:13,887 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-20 07:26:13,895 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 07:26:18,909 - wandb.wandb_agent - INFO - Running runs: ['wqmp3hdz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_072619-wqmp3hdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-83
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/wqmp3hdz
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.29978
wandb:    train_loss 3.55577
wandb: training_time 2.09395
wandb:        val_f1 0.29794
wandb:      val_loss 3.55475
wandb: 
wandb: Synced super-sweep-83: https://wandb.ai/jah377/sffSHA_products/runs/wqmp3hdz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_072619-wqmp3hdz/logs
2022-06-20 07:47:48,466 - wandb.wandb_agent - INFO - Cleaning up finished run: wqmp3hdz
2022-06-20 07:47:51,297 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:47:51,298 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-20 07:47:51,305 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 07:47:56,318 - wandb.wandb_agent - INFO - Running runs: ['cuaz6h14']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_074756-cuaz6h14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-84
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/cuaz6h14
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.16338
wandb:    train_loss 3.52487
wandb: training_time 2.35787
wandb:        val_f1 0.16443
wandb:      val_loss 3.52494
wandb: 
wandb: Synced kind-sweep-84: https://wandb.ai/jah377/sffSHA_products/runs/cuaz6h14
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_074756-cuaz6h14/logs
2022-06-20 08:10:27,700 - wandb.wandb_agent - INFO - Cleaning up finished run: cuaz6h14
2022-06-20 08:10:33,108 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:10:33,108 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 08:10:33,117 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 08:10:38,131 - wandb.wandb_agent - INFO - Running runs: ['7t2wxry8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_081038-7t2wxry8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-85
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/7t2wxry8
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.01293
wandb:    train_loss 3.88863
wandb: training_time 1.74878
wandb:        val_f1 0.01396
wandb:      val_loss 3.88684
wandb: 
wandb: Synced glamorous-sweep-85: https://wandb.ai/jah377/sffSHA_products/runs/7t2wxry8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_081038-7t2wxry8/logs
2022-06-20 08:29:17,947 - wandb.wandb_agent - INFO - Cleaning up finished run: 7t2wxry8
2022-06-20 08:29:18,411 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:29:18,411 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 08:29:18,418 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 08:29:23,431 - wandb.wandb_agent - INFO - Running runs: ['srpfqt8l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_082923-srpfqt8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-86
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/srpfqt8l
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04781
wandb:    train_loss 3.83125
wandb: training_time 1.56729
wandb:        val_f1 0.05017
wandb:      val_loss 3.83074
wandb: 
wandb: Synced leafy-sweep-86: https://wandb.ai/jah377/sffSHA_products/runs/srpfqt8l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_082923-srpfqt8l/logs
2022-06-20 08:46:21,630 - wandb.wandb_agent - INFO - Cleaning up finished run: srpfqt8l
2022-06-20 08:46:22,121 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:46:22,121 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-20 08:46:22,129 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 08:46:27,142 - wandb.wandb_agent - INFO - Running runs: ['t73bs6xh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_084627-t73bs6xh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-87
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/t73bs6xh
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.77352
wandb:    train_loss 0.80466
wandb: training_time 2.12972
wandb:        val_f1 0.7771
wandb:      val_loss 0.81482
wandb: 
wandb: Synced iconic-sweep-87: https://wandb.ai/jah377/sffSHA_products/runs/t73bs6xh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_084627-t73bs6xh/logs
2022-06-20 09:07:21,653 - wandb.wandb_agent - INFO - Cleaning up finished run: t73bs6xh
2022-06-20 09:07:22,118 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:07:22,119 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-20 09:07:22,125 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 09:07:27,139 - wandb.wandb_agent - INFO - Running runs: ['wg3bjvjl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_090727-wg3bjvjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-88
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/wg3bjvjl
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30836
wandb:    train_loss 2.53421
wandb: training_time 2.56076
wandb:        val_f1 0.30834
wandb:      val_loss 2.53504
wandb: 
wandb: Synced apricot-sweep-88: https://wandb.ai/jah377/sffSHA_products/runs/wg3bjvjl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_090727-wg3bjvjl/logs
2022-06-20 09:30:35,450 - wandb.wandb_agent - INFO - Cleaning up finished run: wg3bjvjl
2022-06-20 09:30:35,915 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:30:35,915 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-20 09:30:35,922 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 09:30:40,936 - wandb.wandb_agent - INFO - Running runs: ['uicslt2e']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_093041-uicslt2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-89
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/uicslt2e
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65814
wandb:    train_loss 1.23773
wandb: training_time 3.16059
wandb:        val_f1 0.65483
wandb:      val_loss 1.26578
wandb: 
wandb: Synced hardy-sweep-89: https://wandb.ai/jah377/sffSHA_products/runs/uicslt2e
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_093041-uicslt2e/logs
2022-06-20 09:58:58,776 - wandb.wandb_agent - INFO - Cleaning up finished run: uicslt2e
2022-06-20 09:58:59,288 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:58:59,289 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-20 09:58:59,297 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 09:59:04,311 - wandb.wandb_agent - INFO - Running runs: ['tsb56tft']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_095904-tsb56tft
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-90
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/tsb56tft
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56531
wandb:    train_loss 1.78187
wandb: training_time 1.87545
wandb:        val_f1 0.56486
wandb:      val_loss 1.80516
wandb: 
wandb: Synced blooming-sweep-90: https://wandb.ai/jah377/sffSHA_products/runs/tsb56tft
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_095904-tsb56tft/logs
2022-06-20 10:18:51,926 - wandb.wandb_agent - INFO - Cleaning up finished run: tsb56tft
2022-06-20 10:18:52,834 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 10:18:52,834 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-20 10:18:52,842 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 10:18:57,856 - wandb.wandb_agent - INFO - Running runs: ['2mxtllbu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_101857-2mxtllbu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-91
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/2mxtllbu
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.41533
wandb:    train_loss 1.99012
wandb: training_time 2.12408
wandb:        val_f1 0.40872
wandb:      val_loss 2.01269
wandb: 
wandb: Synced rare-sweep-91: https://wandb.ai/jah377/sffSHA_products/runs/2mxtllbu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_101857-2mxtllbu/logs
2022-06-20 10:40:34,913 - wandb.wandb_agent - INFO - Cleaning up finished run: 2mxtllbu
2022-06-20 10:40:35,344 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 10:40:35,344 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-20 10:40:35,352 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 10:40:40,366 - wandb.wandb_agent - INFO - Running runs: ['i788ja67']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_104040-i788ja67
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-92
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/i788ja67
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.10741
wandb:    train_loss 3.78412
wandb: training_time 2.17674
wandb:        val_f1 0.10493
wandb:      val_loss 3.78614
wandb: 
wandb: Synced giddy-sweep-92: https://wandb.ai/jah377/sffSHA_products/runs/i788ja67
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_104040-i788ja67/logs
2022-06-20 11:02:23,717 - wandb.wandb_agent - INFO - Cleaning up finished run: i788ja67
2022-06-20 11:02:24,543 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 11:02:24,543 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 11:02:24,549 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 11:02:29,562 - wandb.wandb_agent - INFO - Running runs: ['c5s6mi2p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_110229-c5s6mi2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-93
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/c5s6mi2p
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30836
wandb:    train_loss 3.74281
wandb: training_time 2.40072
wandb:        val_f1 0.30834
wandb:      val_loss 3.74278
wandb: 
wandb: Synced serene-sweep-93: https://wandb.ai/jah377/sffSHA_products/runs/c5s6mi2p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_110229-c5s6mi2p/logs
2022-06-20 11:25:28,819 - wandb.wandb_agent - INFO - Cleaning up finished run: c5s6mi2p
2022-06-20 11:25:29,670 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 11:25:29,670 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 11:25:29,677 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 11:25:34,690 - wandb.wandb_agent - INFO - Running runs: ['faxs1eav']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_112534-faxs1eav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-94
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/faxs1eav
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.01203
wandb:    train_loss 3.84737
wandb: training_time 1.38522
wandb:        val_f1 0.01167
wandb:      val_loss 3.84631
wandb: 
wandb: Synced whole-sweep-94: https://wandb.ai/jah377/sffSHA_products/runs/faxs1eav
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_112534-faxs1eav/logs
2022-06-20 11:40:52,654 - wandb.wandb_agent - INFO - Cleaning up finished run: faxs1eav
2022-06-20 11:40:53,300 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 11:40:53,300 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-20 11:40:53,308 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 11:40:58,323 - wandb.wandb_agent - INFO - Running runs: ['qrma4q53']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_114058-qrma4q53
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-95
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/qrma4q53
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36356
wandb:    train_loss 3.12652
wandb: training_time 2.4414
wandb:        val_f1 0.36638
wandb:      val_loss 3.134
wandb: 
wandb: Synced mild-sweep-95: https://wandb.ai/jah377/sffSHA_products/runs/qrma4q53
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_114058-qrma4q53/logs
2022-06-20 12:04:11,938 - wandb.wandb_agent - INFO - Cleaning up finished run: qrma4q53
2022-06-20 12:04:12,591 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 12:04:12,592 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-20 12:04:12,598 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 12:04:17,612 - wandb.wandb_agent - INFO - Running runs: ['2giuqk2p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_120417-2giuqk2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-96
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/2giuqk2p
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.35291
wandb:    train_loss 3.50181
wandb: training_time 2.69347
wandb:        val_f1 0.34814
wandb:      val_loss 3.51634
wandb: 
wandb: Synced quiet-sweep-96: https://wandb.ai/jah377/sffSHA_products/runs/2giuqk2p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_120417-2giuqk2p/logs
2022-06-20 12:30:03,801 - wandb.wandb_agent - INFO - Cleaning up finished run: 2giuqk2p
2022-06-20 12:30:04,368 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 12:30:04,368 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-20 12:30:04,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 12:30:09,390 - wandb.wandb_agent - INFO - Running runs: ['t05ecdfx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_123009-t05ecdfx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-97
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/t05ecdfx
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/products_k3_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36746
wandb:    train_loss 2.88907
wandb: training_time 2.33655
wandb:        val_f1 0.36213
wandb:      val_loss 2.90105
wandb: 
wandb: Synced twilight-sweep-97: https://wandb.ai/jah377/sffSHA_products/runs/t05ecdfx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_123009-t05ecdfx/logs
2022-06-20 19:30:51,802 - wandb.wandb_agent - INFO - Cleaning up finished run: t05ecdfx
2022-06-20 19:30:52,471 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 19:30:52,471 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-20 19:30:52,480 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 19:30:57,494 - wandb.wandb_agent - INFO - Running runs: ['zakons82']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_193058-zakons82
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-98
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/zakons82
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04755
wandb:    train_loss 3.81964
wandb: training_time 1.58788
wandb:        val_f1 0.05081
wandb:      val_loss 3.82033
wandb: 
wandb: Synced scarlet-sweep-98: https://wandb.ai/jah377/sffSHA_products/runs/zakons82
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_193058-zakons82/logs
2022-06-20 19:48:19,389 - wandb.wandb_agent - INFO - Cleaning up finished run: zakons82
2022-06-20 19:48:19,868 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 19:48:19,869 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-20 19:48:19,876 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 19:48:24,890 - wandb.wandb_agent - INFO - Running runs: ['sclrug6v']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_194824-sclrug6v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-99
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/sclrug6v
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.33571
wandb:    train_loss 3.41499
wandb: training_time 1.62339
wandb:        val_f1 0.33634
wandb:      val_loss 3.42973
wandb: 
wandb: Synced gallant-sweep-99: https://wandb.ai/jah377/sffSHA_products/runs/sclrug6v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_194824-sclrug6v/logs
2022-06-20 20:05:00,075 - wandb.wandb_agent - INFO - Cleaning up finished run: sclrug6v
2022-06-20 20:05:00,829 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 20:05:00,829 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-20 20:05:00,836 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 20:05:05,846 - wandb.wandb_agent - INFO - Running runs: ['942q6icp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_products/wandb/run-20220620_200505-942q6icp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-100
wandb:  View project at https://wandb.ai/jah377/sffSHA_products
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb:  View run at https://wandb.ai/jah377/sffSHA_products/runs/942q6icp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.84301
wandb:    train_loss 0.56565
wandb: training_time 2.22972
wandb:        val_f1 0.8419
wandb:      val_loss 0.59575
wandb: 
wandb: Synced light-sweep-100: https://wandb.ai/jah377/sffSHA_products/runs/942q6icp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_200505-942q6icp/logs
2022-06-20 20:26:45,041 - wandb.wandb_agent - INFO - Cleaning up finished run: 942q6icp
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: 1hf2wnuh
Sweep URL: https://wandb.ai/jah377/sffSHA_products/sweeps/1hf2wnuh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: - 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: \ 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: | 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: / 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: - 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: \ 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: | 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: / 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: - 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced bright-spaceship-15: https://wandb.ai/jah377/sffSHA_products/runs/17zuqu9j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_043652-17zuqu9j/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 111 hours 51 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
