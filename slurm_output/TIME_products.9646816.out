Sun 26 Jun 2022 10:52:04 AM CEST
r32n1.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
================= SIGN ===========================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='sign', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=True, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0048
Epoch 10:, Train 0.9375, Val 0.9162, Test 0.7204
Epoch 20:, Train 0.9432, Val 0.9214, Test 0.7509
Epoch 30:, Train 0.9405, Val 0.9180, Test 0.7228
Epoch 40:, Train 0.9409, Val 0.9194, Test 0.7229
Epoch 50:, Train 0.9438, Val 0.9218, Test 0.7508
Epoch 60:, Train 0.9440, Val 0.9190, Test 0.7410
Epoch 70:, Train 0.9443, Val 0.9205, Test 0.7575
Epoch 80:, Train 0.9449, Val 0.9198, Test 0.7236
Epoch 90:, Train 0.9457, Val 0.9221, Test 0.7332
Epoch 100:, Train 0.9402, Val 0.9180, Test 0.7304
Epoch 110:, Train 0.9452, Val 0.9207, Test 0.7470
Epoch 120:, Train 0.9452, Val 0.9209, Test 0.7509
Epoch 130:, Train 0.9449, Val 0.9202, Test 0.7382
Epoch 140:, Train 0.9466, Val 0.9212, Test 0.7405
Epoch 150:, Train 0.9478, Val 0.9223, Test 0.7395
Epoch 160:, Train 0.9470, Val 0.9237, Test 0.7449
Epoch 170:, Train 0.9481, Val 0.9234, Test 0.7453
Epoch 180:, Train 0.9473, Val 0.9216, Test 0.7478
Epoch 190:, Train 0.9489, Val 0.9234, Test 0.7525
Epoch 200:, Train 0.9478, Val 0.9211, Test 0.7491
Epoch 210:, Train 0.9490, Val 0.9222, Test 0.7478
Epoch 220:, Train 0.9495, Val 0.9243, Test 0.7558
Epoch 230:, Train 0.9504, Val 0.9230, Test 0.7561
Epoch 240:, Train 0.9491, Val 0.9243, Test 0.7489
Epoch 250:, Train 0.9495, Val 0.9238, Test 0.7478
Epoch 260:, Train 0.9497, Val 0.9236, Test 0.7499
Epoch 270:, Train 0.9489, Val 0.9235, Test 0.7492
Epoch 280:, Train 0.9512, Val 0.9235, Test 0.7364
Epoch 290:, Train 0.9507, Val 0.9254, Test 0.7569
Epoch 300:, Train 0.9492, Val 0.9216, Test 0.7440
BEST: Epoch 290, Train 0.9507, Val 0.9254, Test 0.7569

RUN #1: seed=4
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 108.0976
Epoch 10:, Train 0.9357, Val 0.9171, Test 0.7515
Epoch 20:, Train 0.9403, Val 0.9191, Test 0.7404
Epoch 30:, Train 0.9429, Val 0.9213, Test 0.7295
Epoch 40:, Train 0.9434, Val 0.9204, Test 0.7352
Epoch 50:, Train 0.9441, Val 0.9206, Test 0.7538
Epoch 60:, Train 0.9442, Val 0.9180, Test 0.7263
Epoch 70:, Train 0.9426, Val 0.9198, Test 0.7539
Epoch 80:, Train 0.9448, Val 0.9208, Test 0.7354
Epoch 90:, Train 0.9445, Val 0.9198, Test 0.7191
Epoch 100:, Train 0.9431, Val 0.9194, Test 0.7405
Epoch 110:, Train 0.9462, Val 0.9236, Test 0.7403
Epoch 120:, Train 0.9449, Val 0.9214, Test 0.7493
Epoch 130:, Train 0.9464, Val 0.9226, Test 0.7635
Epoch 140:, Train 0.9475, Val 0.9226, Test 0.7488
Epoch 150:, Train 0.9472, Val 0.9231, Test 0.7466
Epoch 160:, Train 0.9476, Val 0.9227, Test 0.7527
Epoch 170:, Train 0.9485, Val 0.9236, Test 0.7690
Epoch 180:, Train 0.9449, Val 0.9219, Test 0.7597
Epoch 190:, Train 0.9485, Val 0.9227, Test 0.7402
Epoch 200:, Train 0.9484, Val 0.9244, Test 0.7498
Epoch 210:, Train 0.9486, Val 0.9246, Test 0.7543
Epoch 220:, Train 0.9431, Val 0.9176, Test 0.7372
Epoch 230:, Train 0.9490, Val 0.9232, Test 0.7511
Epoch 240:, Train 0.9481, Val 0.9216, Test 0.7537
Epoch 250:, Train 0.9501, Val 0.9232, Test 0.7439
Epoch 260:, Train 0.9486, Val 0.9238, Test 0.7401
Epoch 270:, Train 0.9504, Val 0.9246, Test 0.7565
Epoch 280:, Train 0.9506, Val 0.9239, Test 0.7527
Epoch 290:, Train 0.9513, Val 0.9253, Test 0.7547
Epoch 300:, Train 0.9493, Val 0.9235, Test 0.7437
BEST: Epoch 290, Train 0.9513, Val 0.9253, Test 0.7547

RUN #2: seed=8
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0229
Epoch 10:, Train 0.9388, Val 0.9190, Test 0.7217
Epoch 20:, Train 0.9326, Val 0.9083, Test 0.7123
Epoch 30:, Train 0.9426, Val 0.9217, Test 0.7463
Epoch 40:, Train 0.9429, Val 0.9197, Test 0.7477
Epoch 50:, Train 0.9433, Val 0.9213, Test 0.7433
Epoch 60:, Train 0.9436, Val 0.9190, Test 0.7442
Epoch 70:, Train 0.9437, Val 0.9205, Test 0.7365
Epoch 80:, Train 0.9427, Val 0.9196, Test 0.7312
Epoch 90:, Train 0.9458, Val 0.9205, Test 0.7349
Epoch 100:, Train 0.9440, Val 0.9189, Test 0.7197
Epoch 110:, Train 0.9458, Val 0.9216, Test 0.7389
Epoch 120:, Train 0.9469, Val 0.9226, Test 0.7505
Epoch 130:, Train 0.9467, Val 0.9231, Test 0.7550
Epoch 140:, Train 0.9469, Val 0.9216, Test 0.7461
Epoch 150:, Train 0.9474, Val 0.9234, Test 0.7514
Epoch 160:, Train 0.9462, Val 0.9228, Test 0.7490
Epoch 170:, Train 0.9496, Val 0.9220, Test 0.7475
Epoch 180:, Train 0.9474, Val 0.9213, Test 0.7479
Epoch 190:, Train 0.9485, Val 0.9224, Test 0.7469
Epoch 200:, Train 0.9494, Val 0.9247, Test 0.7633
Epoch 210:, Train 0.9480, Val 0.9232, Test 0.7510
Epoch 220:, Train 0.9501, Val 0.9250, Test 0.7501
Epoch 230:, Train 0.9484, Val 0.9224, Test 0.7398
Epoch 240:, Train 0.9498, Val 0.9242, Test 0.7494
Epoch 250:, Train 0.9496, Val 0.9251, Test 0.7508
Epoch 260:, Train 0.9513, Val 0.9248, Test 0.7516
Epoch 270:, Train 0.9506, Val 0.9245, Test 0.7566
Epoch 280:, Train 0.9483, Val 0.9233, Test 0.7549
Epoch 290:, Train 0.9508, Val 0.9248, Test 0.7535
Epoch 300:, Train 0.9510, Val 0.9252, Test 0.7592
BEST: Epoch 300, Train 0.9510, Val 0.9252, Test 0.7592

RUN #3: seed=42
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0204
Epoch 10:, Train 0.9370, Val 0.9184, Test 0.7481
Epoch 20:, Train 0.9444, Val 0.9222, Test 0.7511
Epoch 30:, Train 0.9395, Val 0.9180, Test 0.7518
Epoch 40:, Train 0.9414, Val 0.9194, Test 0.7431
Epoch 50:, Train 0.9407, Val 0.9176, Test 0.7472
Epoch 60:, Train 0.9433, Val 0.9198, Test 0.7524
Epoch 70:, Train 0.9426, Val 0.9190, Test 0.7450
Epoch 80:, Train 0.9446, Val 0.9201, Test 0.7396
Epoch 90:, Train 0.9441, Val 0.9197, Test 0.7350
Epoch 100:, Train 0.9465, Val 0.9226, Test 0.7465
Epoch 110:, Train 0.9459, Val 0.9213, Test 0.7535
Epoch 120:, Train 0.9445, Val 0.9194, Test 0.7434
Epoch 130:, Train 0.9473, Val 0.9240, Test 0.7626
Epoch 140:, Train 0.9463, Val 0.9201, Test 0.7317
Epoch 150:, Train 0.9474, Val 0.9224, Test 0.7438
Epoch 160:, Train 0.9496, Val 0.9249, Test 0.7569
Epoch 170:, Train 0.9485, Val 0.9245, Test 0.7498
Epoch 180:, Train 0.9477, Val 0.9233, Test 0.7543
Epoch 190:, Train 0.9483, Val 0.9239, Test 0.7495
Epoch 200:, Train 0.9497, Val 0.9240, Test 0.7498
Epoch 210:, Train 0.9484, Val 0.9246, Test 0.7562
Epoch 220:, Train 0.9496, Val 0.9235, Test 0.7478
Epoch 230:, Train 0.9491, Val 0.9226, Test 0.7624
Epoch 240:, Train 0.9502, Val 0.9245, Test 0.7441
Epoch 250:, Train 0.9481, Val 0.9247, Test 0.7355
Epoch 260:, Train 0.9496, Val 0.9235, Test 0.7428
Epoch 270:, Train 0.9498, Val 0.9239, Test 0.7557
Epoch 280:, Train 0.9510, Val 0.9263, Test 0.7532
Epoch 290:, Train 0.9493, Val 0.9227, Test 0.7349
Epoch 300:, Train 0.9510, Val 0.9239, Test 0.7617
BEST: Epoch 280, Train 0.9510, Val 0.9263, Test 0.7532

RUN #4: seed=64
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 108.0793
Epoch 10:, Train 0.9376, Val 0.9177, Test 0.7392
Epoch 20:, Train 0.9397, Val 0.9173, Test 0.7176
Epoch 30:, Train 0.9379, Val 0.9144, Test 0.7280
Epoch 40:, Train 0.9452, Val 0.9228, Test 0.7449
Epoch 50:, Train 0.9409, Val 0.9178, Test 0.7352
Epoch 60:, Train 0.9427, Val 0.9196, Test 0.7480
Epoch 70:, Train 0.9442, Val 0.9216, Test 0.7411
Epoch 80:, Train 0.9446, Val 0.9207, Test 0.7432
Epoch 90:, Train 0.9449, Val 0.9221, Test 0.7492
Epoch 100:, Train 0.9468, Val 0.9198, Test 0.7280
Epoch 110:, Train 0.9458, Val 0.9205, Test 0.7369
Epoch 120:, Train 0.9436, Val 0.9178, Test 0.7446
Epoch 130:, Train 0.9456, Val 0.9219, Test 0.7601
Epoch 140:, Train 0.9454, Val 0.9188, Test 0.7505
Epoch 150:, Train 0.9458, Val 0.9218, Test 0.7412
Epoch 160:, Train 0.9482, Val 0.9237, Test 0.7589
Epoch 170:, Train 0.9471, Val 0.9212, Test 0.7494
Epoch 180:, Train 0.9482, Val 0.9200, Test 0.7456
Epoch 190:, Train 0.9485, Val 0.9240, Test 0.7614
Epoch 200:, Train 0.9484, Val 0.9227, Test 0.7446
Epoch 210:, Train 0.9489, Val 0.9222, Test 0.7451
Epoch 220:, Train 0.9491, Val 0.9250, Test 0.7517
Epoch 230:, Train 0.9487, Val 0.9220, Test 0.7512
Epoch 240:, Train 0.9502, Val 0.9254, Test 0.7459
Epoch 250:, Train 0.9494, Val 0.9251, Test 0.7456
Epoch 260:, Train 0.9484, Val 0.9237, Test 0.7601
Epoch 270:, Train 0.9501, Val 0.9220, Test 0.7420
Epoch 280:, Train 0.9518, Val 0.9255, Test 0.7567
Epoch 290:, Train 0.9495, Val 0.9229, Test 0.7450
Epoch 300:, Train 0.9499, Val 0.9250, Test 0.7610
BEST: Epoch 280, Train 0.9518, Val 0.9255, Test 0.7567

RUN #5: seed=128
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0007
Epoch 10:, Train 0.9381, Val 0.9190, Test 0.7352
Epoch 20:, Train 0.9428, Val 0.9216, Test 0.7445
Epoch 30:, Train 0.9434, Val 0.9218, Test 0.7425
Epoch 40:, Train 0.9428, Val 0.9215, Test 0.7393
Epoch 50:, Train 0.9447, Val 0.9200, Test 0.7382
Epoch 60:, Train 0.9428, Val 0.9216, Test 0.7481
Epoch 70:, Train 0.9428, Val 0.9200, Test 0.7298
Epoch 80:, Train 0.9441, Val 0.9224, Test 0.7485
Epoch 90:, Train 0.9467, Val 0.9213, Test 0.7449
Epoch 100:, Train 0.9439, Val 0.9209, Test 0.7470
Epoch 110:, Train 0.9460, Val 0.9226, Test 0.7526
Epoch 120:, Train 0.9449, Val 0.9192, Test 0.7361
Epoch 130:, Train 0.9469, Val 0.9213, Test 0.7600
Epoch 140:, Train 0.9469, Val 0.9233, Test 0.7561
Epoch 150:, Train 0.9460, Val 0.9211, Test 0.7537
Epoch 160:, Train 0.9491, Val 0.9228, Test 0.7470
Epoch 170:, Train 0.9479, Val 0.9231, Test 0.7448
Epoch 180:, Train 0.9496, Val 0.9232, Test 0.7581
Epoch 190:, Train 0.9494, Val 0.9235, Test 0.7487
Epoch 200:, Train 0.9487, Val 0.9214, Test 0.7369
Epoch 210:, Train 0.9503, Val 0.9238, Test 0.7490
Epoch 220:, Train 0.9495, Val 0.9231, Test 0.7406
Epoch 230:, Train 0.9489, Val 0.9230, Test 0.7494
Epoch 240:, Train 0.9513, Val 0.9244, Test 0.7524
Epoch 250:, Train 0.9489, Val 0.9225, Test 0.7502
Epoch 260:, Train 0.9509, Val 0.9247, Test 0.7485
Epoch 270:, Train 0.9487, Val 0.9223, Test 0.7338
Epoch 280:, Train 0.9501, Val 0.9224, Test 0.7450
Epoch 290:, Train 0.9512, Val 0.9236, Test 0.7544
Epoch 300:, Train 0.9492, Val 0.9239, Test 0.7491
BEST: Epoch 260, Train 0.9509, Val 0.9247, Test 0.7485

RUN #6: seed=256
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 108.7122
Epoch 10:, Train 0.9396, Val 0.9179, Test 0.7419
Epoch 20:, Train 0.9414, Val 0.9199, Test 0.7529
Epoch 30:, Train 0.9438, Val 0.9193, Test 0.7395
Epoch 40:, Train 0.9437, Val 0.9210, Test 0.7425
Epoch 50:, Train 0.9424, Val 0.9192, Test 0.7374
Epoch 60:, Train 0.9452, Val 0.9230, Test 0.7463
Epoch 70:, Train 0.9443, Val 0.9214, Test 0.7520
Epoch 80:, Train 0.9400, Val 0.9177, Test 0.7415
Epoch 90:, Train 0.9443, Val 0.9210, Test 0.7384
Epoch 100:, Train 0.9457, Val 0.9216, Test 0.7309
Epoch 110:, Train 0.9449, Val 0.9224, Test 0.7424
Epoch 120:, Train 0.9454, Val 0.9216, Test 0.7462
Epoch 130:, Train 0.9446, Val 0.9225, Test 0.7488
Epoch 140:, Train 0.9462, Val 0.9209, Test 0.7502
Epoch 150:, Train 0.9460, Val 0.9223, Test 0.7394
Epoch 160:, Train 0.9477, Val 0.9239, Test 0.7427
Epoch 170:, Train 0.9480, Val 0.9240, Test 0.7562
Epoch 180:, Train 0.9483, Val 0.9225, Test 0.7520
Epoch 190:, Train 0.9462, Val 0.9194, Test 0.7433
Epoch 200:, Train 0.9486, Val 0.9220, Test 0.7509
Epoch 210:, Train 0.9483, Val 0.9228, Test 0.7415
Epoch 220:, Train 0.9479, Val 0.9232, Test 0.7559
Epoch 230:, Train 0.9499, Val 0.9241, Test 0.7521
Epoch 240:, Train 0.9491, Val 0.9237, Test 0.7697
Epoch 250:, Train 0.9496, Val 0.9233, Test 0.7497
Epoch 260:, Train 0.9505, Val 0.9246, Test 0.7627
Epoch 270:, Train 0.9490, Val 0.9230, Test 0.7555
Epoch 280:, Train 0.9502, Val 0.9241, Test 0.7439
Epoch 290:, Train 0.9490, Val 0.9235, Test 0.7497
Epoch 300:, Train 0.9489, Val 0.9234, Test 0.7552
BEST: Epoch 260, Train 0.9505, Val 0.9246, Test 0.7627

RUN #7: seed=512
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0410
Epoch 10:, Train 0.9371, Val 0.9165, Test 0.7366
Epoch 20:, Train 0.9421, Val 0.9206, Test 0.7480
Epoch 30:, Train 0.9408, Val 0.9182, Test 0.7333
Epoch 40:, Train 0.9396, Val 0.9162, Test 0.7396
Epoch 50:, Train 0.9446, Val 0.9214, Test 0.7368
Epoch 60:, Train 0.9452, Val 0.9194, Test 0.7383
Epoch 70:, Train 0.9439, Val 0.9211, Test 0.7445
Epoch 80:, Train 0.9450, Val 0.9213, Test 0.7525
Epoch 90:, Train 0.9467, Val 0.9230, Test 0.7523
Epoch 100:, Train 0.9440, Val 0.9199, Test 0.7506
Epoch 110:, Train 0.9471, Val 0.9236, Test 0.7454
Epoch 120:, Train 0.9463, Val 0.9219, Test 0.7366
Epoch 130:, Train 0.9465, Val 0.9228, Test 0.7458
Epoch 140:, Train 0.9461, Val 0.9225, Test 0.7637
Epoch 150:, Train 0.9475, Val 0.9213, Test 0.7432
Epoch 160:, Train 0.9466, Val 0.9214, Test 0.7337
Epoch 170:, Train 0.9483, Val 0.9224, Test 0.7402
Epoch 180:, Train 0.9492, Val 0.9239, Test 0.7590
Epoch 190:, Train 0.9478, Val 0.9218, Test 0.7515
Epoch 200:, Train 0.9468, Val 0.9200, Test 0.7385
Epoch 210:, Train 0.9487, Val 0.9225, Test 0.7384
Epoch 220:, Train 0.9507, Val 0.9244, Test 0.7562
Epoch 230:, Train 0.9481, Val 0.9235, Test 0.7513
Epoch 240:, Train 0.9495, Val 0.9252, Test 0.7579
Epoch 250:, Train 0.9493, Val 0.9234, Test 0.7457
Epoch 260:, Train 0.9497, Val 0.9219, Test 0.7601
Epoch 270:, Train 0.9513, Val 0.9235, Test 0.7491
Epoch 280:, Train 0.9503, Val 0.9241, Test 0.7469
Epoch 290:, Train 0.9507, Val 0.9242, Test 0.7504
Epoch 300:, Train 0.9495, Val 0.9236, Test 0.7486
BEST: Epoch 240, Train 0.9495, Val 0.9252, Test 0.7579

RUN #8: seed=1024
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 108.3572
Epoch 10:, Train 0.9358, Val 0.9173, Test 0.7211
Epoch 20:, Train 0.9410, Val 0.9192, Test 0.7344
Epoch 30:, Train 0.9429, Val 0.9173, Test 0.7225
Epoch 40:, Train 0.9409, Val 0.9184, Test 0.7311
Epoch 50:, Train 0.9446, Val 0.9215, Test 0.7356
Epoch 60:, Train 0.9440, Val 0.9208, Test 0.7426
Epoch 70:, Train 0.9408, Val 0.9147, Test 0.7305
Epoch 80:, Train 0.9429, Val 0.9170, Test 0.7117
Epoch 90:, Train 0.9445, Val 0.9210, Test 0.7358
Epoch 100:, Train 0.9423, Val 0.9172, Test 0.7355
Epoch 110:, Train 0.9436, Val 0.9197, Test 0.7457
Epoch 120:, Train 0.9441, Val 0.9189, Test 0.7223
Epoch 130:, Train 0.9443, Val 0.9234, Test 0.7472
Epoch 140:, Train 0.9473, Val 0.9221, Test 0.7484
Epoch 150:, Train 0.9460, Val 0.9210, Test 0.7447
Epoch 160:, Train 0.9488, Val 0.9244, Test 0.7510
Epoch 170:, Train 0.9487, Val 0.9227, Test 0.7578
Epoch 180:, Train 0.9468, Val 0.9227, Test 0.7449
Epoch 190:, Train 0.9484, Val 0.9242, Test 0.7499
Epoch 200:, Train 0.9473, Val 0.9238, Test 0.7562
Epoch 210:, Train 0.9478, Val 0.9218, Test 0.7626
Epoch 220:, Train 0.9456, Val 0.9221, Test 0.7465
Epoch 230:, Train 0.9493, Val 0.9231, Test 0.7514
Epoch 240:, Train 0.9495, Val 0.9252, Test 0.7568
Epoch 250:, Train 0.9504, Val 0.9238, Test 0.7632
Epoch 260:, Train 0.9481, Val 0.9238, Test 0.7542
Epoch 270:, Train 0.9485, Val 0.9234, Test 0.7506
Epoch 280:, Train 0.9502, Val 0.9235, Test 0.7547
Epoch 290:, Train 0.9497, Val 0.9242, Test 0.7582
Epoch 300:, Train 0.9504, Val 0.9251, Test 0.7556
BEST: Epoch 240, Train 0.9495, Val 0.9252, Test 0.7568

RUN #9: seed=2048
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 108.1062
Epoch 10:, Train 0.9352, Val 0.9155, Test 0.7331
Epoch 20:, Train 0.9401, Val 0.9192, Test 0.7525
Epoch 30:, Train 0.9433, Val 0.9203, Test 0.7415
Epoch 40:, Train 0.9431, Val 0.9191, Test 0.7552
Epoch 50:, Train 0.9422, Val 0.9200, Test 0.7362
Epoch 60:, Train 0.9427, Val 0.9168, Test 0.7443
Epoch 70:, Train 0.9449, Val 0.9227, Test 0.7558
Epoch 80:, Train 0.9438, Val 0.9201, Test 0.7366
Epoch 90:, Train 0.9451, Val 0.9211, Test 0.7376
Epoch 100:, Train 0.9458, Val 0.9222, Test 0.7408
Epoch 110:, Train 0.9444, Val 0.9241, Test 0.7537
Epoch 120:, Train 0.9457, Val 0.9227, Test 0.7515
Epoch 130:, Train 0.9476, Val 0.9220, Test 0.7478
Epoch 140:, Train 0.9450, Val 0.9191, Test 0.7347
Epoch 150:, Train 0.9483, Val 0.9239, Test 0.7514
Epoch 160:, Train 0.9471, Val 0.9224, Test 0.7515
Epoch 170:, Train 0.9480, Val 0.9221, Test 0.7509
Epoch 180:, Train 0.9476, Val 0.9225, Test 0.7539
Epoch 190:, Train 0.9487, Val 0.9224, Test 0.7321
Epoch 200:, Train 0.9494, Val 0.9245, Test 0.7424
Epoch 210:, Train 0.9476, Val 0.9215, Test 0.7525
Epoch 220:, Train 0.9490, Val 0.9223, Test 0.7550
Epoch 230:, Train 0.9492, Val 0.9225, Test 0.7559
Epoch 240:, Train 0.9492, Val 0.9245, Test 0.7537
Epoch 250:, Train 0.9492, Val 0.9241, Test 0.7520
Epoch 260:, Train 0.9492, Val 0.9230, Test 0.7538
Epoch 270:, Train 0.9492, Val 0.9235, Test 0.7578
Epoch 280:, Train 0.9488, Val 0.9228, Test 0.7536
Epoch 290:, Train 0.9503, Val 0.9251, Test 0.7468
Epoch 300:, Train 0.9497, Val 0.9238, Test 0.7578
BEST: Epoch 290, Train 0.9503, Val 0.9251, Test 0.7468




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 0.0000 +/- 0.0000
Avg. Preaggregation Time (s): 108.6442 +/- 0.4116
Avg. Training Time (epoch) (s): 4.3142 +/- 0.0580
Avg. Inference Time (s): 1.3022 +/- 0.0173

Avg. Training Acc: 0.9507 +/- 0.0007
Avg. Validation Acc: 0.9252 +/- 0.0004
Avg. Test Acc: 0.7553 +/- 0.0045

==================================================

==================================================
================= SIGN+CS ========================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='cosine', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 1.86e-05
convert to csr_matrix: 2.637
calc min-max per row: 0.7383
vectorization: 1.728
Total Normalization: 6.5837
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 257.0457
Epoch 10:, Train 0.9212, Val 0.8954, Test 0.7205
Epoch 20:, Train 0.9213, Val 0.8974, Test 0.7205
Epoch 30:, Train 0.9296, Val 0.9049, Test 0.7465
Epoch 40:, Train 0.9279, Val 0.9031, Test 0.7380
Epoch 50:, Train 0.9283, Val 0.9012, Test 0.7364
Epoch 60:, Train 0.9309, Val 0.9058, Test 0.7431
Epoch 70:, Train 0.9318, Val 0.9047, Test 0.7301
Epoch 80:, Train 0.9325, Val 0.9047, Test 0.7384
Epoch 90:, Train 0.9323, Val 0.9065, Test 0.7432
Epoch 100:, Train 0.9291, Val 0.9034, Test 0.7295
Epoch 110:, Train 0.9342, Val 0.9078, Test 0.7597
Epoch 120:, Train 0.9339, Val 0.9083, Test 0.7533
Epoch 130:, Train 0.9332, Val 0.9068, Test 0.7564
Epoch 140:, Train 0.9333, Val 0.9073, Test 0.7422
Epoch 150:, Train 0.9341, Val 0.9088, Test 0.7578
Epoch 160:, Train 0.9298, Val 0.9007, Test 0.7407
Epoch 170:, Train 0.7857, Val 0.7616, Test 0.5817
Epoch 180:, Train 0.9284, Val 0.9005, Test 0.7443
Epoch 190:, Train 0.9336, Val 0.9051, Test 0.7378
Epoch 200:, Train 0.9340, Val 0.9090, Test 0.7477
Epoch 210:, Train 0.9355, Val 0.9099, Test 0.7475
Epoch 220:, Train 0.9347, Val 0.9054, Test 0.7509
Epoch 230:, Train 0.9353, Val 0.9057, Test 0.7514
Epoch 240:, Train 0.9352, Val 0.9072, Test 0.7474
Epoch 250:, Train 0.9329, Val 0.9067, Test 0.7478
Epoch 260:, Train 0.9343, Val 0.9077, Test 0.7471
Epoch 270:, Train 0.9357, Val 0.9067, Test 0.7526
Epoch 280:, Train 0.9370, Val 0.9077, Test 0.7527
Epoch 290:, Train 0.9339, Val 0.9061, Test 0.7512
Epoch 300:, Train 0.9363, Val 0.9090, Test 0.7473
BEST: Epoch 210, Train 0.9355, Val 0.9099, Test 0.7475

RUN #1: seed=4
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.17e-05
convert to csr_matrix: 2.566
calc min-max per row: 0.7359
vectorization: 1.64
Total Normalization: 6.5309
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 273.0336
Epoch 10:, Train 0.9216, Val 0.8995, Test 0.7344
Epoch 20:, Train 0.9232, Val 0.8991, Test 0.7283
Epoch 30:, Train 0.9258, Val 0.8999, Test 0.7305
Epoch 40:, Train 0.9315, Val 0.9041, Test 0.7393
Epoch 50:, Train 0.9309, Val 0.9069, Test 0.7457
Epoch 60:, Train 0.9270, Val 0.8998, Test 0.7298
Epoch 70:, Train 0.9323, Val 0.9063, Test 0.7415
Epoch 80:, Train 0.9296, Val 0.9022, Test 0.7225
Epoch 90:, Train 0.9320, Val 0.9047, Test 0.7441
Epoch 100:, Train 0.9326, Val 0.9073, Test 0.7501
Epoch 110:, Train 0.9324, Val 0.9054, Test 0.7502
Epoch 120:, Train 0.9334, Val 0.9073, Test 0.7401
Epoch 130:, Train 0.9331, Val 0.9073, Test 0.7557
Epoch 140:, Train 0.9355, Val 0.9094, Test 0.7556
Epoch 150:, Train 0.9334, Val 0.9058, Test 0.7488
Epoch 160:, Train 0.9343, Val 0.9073, Test 0.7486
Epoch 170:, Train 0.9357, Val 0.9068, Test 0.7584
Epoch 180:, Train 0.9323, Val 0.9054, Test 0.7333
Epoch 190:, Train 0.9342, Val 0.9099, Test 0.7589
Epoch 200:, Train 0.9347, Val 0.9078, Test 0.7513
Epoch 210:, Train 0.9352, Val 0.9092, Test 0.7577
Epoch 220:, Train 0.9339, Val 0.9048, Test 0.7488
Epoch 230:, Train 0.9360, Val 0.9095, Test 0.7547
Epoch 240:, Train 0.9344, Val 0.9067, Test 0.7546
Epoch 250:, Train 0.9361, Val 0.9091, Test 0.7537
Epoch 260:, Train 0.9357, Val 0.9073, Test 0.7446
Epoch 270:, Train 0.9358, Val 0.9080, Test 0.7585
Epoch 280:, Train 0.9340, Val 0.9063, Test 0.7433
Epoch 290:, Train 0.9365, Val 0.9075, Test 0.7558
Epoch 300:, Train 0.9330, Val 0.9037, Test 0.7475
BEST: Epoch 190, Train 0.9342, Val 0.9099, Test 0.7589

RUN #2: seed=8
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.098e-05
convert to csr_matrix: 2.668
calc min-max per row: 0.7497
vectorization: 1.744
Total Normalization: 6.7476
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 263.7050
Epoch 10:, Train 0.9173, Val 0.8940, Test 0.7134
Epoch 20:, Train 0.9247, Val 0.8992, Test 0.7341
Epoch 30:, Train 0.9241, Val 0.9024, Test 0.7459
Epoch 40:, Train 0.9289, Val 0.9036, Test 0.7383
Epoch 50:, Train 0.9308, Val 0.9060, Test 0.7498
Epoch 60:, Train 0.9293, Val 0.9053, Test 0.7406
Epoch 70:, Train 0.9296, Val 0.9001, Test 0.7391
Epoch 80:, Train 0.9323, Val 0.9075, Test 0.7452
Epoch 90:, Train 0.9318, Val 0.9055, Test 0.7469
Epoch 100:, Train 0.9331, Val 0.9072, Test 0.7432
Epoch 110:, Train 0.9322, Val 0.9072, Test 0.7465
Epoch 120:, Train 0.9339, Val 0.9048, Test 0.7511
Epoch 130:, Train 0.9335, Val 0.9067, Test 0.7493
Epoch 140:, Train 0.9351, Val 0.9098, Test 0.7503
Epoch 150:, Train 0.9336, Val 0.9056, Test 0.7446
Epoch 160:, Train 0.9320, Val 0.9066, Test 0.7448
Epoch 170:, Train 0.9336, Val 0.9049, Test 0.7511
Epoch 180:, Train 0.9338, Val 0.9047, Test 0.7468
Epoch 190:, Train 0.9339, Val 0.9082, Test 0.7462
Epoch 200:, Train 0.9362, Val 0.9105, Test 0.7531
Epoch 210:, Train 0.9346, Val 0.9100, Test 0.7484
Epoch 220:, Train 0.9359, Val 0.9078, Test 0.7503
Epoch 230:, Train 0.9359, Val 0.9078, Test 0.7551
Epoch 240:, Train 0.9344, Val 0.9078, Test 0.7434
Epoch 250:, Train 0.9369, Val 0.9086, Test 0.7558
Epoch 260:, Train 0.9347, Val 0.9082, Test 0.7483
Epoch 270:, Train 0.9351, Val 0.9100, Test 0.7600
Epoch 280:, Train 0.9370, Val 0.9106, Test 0.7591
Epoch 290:, Train 0.9359, Val 0.9095, Test 0.7572
Epoch 300:, Train 0.9346, Val 0.9068, Test 0.7520
BEST: Epoch 280, Train 0.9370, Val 0.9106, Test 0.7591

RUN #3: seed=42
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.05e-05
convert to csr_matrix: 2.645
calc min-max per row: 0.7194
vectorization: 1.726
Total Normalization: 6.5624
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 256.8784
Epoch 10:, Train 0.9185, Val 0.8948, Test 0.7246
Epoch 20:, Train 0.9270, Val 0.9031, Test 0.7440
Epoch 30:, Train 0.9248, Val 0.8980, Test 0.7307
Epoch 40:, Train 0.9292, Val 0.9027, Test 0.7351
Epoch 50:, Train 0.9291, Val 0.9039, Test 0.7448
Epoch 60:, Train 0.9340, Val 0.9065, Test 0.7451
Epoch 70:, Train 0.9344, Val 0.9076, Test 0.7452
Epoch 80:, Train 0.9332, Val 0.9078, Test 0.7401
Epoch 90:, Train 0.9299, Val 0.9006, Test 0.7315
Epoch 100:, Train 0.9343, Val 0.9073, Test 0.7506
Epoch 110:, Train 0.9315, Val 0.9041, Test 0.7468
Epoch 120:, Train 0.9307, Val 0.9018, Test 0.7426
Epoch 130:, Train 0.9330, Val 0.9042, Test 0.7440
Epoch 140:, Train 0.9327, Val 0.9073, Test 0.7468
Epoch 150:, Train 0.9342, Val 0.9087, Test 0.7553
Epoch 160:, Train 0.9344, Val 0.9062, Test 0.7480
Epoch 170:, Train 0.9331, Val 0.9060, Test 0.7391
Epoch 180:, Train 0.9353, Val 0.9071, Test 0.7552
Epoch 190:, Train 0.9341, Val 0.9077, Test 0.7528
Epoch 200:, Train 0.9350, Val 0.9075, Test 0.7451
Epoch 210:, Train 0.9086, Val 0.8803, Test 0.6933
Epoch 220:, Train 0.9359, Val 0.9092, Test 0.7605
Epoch 230:, Train 0.9338, Val 0.9038, Test 0.7573
Epoch 240:, Train 0.9355, Val 0.9091, Test 0.7450
Epoch 250:, Train 0.9364, Val 0.9091, Test 0.7476
Epoch 260:, Train 0.9362, Val 0.9096, Test 0.7517
Epoch 270:, Train 0.9356, Val 0.9071, Test 0.7478
Epoch 280:, Train 0.9363, Val 0.9070, Test 0.7535
Epoch 290:, Train 0.9339, Val 0.9074, Test 0.7406
Epoch 300:, Train 0.9351, Val 0.9074, Test 0.7473
BEST: Epoch 260, Train 0.9362, Val 0.9096, Test 0.7517

RUN #4: seed=64
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.933e-05
convert to csr_matrix: 2.661
calc min-max per row: 0.7494
vectorization: 1.744
Total Normalization: 6.6952
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 268.9175
Epoch 10:, Train 0.9214, Val 0.8973, Test 0.7319
Epoch 20:, Train 0.9222, Val 0.8974, Test 0.7359
Epoch 30:, Train 0.9298, Val 0.9039, Test 0.7358
Epoch 40:, Train 0.9299, Val 0.9015, Test 0.7350
Epoch 50:, Train 0.9296, Val 0.9017, Test 0.7314
Epoch 60:, Train 0.9291, Val 0.9032, Test 0.7347
Epoch 70:, Train 0.9322, Val 0.9066, Test 0.7368
Epoch 80:, Train 0.9339, Val 0.9069, Test 0.7464
Epoch 90:, Train 0.9342, Val 0.9066, Test 0.7543
Epoch 100:, Train 0.9327, Val 0.9060, Test 0.7441
Epoch 110:, Train 0.9343, Val 0.9070, Test 0.7464
Epoch 120:, Train 0.9335, Val 0.9053, Test 0.7433
Epoch 130:, Train 0.9339, Val 0.9084, Test 0.7528
Epoch 140:, Train 0.9355, Val 0.9082, Test 0.7510
Epoch 150:, Train 0.9343, Val 0.9063, Test 0.7396
Epoch 160:, Train 0.9336, Val 0.9058, Test 0.7462
Epoch 170:, Train 0.9338, Val 0.9082, Test 0.7486
Epoch 180:, Train 0.9346, Val 0.9077, Test 0.7453
Epoch 190:, Train 0.9355, Val 0.9088, Test 0.7556
Epoch 200:, Train 0.9331, Val 0.9033, Test 0.7379
Epoch 210:, Train 0.9334, Val 0.9066, Test 0.7419
Epoch 220:, Train 0.9355, Val 0.9071, Test 0.7527
Epoch 230:, Train 0.9335, Val 0.9077, Test 0.7538
Epoch 240:, Train 0.9341, Val 0.9070, Test 0.7459
Epoch 250:, Train 0.9333, Val 0.9081, Test 0.7433
Epoch 260:, Train 0.9352, Val 0.9080, Test 0.7570
Epoch 270:, Train 0.9342, Val 0.9047, Test 0.7425
Epoch 280:, Train 0.9344, Val 0.9064, Test 0.7478
Epoch 290:, Train 0.9348, Val 0.9079, Test 0.7393
Epoch 300:, Train 0.9345, Val 0.9079, Test 0.7441
BEST: Epoch 190, Train 0.9355, Val 0.9088, Test 0.7556

RUN #5: seed=128
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 1.907e-05
convert to csr_matrix: 2.525
calc min-max per row: 0.7214
vectorization: 1.644
Total Normalization: 6.3791
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 258.1878
Epoch 10:, Train 0.9225, Val 0.9017, Test 0.7259
Epoch 20:, Train 0.9200, Val 0.8961, Test 0.7381
Epoch 30:, Train 0.9286, Val 0.9044, Test 0.7367
Epoch 40:, Train 0.9310, Val 0.9051, Test 0.7356
Epoch 50:, Train 0.9315, Val 0.9019, Test 0.7356
Epoch 60:, Train 0.9297, Val 0.9053, Test 0.7399
Epoch 70:, Train 0.9327, Val 0.9070, Test 0.7439
Epoch 80:, Train 0.9315, Val 0.9063, Test 0.7436
Epoch 90:, Train 0.9329, Val 0.9044, Test 0.7497
Epoch 100:, Train 0.9336, Val 0.9060, Test 0.7476
Epoch 110:, Train 0.9337, Val 0.9066, Test 0.7517
Epoch 120:, Train 0.9339, Val 0.9061, Test 0.7401
Epoch 130:, Train 0.9347, Val 0.9074, Test 0.7490
Epoch 140:, Train 0.9312, Val 0.9047, Test 0.7424
Epoch 150:, Train 0.9336, Val 0.9063, Test 0.7535
Epoch 160:, Train 0.9330, Val 0.9072, Test 0.7427
Epoch 170:, Train 0.9321, Val 0.9043, Test 0.7422
Epoch 180:, Train 0.9356, Val 0.9085, Test 0.7460
Epoch 190:, Train 0.9324, Val 0.9028, Test 0.7429
Epoch 200:, Train 0.9349, Val 0.9077, Test 0.7420
Epoch 210:, Train 0.9336, Val 0.9051, Test 0.7407
Epoch 220:, Train 0.9358, Val 0.9082, Test 0.7481
Epoch 230:, Train 0.9339, Val 0.9039, Test 0.7380
Epoch 240:, Train 0.9367, Val 0.9104, Test 0.7490
Epoch 250:, Train 0.9320, Val 0.9026, Test 0.7451
Epoch 260:, Train 0.9351, Val 0.9077, Test 0.7463
Epoch 270:, Train 0.9357, Val 0.9088, Test 0.7511
Epoch 280:, Train 0.9368, Val 0.9077, Test 0.7559
Epoch 290:, Train 0.9365, Val 0.9094, Test 0.7566
Epoch 300:, Train 0.9360, Val 0.9092, Test 0.7518
BEST: Epoch 240, Train 0.9367, Val 0.9104, Test 0.7490

RUN #6: seed=256
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.766e-05
convert to csr_matrix: 2.638
calc min-max per row: 0.7508
vectorization: 1.727
Total Normalization: 6.6049
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 239.4446
Epoch 10:, Train 0.9214, Val 0.8971, Test 0.7308
Epoch 20:, Train 0.9246, Val 0.8970, Test 0.7337
Epoch 30:, Train 0.9257, Val 0.8990, Test 0.7324
Epoch 40:, Train 0.9305, Val 0.9050, Test 0.7381
Epoch 50:, Train 0.9318, Val 0.9064, Test 0.7440
Epoch 60:, Train 0.9320, Val 0.9063, Test 0.7436
Epoch 70:, Train 0.9315, Val 0.9051, Test 0.7426
Epoch 80:, Train 0.9317, Val 0.9058, Test 0.7432
Epoch 90:, Train 0.9310, Val 0.9039, Test 0.7447
Epoch 100:, Train 0.9315, Val 0.9024, Test 0.7351
Epoch 110:, Train 0.9325, Val 0.9051, Test 0.7443
Epoch 120:, Train 0.9334, Val 0.9055, Test 0.7481
Epoch 130:, Train 0.9323, Val 0.9059, Test 0.7491
Epoch 140:, Train 0.9343, Val 0.9076, Test 0.7460
Epoch 150:, Train 0.9340, Val 0.9072, Test 0.7462
Epoch 160:, Train 0.9320, Val 0.9032, Test 0.7439
Epoch 170:, Train 0.9353, Val 0.9066, Test 0.7464
Epoch 180:, Train 0.9350, Val 0.9076, Test 0.7517
Epoch 190:, Train 0.9316, Val 0.9020, Test 0.7419
Epoch 200:, Train 0.9347, Val 0.9085, Test 0.7453
Epoch 210:, Train 0.9339, Val 0.9055, Test 0.7457
Epoch 220:, Train 0.9365, Val 0.9095, Test 0.7608
Epoch 230:, Train 0.9335, Val 0.9057, Test 0.7489
Epoch 240:, Train 0.9333, Val 0.9043, Test 0.7498
Epoch 250:, Train 0.9348, Val 0.9051, Test 0.7493
Epoch 260:, Train 0.9343, Val 0.9070, Test 0.7505
Epoch 270:, Train 0.9326, Val 0.9023, Test 0.7490
Epoch 280:, Train 0.9339, Val 0.9079, Test 0.7515
Epoch 290:, Train 0.9360, Val 0.9063, Test 0.7660
Epoch 300:, Train 0.9349, Val 0.9093, Test 0.7518
BEST: Epoch 220, Train 0.9365, Val 0.9095, Test 0.7608

RUN #7: seed=512
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.789e-05
convert to csr_matrix: 2.581
calc min-max per row: 0.7301
vectorization: 1.73
Total Normalization: 6.5333
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 254.4950
Epoch 10:, Train 0.9216, Val 0.8987, Test 0.7341
Epoch 20:, Train 0.9257, Val 0.9014, Test 0.7328
Epoch 30:, Train 0.9287, Val 0.9035, Test 0.7437
Epoch 40:, Train 0.9275, Val 0.9002, Test 0.7456
Epoch 50:, Train 0.9316, Val 0.9052, Test 0.7401
Epoch 60:, Train 0.9327, Val 0.9067, Test 0.7407
Epoch 70:, Train 0.9322, Val 0.9061, Test 0.7417
Epoch 80:, Train 0.9325, Val 0.9045, Test 0.7458
Epoch 90:, Train 0.9314, Val 0.9052, Test 0.7425
Epoch 100:, Train 0.9328, Val 0.9066, Test 0.7469
Epoch 110:, Train 0.9315, Val 0.9030, Test 0.7368
Epoch 120:, Train 0.9329, Val 0.9056, Test 0.7446
Epoch 130:, Train 0.9330, Val 0.9086, Test 0.7495
Epoch 140:, Train 0.9333, Val 0.9041, Test 0.7522
Epoch 150:, Train 0.9348, Val 0.9085, Test 0.7487
Epoch 160:, Train 0.9342, Val 0.9062, Test 0.7488
Epoch 170:, Train 0.9347, Val 0.9070, Test 0.7558
Epoch 180:, Train 0.9315, Val 0.9016, Test 0.7421
Epoch 190:, Train 0.9325, Val 0.9050, Test 0.7501
Epoch 200:, Train 0.9339, Val 0.9069, Test 0.7482
Epoch 210:, Train 0.9348, Val 0.9068, Test 0.7527
Epoch 220:, Train 0.9370, Val 0.9090, Test 0.7512
Epoch 230:, Train 0.9346, Val 0.9073, Test 0.7568
Epoch 240:, Train 0.9363, Val 0.9094, Test 0.7549
Epoch 250:, Train 0.9354, Val 0.9086, Test 0.7561
Epoch 260:, Train 0.9344, Val 0.9073, Test 0.7514
Epoch 270:, Train 0.9371, Val 0.9095, Test 0.7504
Epoch 280:, Train 0.9341, Val 0.9056, Test 0.7458
Epoch 290:, Train 0.9341, Val 0.9071, Test 0.7511
Epoch 300:, Train 0.9354, Val 0.9086, Test 0.7488
BEST: Epoch 270, Train 0.9371, Val 0.9095, Test 0.7504

RUN #8: seed=1024
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 1.907e-05
convert to csr_matrix: 2.528
calc min-max per row: 0.7203
vectorization: 1.66
Total Normalization: 6.3955
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 259.9631
Epoch 10:, Train 0.9195, Val 0.8971, Test 0.7258
Epoch 20:, Train 0.9273, Val 0.9026, Test 0.7363
Epoch 30:, Train 0.9307, Val 0.9042, Test 0.7411
Epoch 40:, Train 0.9299, Val 0.9022, Test 0.7431
Epoch 50:, Train 0.9303, Val 0.9027, Test 0.7338
Epoch 60:, Train 0.9313, Val 0.9051, Test 0.7518
Epoch 70:, Train 0.9307, Val 0.9052, Test 0.7369
Epoch 80:, Train 0.9310, Val 0.9044, Test 0.7409
Epoch 90:, Train 0.9339, Val 0.9051, Test 0.7434
Epoch 100:, Train 0.9328, Val 0.9064, Test 0.7457
Epoch 110:, Train 0.9347, Val 0.9062, Test 0.7478
Epoch 120:, Train 0.9339, Val 0.9089, Test 0.7491
Epoch 130:, Train 0.9328, Val 0.9059, Test 0.7416
Epoch 140:, Train 0.9347, Val 0.9069, Test 0.7484
Epoch 150:, Train 0.9329, Val 0.9061, Test 0.7437
Epoch 160:, Train 0.9356, Val 0.9084, Test 0.7443
Epoch 170:, Train 0.9348, Val 0.9079, Test 0.7467
Epoch 180:, Train 0.9332, Val 0.9048, Test 0.7541
Epoch 190:, Train 0.9364, Val 0.9091, Test 0.7542
Epoch 200:, Train 0.9320, Val 0.9060, Test 0.7478
Epoch 210:, Train 0.9332, Val 0.9065, Test 0.7538
Epoch 220:, Train 0.9369, Val 0.9088, Test 0.7564
Epoch 230:, Train 0.9341, Val 0.9073, Test 0.7527
Epoch 240:, Train 0.9342, Val 0.9068, Test 0.7508
Epoch 250:, Train 0.9364, Val 0.9102, Test 0.7567
Epoch 260:, Train 0.9333, Val 0.9045, Test 0.7447
Epoch 270:, Train 0.9342, Val 0.9087, Test 0.7598
Epoch 280:, Train 0.9348, Val 0.9079, Test 0.7533
Epoch 290:, Train 0.9327, Val 0.9045, Test 0.7497
Epoch 300:, Train 0.9355, Val 0.9091, Test 0.7475
BEST: Epoch 250, Train 0.9364, Val 0.9102, Test 0.7567

RUN #9: seed=2048
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.027e-05
convert to csr_matrix: 2.527
calc min-max per row: 0.7221
vectorization: 1.643
Total Normalization: 6.3816
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 258.8691
Epoch 10:, Train 0.9172, Val 0.8928, Test 0.7214
Epoch 20:, Train 0.9259, Val 0.8999, Test 0.7350
Epoch 30:, Train 0.9296, Val 0.9041, Test 0.7382
Epoch 40:, Train 0.9299, Val 0.9040, Test 0.7388
Epoch 50:, Train 0.9301, Val 0.9050, Test 0.7361
Epoch 60:, Train 0.9298, Val 0.9015, Test 0.7394
Epoch 70:, Train 0.9305, Val 0.9026, Test 0.7338
Epoch 80:, Train 0.9315, Val 0.9027, Test 0.7426
Epoch 90:, Train 0.9327, Val 0.9057, Test 0.7382
Epoch 100:, Train 0.9319, Val 0.9067, Test 0.7425
Epoch 110:, Train 0.9328, Val 0.9075, Test 0.7394
Epoch 120:, Train 0.9314, Val 0.9060, Test 0.7425
Epoch 130:, Train 0.9361, Val 0.9089, Test 0.7560
Epoch 140:, Train 0.9325, Val 0.9053, Test 0.7419
Epoch 150:, Train 0.9337, Val 0.9063, Test 0.7403
Epoch 160:, Train 0.9342, Val 0.9051, Test 0.7516
Epoch 170:, Train 0.9331, Val 0.9063, Test 0.7477
Epoch 180:, Train 0.9343, Val 0.9069, Test 0.7598
Epoch 190:, Train 0.9356, Val 0.9071, Test 0.7486
Epoch 200:, Train 0.9337, Val 0.9055, Test 0.7444
Epoch 210:, Train 0.9329, Val 0.9061, Test 0.7508
Epoch 220:, Train 0.9329, Val 0.9062, Test 0.7497
Epoch 230:, Train 0.9341, Val 0.9080, Test 0.7517
Epoch 240:, Train 0.9344, Val 0.9080, Test 0.7543
Epoch 250:, Train 0.9349, Val 0.9090, Test 0.7487
Epoch 260:, Train 0.9346, Val 0.9072, Test 0.7583
Epoch 270:, Train 0.9350, Val 0.9080, Test 0.7574
Epoch 280:, Train 0.9355, Val 0.9075, Test 0.7430
Epoch 290:, Train 0.9337, Val 0.9075, Test 0.7577
Epoch 300:, Train 0.9349, Val 0.9096, Test 0.7538
BEST: Epoch 300, Train 0.9349, Val 0.9096, Test 0.7538




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 150.7339 +/- 7.7094
Avg. Preaggregation Time (s): 259.0540 +/- 8.5442
Avg. Training Time (epoch) (s): 4.3234 +/- 0.0614
Avg. Inference Time (s): 1.3101 +/- 0.0200

Avg. Training Acc: 0.9360 +/- 0.0009
Avg. Validation Acc: 0.9098 +/- 0.0005
Avg. Test Acc: 0.7543 +/- 0.0044

==================================================

==================================================
================= SIGN+SHA =======================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0003807349130511284
coalesce scoo: 1.645e-05
convert to csr_matrix: 2.698
calc min-max per row: 0.7534
vectorization: 1.762
Normalization Time: 6.7344
DOT_PRODUCT
Attention Filter (n=122947251): 0.151 +\- 0.234 [0.000-1.000]
Total Transformation Time: 215.8239
Epoch 10:, Train 0.9058, Val 0.8819, Test 0.7108
Epoch 20:, Train 0.9239, Val 0.8915, Test 0.7310
Epoch 30:, Train 0.9206, Val 0.8922, Test 0.7363
Epoch 40:, Train 0.9240, Val 0.8905, Test 0.7256
Epoch 50:, Train 0.9269, Val 0.8942, Test 0.7415
Epoch 60:, Train 0.9305, Val 0.8946, Test 0.7362
Epoch 70:, Train 0.9317, Val 0.8978, Test 0.7397
Epoch 80:, Train 0.9248, Val 0.8904, Test 0.7331
Epoch 90:, Train 0.9330, Val 0.8985, Test 0.7361
Epoch 100:, Train 0.9361, Val 0.8985, Test 0.7461
Epoch 110:, Train 0.9323, Val 0.8958, Test 0.7395
Epoch 120:, Train 0.9342, Val 0.8969, Test 0.7427
Epoch 130:, Train 0.9310, Val 0.8943, Test 0.7398
Epoch 140:, Train 0.9347, Val 0.8973, Test 0.7429
Epoch 150:, Train 0.9318, Val 0.8965, Test 0.7410
Epoch 160:, Train 0.9376, Val 0.8983, Test 0.7466
Epoch 170:, Train 0.9340, Val 0.8967, Test 0.7414
Epoch 180:, Train 0.9326, Val 0.8973, Test 0.7453
Epoch 190:, Train 0.9349, Val 0.8977, Test 0.7426
Epoch 200:, Train 0.9360, Val 0.8975, Test 0.7471
Epoch 210:, Train 0.9351, Val 0.8992, Test 0.7445
Epoch 220:, Train 0.9351, Val 0.8977, Test 0.7392
Epoch 230:, Train 0.9371, Val 0.8994, Test 0.7429
Epoch 240:, Train 0.9376, Val 0.9009, Test 0.7467
Epoch 250:, Train 0.9384, Val 0.9007, Test 0.7438
Epoch 260:, Train 0.9281, Val 0.8880, Test 0.7269
Epoch 270:, Train 0.9370, Val 0.9002, Test 0.7398
Epoch 280:, Train 0.9369, Val 0.8980, Test 0.7353
Epoch 290:, Train 0.9347, Val 0.8983, Test 0.7428
Epoch 300:, Train 0.9373, Val 0.8995, Test 0.7444
BEST: Epoch 240, Train 0.9376, Val 0.9009, Test 0.7467

RUN #1: seed=4
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004695733543485403
coalesce scoo: 1.645e-05
convert to csr_matrix: 2.678
calc min-max per row: 0.7298
vectorization: 1.752
Normalization Time: 6.6637
DOT_PRODUCT
Attention Filter (n=122825229): 0.152 +\- 0.232 [0.000-1.000]
Total Transformation Time: 216.9494
Epoch 10:, Train 0.9106, Val 0.8868, Test 0.7274
Epoch 20:, Train 0.9115, Val 0.8817, Test 0.7212
Epoch 30:, Train 0.9216, Val 0.8901, Test 0.7329
Epoch 40:, Train 0.9258, Val 0.8935, Test 0.7409
Epoch 50:, Train 0.9303, Val 0.8970, Test 0.7483
Epoch 60:, Train 0.9301, Val 0.8953, Test 0.7425
Epoch 70:, Train 0.9306, Val 0.8936, Test 0.7470
Epoch 80:, Train 0.9311, Val 0.8967, Test 0.7399
Epoch 90:, Train 0.9310, Val 0.8956, Test 0.7433
Epoch 100:, Train 0.9350, Val 0.8980, Test 0.7491
Epoch 110:, Train 0.9360, Val 0.8971, Test 0.7541
Epoch 120:, Train 0.9291, Val 0.8934, Test 0.7332
Epoch 130:, Train 0.9334, Val 0.8957, Test 0.7505
Epoch 140:, Train 0.9377, Val 0.9000, Test 0.7502
Epoch 150:, Train 0.9343, Val 0.8979, Test 0.7496
Epoch 160:, Train 0.9375, Val 0.8985, Test 0.7515
Epoch 170:, Train 0.9381, Val 0.8977, Test 0.7520
Epoch 180:, Train 0.9367, Val 0.8972, Test 0.7469
Epoch 190:, Train 0.9393, Val 0.9017, Test 0.7563
Epoch 200:, Train 0.9364, Val 0.8971, Test 0.7479
Epoch 210:, Train 0.9333, Val 0.8970, Test 0.7437
Epoch 220:, Train 0.9373, Val 0.8978, Test 0.7495
Epoch 230:, Train 0.9345, Val 0.8963, Test 0.7414
Epoch 240:, Train 0.9310, Val 0.8932, Test 0.7382
Epoch 250:, Train 0.9372, Val 0.8980, Test 0.7434
Epoch 260:, Train 0.9339, Val 0.8945, Test 0.7376
Epoch 270:, Train 0.9306, Val 0.8912, Test 0.7342
Epoch 280:, Train 0.9365, Val 0.8964, Test 0.7583
Epoch 290:, Train 0.9393, Val 0.9017, Test 0.7504
Epoch 300:, Train 0.9375, Val 0.8990, Test 0.7537
BEST: Epoch 190, Train 0.9393, Val 0.9017, Test 0.7563

RUN #2: seed=8
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0016792048700153828
coalesce scoo: 1.454e-05
convert to csr_matrix: 2.69
calc min-max per row: 0.729
vectorization: 1.757
Normalization Time: 6.6804
DOT_PRODUCT
Attention Filter (n=123020289): 0.147 +\- 0.229 [0.000-1.000]
Total Transformation Time: 210.8105
Epoch 10:, Train 0.9142, Val 0.8898, Test 0.7265
Epoch 20:, Train 0.9218, Val 0.8915, Test 0.7279
Epoch 30:, Train 0.9238, Val 0.8927, Test 0.7278
Epoch 40:, Train 0.9184, Val 0.8872, Test 0.7406
Epoch 50:, Train 0.9221, Val 0.8894, Test 0.7288
Epoch 60:, Train 0.9319, Val 0.8970, Test 0.7420
Epoch 70:, Train 0.9294, Val 0.8922, Test 0.7451
Epoch 80:, Train 0.9326, Val 0.8994, Test 0.7525
Epoch 90:, Train 0.9212, Val 0.8856, Test 0.7216
Epoch 100:, Train 0.9263, Val 0.8903, Test 0.7390
Epoch 110:, Train 0.9309, Val 0.8936, Test 0.7422
Epoch 120:, Train 0.9301, Val 0.8933, Test 0.7327
Epoch 130:, Train 0.9354, Val 0.8971, Test 0.7458
Epoch 140:, Train 0.9278, Val 0.8924, Test 0.7335
Epoch 150:, Train 0.9331, Val 0.8971, Test 0.7386
Epoch 160:, Train 0.9361, Val 0.8987, Test 0.7449
Epoch 170:, Train 0.9364, Val 0.8983, Test 0.7507
Epoch 180:, Train 0.9339, Val 0.8949, Test 0.7426
Epoch 190:, Train 0.9340, Val 0.8967, Test 0.7362
Epoch 200:, Train 0.9335, Val 0.8940, Test 0.7426
Epoch 210:, Train 0.9316, Val 0.8930, Test 0.7366
Epoch 220:, Train 0.9373, Val 0.8971, Test 0.7471
Epoch 230:, Train 0.9380, Val 0.8977, Test 0.7445
Epoch 240:, Train 0.9350, Val 0.8954, Test 0.7420
Epoch 250:, Train 0.9315, Val 0.8925, Test 0.7385
Epoch 260:, Train 0.9376, Val 0.8998, Test 0.7466
Epoch 270:, Train 0.9340, Val 0.8937, Test 0.7423
Epoch 280:, Train 0.9373, Val 0.8975, Test 0.7456
Epoch 290:, Train 0.9357, Val 0.8953, Test 0.7392
Epoch 300:, Train 0.9333, Val 0.8956, Test 0.7393
BEST: Epoch 260, Train 0.9376, Val 0.8998, Test 0.7466

RUN #3: seed=42
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0031600971706211567
coalesce scoo: 1.645e-05
convert to csr_matrix: 2.483
calc min-max per row: 0.7288
vectorization: 1.577
Normalization Time: 6.3155
DOT_PRODUCT
Attention Filter (n=123001819): 0.148 +\- 0.229 [0.000-1.000]
Total Transformation Time: 209.2736
Epoch 10:, Train 0.9134, Val 0.8871, Test 0.7183
Epoch 20:, Train 0.9185, Val 0.8895, Test 0.7212
Epoch 30:, Train 0.9209, Val 0.8892, Test 0.7204
Epoch 40:, Train 0.9300, Val 0.8969, Test 0.7382
Epoch 50:, Train 0.9309, Val 0.8966, Test 0.7377
Epoch 60:, Train 0.9248, Val 0.8906, Test 0.7256
Epoch 70:, Train 0.9319, Val 0.8976, Test 0.7402
Epoch 80:, Train 0.9230, Val 0.8883, Test 0.7237
Epoch 90:, Train 0.9327, Val 0.8978, Test 0.7383
Epoch 100:, Train 0.9280, Val 0.8918, Test 0.7385
Epoch 110:, Train 0.9353, Val 0.8987, Test 0.7372
Epoch 120:, Train 0.9328, Val 0.8956, Test 0.7439
Epoch 130:, Train 0.9330, Val 0.8933, Test 0.7319
Epoch 140:, Train 0.9319, Val 0.8962, Test 0.7362
Epoch 150:, Train 0.9334, Val 0.8968, Test 0.7444
Epoch 160:, Train 0.9355, Val 0.8990, Test 0.7424
Epoch 170:, Train 0.9363, Val 0.8972, Test 0.7464
Epoch 180:, Train 0.9320, Val 0.8935, Test 0.7347
Epoch 190:, Train 0.9326, Val 0.8937, Test 0.7421
Epoch 200:, Train 0.9354, Val 0.8976, Test 0.7458
Epoch 210:, Train 0.9342, Val 0.8965, Test 0.7430
Epoch 220:, Train 0.9365, Val 0.8989, Test 0.7420
Epoch 230:, Train 0.9345, Val 0.8976, Test 0.7478
Epoch 240:, Train 0.9351, Val 0.8970, Test 0.7412
Epoch 250:, Train 0.9409, Val 0.9006, Test 0.7480
Epoch 260:, Train 0.9373, Val 0.8983, Test 0.7509
Epoch 270:, Train 0.9383, Val 0.9010, Test 0.7439
Epoch 280:, Train 0.9378, Val 0.9011, Test 0.7436
Epoch 290:, Train 0.9371, Val 0.9014, Test 0.7482
Epoch 300:, Train 0.9387, Val 0.9013, Test 0.7489
BEST: Epoch 290, Train 0.9371, Val 0.9014, Test 0.7482

RUN #4: seed=64
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004785676021128893
coalesce scoo: 1.764e-05
convert to csr_matrix: 2.693
calc min-max per row: 0.7295
vectorization: 1.759
Normalization Time: 6.6904
DOT_PRODUCT
Attention Filter (n=123009438): 0.151 +\- 0.234 [0.000-1.000]
Total Transformation Time: 216.5492
Epoch 10:, Train 0.9091, Val 0.8826, Test 0.7226
Epoch 20:, Train 0.9197, Val 0.8879, Test 0.7323
Epoch 30:, Train 0.9244, Val 0.8905, Test 0.7327
Epoch 40:, Train 0.9239, Val 0.8882, Test 0.7299
Epoch 50:, Train 0.9280, Val 0.8932, Test 0.7410
Epoch 60:, Train 0.9295, Val 0.8942, Test 0.7373
Epoch 70:, Train 0.9300, Val 0.8903, Test 0.7285
Epoch 80:, Train 0.9252, Val 0.8895, Test 0.7343
Epoch 90:, Train 0.9277, Val 0.8893, Test 0.7295
Epoch 100:, Train 0.9232, Val 0.8871, Test 0.7261
Epoch 110:, Train 0.9333, Val 0.8959, Test 0.7416
Epoch 120:, Train 0.9329, Val 0.8942, Test 0.7315
Epoch 130:, Train 0.9323, Val 0.8889, Test 0.7334
Epoch 140:, Train 0.9337, Val 0.8936, Test 0.7451
Epoch 150:, Train 0.9387, Val 0.8982, Test 0.7448
Epoch 160:, Train 0.9352, Val 0.8967, Test 0.7457
Epoch 170:, Train 0.9336, Val 0.8922, Test 0.7365
Epoch 180:, Train 0.8568, Val 0.8268, Test 0.6889
Epoch 190:, Train 0.9344, Val 0.8938, Test 0.7343
Epoch 200:, Train 0.9356, Val 0.8971, Test 0.7426
Epoch 210:, Train 0.9350, Val 0.8957, Test 0.7417
Epoch 220:, Train 0.9381, Val 0.8974, Test 0.7450
Epoch 230:, Train 0.9361, Val 0.8953, Test 0.7391
Epoch 240:, Train 0.9326, Val 0.8933, Test 0.7346
Epoch 250:, Train 0.9374, Val 0.8986, Test 0.7420
Epoch 260:, Train 0.9375, Val 0.8986, Test 0.7407
Epoch 270:, Train 0.9358, Val 0.8957, Test 0.7429
Epoch 280:, Train 0.9299, Val 0.8898, Test 0.7269
Epoch 290:, Train 0.9379, Val 0.8978, Test 0.7478
Epoch 300:, Train 0.9356, Val 0.8949, Test 0.7337
BEST: Epoch 260, Train 0.9375, Val 0.8986, Test 0.7407

RUN #5: seed=128
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00019998301286250353
coalesce scoo: 1.431e-05
convert to csr_matrix: 2.468
calc min-max per row: 0.7268
vectorization: 1.557
Normalization Time: 6.2507
DOT_PRODUCT
Attention Filter (n=122841277): 0.151 +\- 0.233 [0.000-1.000]
Total Transformation Time: 206.6906
Epoch 10:, Train 0.9049, Val 0.8768, Test 0.7019
Epoch 20:, Train 0.9134, Val 0.8843, Test 0.7136
Epoch 30:, Train 0.9189, Val 0.8879, Test 0.7226
Epoch 40:, Train 0.9249, Val 0.8923, Test 0.7369
Epoch 50:, Train 0.9275, Val 0.8956, Test 0.7398
Epoch 60:, Train 0.9294, Val 0.8950, Test 0.7349
Epoch 70:, Train 0.9282, Val 0.8945, Test 0.7302
Epoch 80:, Train 0.9260, Val 0.8928, Test 0.7264
Epoch 90:, Train 0.9326, Val 0.8957, Test 0.7463
Epoch 100:, Train 0.9334, Val 0.8990, Test 0.7329
Epoch 110:, Train 0.9275, Val 0.8906, Test 0.7315
Epoch 120:, Train 0.9336, Val 0.8980, Test 0.7389
Epoch 130:, Train 0.9326, Val 0.8965, Test 0.7383
Epoch 140:, Train 0.9376, Val 0.8998, Test 0.7432
Epoch 150:, Train 0.9345, Val 0.8968, Test 0.7411
Epoch 160:, Train 0.9341, Val 0.8996, Test 0.7433
Epoch 170:, Train 0.9366, Val 0.8994, Test 0.7443
Epoch 180:, Train 0.9329, Val 0.8941, Test 0.7281
Epoch 190:, Train 0.9330, Val 0.8967, Test 0.7343
Epoch 200:, Train 0.9327, Val 0.8944, Test 0.7365
Epoch 210:, Train 0.9356, Val 0.8975, Test 0.7438
Epoch 220:, Train 0.9314, Val 0.8958, Test 0.7321
Epoch 230:, Train 0.9360, Val 0.8991, Test 0.7359
Epoch 240:, Train 0.9354, Val 0.8976, Test 0.7392
Epoch 250:, Train 0.9319, Val 0.8930, Test 0.7365
Epoch 260:, Train 0.9379, Val 0.8983, Test 0.7373
Epoch 270:, Train 0.9300, Val 0.8918, Test 0.7330
Epoch 280:, Train 0.9359, Val 0.8953, Test 0.7420
Epoch 290:, Train 0.9351, Val 0.8985, Test 0.7434
Epoch 300:, Train 0.9366, Val 0.8997, Test 0.7363
BEST: Epoch 140, Train 0.9376, Val 0.8998, Test 0.7432

RUN #6: seed=256
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0025518205948174
coalesce scoo: 1.812e-05
convert to csr_matrix: 2.472
calc min-max per row: 0.7268
vectorization: 1.569
Normalization Time: 6.2847
DOT_PRODUCT
Attention Filter (n=123037660): 0.162 +\- 0.240 [0.000-1.000]
Total Transformation Time: 208.2902
Epoch 10:, Train 0.9152, Val 0.8885, Test 0.7255
Epoch 20:, Train 0.9217, Val 0.8906, Test 0.7276
Epoch 30:, Train 0.9254, Val 0.8902, Test 0.7319
Epoch 40:, Train 0.9238, Val 0.8897, Test 0.7346
Epoch 50:, Train 0.9323, Val 0.8962, Test 0.7494
Epoch 60:, Train 0.9316, Val 0.8964, Test 0.7491
Epoch 70:, Train 0.9304, Val 0.8968, Test 0.7329
Epoch 80:, Train 0.9329, Val 0.8983, Test 0.7444
Epoch 90:, Train 0.9362, Val 0.8982, Test 0.7516
Epoch 100:, Train 0.9356, Val 0.9000, Test 0.7448
Epoch 110:, Train 0.9374, Val 0.9005, Test 0.7481
Epoch 120:, Train 0.9362, Val 0.8986, Test 0.7434
Epoch 130:, Train 0.9368, Val 0.8998, Test 0.7425
Epoch 140:, Train 0.9374, Val 0.8998, Test 0.7411
Epoch 150:, Train 0.9355, Val 0.8974, Test 0.7370
Epoch 160:, Train 0.9355, Val 0.8980, Test 0.7354
Epoch 170:, Train 0.9379, Val 0.8980, Test 0.7505
Epoch 180:, Train 0.9388, Val 0.8970, Test 0.7507
Epoch 190:, Train 0.9378, Val 0.8970, Test 0.7373
Epoch 200:, Train 0.9417, Val 0.9015, Test 0.7557
Epoch 210:, Train 0.9362, Val 0.8985, Test 0.7470
Epoch 220:, Train 0.9371, Val 0.8975, Test 0.7383
Epoch 230:, Train 0.9358, Val 0.8947, Test 0.7477
Epoch 240:, Train 0.9385, Val 0.8983, Test 0.7387
Epoch 250:, Train 0.9370, Val 0.8995, Test 0.7467
Epoch 260:, Train 0.9347, Val 0.8970, Test 0.7404
Epoch 270:, Train 0.9324, Val 0.8949, Test 0.7461
Epoch 280:, Train 0.9374, Val 0.8977, Test 0.7404
Epoch 290:, Train 0.9408, Val 0.9017, Test 0.7452
Epoch 300:, Train 0.9384, Val 0.8987, Test 0.7456
BEST: Epoch 290, Train 0.9408, Val 0.9017, Test 0.7452

RUN #7: seed=512
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.002371214795857668
coalesce scoo: 1.86e-05
convert to csr_matrix: 2.778
calc min-max per row: 0.7248
vectorization: 1.553
Normalization Time: 6.5496
DOT_PRODUCT
Attention Filter (n=122883286): 0.149 +\- 0.230 [0.000-1.000]
Total Transformation Time: 213.7832
Epoch 10:, Train 0.9117, Val 0.8844, Test 0.7194
Epoch 20:, Train 0.9229, Val 0.8929, Test 0.7318
Epoch 30:, Train 0.9235, Val 0.8921, Test 0.7319
Epoch 40:, Train 0.9261, Val 0.8957, Test 0.7334
Epoch 50:, Train 0.9263, Val 0.8926, Test 0.7304
Epoch 60:, Train 0.9336, Val 0.8980, Test 0.7463
Epoch 70:, Train 0.9296, Val 0.8961, Test 0.7364
Epoch 80:, Train 0.9314, Val 0.8951, Test 0.7400
Epoch 90:, Train 0.9337, Val 0.8966, Test 0.7347
Epoch 100:, Train 0.9366, Val 0.8999, Test 0.7454
Epoch 110:, Train 0.9324, Val 0.8979, Test 0.7384
Epoch 120:, Train 0.9351, Val 0.8986, Test 0.7449
Epoch 130:, Train 0.9364, Val 0.8998, Test 0.7427
Epoch 140:, Train 0.9371, Val 0.8998, Test 0.7488
Epoch 150:, Train 0.9362, Val 0.9002, Test 0.7447
Epoch 160:, Train 0.9369, Val 0.8998, Test 0.7471
Epoch 170:, Train 0.9343, Val 0.8969, Test 0.7430
Epoch 180:, Train 0.9386, Val 0.8991, Test 0.7483
Epoch 190:, Train 0.9377, Val 0.9004, Test 0.7361
Epoch 200:, Train 0.9365, Val 0.8999, Test 0.7358
Epoch 210:, Train 0.9361, Val 0.8989, Test 0.7394
Epoch 220:, Train 0.9377, Val 0.8970, Test 0.7383
Epoch 230:, Train 0.9398, Val 0.9003, Test 0.7393
Epoch 240:, Train 0.9383, Val 0.8980, Test 0.7367
Epoch 250:, Train 0.9366, Val 0.8979, Test 0.7389
Epoch 260:, Train 0.9397, Val 0.8995, Test 0.7438
Epoch 270:, Train 0.9387, Val 0.8981, Test 0.7383
Epoch 280:, Train 0.9369, Val 0.8977, Test 0.7461
Epoch 290:, Train 0.9382, Val 0.9001, Test 0.7493
Epoch 300:, Train 0.9391, Val 0.9000, Test 0.7466
BEST: Epoch 190, Train 0.9377, Val 0.9004, Test 0.7361

RUN #8: seed=1024
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.000924520893022418
coalesce scoo: 1.502e-05
convert to csr_matrix: 2.575
calc min-max per row: 0.7281
vectorization: 1.654
Normalization Time: 6.4577
DOT_PRODUCT
Attention Filter (n=122896656): 0.151 +\- 0.233 [0.000-1.000]
Total Transformation Time: 216.2929
Epoch 10:, Train 0.9084, Val 0.8811, Test 0.7118
Epoch 20:, Train 0.9152, Val 0.8867, Test 0.7381
Epoch 30:, Train 0.9201, Val 0.8877, Test 0.7177
Epoch 40:, Train 0.9189, Val 0.8870, Test 0.7336
Epoch 50:, Train 0.9253, Val 0.8909, Test 0.7316
Epoch 60:, Train 0.9293, Val 0.8941, Test 0.7323
Epoch 70:, Train 0.9271, Val 0.8933, Test 0.7358
Epoch 80:, Train 0.9277, Val 0.8914, Test 0.7368
Epoch 90:, Train 0.9305, Val 0.8912, Test 0.7319
Epoch 100:, Train 0.9310, Val 0.8965, Test 0.7437
Epoch 110:, Train 0.9293, Val 0.8936, Test 0.7355
Epoch 120:, Train 0.9289, Val 0.8911, Test 0.7322
Epoch 130:, Train 0.9304, Val 0.8951, Test 0.7435
Epoch 140:, Train 0.9332, Val 0.8960, Test 0.7455
Epoch 150:, Train 0.9293, Val 0.8911, Test 0.7389
Epoch 160:, Train 0.9263, Val 0.8906, Test 0.7329
Epoch 170:, Train 0.9337, Val 0.8954, Test 0.7367
Epoch 180:, Train 0.9345, Val 0.8979, Test 0.7456
Epoch 190:, Train 0.9364, Val 0.8986, Test 0.7456
Epoch 200:, Train 0.9329, Val 0.8967, Test 0.7415
Epoch 210:, Train 0.9360, Val 0.8964, Test 0.7428
Epoch 220:, Train 0.9339, Val 0.8971, Test 0.7461
Epoch 230:, Train 0.9365, Val 0.8953, Test 0.7367
Epoch 240:, Train 0.9316, Val 0.8905, Test 0.7347
Epoch 250:, Train 0.9350, Val 0.8976, Test 0.7364
Epoch 260:, Train 0.9357, Val 0.8958, Test 0.7387
Epoch 270:, Train 0.9346, Val 0.8969, Test 0.7438
Epoch 280:, Train 0.9330, Val 0.8951, Test 0.7367
Epoch 290:, Train 0.9358, Val 0.8965, Test 0.7378
Epoch 300:, Train 0.9354, Val 0.8972, Test 0.7388
BEST: Epoch 190, Train 0.9364, Val 0.8986, Test 0.7456

RUN #9: seed=2048
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00865280069410801
coalesce scoo: 1.788e-05
convert to csr_matrix: 2.519
calc min-max per row: 0.7262
vectorization: 1.553
Normalization Time: 6.3225
DOT_PRODUCT
Attention Filter (n=123018678): 0.153 +\- 0.235 [0.000-1.000]
Total Transformation Time: 214.6831
Epoch 10:, Train 0.9097, Val 0.8830, Test 0.7127
Epoch 20:, Train 0.9155, Val 0.8855, Test 0.7323
Epoch 30:, Train 0.9270, Val 0.8941, Test 0.7367
Epoch 40:, Train 0.9225, Val 0.8899, Test 0.7239
Epoch 50:, Train 0.9259, Val 0.8916, Test 0.7249
Epoch 60:, Train 0.9308, Val 0.8972, Test 0.7299
Epoch 70:, Train 0.9318, Val 0.8959, Test 0.7392
Epoch 80:, Train 0.9312, Val 0.8928, Test 0.7351
Epoch 90:, Train 0.9284, Val 0.8928, Test 0.7232
Epoch 100:, Train 0.9314, Val 0.8938, Test 0.7369
Epoch 110:, Train 0.9293, Val 0.8905, Test 0.7255
Epoch 120:, Train 0.9347, Val 0.8993, Test 0.7436
Epoch 130:, Train 0.9325, Val 0.8927, Test 0.7273
Epoch 140:, Train 0.9318, Val 0.8937, Test 0.7379
Epoch 150:, Train 0.9367, Val 0.8970, Test 0.7419
Epoch 160:, Train 0.9323, Val 0.8949, Test 0.7293
Epoch 170:, Train 0.9361, Val 0.8996, Test 0.7393
Epoch 180:, Train 0.9329, Val 0.8941, Test 0.7333
Epoch 190:, Train 0.9366, Val 0.8982, Test 0.7454
Epoch 200:, Train 0.9382, Val 0.8970, Test 0.7310
Epoch 210:, Train 0.9372, Val 0.8983, Test 0.7420
Epoch 220:, Train 0.9378, Val 0.8995, Test 0.7419
Epoch 230:, Train 0.9353, Val 0.8975, Test 0.7440
Epoch 240:, Train 0.9275, Val 0.8889, Test 0.7269
Epoch 250:, Train 0.9361, Val 0.8963, Test 0.7405
Epoch 260:, Train 0.9341, Val 0.8928, Test 0.7357
Epoch 270:, Train 0.9337, Val 0.8920, Test 0.7373
Epoch 280:, Train 0.9327, Val 0.8949, Test 0.7347
Epoch 290:, Train 0.9358, Val 0.8978, Test 0.7308
Epoch 300:, Train 0.9343, Val 0.8950, Test 0.7309
BEST: Epoch 170, Train 0.9361, Val 0.8996, Test 0.7393




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 95.3999 +/- 3.8467
Avg. Preaggregation Time (s): 212.9147 +/- 3.6202
Avg. Training Time (epoch) (s): 4.4161 +/- 0.0828
Avg. Inference Time (s): 1.2734 +/- 0.0158

Avg. Training Acc: 0.9378 +/- 0.0013
Avg. Validation Acc: 0.9002 +/- 0.0011
Avg. Test Acc: 0.7448 +/- 0.0053

==================================================

==================================================
================= SIGN+MHA =======================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=4, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.002750938758254051
coalesce scoo: 1.931e-05
convert to csr_matrix: 3.283
calc min-max per row: 0.7745
vectorization: 1.763
Normalization Time: 8.0395
DOT_PRODUCT
Attention Filter (n=123577305): 0.182 +\- 0.255 [0.000-1.000]
Total Transformation Time: 594.3165
Epoch 10:, Train 0.9170, Val 0.8932, Test 0.7205
Epoch 20:, Train 0.9270, Val 0.8984, Test 0.7383
Epoch 30:, Train 0.9272, Val 0.8962, Test 0.7426
Epoch 40:, Train 0.9266, Val 0.8988, Test 0.7349
Epoch 50:, Train 0.9295, Val 0.8993, Test 0.7356
Epoch 60:, Train 0.9372, Val 0.9064, Test 0.7596
Epoch 70:, Train 0.9360, Val 0.9033, Test 0.7459
Epoch 80:, Train 0.9385, Val 0.9027, Test 0.7510
Epoch 90:, Train 0.9393, Val 0.9080, Test 0.7506
Epoch 100:, Train 0.9393, Val 0.9073, Test 0.7528
Epoch 110:, Train 0.9370, Val 0.9029, Test 0.7484
Epoch 120:, Train 0.9380, Val 0.9047, Test 0.7466
Epoch 130:, Train 0.9405, Val 0.9068, Test 0.7460
Epoch 140:, Train 0.9404, Val 0.9075, Test 0.7428
Epoch 150:, Train 0.9380, Val 0.9035, Test 0.7418
Epoch 160:, Train 0.9413, Val 0.9061, Test 0.7492
Epoch 170:, Train 0.9415, Val 0.9089, Test 0.7526
Epoch 180:, Train 0.9421, Val 0.9086, Test 0.7602
Epoch 190:, Train 0.9433, Val 0.9076, Test 0.7562
Epoch 200:, Train 0.9386, Val 0.9072, Test 0.7496
Epoch 210:, Train 0.9414, Val 0.9086, Test 0.7518
Epoch 220:, Train 0.9422, Val 0.9075, Test 0.7532
Epoch 230:, Train 0.9374, Val 0.9051, Test 0.7414
Epoch 240:, Train 0.9426, Val 0.9072, Test 0.7572
Epoch 250:, Train 0.9430, Val 0.9077, Test 0.7588
Epoch 260:, Train 0.9418, Val 0.9076, Test 0.7512
Epoch 270:, Train 0.9385, Val 0.9054, Test 0.7458
Epoch 280:, Train 0.9433, Val 0.9096, Test 0.7511
Epoch 290:, Train 0.9405, Val 0.9039, Test 0.7492
/var/spool/slurm/slurmd/job9646816/slurm_script: line 178: 26131 Killed                  python $PY_FILE --DATASET $DATASET --ATTN_FILTER $ATTN_FILTER --EPOCHS $EPOCHS --EVAL_EVERY $EVAL_EVERY --RUN_SEEDS $RUN_SEEDS --HOPS $HOPS --BATCH_SIZE $BATCH_SIZE --LEARNING_RATE $LEARNING_RATE --WEIGHT_DECAY $WEIGHT_DECAY --INCEPTION_LAYERS $INCEPTION_LAYERS --INCEPTION_UNITS $INCEPTION_UNITS --CLASSIFICATION_LAYERS $CLASSIFICATION_LAYERS --CLASSIFICATION_UNITS $CLASSIFICATION_UNITS --FEATURE_DROPOUT $FEATURE_DROPOUT --NODE_DROPOUT $NODE_DROPOUT --BATCH_NORMALIZATION $BATCH_NORMALIZATION --ATTN_NORMALIZATION $ATTN_NORMALIZATION --ATTN_HEADS $ATTN_HEADS
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 18 hours 42 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
slurmstepd: error: Detected 1 oom-kill event(s) in StepId=9646816.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.
