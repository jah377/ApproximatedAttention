Thu 16 Jun 2022 12:12:17 AM CEST
r31n2.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: arxiv
method: bayes
model: SIGNff
iterations: 100
run_trial: false
config: SIGNff.yaml
train_file: hps_SIGNff.py
project_name: sff_arxiv
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 2048
    - 4096
    - 8192
    - 16384
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  DATASET:
    value: arxiv
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_001308-4sannvmz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-shape-97
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/4sannvmz
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-16 00:13:16,478 - wandb.wandb_agent - INFO - Running runs: []
2022-06-16 00:13:16,749 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 00:13:16,750 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 00:13:16,756 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 00:13:21,766 - wandb.wandb_agent - INFO - Running runs: ['uru5fo7z']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_001321-uru5fo7z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-1
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/uru5fo7z
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68063
wandb:    train_loss 1.03643
wandb: training_time 0.95352
wandb:        val_f1 0.61126
wandb:      val_loss 1.28781
wandb: 
wandb: Synced stilted-sweep-1: https://wandb.ai/jah377/sff_arxiv/runs/uru5fo7z
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_001321-uru5fo7z/logs
2022-06-16 00:23:45,530 - wandb.wandb_agent - INFO - Cleaning up finished run: uru5fo7z
2022-06-16 00:23:45,863 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 00:23:45,864 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 00:23:45,870 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 00:23:50,883 - wandb.wandb_agent - INFO - Running runs: ['y359xdfw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_002351-y359xdfw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-2
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/y359xdfw
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.19944
wandb:    train_loss 3.55026
wandb: training_time 0.67391
wandb:        val_f1 0.11386
wandb:      val_loss 3.58329
wandb: 
wandb: Synced pretty-sweep-2: https://wandb.ai/jah377/sff_arxiv/runs/y359xdfw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_002351-y359xdfw/logs
2022-06-16 00:32:00,558 - wandb.wandb_agent - INFO - Cleaning up finished run: y359xdfw
2022-06-16 00:32:00,989 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 00:32:00,989 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 00:32:00,997 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 00:32:06,010 - wandb.wandb_agent - INFO - Running runs: ['0bafjrwm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_003206-0bafjrwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-3
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/0bafjrwm
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17922
wandb:    train_loss 3.64533
wandb: training_time 0.87194
wandb:        val_f1 0.07628
wandb:      val_loss 3.64783
wandb: 
wandb: Synced worldly-sweep-3: https://wandb.ai/jah377/sff_arxiv/runs/0bafjrwm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_003206-0bafjrwm/logs
2022-06-16 00:42:10,227 - wandb.wandb_agent - INFO - Cleaning up finished run: 0bafjrwm
2022-06-16 00:42:10,626 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 00:42:10,627 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 00:42:10,635 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 00:42:15,651 - wandb.wandb_agent - INFO - Running runs: ['4yhdt2hi']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_004215-4yhdt2hi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-4
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/4yhdt2hi
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17931
wandb:    train_loss 3.64531
wandb: training_time 0.82237
wandb:        val_f1 0.07628
wandb:      val_loss 3.64794
wandb: 
wandb: Synced skilled-sweep-4: https://wandb.ai/jah377/sff_arxiv/runs/4yhdt2hi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_004215-4yhdt2hi/logs
2022-06-16 00:52:18,555 - wandb.wandb_agent - INFO - Cleaning up finished run: 4yhdt2hi
2022-06-16 00:52:18,986 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 00:52:18,987 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 00:52:18,993 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 00:52:24,007 - wandb.wandb_agent - INFO - Running runs: ['5gc9imu3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_005224-5gc9imu3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-5
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/5gc9imu3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.24211
wandb:    train_loss 2301.1432
wandb: training_time 1.05437
wandb:        val_f1 0.22195
wandb:      val_loss 1458.75853
wandb: 
wandb: Synced giddy-sweep-5: https://wandb.ai/jah377/sff_arxiv/runs/5gc9imu3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_005224-5gc9imu3/logs
2022-06-16 01:03:54,939 - wandb.wandb_agent - INFO - Cleaning up finished run: 5gc9imu3
2022-06-16 01:03:55,404 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:03:55,404 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 01:03:55,411 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 01:04:00,426 - wandb.wandb_agent - INFO - Running runs: ['zmvppqai']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_010400-zmvppqai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-6
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/zmvppqai
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40809
wandb:    train_loss 2.36735
wandb: training_time 1.35104
wandb:        val_f1 0.40354
wandb:      val_loss 2.44372
wandb: 
wandb: Synced frosty-sweep-6: https://wandb.ai/jah377/sff_arxiv/runs/zmvppqai
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_010400-zmvppqai/logs
2022-06-16 01:16:58,435 - wandb.wandb_agent - INFO - Cleaning up finished run: zmvppqai
2022-06-16 01:16:58,840 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:16:58,841 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 01:16:58,848 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 01:17:03,862 - wandb.wandb_agent - INFO - Running runs: ['o4o7zm3f']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_011703-o4o7zm3f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-7
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/o4o7zm3f
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60629
wandb:    train_loss 1.33433
wandb: training_time 0.70546
wandb:        val_f1 0.56928
wandb:      val_loss 1.48462
wandb: 
wandb: Synced decent-sweep-7: https://wandb.ai/jah377/sff_arxiv/runs/o4o7zm3f
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_011703-o4o7zm3f/logs
2022-06-16 01:25:53,429 - wandb.wandb_agent - INFO - Cleaning up finished run: o4o7zm3f
2022-06-16 01:25:53,844 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:25:53,844 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 01:25:53,851 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:25:58,866 - wandb.wandb_agent - INFO - Running runs: ['32ugpmn9']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_012558-32ugpmn9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-8
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/32ugpmn9
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.18309
wandb:    train_loss 3.46235
wandb: training_time 1.07405
wandb:        val_f1 0.09759
wandb:      val_loss 3.61268
wandb: 
wandb: Synced stilted-sweep-8: https://wandb.ai/jah377/sff_arxiv/runs/32ugpmn9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_012558-32ugpmn9/logs
2022-06-16 01:37:40,352 - wandb.wandb_agent - INFO - Cleaning up finished run: 32ugpmn9
2022-06-16 01:37:40,729 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:37:40,729 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 01:37:40,736 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:37:45,750 - wandb.wandb_agent - INFO - Running runs: ['1882wug0']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_013745-1882wug0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-9
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/1882wug0
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.32025
wandb:    train_loss 2.7001
wandb: training_time 0.94055
wandb:        val_f1 0.30491
wandb:      val_loss 2.81353
wandb: 
wandb: Synced honest-sweep-9: https://wandb.ai/jah377/sff_arxiv/runs/1882wug0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_013745-1882wug0/logs
2022-06-16 01:47:43,435 - wandb.wandb_agent - INFO - Cleaning up finished run: 1882wug0
2022-06-16 01:47:43,838 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:47:43,838 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 01:47:43,844 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 01:47:48,859 - wandb.wandb_agent - INFO - Running runs: ['l6cid5un']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_014748-l6cid5un
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-10
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/l6cid5un
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.18233
wandb:    train_loss 3.08771
wandb: training_time 0.77759
wandb:        val_f1 0.07708
wandb:      val_loss 3.08002
wandb: 
wandb: Synced twilight-sweep-10: https://wandb.ai/jah377/sff_arxiv/runs/l6cid5un
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_014748-l6cid5un/logs
2022-06-16 01:57:10,343 - wandb.wandb_agent - INFO - Cleaning up finished run: l6cid5un
2022-06-16 01:57:10,797 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:57:10,797 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 01:57:10,805 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:57:15,818 - wandb.wandb_agent - INFO - Running runs: ['5104gjgp']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_015715-5104gjgp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-11
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/5104gjgp
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.32218
wandb:    train_loss 2.58265
wandb: training_time 1.25464
wandb:        val_f1 0.23397
wandb:      val_loss 2.73567
wandb: 
wandb: Synced atomic-sweep-11: https://wandb.ai/jah377/sff_arxiv/runs/5104gjgp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_015715-5104gjgp/logs
2022-06-16 02:09:43,316 - wandb.wandb_agent - INFO - Cleaning up finished run: 5104gjgp
2022-06-16 02:09:43,717 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:09:43,718 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 02:09:43,726 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 02:09:48,738 - wandb.wandb_agent - INFO - Running runs: ['pejo4ro0']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_020948-pejo4ro0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-12
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/pejo4ro0
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26409
wandb:    train_loss 3.43488
wandb: training_time 0.82119
wandb:        val_f1 0.20377
wandb:      val_loss 3.51874
wandb: 
wandb: Synced rare-sweep-12: https://wandb.ai/jah377/sff_arxiv/runs/pejo4ro0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_020948-pejo4ro0/logs
2022-06-16 02:19:05,262 - wandb.wandb_agent - INFO - Cleaning up finished run: pejo4ro0
2022-06-16 02:19:06,694 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:19:06,695 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 02:19:06,703 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 02:19:11,714 - wandb.wandb_agent - INFO - Running runs: ['3ohe1o6e']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_021911-3ohe1o6e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-13
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/3ohe1o6e
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6143
wandb:    train_loss 1.34507
wandb: training_time 0.97537
wandb:        val_f1 0.58448
wandb:      val_loss 1.47519
wandb: 
wandb: Synced desert-sweep-13: https://wandb.ai/jah377/sff_arxiv/runs/3ohe1o6e
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_021911-3ohe1o6e/logs
2022-06-16 02:29:55,851 - wandb.wandb_agent - INFO - Cleaning up finished run: 3ohe1o6e
2022-06-16 02:29:56,399 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:29:56,399 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 02:29:56,406 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 02:30:01,423 - wandb.wandb_agent - INFO - Running runs: ['z1zr48s6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_023001-z1zr48s6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-14
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/z1zr48s6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36609
wandb:    train_loss 3.02357
wandb: training_time 0.70961
wandb:        val_f1 0.37458
wandb:      val_loss 3.02652
wandb: 
wandb: Synced devout-sweep-14: https://wandb.ai/jah377/sff_arxiv/runs/z1zr48s6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_023001-z1zr48s6/logs
2022-06-16 02:38:21,277 - wandb.wandb_agent - INFO - Cleaning up finished run: z1zr48s6
2022-06-16 02:38:21,680 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:38:21,680 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 02:38:21,687 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 02:38:26,703 - wandb.wandb_agent - INFO - Running runs: ['m5r8iifm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_023826-m5r8iifm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-15
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/m5r8iifm
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.48398
wandb:    train_loss 1.92162
wandb: training_time 0.96338
wandb:        val_f1 0.49465
wandb:      val_loss 1.92011
wandb: 
wandb: Synced eternal-sweep-15: https://wandb.ai/jah377/sff_arxiv/runs/m5r8iifm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_023826-m5r8iifm/logs
2022-06-16 02:49:01,443 - wandb.wandb_agent - INFO - Cleaning up finished run: m5r8iifm
2022-06-16 02:49:01,847 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:49:01,847 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 02:49:01,855 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 02:49:06,870 - wandb.wandb_agent - INFO - Running runs: ['9h9zahd4']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_024906-9h9zahd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-16
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/9h9zahd4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.12426
wandb:    train_loss 3.63597
wandb: training_time 1.02152
wandb:        val_f1 0.04762
wandb:      val_loss 3.70948
wandb: 
wandb: Synced lively-sweep-16: https://wandb.ai/jah377/sff_arxiv/runs/9h9zahd4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_024906-9h9zahd4/logs
2022-06-16 02:59:45,458 - wandb.wandb_agent - INFO - Cleaning up finished run: 9h9zahd4
2022-06-16 02:59:46,013 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:59:46,014 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 02:59:46,020 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 02:59:51,036 - wandb.wandb_agent - INFO - Running runs: ['h6j7wyva']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_025951-h6j7wyva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-17
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/h6j7wyva
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 11
wandb:      train_f1 0.01562
wandb:    train_loss 3.69195
wandb: training_time 1.20037
wandb:        val_f1 0.01641
wandb:      val_loss 3.66556
wandb: 
wandb: Synced icy-sweep-17: https://wandb.ai/jah377/sff_arxiv/runs/h6j7wyva
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_025951-h6j7wyva/logs
2022-06-16 03:00:32,259 - wandb.wandb_agent - INFO - Cleaning up finished run: h6j7wyva
2022-06-16 03:00:32,678 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:00:32,678 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 03:00:32,684 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 03:00:37,698 - wandb.wandb_agent - INFO - Running runs: ['bbjv4h8j']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_030036-bbjv4h8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-18
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/bbjv4h8j
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40575
wandb:    train_loss 2.36915
wandb: training_time 0.88743
wandb:        val_f1 0.41481
wandb:      val_loss 2.40995
wandb: 
wandb: Synced mild-sweep-18: https://wandb.ai/jah377/sff_arxiv/runs/bbjv4h8j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_030036-bbjv4h8j/logs
2022-06-16 03:11:11,294 - wandb.wandb_agent - INFO - Cleaning up finished run: bbjv4h8j
2022-06-16 03:11:11,785 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:11:11,785 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 03:11:11,791 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 03:11:16,806 - wandb.wandb_agent - INFO - Running runs: ['s5sab4ax']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_031116-s5sab4ax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-19
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/s5sab4ax
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54067
wandb:    train_loss 1.58752
wandb: training_time 1.04866
wandb:        val_f1 0.52844
wandb:      val_loss 1.63402
wandb: 
wandb: Synced flowing-sweep-19: https://wandb.ai/jah377/sff_arxiv/runs/s5sab4ax
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_031116-s5sab4ax/logs
2022-06-16 03:22:37,110 - wandb.wandb_agent - INFO - Cleaning up finished run: s5sab4ax
2022-06-16 03:22:37,581 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:22:37,582 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 03:22:37,588 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 03:22:42,603 - wandb.wandb_agent - INFO - Running runs: ['asw2pjze']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_032242-asw2pjze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-20
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/asw2pjze
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.37887
wandb:    train_loss 2.50919
wandb: training_time 1.16197
wandb:        val_f1 0.37464
wandb:      val_loss 2.53889
wandb: 
wandb: Synced polished-sweep-20: https://wandb.ai/jah377/sff_arxiv/runs/asw2pjze
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_032242-asw2pjze/logs
2022-06-16 03:34:11,702 - wandb.wandb_agent - INFO - Cleaning up finished run: asw2pjze
2022-06-16 03:34:12,114 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:34:12,115 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 03:34:12,123 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 03:34:17,134 - wandb.wandb_agent - INFO - Running runs: ['ggjk3k65']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_033417-ggjk3k65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-21
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ggjk3k65
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.46927
wandb:    train_loss 1.90293
wandb: training_time 1.27412
wandb:        val_f1 0.4726
wandb:      val_loss 1.92925
wandb: 
wandb: Synced gallant-sweep-21: https://wandb.ai/jah377/sff_arxiv/runs/ggjk3k65
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_033417-ggjk3k65/logs
2022-06-16 03:46:29,642 - wandb.wandb_agent - INFO - Cleaning up finished run: ggjk3k65
2022-06-16 03:46:30,150 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:46:30,150 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 03:46:30,156 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 03:46:35,172 - wandb.wandb_agent - INFO - Running runs: ['9o193eia']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_034635-9o193eia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-22
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/9o193eia
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3745
wandb:    train_loss 2.49068
wandb: training_time 0.80815
wandb:        val_f1 0.37538
wandb:      val_loss 2.49078
wandb: 
wandb: Synced lively-sweep-22: https://wandb.ai/jah377/sff_arxiv/runs/9o193eia
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_034635-9o193eia/logs
2022-06-16 03:56:23,986 - wandb.wandb_agent - INFO - Cleaning up finished run: 9o193eia
2022-06-16 03:56:24,367 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:56:24,367 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 03:56:24,375 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 03:56:29,386 - wandb.wandb_agent - INFO - Running runs: ['06h6csqm']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_035629-06h6csqm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-23
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/06h6csqm
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53866
wandb:    train_loss 1.69968
wandb: training_time 0.90759
wandb:        val_f1 0.53324
wandb:      val_loss 1.77074
wandb: 
wandb: Synced atomic-sweep-23: https://wandb.ai/jah377/sff_arxiv/runs/06h6csqm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_035629-06h6csqm/logs
2022-06-16 04:06:43,190 - wandb.wandb_agent - INFO - Cleaning up finished run: 06h6csqm
2022-06-16 04:06:43,646 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:06:43,647 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 04:06:43,655 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 04:06:48,667 - wandb.wandb_agent - INFO - Running runs: ['8wtrtx9w']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_040648-8wtrtx9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-24
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/8wtrtx9w
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17896
wandb:    train_loss 3.64538
wandb: training_time 0.97207
wandb:        val_f1 0.07628
wandb:      val_loss 3.64783
wandb: 
wandb: Synced glad-sweep-24: https://wandb.ai/jah377/sff_arxiv/runs/8wtrtx9w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_040648-8wtrtx9w/logs
2022-06-16 04:17:33,437 - wandb.wandb_agent - INFO - Cleaning up finished run: 8wtrtx9w
2022-06-16 04:17:33,823 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:17:33,823 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 04:17:33,829 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 04:17:38,842 - wandb.wandb_agent - INFO - Running runs: ['g0vlmx5x']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_041738-g0vlmx5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-25
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/g0vlmx5x
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17932
wandb:    train_loss 3.23776
wandb: training_time 0.92057
wandb:        val_f1 0.07628
wandb:      val_loss 3.23094
wandb: 
wandb: Synced royal-sweep-25: https://wandb.ai/jah377/sff_arxiv/runs/g0vlmx5x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_041738-g0vlmx5x/logs
2022-06-16 04:27:57,446 - wandb.wandb_agent - INFO - Cleaning up finished run: g0vlmx5x
2022-06-16 04:27:57,964 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:27:57,964 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 04:27:57,970 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 04:28:02,985 - wandb.wandb_agent - INFO - Running runs: ['6gdlqff2']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_042802-6gdlqff2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-26
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/6gdlqff2
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5344
wandb:    train_loss 1.61887
wandb: training_time 1.29862
wandb:        val_f1 0.52317
wandb:      val_loss 1.67791
wandb: 
wandb: Synced usual-sweep-26: https://wandb.ai/jah377/sff_arxiv/runs/6gdlqff2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_042802-6gdlqff2/logs
2022-06-16 04:40:40,594 - wandb.wandb_agent - INFO - Cleaning up finished run: 6gdlqff2
2022-06-16 04:40:40,965 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:40:40,966 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 04:40:40,973 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 04:40:45,982 - wandb.wandb_agent - INFO - Running runs: ['r2hq7hxc']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_044045-r2hq7hxc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-27
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/r2hq7hxc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27885
wandb:    train_loss 2.84261
wandb: training_time 1.0786
wandb:        val_f1 0.2936
wandb:      val_loss 2.83023
wandb: 
wandb: Synced pleasant-sweep-27: https://wandb.ai/jah377/sff_arxiv/runs/r2hq7hxc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_044045-r2hq7hxc/logs
2022-06-16 04:51:55,734 - wandb.wandb_agent - INFO - Cleaning up finished run: r2hq7hxc
2022-06-16 04:51:56,083 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:51:56,083 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 04:51:56,091 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 04:52:01,116 - wandb.wandb_agent - INFO - Running runs: ['bvt5kvqj']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_045201-bvt5kvqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-28
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/bvt5kvqj
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17856
wandb:    train_loss 3.13019
wandb: training_time 0.80486
wandb:        val_f1 0.07628
wandb:      val_loss 3.23854
wandb: 
wandb: Synced wild-sweep-28: https://wandb.ai/jah377/sff_arxiv/runs/bvt5kvqj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_045201-bvt5kvqj/logs
2022-06-16 05:01:19,144 - wandb.wandb_agent - INFO - Cleaning up finished run: bvt5kvqj
2022-06-16 05:01:19,543 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:01:19,543 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 05:01:19,549 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 05:01:24,562 - wandb.wandb_agent - INFO - Running runs: ['hm50h3vd']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_050124-hm50h3vd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-29
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/hm50h3vd
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.48804
wandb:    train_loss 1.8275
wandb: training_time 0.8193
wandb:        val_f1 0.48555
wandb:      val_loss 1.88222
wandb: 
wandb: Synced deft-sweep-29: https://wandb.ai/jah377/sff_arxiv/runs/hm50h3vd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_050124-hm50h3vd/logs
2022-06-16 05:11:17,371 - wandb.wandb_agent - INFO - Cleaning up finished run: hm50h3vd
2022-06-16 05:11:17,798 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:11:17,798 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 05:11:17,806 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 05:11:22,822 - wandb.wandb_agent - INFO - Running runs: ['imi34t61']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_051122-imi34t61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-30
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/imi34t61
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.28977
wandb:    train_loss 2.83398
wandb: training_time 0.77678
wandb:        val_f1 0.29326
wandb:      val_loss 2.85552
wandb: 
wandb: Synced leafy-sweep-30: https://wandb.ai/jah377/sff_arxiv/runs/imi34t61
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_051122-imi34t61/logs
2022-06-16 05:20:30,006 - wandb.wandb_agent - INFO - Cleaning up finished run: imi34t61
2022-06-16 05:20:30,472 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:20:30,472 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 05:20:30,480 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 05:20:35,494 - wandb.wandb_agent - INFO - Running runs: ['q3o970gw']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_052035-q3o970gw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-31
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/q3o970gw
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27733
wandb:    train_loss 3.02012
wandb: training_time 1.04723
wandb:        val_f1 0.29075
wandb:      val_loss 3.0409
wandb: 
wandb: Synced prime-sweep-31: https://wandb.ai/jah377/sff_arxiv/runs/q3o970gw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_052035-q3o970gw/logs
2022-06-16 05:32:21,382 - wandb.wandb_agent - INFO - Cleaning up finished run: q3o970gw
2022-06-16 05:32:21,782 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:32:21,783 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 05:32:21,790 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 05:32:26,802 - wandb.wandb_agent - INFO - Running runs: ['bxemc552']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_053226-bxemc552
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-32
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/bxemc552
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.58817
wandb:    train_loss 1.44557
wandb: training_time 0.80643
wandb:        val_f1 0.56465
wandb:      val_loss 1.5642
wandb: 
wandb: Synced golden-sweep-32: https://wandb.ai/jah377/sff_arxiv/runs/bxemc552
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_053226-bxemc552/logs
2022-06-16 05:42:03,920 - wandb.wandb_agent - INFO - Cleaning up finished run: bxemc552
2022-06-16 05:42:04,377 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:42:04,377 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 05:42:04,384 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 05:42:09,398 - wandb.wandb_agent - INFO - Running runs: ['hnzs6mws']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_054209-hnzs6mws
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-33
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/hnzs6mws
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.34392
wandb:    train_loss 2.64541
wandb: training_time 0.74027
wandb:        val_f1 0.36411
wandb:      val_loss 2.60665
wandb: 
wandb: Synced rich-sweep-33: https://wandb.ai/jah377/sff_arxiv/runs/hnzs6mws
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_054209-hnzs6mws/logs
2022-06-16 05:51:20,475 - wandb.wandb_agent - INFO - Cleaning up finished run: hnzs6mws
2022-06-16 05:51:20,940 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:51:20,941 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 05:51:20,947 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 05:51:25,962 - wandb.wandb_agent - INFO - Running runs: ['7g5y13j1']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_055125-7g5y13j1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-34
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/7g5y13j1
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54085
wandb:    train_loss 1.67071
wandb: training_time 1.05049
wandb:        val_f1 0.5175
wandb:      val_loss 1.78249
wandb: 
wandb: Synced worldly-sweep-34: https://wandb.ai/jah377/sff_arxiv/runs/7g5y13j1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_055125-7g5y13j1/logs
2022-06-16 06:03:02,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 7g5y13j1
2022-06-16 06:03:02,762 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:03:02,763 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 06:03:02,771 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 06:03:07,780 - wandb.wandb_agent - INFO - Running runs: ['7n0874sh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_060307-7n0874sh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-35
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/7n0874sh
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.35753
wandb:    train_loss 2.58009
wandb: training_time 0.84111
wandb:        val_f1 0.36028
wandb:      val_loss 2.58898
wandb: 
wandb: Synced morning-sweep-35: https://wandb.ai/jah377/sff_arxiv/runs/7n0874sh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_060307-7n0874sh/logs
2022-06-16 06:12:56,099 - wandb.wandb_agent - INFO - Cleaning up finished run: 7n0874sh
2022-06-16 06:12:56,686 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:12:56,687 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 06:12:56,694 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 06:13:01,706 - wandb.wandb_agent - INFO - Running runs: ['f26qvg1i']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_061301-f26qvg1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-36
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/f26qvg1i
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.61203
wandb:    train_loss 1.2943
wandb: training_time 0.99694
wandb:        val_f1 0.58546
wandb:      val_loss 1.40909
wandb: 
wandb: Synced dashing-sweep-36: https://wandb.ai/jah377/sff_arxiv/runs/f26qvg1i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_061301-f26qvg1i/logs
2022-06-16 06:24:11,750 - wandb.wandb_agent - INFO - Cleaning up finished run: f26qvg1i
2022-06-16 06:24:12,243 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:24:12,243 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 06:24:12,250 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 06:24:17,264 - wandb.wandb_agent - INFO - Running runs: ['r3m7ujdy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_062417-r3m7ujdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-37
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/r3m7ujdy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27579
wandb:    train_loss 2.96182
wandb: training_time 1.28885
wandb:        val_f1 0.28682
wandb:      val_loss 2.96214
wandb: 
wandb: Synced logical-sweep-37: https://wandb.ai/jah377/sff_arxiv/runs/r3m7ujdy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_062417-r3m7ujdy/logs
2022-06-16 06:36:34,135 - wandb.wandb_agent - INFO - Cleaning up finished run: r3m7ujdy
2022-06-16 06:36:34,600 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:36:34,600 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 06:36:34,607 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 06:36:39,618 - wandb.wandb_agent - INFO - Running runs: ['ws7bxgv6']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_063639-ws7bxgv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-38
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ws7bxgv6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17901
wandb:    train_loss 3.64536
wandb: training_time 1.065
wandb:        val_f1 0.07628
wandb:      val_loss 3.64784
wandb: 
wandb: Synced gallant-sweep-38: https://wandb.ai/jah377/sff_arxiv/runs/ws7bxgv6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_063639-ws7bxgv6/logs
2022-06-16 06:47:55,159 - wandb.wandb_agent - INFO - Cleaning up finished run: ws7bxgv6
2022-06-16 06:47:55,642 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:47:55,643 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 06:47:55,649 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 06:48:00,662 - wandb.wandb_agent - INFO - Running runs: ['cso9emz3']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_064800-cso9emz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-39
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/cso9emz3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42175
wandb:    train_loss 2.28354
wandb: training_time 0.84477
wandb:        val_f1 0.44163
wandb:      val_loss 2.25379
wandb: 
wandb: Synced warm-sweep-39: https://wandb.ai/jah377/sff_arxiv/runs/cso9emz3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_064800-cso9emz3/logs
2022-06-16 06:57:38,260 - wandb.wandb_agent - INFO - Cleaning up finished run: cso9emz3
2022-06-16 06:57:38,760 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:57:38,761 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 06:57:38,769 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 06:57:43,782 - wandb.wandb_agent - INFO - Running runs: ['dxytgrv3']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_065743-dxytgrv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-40
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/dxytgrv3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27945
wandb:    train_loss 2.8289
wandb: training_time 1.14867
wandb:        val_f1 0.29588
wandb:      val_loss 2.79374
wandb: 
wandb: Synced rose-sweep-40: https://wandb.ai/jah377/sff_arxiv/runs/dxytgrv3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_065743-dxytgrv3/logs
2022-06-16 07:09:26,143 - wandb.wandb_agent - INFO - Cleaning up finished run: dxytgrv3
2022-06-16 07:09:26,670 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:09:26,670 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 07:09:26,677 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:09:31,690 - wandb.wandb_agent - INFO - Running runs: ['8zr02w39']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_070931-8zr02w39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-41
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/8zr02w39
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.49915
wandb:    train_loss 1.86849
wandb: training_time 0.86787
wandb:        val_f1 0.49307
wandb:      val_loss 1.9241
wandb: 
wandb: Synced rare-sweep-41: https://wandb.ai/jah377/sff_arxiv/runs/8zr02w39
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_070931-8zr02w39/logs
2022-06-16 07:19:14,775 - wandb.wandb_agent - INFO - Cleaning up finished run: 8zr02w39
2022-06-16 07:19:15,486 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:19:15,486 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 07:19:15,494 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:19:20,506 - wandb.wandb_agent - INFO - Running runs: ['iocyel4d']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_071920-iocyel4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-42
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/iocyel4d
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 43
wandb:      train_f1 0.17919
wandb:    train_loss 3.64531
wandb: training_time 1.35573
wandb:        val_f1 0.07628
wandb:      val_loss 3.64779
wandb: 
wandb: Synced glorious-sweep-42: https://wandb.ai/jah377/sff_arxiv/runs/iocyel4d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_071920-iocyel4d/logs
2022-06-16 07:21:18,935 - wandb.wandb_agent - INFO - Cleaning up finished run: iocyel4d
2022-06-16 07:21:19,459 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:21:19,460 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 07:21:19,466 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:21:24,478 - wandb.wandb_agent - INFO - Running runs: ['hf4dz0h9']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_072124-hf4dz0h9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-43
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/hf4dz0h9
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.34071
wandb:    train_loss 3.0988
wandb: training_time 0.7462
wandb:        val_f1 0.35786
wandb:      val_loss 3.15314
wandb: 
wandb: Synced dauntless-sweep-43: https://wandb.ai/jah377/sff_arxiv/runs/hf4dz0h9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_072124-hf4dz0h9/logs
2022-06-16 07:30:32,794 - wandb.wandb_agent - INFO - Cleaning up finished run: hf4dz0h9
2022-06-16 07:30:33,409 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:30:33,410 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 07:30:33,416 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:30:38,432 - wandb.wandb_agent - INFO - Running runs: ['2n4506ix']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_073038-2n4506ix
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-44
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/2n4506ix
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55599
wandb:    train_loss 1.52597
wandb: training_time 0.84942
wandb:        val_f1 0.55196
wandb:      val_loss 1.53739
wandb: 
wandb: Synced smooth-sweep-44: https://wandb.ai/jah377/sff_arxiv/runs/2n4506ix
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_073038-2n4506ix/logs
2022-06-16 07:40:25,730 - wandb.wandb_agent - INFO - Cleaning up finished run: 2n4506ix
2022-06-16 07:40:26,417 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:40:26,417 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 07:40:26,424 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:40:31,438 - wandb.wandb_agent - INFO - Running runs: ['xywg3k9o']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_074031-xywg3k9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-45
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/xywg3k9o
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38478
wandb:    train_loss 2.33802
wandb: training_time 0.94146
wandb:        val_f1 0.39911
wandb:      val_loss 2.32545
wandb: 
wandb: Synced deft-sweep-45: https://wandb.ai/jah377/sff_arxiv/runs/xywg3k9o
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_074031-xywg3k9o/logs
2022-06-16 07:51:05,262 - wandb.wandb_agent - INFO - Cleaning up finished run: xywg3k9o
2022-06-16 07:51:05,757 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:51:05,758 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 07:51:05,764 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 07:51:10,778 - wandb.wandb_agent - INFO - Running runs: ['njsm49jk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_075110-njsm49jk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-46
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/njsm49jk
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17923
wandb:    train_loss 3.23914
wandb: training_time 1.17051
wandb:        val_f1 0.07628
wandb:      val_loss 3.23201
wandb: 
wandb: Synced neat-sweep-46: https://wandb.ai/jah377/sff_arxiv/runs/njsm49jk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_075110-njsm49jk/logs
2022-06-16 08:02:53,258 - wandb.wandb_agent - INFO - Cleaning up finished run: njsm49jk
2022-06-16 08:02:53,770 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:02:53,770 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 08:02:53,778 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 08:02:58,793 - wandb.wandb_agent - INFO - Running runs: ['vz1hg59y']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_080259-vz1hg59y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-47
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/vz1hg59y
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 11
wandb:      train_f1 0.01002
wandb:    train_loss 3.74856
wandb: training_time 0.77497
wandb:        val_f1 0.00577
wandb:      val_loss 3.77238
wandb: 
wandb: Synced sunny-sweep-47: https://wandb.ai/jah377/sff_arxiv/runs/vz1hg59y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_080259-vz1hg59y/logs
2022-06-16 08:03:34,826 - wandb.wandb_agent - INFO - Cleaning up finished run: vz1hg59y
2022-06-16 08:03:35,319 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:03:35,320 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 08:03:35,326 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 08:03:40,338 - wandb.wandb_agent - INFO - Running runs: ['zkok4h3s']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_080339-zkok4h3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-48
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/zkok4h3s
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.08413
wandb:    train_loss 3.63165
wandb: training_time 0.91774
wandb:        val_f1 0.06309
wandb:      val_loss 3.64039
wandb: 
wandb: Synced daily-sweep-48: https://wandb.ai/jah377/sff_arxiv/runs/zkok4h3s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_080339-zkok4h3s/logs
2022-06-16 08:13:38,973 - wandb.wandb_agent - INFO - Cleaning up finished run: zkok4h3s
2022-06-16 08:13:39,543 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:13:39,543 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 08:13:39,550 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 08:13:44,565 - wandb.wandb_agent - INFO - Running runs: ['ilf3akd0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_081344-ilf3akd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-49
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ilf3akd0
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55238
wandb:    train_loss 1.55348
wandb: training_time 0.79782
wandb:        val_f1 0.5519
wandb:      val_loss 1.55718
wandb: 
wandb: Synced zany-sweep-49: https://wandb.ai/jah377/sff_arxiv/runs/ilf3akd0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_081344-ilf3akd0/logs
2022-06-16 08:23:11,413 - wandb.wandb_agent - INFO - Cleaning up finished run: ilf3akd0
2022-06-16 08:23:12,120 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:23:12,120 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 08:23:12,126 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 08:23:17,137 - wandb.wandb_agent - INFO - Running runs: ['zq5urvcy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_082317-zq5urvcy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-50
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/zq5urvcy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63583
wandb:    train_loss 1.27466
wandb: training_time 0.8001
wandb:        val_f1 0.60056
wandb:      val_loss 1.39759
wandb: 
wandb: Synced easy-sweep-50: https://wandb.ai/jah377/sff_arxiv/runs/zq5urvcy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_082317-zq5urvcy/logs
2022-06-16 08:32:57,560 - wandb.wandb_agent - INFO - Cleaning up finished run: zq5urvcy
2022-06-16 08:32:58,134 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:32:58,135 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 08:32:58,141 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 08:33:03,156 - wandb.wandb_agent - INFO - Running runs: ['um1h88rc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_083303-um1h88rc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-51
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/um1h88rc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55686
wandb:    train_loss 1.55077
wandb: training_time 1.01918
wandb:        val_f1 0.53972
wandb:      val_loss 1.65176
wandb: 
wandb: Synced spring-sweep-51: https://wandb.ai/jah377/sff_arxiv/runs/um1h88rc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_083303-um1h88rc/logs
2022-06-16 08:44:08,502 - wandb.wandb_agent - INFO - Cleaning up finished run: um1h88rc
2022-06-16 08:44:09,197 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:44:09,198 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 08:44:09,206 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 08:44:14,220 - wandb.wandb_agent - INFO - Running runs: ['e6zkhv2n']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_084413-e6zkhv2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-52
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/e6zkhv2n
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27744
wandb:    train_loss 2.90649
wandb: training_time 1.36913
wandb:        val_f1 0.29189
wandb:      val_loss 2.88366
wandb: 
wandb: Synced swept-sweep-52: https://wandb.ai/jah377/sff_arxiv/runs/e6zkhv2n
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_084413-e6zkhv2n/logs
2022-06-16 08:57:36,861 - wandb.wandb_agent - INFO - Cleaning up finished run: e6zkhv2n
2022-06-16 08:57:37,364 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:57:37,364 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 08:57:37,370 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 08:57:42,382 - wandb.wandb_agent - INFO - Running runs: ['un3dqvt4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_085742-un3dqvt4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-53
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/un3dqvt4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1792
wandb:    train_loss 3.64535
wandb: training_time 0.88731
wandb:        val_f1 0.07628
wandb:      val_loss 3.64784
wandb: 
wandb: Synced volcanic-sweep-53: https://wandb.ai/jah377/sff_arxiv/runs/un3dqvt4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_085742-un3dqvt4/logs
2022-06-16 09:07:19,940 - wandb.wandb_agent - INFO - Cleaning up finished run: un3dqvt4
2022-06-16 09:07:20,489 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:07:20,489 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 09:07:20,496 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 09:07:25,510 - wandb.wandb_agent - INFO - Running runs: ['22g5tdw1']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_090725-22g5tdw1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-54
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/22g5tdw1
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17887
wandb:    train_loss 3.23904
wandb: training_time 0.98537
wandb:        val_f1 0.07628
wandb:      val_loss 3.23186
wandb: 
wandb: Synced quiet-sweep-54: https://wandb.ai/jah377/sff_arxiv/runs/22g5tdw1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_090725-22g5tdw1/logs
2022-06-16 09:18:05,069 - wandb.wandb_agent - INFO - Cleaning up finished run: 22g5tdw1
2022-06-16 09:18:05,610 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:18:05,610 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 09:18:05,618 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 09:18:10,630 - wandb.wandb_agent - INFO - Running runs: ['7nokqhj6']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_091810-7nokqhj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-55
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/7nokqhj6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.41429
wandb:    train_loss 2.39746
wandb: training_time 1.07677
wandb:        val_f1 0.43072
wandb:      val_loss 2.38196
wandb: 
wandb: Synced prime-sweep-55: https://wandb.ai/jah377/sff_arxiv/runs/7nokqhj6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_091810-7nokqhj6/logs
2022-06-16 09:29:55,852 - wandb.wandb_agent - INFO - Cleaning up finished run: 7nokqhj6
2022-06-16 09:29:56,673 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:29:56,674 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 09:29:56,680 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 09:30:01,694 - wandb.wandb_agent - INFO - Running runs: ['jz97hut9']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_093001-jz97hut9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-56
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/jz97hut9
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.37671
wandb:    train_loss 2.99262
wandb: training_time 1.05471
wandb:        val_f1 0.37622
wandb:      val_loss 3.0756
wandb: 
wandb: Synced sleek-sweep-56: https://wandb.ai/jah377/sff_arxiv/runs/jz97hut9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_093001-jz97hut9/logs
2022-06-16 09:41:42,888 - wandb.wandb_agent - INFO - Cleaning up finished run: jz97hut9
2022-06-16 09:41:43,572 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:41:43,572 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 09:41:43,578 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 09:41:48,590 - wandb.wandb_agent - INFO - Running runs: ['ig3az0ty']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_094148-ig3az0ty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-57
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ig3az0ty
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17961
wandb:    train_loss 3.64549
wandb: training_time 0.87612
wandb:        val_f1 0.07628
wandb:      val_loss 3.64796
wandb: 
wandb: Synced hardy-sweep-57: https://wandb.ai/jah377/sff_arxiv/runs/ig3az0ty
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_094148-ig3az0ty/logs
2022-06-16 09:52:02,330 - wandb.wandb_agent - INFO - Cleaning up finished run: ig3az0ty
2022-06-16 09:52:03,196 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:52:03,197 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 09:52:03,205 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 09:52:08,220 - wandb.wandb_agent - INFO - Running runs: ['jrpb004d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_095208-jrpb004d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-58
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/jrpb004d
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42829
wandb:    train_loss 2.22593
wandb: training_time 0.8706
wandb:        val_f1 0.44904
wandb:      val_loss 2.2104
wandb: 
wandb: Synced efficient-sweep-58: https://wandb.ai/jah377/sff_arxiv/runs/jrpb004d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_095208-jrpb004d/logs
2022-06-16 10:02:01,470 - wandb.wandb_agent - INFO - Cleaning up finished run: jrpb004d
2022-06-16 10:02:02,113 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:02:02,114 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 10:02:02,122 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 10:02:07,134 - wandb.wandb_agent - INFO - Running runs: ['tif493tr']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_100207-tif493tr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-59
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/tif493tr
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.44719
wandb:    train_loss 2.5949
wandb: training_time 0.75833
wandb:        val_f1 0.45381
wandb:      val_loss 2.61201
wandb: 
wandb: Synced dashing-sweep-59: https://wandb.ai/jah377/sff_arxiv/runs/tif493tr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_100207-tif493tr/logs
2022-06-16 10:10:52,819 - wandb.wandb_agent - INFO - Cleaning up finished run: tif493tr
2022-06-16 10:10:53,359 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:10:53,359 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 10:10:53,365 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 10:10:58,380 - wandb.wandb_agent - INFO - Running runs: ['cv6gaj99']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_101058-cv6gaj99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-60
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/cv6gaj99
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.18782
wandb:    train_loss 3.14099
wandb: training_time 0.88337
wandb:        val_f1 0.08299
wandb:      val_loss 3.16997
wandb: 
wandb: Synced fine-sweep-60: https://wandb.ai/jah377/sff_arxiv/runs/cv6gaj99
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_101058-cv6gaj99/logs
2022-06-16 10:21:01,275 - wandb.wandb_agent - INFO - Cleaning up finished run: cv6gaj99
2022-06-16 10:21:01,811 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:21:01,811 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 10:21:01,819 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 10:21:06,830 - wandb.wandb_agent - INFO - Running runs: ['q9updfoy']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_102106-q9updfoy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-61
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/q9updfoy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50465
wandb:    train_loss 1.72567
wandb: training_time 0.84147
wandb:        val_f1 0.5074
wandb:      val_loss 1.70059
wandb: 
wandb: Synced visionary-sweep-61: https://wandb.ai/jah377/sff_arxiv/runs/q9updfoy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_102106-q9updfoy/logs
2022-06-16 10:30:34,131 - wandb.wandb_agent - INFO - Cleaning up finished run: q9updfoy
2022-06-16 10:30:34,674 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:30:34,675 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 10:30:34,683 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 10:30:39,698 - wandb.wandb_agent - INFO - Running runs: ['7r4kks9r']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_103039-7r4kks9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-62
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/7r4kks9r
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17917
wandb:    train_loss 3.08031
wandb: training_time 1.43331
wandb:        val_f1 0.07628
wandb:      val_loss 3.02763
wandb: 
wandb: Synced splendid-sweep-62: https://wandb.ai/jah377/sff_arxiv/runs/7r4kks9r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_103039-7r4kks9r/logs
2022-06-16 10:44:45,069 - wandb.wandb_agent - INFO - Cleaning up finished run: 7r4kks9r
2022-06-16 10:44:45,619 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:44:45,619 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 10:44:45,625 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 10:44:50,641 - wandb.wandb_agent - INFO - Running runs: ['3d252vyd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_104450-3d252vyd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-63
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/3d252vyd
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17917
wandb:    train_loss 3.64534
wandb: training_time 1.0252
wandb:        val_f1 0.07628
wandb:      val_loss 3.64783
wandb: 
wandb: Synced astral-sweep-63: https://wandb.ai/jah377/sff_arxiv/runs/3d252vyd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_104450-3d252vyd/logs
2022-06-16 10:56:07,682 - wandb.wandb_agent - INFO - Cleaning up finished run: 3d252vyd
2022-06-16 10:56:08,184 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:56:08,185 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 10:56:08,193 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 10:56:13,207 - wandb.wandb_agent - INFO - Running runs: ['y751cap8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_105613-y751cap8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-64
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/y751cap8
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 11
wandb:      train_f1 0.02111
wandb:    train_loss 3.73409
wandb: training_time 0.90754
wandb:        val_f1 0.01326
wandb:      val_loss 3.72335
wandb: 
wandb: Synced polished-sweep-64: https://wandb.ai/jah377/sff_arxiv/runs/y751cap8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_105613-y751cap8/logs
2022-06-16 10:56:54,665 - wandb.wandb_agent - INFO - Cleaning up finished run: y751cap8
2022-06-16 10:56:55,146 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:56:55,147 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 10:56:55,154 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 10:57:00,170 - wandb.wandb_agent - INFO - Running runs: ['ewa74l7t']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_105659-ewa74l7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-65
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ewa74l7t
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17963
wandb:    train_loss 3.64527
wandb: training_time 0.70717
wandb:        val_f1 0.07628
wandb:      val_loss 3.64786
wandb: 
wandb: Synced mild-sweep-65: https://wandb.ai/jah377/sff_arxiv/runs/ewa74l7t
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_105659-ewa74l7t/logs
2022-06-16 11:05:42,274 - wandb.wandb_agent - INFO - Cleaning up finished run: ewa74l7t
2022-06-16 11:05:42,843 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:05:42,843 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 11:05:42,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 11:05:47,862 - wandb.wandb_agent - INFO - Running runs: ['o8sct92i']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_110547-o8sct92i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-66
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/o8sct92i
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50049
wandb:    train_loss 2.16741
wandb: training_time 0.8523
wandb:        val_f1 0.5078
wandb:      val_loss 2.17911
wandb: 
wandb: Synced fearless-sweep-66: https://wandb.ai/jah377/sff_arxiv/runs/o8sct92i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_110547-o8sct92i/logs
2022-06-16 11:15:30,406 - wandb.wandb_agent - INFO - Cleaning up finished run: o8sct92i
2022-06-16 11:15:30,928 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:15:30,928 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 11:15:30,935 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 11:15:35,950 - wandb.wandb_agent - INFO - Running runs: ['6e3vww1i']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_111536-6e3vww1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-67
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/6e3vww1i
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.02258
wandb:    train_loss 3.66047
wandb: training_time 0.80357
wandb:        val_f1 0.01084
wandb:      val_loss 3.66577
wandb: 
wandb: Synced mild-sweep-67: https://wandb.ai/jah377/sff_arxiv/runs/6e3vww1i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_111536-6e3vww1i/logs
2022-06-16 11:24:39,070 - wandb.wandb_agent - INFO - Cleaning up finished run: 6e3vww1i
2022-06-16 11:24:39,606 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:24:39,606 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 11:24:39,612 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 11:24:44,626 - wandb.wandb_agent - INFO - Running runs: ['6x1uvzv9']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_112444-6x1uvzv9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-68
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/6x1uvzv9
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17928
wandb:    train_loss 3.6453
wandb: training_time 0.6674
wandb:        val_f1 0.07628
wandb:      val_loss 3.64783
wandb: 
wandb: Synced stellar-sweep-68: https://wandb.ai/jah377/sff_arxiv/runs/6x1uvzv9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_112444-6x1uvzv9/logs
2022-06-16 11:32:44,718 - wandb.wandb_agent - INFO - Cleaning up finished run: 6x1uvzv9
2022-06-16 11:32:45,156 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:32:45,156 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 11:32:45,163 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 11:32:50,178 - wandb.wandb_agent - INFO - Running runs: ['cvy6g78r']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_113250-cvy6g78r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-69
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/cvy6g78r
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.20629
wandb:    train_loss 3.52694
wandb: training_time 0.8291
wandb:        val_f1 0.11554
wandb:      val_loss 3.53309
wandb: 
wandb: Synced dry-sweep-69: https://wandb.ai/jah377/sff_arxiv/runs/cvy6g78r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_113250-cvy6g78r/logs
2022-06-16 11:42:29,624 - wandb.wandb_agent - INFO - Cleaning up finished run: cvy6g78r
2022-06-16 11:42:30,286 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:42:30,286 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 11:42:30,294 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 11:42:35,309 - wandb.wandb_agent - INFO - Running runs: ['79ivqe5y']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_114235-79ivqe5y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-70
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/79ivqe5y
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42668
wandb:    train_loss 2.34408
wandb: training_time 0.73042
wandb:        val_f1 0.44515
wandb:      val_loss 2.2879
wandb: 
wandb: Synced leafy-sweep-70: https://wandb.ai/jah377/sff_arxiv/runs/79ivqe5y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_114235-79ivqe5y/logs
2022-06-16 11:51:21,947 - wandb.wandb_agent - INFO - Cleaning up finished run: 79ivqe5y
2022-06-16 11:51:22,607 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:51:22,608 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 11:51:22,614 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 11:51:27,629 - wandb.wandb_agent - INFO - Running runs: ['odola7u3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_115127-odola7u3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-71
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/odola7u3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.24928
wandb:    train_loss 2.79323
wandb: training_time 0.6673
wandb:        val_f1 0.23289
wandb:      val_loss 2.74347
wandb: 
wandb: Synced valiant-sweep-71: https://wandb.ai/jah377/sff_arxiv/runs/odola7u3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_115127-odola7u3/logs
2022-06-16 12:00:03,750 - wandb.wandb_agent - INFO - Cleaning up finished run: odola7u3
2022-06-16 12:00:04,296 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:00:04,296 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 12:00:04,302 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 12:00:09,314 - wandb.wandb_agent - INFO - Running runs: ['adyrfggn']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_120009-adyrfggn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-72
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/adyrfggn
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64099
wandb:    train_loss 1.23487
wandb: training_time 0.80317
wandb:        val_f1 0.5667
wandb:      val_loss 1.4823
wandb: 
wandb: Synced dulcet-sweep-72: https://wandb.ai/jah377/sff_arxiv/runs/adyrfggn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_120009-adyrfggn/logs
2022-06-16 12:09:21,417 - wandb.wandb_agent - INFO - Cleaning up finished run: adyrfggn
2022-06-16 12:09:21,984 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:09:21,984 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 12:09:21,991 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 12:09:27,002 - wandb.wandb_agent - INFO - Running runs: ['00b4hvhs']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_120926-00b4hvhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-73
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/00b4hvhs
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5037
wandb:    train_loss 1.90478
wandb: training_time 0.85613
wandb:        val_f1 0.51341
wandb:      val_loss 1.91372
wandb: 
wandb: Synced quiet-sweep-73: https://wandb.ai/jah377/sff_arxiv/runs/00b4hvhs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_120926-00b4hvhs/logs
2022-06-16 12:19:24,740 - wandb.wandb_agent - INFO - Cleaning up finished run: 00b4hvhs
2022-06-16 12:19:25,371 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:19:25,372 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 12:19:25,379 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 12:19:30,390 - wandb.wandb_agent - INFO - Running runs: ['p6djru12']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_121930-p6djru12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-74
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/p6djru12
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52315
wandb:    train_loss 1.7544
wandb: training_time 1.0042
wandb:        val_f1 0.52582
wandb:      val_loss 1.78257
wandb: 
wandb: Synced smooth-sweep-74: https://wandb.ai/jah377/sff_arxiv/runs/p6djru12
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_121930-p6djru12/logs
2022-06-16 12:30:15,353 - wandb.wandb_agent - INFO - Cleaning up finished run: p6djru12
2022-06-16 12:30:15,886 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:30:15,886 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 12:30:15,894 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 12:30:20,910 - wandb.wandb_agent - INFO - Running runs: ['ngjo094i']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_123020-ngjo094i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-75
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ngjo094i
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.58485
wandb:    train_loss 1.41374
wandb: training_time 0.8293
wandb:        val_f1 0.56505
wandb:      val_loss 1.49373
wandb: 
wandb: Synced rural-sweep-75: https://wandb.ai/jah377/sff_arxiv/runs/ngjo094i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_123020-ngjo094i/logs
2022-06-16 12:39:47,542 - wandb.wandb_agent - INFO - Cleaning up finished run: ngjo094i
2022-06-16 12:39:48,704 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:39:48,704 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 12:39:48,712 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 12:39:53,726 - wandb.wandb_agent - INFO - Running runs: ['88komrg6']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_123953-88komrg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-76
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/88komrg6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47936
wandb:    train_loss 2.06341
wandb: training_time 0.87289
wandb:        val_f1 0.49508
wandb:      val_loss 2.06757
wandb: 
wandb: Synced noble-sweep-76: https://wandb.ai/jah377/sff_arxiv/runs/88komrg6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_123953-88komrg6/logs
2022-06-16 12:49:47,700 - wandb.wandb_agent - INFO - Cleaning up finished run: 88komrg6
2022-06-16 12:49:48,184 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:49:48,185 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 12:49:48,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 12:49:53,207 - wandb.wandb_agent - INFO - Running runs: ['8mnvdqvx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_124953-8mnvdqvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-77
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/8mnvdqvx
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.24658
wandb:    train_loss 3.25391
wandb: training_time 1.44301
wandb:        val_f1 0.16732
wandb:      val_loss 3.26714
wandb: 
wandb: Synced deep-sweep-77: https://wandb.ai/jah377/sff_arxiv/runs/8mnvdqvx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_124953-8mnvdqvx/logs
2022-06-16 13:03:28,193 - wandb.wandb_agent - INFO - Cleaning up finished run: 8mnvdqvx
2022-06-16 13:03:29,172 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:03:29,172 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 13:03:29,179 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 13:03:34,190 - wandb.wandb_agent - INFO - Running runs: ['928xx2pv']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_130334-928xx2pv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-78
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/928xx2pv
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17861
wandb:    train_loss 3.64535
wandb: training_time 0.85576
wandb:        val_f1 0.07628
wandb:      val_loss 3.64789
wandb: 
wandb: Synced vivid-sweep-78: https://wandb.ai/jah377/sff_arxiv/runs/928xx2pv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_130334-928xx2pv/logs
2022-06-16 13:13:43,914 - wandb.wandb_agent - INFO - Cleaning up finished run: 928xx2pv
2022-06-16 13:13:44,509 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:13:44,509 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 13:13:44,516 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 13:13:49,530 - wandb.wandb_agent - INFO - Running runs: ['aof4p9tc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_131349-aof4p9tc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-79
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/aof4p9tc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1503
wandb:    train_loss 3.54545
wandb: training_time 0.94924
wandb:        val_f1 0.09044
wandb:      val_loss 3.64176
wandb: 
wandb: Synced prime-sweep-79: https://wandb.ai/jah377/sff_arxiv/runs/aof4p9tc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_131349-aof4p9tc/logs
2022-06-16 13:24:03,593 - wandb.wandb_agent - INFO - Cleaning up finished run: aof4p9tc
2022-06-16 13:24:04,254 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:24:04,254 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 13:24:04,260 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 13:24:09,274 - wandb.wandb_agent - INFO - Running runs: ['fbrqx4l0']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_132409-fbrqx4l0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-80
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/fbrqx4l0
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56077
wandb:    train_loss 1.5406
wandb: training_time 0.84897
wandb:        val_f1 0.55327
wandb:      val_loss 1.599
wandb: 
wandb: Synced stellar-sweep-80: https://wandb.ai/jah377/sff_arxiv/runs/fbrqx4l0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_132409-fbrqx4l0/logs
2022-06-16 13:34:07,227 - wandb.wandb_agent - INFO - Cleaning up finished run: fbrqx4l0
2022-06-16 13:34:07,735 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:34:07,736 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 13:34:07,743 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 13:34:12,758 - wandb.wandb_agent - INFO - Running runs: ['nwsdm9cm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_133412-nwsdm9cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-81
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/nwsdm9cm
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17908
wandb:    train_loss 4.80578
wandb: training_time 1.20271
wandb:        val_f1 0.07628
wandb:      val_loss 4.09249
wandb: 
wandb: Synced sunny-sweep-81: https://wandb.ai/jah377/sff_arxiv/runs/nwsdm9cm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_133412-nwsdm9cm/logs
2022-06-16 13:46:09,653 - wandb.wandb_agent - INFO - Cleaning up finished run: nwsdm9cm
2022-06-16 13:46:10,287 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:46:10,287 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 13:46:10,294 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 13:46:15,309 - wandb.wandb_agent - INFO - Running runs: ['m0o3plr1']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_134615-m0o3plr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-82
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/m0o3plr1
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.027
wandb:    train_loss 3.69665
wandb: training_time 0.83271
wandb:        val_f1 0.02087
wandb:      val_loss 3.6911
wandb: 
wandb: Synced logical-sweep-82: https://wandb.ai/jah377/sff_arxiv/runs/m0o3plr1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_134615-m0o3plr1/logs
2022-06-16 13:56:18,584 - wandb.wandb_agent - INFO - Cleaning up finished run: m0o3plr1
2022-06-16 13:56:19,223 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:56:19,223 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 13:56:19,230 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 13:56:24,242 - wandb.wandb_agent - INFO - Running runs: ['ywtx63cl']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_135624-ywtx63cl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-83
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ywtx63cl
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26294
wandb:    train_loss 2.78543
wandb: training_time 0.66021
wandb:        val_f1 0.25883
wandb:      val_loss 2.74637
wandb: 
wandb: Synced fancy-sweep-83: https://wandb.ai/jah377/sff_arxiv/runs/ywtx63cl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_135624-ywtx63cl/logs
2022-06-16 14:04:23,803 - wandb.wandb_agent - INFO - Cleaning up finished run: ywtx63cl
2022-06-16 14:04:25,202 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:04:25,202 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 14:04:25,209 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:04:30,222 - wandb.wandb_agent - INFO - Running runs: ['ta9xfzox']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_140430-ta9xfzox
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-84
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ta9xfzox
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 13
wandb:      train_f1 0.17891
wandb:    train_loss 3.644
wandb: training_time 0.77687
wandb:        val_f1 0.07628
wandb:      val_loss 3.64723
wandb: 
wandb: Synced glad-sweep-84: https://wandb.ai/jah377/sff_arxiv/runs/ta9xfzox
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_140430-ta9xfzox/logs
2022-06-16 14:05:11,430 - wandb.wandb_agent - INFO - Cleaning up finished run: ta9xfzox
2022-06-16 14:05:12,143 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:05:12,144 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 14:05:12,152 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:05:17,166 - wandb.wandb_agent - INFO - Running runs: ['n3h775z4']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_140516-n3h775z4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-85
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/n3h775z4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50032
wandb:    train_loss 1.76949
wandb: training_time 0.81385
wandb:        val_f1 0.50703
wandb:      val_loss 1.72595
wandb: 
wandb: Synced eager-sweep-85: https://wandb.ai/jah377/sff_arxiv/runs/n3h775z4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_140516-n3h775z4/logs
2022-06-16 14:14:39,706 - wandb.wandb_agent - INFO - Cleaning up finished run: n3h775z4
2022-06-16 14:14:40,489 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:14:40,489 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 14:14:40,496 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:14:45,510 - wandb.wandb_agent - INFO - Running runs: ['obut9cvv']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_141445-obut9cvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-86
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/obut9cvv
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.23111
wandb:    train_loss 2.86867
wandb: training_time 0.70269
wandb:        val_f1 0.19283
wandb:      val_loss 2.81689
wandb: 
wandb: Synced vocal-sweep-86: https://wandb.ai/jah377/sff_arxiv/runs/obut9cvv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_141445-obut9cvv/logs
2022-06-16 14:23:36,971 - wandb.wandb_agent - INFO - Cleaning up finished run: obut9cvv
2022-06-16 14:23:37,905 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:23:37,905 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 14:23:37,913 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:23:42,926 - wandb.wandb_agent - INFO - Running runs: ['nmjvnsyo']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_142342-nmjvnsyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-87
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/nmjvnsyo
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 224
wandb:      train_f1 0.14443
wandb:    train_loss 3.64728
wandb: training_time 0.90331
wandb:        val_f1 0.10208
wandb:      val_loss 3.647
wandb: 
wandb: Synced dandy-sweep-87: https://wandb.ai/jah377/sff_arxiv/runs/nmjvnsyo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_142342-nmjvnsyo/logs
2022-06-16 14:31:17,200 - wandb.wandb_agent - INFO - Cleaning up finished run: nmjvnsyo
2022-06-16 14:31:18,559 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:31:18,559 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 14:31:18,566 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 14:31:23,578 - wandb.wandb_agent - INFO - Running runs: ['afv4fyio']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_143123-afv4fyio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-88
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/afv4fyio
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.10501
wandb:    train_loss 3.61102
wandb: training_time 1.0875
wandb:        val_f1 0.05295
wandb:      val_loss 3.695
wandb: 
wandb: Synced super-sweep-88: https://wandb.ai/jah377/sff_arxiv/runs/afv4fyio
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_143123-afv4fyio/logs
2022-06-16 14:42:29,437 - wandb.wandb_agent - INFO - Cleaning up finished run: afv4fyio
2022-06-16 14:42:29,980 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:42:29,980 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 14:42:29,987 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:42:34,998 - wandb.wandb_agent - INFO - Running runs: ['gfgh5g1b']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_144234-gfgh5g1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-89
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/gfgh5g1b
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.16329
wandb:    train_loss 3.52469
wandb: training_time 0.77202
wandb:        val_f1 0.15756
wandb:      val_loss 3.51918
wandb: 
wandb: Synced astral-sweep-89: https://wandb.ai/jah377/sff_arxiv/runs/gfgh5g1b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_144234-gfgh5g1b/logs
2022-06-16 14:51:42,002 - wandb.wandb_agent - INFO - Cleaning up finished run: gfgh5g1b
2022-06-16 14:51:42,670 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:51:42,671 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 14:51:42,677 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:51:47,690 - wandb.wandb_agent - INFO - Running runs: ['8q7nzlpz']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_145147-8q7nzlpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-90
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/8q7nzlpz
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.18252
wandb:    train_loss 3.44986
wandb: training_time 0.94419
wandb:        val_f1 0.10765
wandb:      val_loss 3.56661
wandb: 
wandb: Synced jumping-sweep-90: https://wandb.ai/jah377/sff_arxiv/runs/8q7nzlpz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_145147-8q7nzlpz/logs
2022-06-16 15:02:54,218 - wandb.wandb_agent - INFO - Cleaning up finished run: 8q7nzlpz
2022-06-16 15:02:54,857 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:02:54,857 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 15:02:54,864 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 15:02:59,878 - wandb.wandb_agent - INFO - Running runs: ['1gmntfpg']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_150259-1gmntfpg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-91
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/1gmntfpg
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5288
wandb:    train_loss 1.69564
wandb: training_time 1.18912
wandb:        val_f1 0.52915
wandb:      val_loss 1.71972
wandb: 
wandb: Synced wobbly-sweep-91: https://wandb.ai/jah377/sff_arxiv/runs/1gmntfpg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_150259-1gmntfpg/logs
2022-06-16 15:14:52,532 - wandb.wandb_agent - INFO - Cleaning up finished run: 1gmntfpg
2022-06-16 15:14:53,387 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:14:53,387 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 15:14:53,395 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 15:14:58,406 - wandb.wandb_agent - INFO - Running runs: ['c1i31j24']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_151458-c1i31j24
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-92
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/c1i31j24
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17907
wandb:    train_loss 3.64534
wandb: training_time 0.95289
wandb:        val_f1 0.07628
wandb:      val_loss 3.64783
wandb: 
wandb: Synced eager-sweep-92: https://wandb.ai/jah377/sff_arxiv/runs/c1i31j24
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_151458-c1i31j24/logs
2022-06-16 15:25:55,928 - wandb.wandb_agent - INFO - Cleaning up finished run: c1i31j24
2022-06-16 15:25:56,441 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:25:56,442 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 15:25:56,449 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 15:26:01,462 - wandb.wandb_agent - INFO - Running runs: ['ceewv2wm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_152601-ceewv2wm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-93
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ceewv2wm
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17831
wandb:    train_loss 3.64548
wandb: training_time 0.85481
wandb:        val_f1 0.07628
wandb:      val_loss 3.64782
wandb: 
wandb: Synced devout-sweep-93: https://wandb.ai/jah377/sff_arxiv/runs/ceewv2wm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_152601-ceewv2wm/logs
2022-06-16 15:36:00,240 - wandb.wandb_agent - INFO - Cleaning up finished run: ceewv2wm
2022-06-16 15:36:00,777 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:36:00,777 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 15:36:00,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 15:36:05,798 - wandb.wandb_agent - INFO - Running runs: ['amv2b9jl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_153605-amv2b9jl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-94
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/amv2b9jl
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17888
wandb:    train_loss 3.55112
wandb: training_time 0.79918
wandb:        val_f1 0.07628
wandb:      val_loss 3.55795
wandb: 
wandb: Synced efficient-sweep-94: https://wandb.ai/jah377/sff_arxiv/runs/amv2b9jl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_153605-amv2b9jl/logs
2022-06-16 15:45:35,607 - wandb.wandb_agent - INFO - Cleaning up finished run: amv2b9jl
2022-06-16 15:45:36,198 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:45:36,198 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 15:45:36,205 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 15:45:41,218 - wandb.wandb_agent - INFO - Running runs: ['xpcy48hn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_154541-xpcy48hn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-95
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/xpcy48hn
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.16848
wandb:    train_loss 3.52321
wandb: training_time 0.7704
wandb:        val_f1 0.19689
wandb:      val_loss 3.4968
wandb: 
wandb: Synced cool-sweep-95: https://wandb.ai/jah377/sff_arxiv/runs/xpcy48hn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_154541-xpcy48hn/logs
2022-06-16 15:54:53,845 - wandb.wandb_agent - INFO - Cleaning up finished run: xpcy48hn
2022-06-16 15:54:54,366 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:54:54,366 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 15:54:54,375 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 15:54:59,390 - wandb.wandb_agent - INFO - Running runs: ['j5g0imri']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_155459-j5g0imri
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-96
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/j5g0imri
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.36847
wandb:    train_loss 2.86859
wandb: training_time 1.04035
wandb:        val_f1 0.37827
wandb:      val_loss 2.87951
wandb: 
wandb: Synced polar-sweep-96: https://wandb.ai/jah377/sff_arxiv/runs/j5g0imri
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_155459-j5g0imri/logs
2022-06-16 16:05:46,485 - wandb.wandb_agent - INFO - Cleaning up finished run: j5g0imri
2022-06-16 16:05:47,332 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:05:47,332 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 16:05:47,340 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 16:05:52,354 - wandb.wandb_agent - INFO - Running runs: ['5x73e4g4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_160552-5x73e4g4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-97
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/5x73e4g4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.23242
wandb:    train_loss 3.77677
wandb: training_time 0.94027
wandb:        val_f1 0.21142
wandb:      val_loss 3.55071
wandb: 
wandb: Synced brisk-sweep-97: https://wandb.ai/jah377/sff_arxiv/runs/5x73e4g4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_160552-5x73e4g4/logs
2022-06-16 16:16:27,824 - wandb.wandb_agent - INFO - Cleaning up finished run: 5x73e4g4
2022-06-16 16:16:28,453 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:16:28,453 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 16:16:28,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 16:16:33,474 - wandb.wandb_agent - INFO - Running runs: ['mjczlkts']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_161633-mjczlkts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-98
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/mjczlkts
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54244
wandb:    train_loss 2.33804
wandb: training_time 0.84149
wandb:        val_f1 0.53532
wandb:      val_loss 2.4227
wandb: 
wandb: Synced kind-sweep-98: https://wandb.ai/jah377/sff_arxiv/runs/mjczlkts
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_161633-mjczlkts/logs
2022-06-16 16:26:42,803 - wandb.wandb_agent - INFO - Cleaning up finished run: mjczlkts
2022-06-16 16:26:43,561 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:26:43,561 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 16:26:43,570 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 16:26:48,584 - wandb.wandb_agent - INFO - Running runs: ['ktdz3w1m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_162648-ktdz3w1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-99
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/ktdz3w1m
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56521
wandb:    train_loss 1.48739
wandb: training_time 0.87709
wandb:        val_f1 0.56005
wandb:      val_loss 1.53028
wandb: 
wandb: Synced clean-sweep-99: https://wandb.ai/jah377/sff_arxiv/runs/ktdz3w1m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_162648-ktdz3w1m/logs
2022-06-16 16:36:54,055 - wandb.wandb_agent - INFO - Cleaning up finished run: ktdz3w1m
2022-06-16 16:36:54,710 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:36:54,710 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 16:36:54,717 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 16:36:59,733 - wandb.wandb_agent - INFO - Running runs: ['z8i51pdx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_arxiv/wandb/run-20220616_163659-z8i51pdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-100
wandb:  View project at https://wandb.ai/jah377/sff_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb:  View run at https://wandb.ai/jah377/sff_arxiv/runs/z8i51pdx
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17904
wandb:    train_loss 3.64563
wandb: training_time 0.91166
wandb:        val_f1 0.07628
wandb:      val_loss 3.64961
wandb: 
wandb: Synced gallant-sweep-100: https://wandb.ai/jah377/sff_arxiv/runs/z8i51pdx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_163659-z8i51pdx/logs
2022-06-16 16:47:25,294 - wandb.wandb_agent - INFO - Cleaning up finished run: z8i51pdx
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: mzef3qsc
Sweep URL: https://wandb.ai/jah377/sff_arxiv/sweeps/mzef3qsc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: - 0.242 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: \ 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: | 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: / 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: - 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: \ 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: | 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: / 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: - 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced glamorous-shape-97: https://wandb.ai/jah377/sff_arxiv/runs/4sannvmz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_001308-4sannvmz/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 16 hours 35 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
