Sun 19 Jun 2022 02:30:36 PM CEST
r31n4.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: arxiv
method: bayes
model: SIGNff_CS
iterations: 100
run_trial: false
config: SIGNff_CSX.yaml
train_file: hps_SIGNff_CS.py
project_name: sffCSX_arxiv
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  ATTN_NORMALIZATION:
    values:
    - 0
    - 1
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 2048
    - 4096
    - 8192
    - 16384
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  DATASET:
    value: arxiv
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  TRANSFORMATION:
    value: cosine_per_k
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff_CS.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_143118-3ew9q5dw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-lake-334
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/3ew9q5dw
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-19 14:31:26,548 - wandb.wandb_agent - INFO - Running runs: []
2022-06-19 14:31:26,859 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:31:26,860 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 14:31:26,867 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 14:31:31,880 - wandb.wandb_agent - INFO - Running runs: ['rf0yb7u3']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_143131-rf0yb7u3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-1
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/rf0yb7u3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
Traceback (most recent call last):
  File "/scratch/sffCSX_arxiv/hps_SIGNff_CS.py", line 321, in <module>
    main(config)
  File "/scratch/sffCSX_arxiv/hps_SIGNff_CS.py", line 239, in main
    data, _ = transform_data(data, config)
  File "/scratch/sffCSX_arxiv/SIGNff_utils.py", line 24, in wrapper
    output = func(*args, **kwargs)
  File "/scratch/sffCSX_arxiv/transformation.py", line 51, in transform_data
    adj_t = cosine_filter(xs[-1], data.edge_index, args)
  File "/scratch/sffCSX_arxiv/transform_cs.py", line 38, in cosine_filter
    return sparse_min_max_norm(attn)
  File "/scratch/sffCSX_arxiv/SIGNff_utils.py", line 94, in sparse_min_max_norm
    max_r = np.maximum.reduceat(v, idx)  # max per row
IndexError: index 702234 out-of-bounds in maximum.reduceat [0, 702234)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced playful-sweep-1: https://wandb.ai/jah377/sffCSX_arxiv/runs/rf0yb7u3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_143131-rf0yb7u3/logs
2022-06-19 15:07:42,970 - wandb.wandb_agent - INFO - Cleaning up finished run: rf0yb7u3
2022-06-19 15:07:43,274 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:07:43,274 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 15:07:43,284 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 15:07:48,300 - wandb.wandb_agent - INFO - Running runs: ['v9dcdxfo']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_150748-v9dcdxfo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-2
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/v9dcdxfo
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}

TRANSFORMED FILE: data/arxiv_k1_cosine_per_k_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.04507
wandb:    train_loss 3.6798
wandb: training_time 1.19487
wandb:        val_f1 0.02054
wandb:      val_loss 3.7064
wandb: 
wandb: Synced rare-sweep-2: https://wandb.ai/jah377/sffCSX_arxiv/runs/v9dcdxfo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_150748-v9dcdxfo/logs
2022-06-19 15:37:47,626 - wandb.wandb_agent - INFO - Cleaning up finished run: v9dcdxfo
2022-06-19 15:37:48,722 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:37:48,722 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-19 15:37:48,732 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 15:37:53,746 - wandb.wandb_agent - INFO - Running runs: ['dad8xhxn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_153754-dad8xhxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-3
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/dad8xhxn
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}

TRANSFORMED FILE: data/arxiv_k2_cosine_per_k_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.19172
wandb:    train_loss 18.24462
wandb: training_time 0.7038
wandb:        val_f1 0.23276
wandb:      val_loss 15.34994
wandb: 
wandb: Synced warm-sweep-3: https://wandb.ai/jah377/sffCSX_arxiv/runs/dad8xhxn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_153754-dad8xhxn/logs
2022-06-19 16:21:54,083 - wandb.wandb_agent - INFO - Cleaning up finished run: dad8xhxn
2022-06-19 16:21:54,469 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:21:54,469 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 16:21:54,476 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 16:21:59,490 - wandb.wandb_agent - INFO - Running runs: ['ub9c2vr5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_162159-ub9c2vr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-4
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/ub9c2vr5
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}

TRANSFORMED FILE: data/arxiv_k0_cosine_per_k_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47956
wandb:    train_loss 1.83932
wandb: training_time 0.94542
wandb:        val_f1 0.49109
wandb:      val_loss 1.78765
wandb: 
wandb: Synced trim-sweep-4: https://wandb.ai/jah377/sffCSX_arxiv/runs/ub9c2vr5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_162159-ub9c2vr5/logs
2022-06-19 16:32:48,883 - wandb.wandb_agent - INFO - Cleaning up finished run: ub9c2vr5
2022-06-19 16:32:49,220 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:32:49,220 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-19 16:32:49,227 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 16:32:54,242 - wandb.wandb_agent - INFO - Running runs: ['rtxk5fys']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_163254-rtxk5fys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-5
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/rtxk5fys
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}

TRANSFORMED FILE: data/arxiv_k0_cosine_per_k_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26635
wandb:    train_loss 3.37406
wandb: training_time 0.76601
wandb:        val_f1 0.27279
wandb:      val_loss 3.36592
wandb: 
wandb: Synced wise-sweep-5: https://wandb.ai/jah377/sffCSX_arxiv/runs/rtxk5fys
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_163254-rtxk5fys/logs
2022-06-19 16:42:10,705 - wandb.wandb_agent - INFO - Cleaning up finished run: rtxk5fys
2022-06-19 16:42:11,099 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:42:11,099 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 16:42:11,108 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 16:42:16,120 - wandb.wandb_agent - INFO - Running runs: ['0tas0fbs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_164216-0tas0fbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-6
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/0tas0fbs
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
Traceback (most recent call last):
  File "/scratch/sffCSX_arxiv/hps_SIGNff_CS.py", line 321, in <module>
    main(config)
  File "/scratch/sffCSX_arxiv/hps_SIGNff_CS.py", line 239, in main
    data, _ = transform_data(data, config)
  File "/scratch/sffCSX_arxiv/SIGNff_utils.py", line 24, in wrapper
    output = func(*args, **kwargs)
  File "/scratch/sffCSX_arxiv/transformation.py", line 51, in transform_data
    adj_t = cosine_filter(xs[-1], data.edge_index, args)
  File "/scratch/sffCSX_arxiv/transform_cs.py", line 38, in cosine_filter
    return sparse_min_max_norm(attn)
  File "/scratch/sffCSX_arxiv/SIGNff_utils.py", line 94, in sparse_min_max_norm
    max_r = np.maximum.reduceat(v, idx)  # max per row
IndexError: index 702234 out-of-bounds in maximum.reduceat [0, 702234)
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: / 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: - 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.005 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced silver-sweep-6: https://wandb.ai/jah377/sffCSX_arxiv/runs/0tas0fbs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_164216-0tas0fbs/logs
2022-06-19 17:18:42,635 - wandb.wandb_agent - INFO - Cleaning up finished run: 0tas0fbs
2022-06-19 17:18:42,999 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:18:43,000 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 17:18:43,008 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 17:18:48,023 - wandb.wandb_agent - INFO - Running runs: ['7dt0qh8c']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_171848-7dt0qh8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-7
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/7dt0qh8c
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54861
wandb:    train_loss 1.59456
wandb: training_time 0.93823
wandb:        val_f1 0.56233
wandb:      val_loss 1.52677
wandb: 
wandb: Synced gentle-sweep-7: https://wandb.ai/jah377/sffCSX_arxiv/runs/7dt0qh8c
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_171848-7dt0qh8c/logs
2022-06-19 17:29:56,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 7dt0qh8c
2022-06-19 17:29:56,485 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:29:56,485 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-19 17:29:56,495 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 17:30:01,508 - wandb.wandb_agent - INFO - Running runs: ['8gg3t7ky']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_173001-8gg3t7ky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-8
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/8gg3t7ky
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.44316
wandb:    train_loss 2.07776
wandb: training_time 0.75123
wandb:        val_f1 0.45787
wandb:      val_loss 2.02679
wandb: 
wandb: Synced treasured-sweep-8: https://wandb.ai/jah377/sffCSX_arxiv/runs/8gg3t7ky
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_173001-8gg3t7ky/logs
2022-06-19 17:39:28,539 - wandb.wandb_agent - INFO - Cleaning up finished run: 8gg3t7ky
2022-06-19 17:39:29,111 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:39:29,111 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.1
2022-06-19 17:39:29,119 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 17:39:34,132 - wandb.wandb_agent - INFO - Running runs: ['ruug70u4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_173934-ruug70u4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-9
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/ruug70u4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39502
wandb:    train_loss 2.36003
wandb: training_time 0.97776
wandb:        val_f1 0.4126
wandb:      val_loss 2.23456
wandb: 
wandb: Synced brisk-sweep-9: https://wandb.ai/jah377/sffCSX_arxiv/runs/ruug70u4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_173934-ruug70u4/logs
2022-06-19 17:49:27,268 - wandb.wandb_agent - INFO - Cleaning up finished run: ruug70u4
2022-06-19 17:49:27,626 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:49:27,626 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 17:49:27,635 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 17:49:32,648 - wandb.wandb_agent - INFO - Running runs: ['9ifqo4du']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_174932-9ifqo4du
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-10
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/9ifqo4du
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42787
wandb:    train_loss 2.16773
wandb: training_time 0.90434
wandb:        val_f1 0.44562
wandb:      val_loss 2.0956
wandb: 
wandb: Synced daily-sweep-10: https://wandb.ai/jah377/sffCSX_arxiv/runs/9ifqo4du
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_174932-9ifqo4du/logs
2022-06-19 18:00:23,812 - wandb.wandb_agent - INFO - Cleaning up finished run: 9ifqo4du
2022-06-19 18:00:24,187 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:00:24,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 18:00:24,195 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 18:00:29,211 - wandb.wandb_agent - INFO - Running runs: ['i4rnbv1o']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_180029-i4rnbv1o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-11
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/i4rnbv1o
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51822
wandb:    train_loss 1.67638
wandb: training_time 0.88749
wandb:        val_f1 0.51676
wandb:      val_loss 1.66725
wandb: 
wandb: Synced bumbling-sweep-11: https://wandb.ai/jah377/sffCSX_arxiv/runs/i4rnbv1o
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_180029-i4rnbv1o/logs
2022-06-19 18:10:49,448 - wandb.wandb_agent - INFO - Cleaning up finished run: i4rnbv1o
2022-06-19 18:10:49,825 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:10:49,825 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-19 18:10:49,833 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 18:10:54,848 - wandb.wandb_agent - INFO - Running runs: ['rr3x0oey']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_181054-rr3x0oey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-12
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/rr3x0oey
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30906
wandb:    train_loss 2.66098
wandb: training_time 0.8078
wandb:        val_f1 0.30931
wandb:      val_loss 2.53532
wandb: 
wandb: Synced woven-sweep-12: https://wandb.ai/jah377/sffCSX_arxiv/runs/rr3x0oey
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_181054-rr3x0oey/logs
2022-06-19 18:20:29,100 - wandb.wandb_agent - INFO - Cleaning up finished run: rr3x0oey
2022-06-19 18:20:29,438 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:20:29,439 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 18:20:29,446 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 18:20:34,460 - wandb.wandb_agent - INFO - Running runs: ['wquwg920']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_182034-wquwg920
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-13
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/wquwg920
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.28159
wandb:    train_loss 3.17377
wandb: training_time 0.91258
wandb:        val_f1 0.29561
wandb:      val_loss 3.15871
wandb: 
wandb: Synced worthy-sweep-13: https://wandb.ai/jah377/sffCSX_arxiv/runs/wquwg920
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_182034-wquwg920/logs
2022-06-19 18:30:32,710 - wandb.wandb_agent - INFO - Cleaning up finished run: wquwg920
2022-06-19 18:30:33,096 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:30:33,097 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 18:30:33,106 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 18:30:38,121 - wandb.wandb_agent - INFO - Running runs: ['iaoijerw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_183038-iaoijerw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-14
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/iaoijerw
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1048
wandb:    train_loss 3.60404
wandb: training_time 0.78751
wandb:        val_f1 0.08648
wandb:      val_loss 3.59589
wandb: 
wandb: Synced clear-sweep-14: https://wandb.ai/jah377/sffCSX_arxiv/runs/iaoijerw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_183038-iaoijerw/logs
2022-06-19 18:40:10,772 - wandb.wandb_agent - INFO - Cleaning up finished run: iaoijerw
2022-06-19 18:40:11,209 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:40:11,210 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.1
2022-06-19 18:40:11,218 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 18:40:16,232 - wandb.wandb_agent - INFO - Running runs: ['s9kxs948']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_184016-s9kxs948
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-15
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/s9kxs948
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45426
wandb:    train_loss 2.07127
wandb: training_time 0.94494
wandb:        val_f1 0.47817
wandb:      val_loss 1.99679
wandb: 
wandb: Synced rosy-sweep-15: https://wandb.ai/jah377/sffCSX_arxiv/runs/s9kxs948
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_184016-s9kxs948/logs
2022-06-19 18:51:27,182 - wandb.wandb_agent - INFO - Cleaning up finished run: s9kxs948
2022-06-19 18:51:27,561 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:51:27,561 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 18:51:27,570 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 18:51:32,584 - wandb.wandb_agent - INFO - Running runs: ['a0aro09h']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_185132-a0aro09h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-16
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/a0aro09h
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.44428
wandb:    train_loss 1.99834
wandb: training_time 0.85238
wandb:        val_f1 0.43609
wandb:      val_loss 1.99358
wandb: 
wandb: Synced smooth-sweep-16: https://wandb.ai/jah377/sffCSX_arxiv/runs/a0aro09h
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_185132-a0aro09h/logs
2022-06-19 19:02:02,202 - wandb.wandb_agent - INFO - Cleaning up finished run: a0aro09h
2022-06-19 19:02:02,579 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:02:02,579 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 19:02:02,588 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 19:02:07,600 - wandb.wandb_agent - INFO - Running runs: ['hw5kxduw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_190207-hw5kxduw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-17
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/hw5kxduw
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38811
wandb:    train_loss 2.49158
wandb: training_time 0.80982
wandb:        val_f1 0.41324
wandb:      val_loss 2.404
wandb: 
wandb: Synced confused-sweep-17: https://wandb.ai/jah377/sffCSX_arxiv/runs/hw5kxduw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_190207-hw5kxduw/logs
2022-06-19 19:11:40,817 - wandb.wandb_agent - INFO - Cleaning up finished run: hw5kxduw
2022-06-19 19:11:41,242 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:11:41,243 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 19:11:41,253 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 19:11:46,268 - wandb.wandb_agent - INFO - Running runs: ['86vlz7u6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_191146-86vlz7u6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-18
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/86vlz7u6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.37649
wandb:    train_loss 2.32551
wandb: training_time 0.82315
wandb:        val_f1 0.39058
wandb:      val_loss 2.25089
wandb: 
wandb: Synced vivid-sweep-18: https://wandb.ai/jah377/sffCSX_arxiv/runs/86vlz7u6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_191146-86vlz7u6/logs
2022-06-19 19:21:41,348 - wandb.wandb_agent - INFO - Cleaning up finished run: 86vlz7u6
2022-06-19 19:21:41,718 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:21:41,719 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 19:21:41,728 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 19:21:46,741 - wandb.wandb_agent - INFO - Running runs: ['at1h6xry']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_192146-at1h6xry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-19
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/at1h6xry
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45051
wandb:    train_loss 1.90354
wandb: training_time 0.83457
wandb:        val_f1 0.45367
wandb:      val_loss 1.84148
wandb: 
wandb: Synced restful-sweep-19: https://wandb.ai/jah377/sffCSX_arxiv/runs/at1h6xry
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_192146-at1h6xry/logs
2022-06-19 19:32:07,846 - wandb.wandb_agent - INFO - Cleaning up finished run: at1h6xry
2022-06-19 19:32:08,224 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:32:08,225 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.1
2022-06-19 19:32:08,233 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 19:32:13,248 - wandb.wandb_agent - INFO - Running runs: ['vflg4mhu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_193213-vflg4mhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-20
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/vflg4mhu
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.2592
wandb:    train_loss 2.79576
wandb: training_time 1.15444
wandb:        val_f1 0.25477
wandb:      val_loss 2.75293
wandb: 
wandb: Synced elated-sweep-20: https://wandb.ai/jah377/sffCSX_arxiv/runs/vflg4mhu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_193213-vflg4mhu/logs
2022-06-19 19:43:50,513 - wandb.wandb_agent - INFO - Cleaning up finished run: vflg4mhu
2022-06-19 19:43:50,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:43:50,879 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.1
2022-06-19 19:43:50,887 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 19:43:55,902 - wandb.wandb_agent - INFO - Running runs: ['i57tb9b4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_194356-i57tb9b4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-21
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/i57tb9b4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17899
wandb:    train_loss 3.13853
wandb: training_time 0.84474
wandb:        val_f1 0.07628
wandb:      val_loss 3.22409
wandb: 
wandb: Synced celestial-sweep-21: https://wandb.ai/jah377/sffCSX_arxiv/runs/i57tb9b4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_194356-i57tb9b4/logs
2022-06-19 19:53:44,587 - wandb.wandb_agent - INFO - Cleaning up finished run: i57tb9b4
2022-06-19 19:53:44,922 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:53:44,923 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 19:53:44,932 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 19:53:49,948 - wandb.wandb_agent - INFO - Running runs: ['itztjfps']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_195350-itztjfps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-22
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/itztjfps
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.06583
wandb:    train_loss 3.63809
wandb: training_time 0.79173
wandb:        val_f1 0.03305
wandb:      val_loss 3.68303
wandb: 
wandb: Synced eager-sweep-22: https://wandb.ai/jah377/sffCSX_arxiv/runs/itztjfps
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_195350-itztjfps/logs
2022-06-19 20:03:21,970 - wandb.wandb_agent - INFO - Cleaning up finished run: itztjfps
2022-06-19 20:03:22,336 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:03:22,337 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 20:03:22,345 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 20:03:27,360 - wandb.wandb_agent - INFO - Running runs: ['h9o3ev7r']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_200327-h9o3ev7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-23
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/h9o3ev7r
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3305
wandb:    train_loss 2.4627
wandb: training_time 1.03406
wandb:        val_f1 0.3434
wandb:      val_loss 2.40477
wandb: 
wandb: Synced iconic-sweep-23: https://wandb.ai/jah377/sffCSX_arxiv/runs/h9o3ev7r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_200327-h9o3ev7r/logs
2022-06-19 20:14:39,876 - wandb.wandb_agent - INFO - Cleaning up finished run: h9o3ev7r
2022-06-19 20:14:40,323 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:14:40,323 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 20:14:40,330 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 20:14:45,344 - wandb.wandb_agent - INFO - Running runs: ['7c0ew09y']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_201445-7c0ew09y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-24
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/7c0ew09y
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39415
wandb:    train_loss 2.2007
wandb: training_time 0.80372
wandb:        val_f1 0.40488
wandb:      val_loss 2.15373
wandb: 
wandb: Synced morning-sweep-24: https://wandb.ai/jah377/sffCSX_arxiv/runs/7c0ew09y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_201445-7c0ew09y/logs
2022-06-19 20:24:28,354 - wandb.wandb_agent - INFO - Cleaning up finished run: 7c0ew09y
2022-06-19 20:24:28,928 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:24:28,928 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 20:24:28,938 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 20:24:33,953 - wandb.wandb_agent - INFO - Running runs: ['xy8jlx73']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_202434-xy8jlx73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-25
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/xy8jlx73
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.46398
wandb:    train_loss 1.92208
wandb: training_time 1.02028
wandb:        val_f1 0.46851
wandb:      val_loss 1.88746
wandb: 
wandb: Synced classic-sweep-25: https://wandb.ai/jah377/sffCSX_arxiv/runs/xy8jlx73
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_202434-xy8jlx73/logs
2022-06-19 20:34:57,759 - wandb.wandb_agent - INFO - Cleaning up finished run: xy8jlx73
2022-06-19 20:34:58,117 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:34:58,117 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 20:34:58,127 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 20:35:03,142 - wandb.wandb_agent - INFO - Running runs: ['bddsdeuj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_203503-bddsdeuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-26
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/bddsdeuj
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27703
wandb:    train_loss 3.00254
wandb: training_time 0.90954
wandb:        val_f1 0.26283
wandb:      val_loss 3.08243
wandb: 
wandb: Synced warm-sweep-26: https://wandb.ai/jah377/sffCSX_arxiv/runs/bddsdeuj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_203503-bddsdeuj/logs
2022-06-19 20:45:33,590 - wandb.wandb_agent - INFO - Cleaning up finished run: bddsdeuj
2022-06-19 20:45:34,020 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:45:34,021 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-19 20:45:34,029 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 20:45:39,044 - wandb.wandb_agent - INFO - Running runs: ['j6xbpyj7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_204539-j6xbpyj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-27
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/j6xbpyj7
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.46066
wandb:    train_loss 1.88562
wandb: training_time 0.82059
wandb:        val_f1 0.46592
wandb:      val_loss 1.82538
wandb: 
wandb: Synced glowing-sweep-27: https://wandb.ai/jah377/sffCSX_arxiv/runs/j6xbpyj7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_204539-j6xbpyj7/logs
2022-06-19 20:55:21,566 - wandb.wandb_agent - INFO - Cleaning up finished run: j6xbpyj7
2022-06-19 20:55:21,995 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:55:21,995 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 20:55:22,005 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 20:55:27,016 - wandb.wandb_agent - INFO - Running runs: ['7ccevfzs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_205527-7ccevfzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-28
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/7ccevfzs
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.29749
wandb:    train_loss 3.07435
wandb: training_time 0.81904
wandb:        val_f1 0.30407
wandb:      val_loss 3.07706
wandb: 
wandb: Synced magic-sweep-28: https://wandb.ai/jah377/sffCSX_arxiv/runs/7ccevfzs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_205527-7ccevfzs/logs
2022-06-19 21:04:59,284 - wandb.wandb_agent - INFO - Cleaning up finished run: 7ccevfzs
2022-06-19 21:04:59,636 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:04:59,636 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 21:04:59,645 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 21:05:04,660 - wandb.wandb_agent - INFO - Running runs: ['2rwfo366']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_210504-2rwfo366
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-29
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/2rwfo366
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 11
wandb:      train_f1 0.02714
wandb:    train_loss 3.78369
wandb: training_time 0.79082
wandb:        val_f1 0.04044
wandb:      val_loss 3.73173
wandb: 
wandb: Synced generous-sweep-29: https://wandb.ai/jah377/sffCSX_arxiv/runs/2rwfo366
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_210504-2rwfo366/logs
2022-06-19 21:05:40,736 - wandb.wandb_agent - INFO - Cleaning up finished run: 2rwfo366
2022-06-19 21:05:41,178 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:05:41,179 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 21:05:41,188 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 21:05:46,200 - wandb.wandb_agent - INFO - Running runs: ['2gity2pg']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_210545-2gity2pg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-30
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/2gity2pg
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4748
wandb:    train_loss 1.85573
wandb: training_time 0.86113
wandb:        val_f1 0.48381
wandb:      val_loss 1.80132
wandb: 
wandb: Synced stellar-sweep-30: https://wandb.ai/jah377/sffCSX_arxiv/runs/2gity2pg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_210545-2gity2pg/logs
2022-06-19 21:15:28,669 - wandb.wandb_agent - INFO - Cleaning up finished run: 2gity2pg
2022-06-19 21:15:35,320 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:15:35,321 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-19 21:15:35,328 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 21:15:40,340 - wandb.wandb_agent - INFO - Running runs: ['99x3526b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_211540-99x3526b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-31
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/99x3526b
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27706
wandb:    train_loss 2.93594
wandb: training_time 1.20884
wandb:        val_f1 0.27749
wandb:      val_loss 2.94133
wandb: 
wandb: Synced lucky-sweep-31: https://wandb.ai/jah377/sffCSX_arxiv/runs/99x3526b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_211540-99x3526b/logs
2022-06-19 21:27:57,895 - wandb.wandb_agent - INFO - Cleaning up finished run: 99x3526b
2022-06-19 21:27:58,253 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:27:58,253 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 21:27:58,261 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 21:28:03,276 - wandb.wandb_agent - INFO - Running runs: ['an9xqkuc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_212803-an9xqkuc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-32
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/an9xqkuc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.46701
wandb:    train_loss 1.83985
wandb: training_time 0.92498
wandb:        val_f1 0.46777
wandb:      val_loss 1.8019
wandb: 
wandb: Synced sweepy-sweep-32: https://wandb.ai/jah377/sffCSX_arxiv/runs/an9xqkuc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_212803-an9xqkuc/logs
2022-06-19 21:38:58,311 - wandb.wandb_agent - INFO - Cleaning up finished run: an9xqkuc
2022-06-19 21:38:58,802 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:38:58,803 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-19 21:38:58,810 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 21:39:03,824 - wandb.wandb_agent - INFO - Running runs: ['sfevjz7h']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_213904-sfevjz7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-33
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/sfevjz7h
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}

TRANSFORMED FILE: data/arxiv_k1_cosine_per_k_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60383
wandb:    train_loss 1.3183
wandb: training_time 0.94745
wandb:        val_f1 0.59036
wandb:      val_loss 1.35553
wandb: 
wandb: Synced lunar-sweep-33: https://wandb.ai/jah377/sffCSX_arxiv/runs/sfevjz7h
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_213904-sfevjz7h/logs
2022-06-19 22:09:13,775 - wandb.wandb_agent - INFO - Cleaning up finished run: sfevjz7h
2022-06-19 22:09:23,556 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:09:23,557 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 22:09:23,564 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 22:09:28,576 - wandb.wandb_agent - INFO - Running runs: ['s4t12xod']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_220928-s4t12xod
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-34
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/s4t12xod
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.41553
wandb:    train_loss 2.128
wandb: training_time 0.89091
wandb:        val_f1 0.40938
wandb:      val_loss 2.17214
wandb: 
wandb: Synced happy-sweep-34: https://wandb.ai/jah377/sffCSX_arxiv/runs/s4t12xod
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_220928-s4t12xod/logs
2022-06-19 22:20:00,550 - wandb.wandb_agent - INFO - Cleaning up finished run: s4t12xod
2022-06-19 22:20:01,115 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:20:01,116 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-19 22:20:01,123 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 22:20:06,137 - wandb.wandb_agent - INFO - Running runs: ['kno1puwt']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_222006-kno1puwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-35
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/kno1puwt
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.43389
wandb:    train_loss 2.1127
wandb: training_time 0.98298
wandb:        val_f1 0.45095
wandb:      val_loss 2.04911
wandb: 
wandb: Synced clear-sweep-35: https://wandb.ai/jah377/sffCSX_arxiv/runs/kno1puwt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_222006-kno1puwt/logs
2022-06-19 22:31:21,788 - wandb.wandb_agent - INFO - Cleaning up finished run: kno1puwt
2022-06-19 22:31:22,225 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:31:22,225 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-19 22:31:22,233 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 22:31:27,244 - wandb.wandb_agent - INFO - Running runs: ['xdctk0wb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_223127-xdctk0wb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-36
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/xdctk0wb
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55604
wandb:    train_loss 1.50074
wandb: training_time 0.96694
wandb:        val_f1 0.547
wandb:      val_loss 1.53676
wandb: 
wandb: Synced summer-sweep-36: https://wandb.ai/jah377/sffCSX_arxiv/runs/xdctk0wb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_223127-xdctk0wb/logs
2022-06-19 22:42:37,940 - wandb.wandb_agent - INFO - Cleaning up finished run: xdctk0wb
2022-06-19 22:42:39,968 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:42:39,969 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-19 22:42:39,979 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 22:42:44,995 - wandb.wandb_agent - INFO - Running runs: ['3egvg2my']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_224245-3egvg2my
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-37
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/3egvg2my
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3747
wandb:    train_loss 2.18279
wandb: training_time 0.92766
wandb:        val_f1 0.3882
wandb:      val_loss 2.10213
wandb: 
wandb: Synced curious-sweep-37: https://wandb.ai/jah377/sffCSX_arxiv/runs/3egvg2my
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_224245-3egvg2my/logs
2022-06-19 22:53:30,212 - wandb.wandb_agent - INFO - Cleaning up finished run: 3egvg2my
2022-06-19 22:53:30,719 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:53:30,720 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-19 22:53:30,728 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 22:53:35,740 - wandb.wandb_agent - INFO - Running runs: ['gvbyvj7b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_225335-gvbyvj7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-38
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/gvbyvj7b
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.49928
wandb:    train_loss 1.74431
wandb: training_time 0.97236
wandb:        val_f1 0.49824
wandb:      val_loss 1.71308
wandb: 
wandb: Synced sparkling-sweep-38: https://wandb.ai/jah377/sffCSX_arxiv/runs/gvbyvj7b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_225335-gvbyvj7b/logs
2022-06-19 23:04:40,436 - wandb.wandb_agent - INFO - Cleaning up finished run: gvbyvj7b
2022-06-19 23:04:41,005 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:04:41,005 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-19 23:04:41,012 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 23:04:46,027 - wandb.wandb_agent - INFO - Running runs: ['fltt12fo']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_230446-fltt12fo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-39
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/fltt12fo
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51068
wandb:    train_loss 1.69591
wandb: training_time 0.89949
wandb:        val_f1 0.50146
wandb:      val_loss 1.71798
wandb: 
wandb: Synced laced-sweep-39: https://wandb.ai/jah377/sffCSX_arxiv/runs/fltt12fo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_230446-fltt12fo/logs
2022-06-19 23:15:18,168 - wandb.wandb_agent - INFO - Cleaning up finished run: fltt12fo
2022-06-19 23:15:18,647 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:15:18,647 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-19 23:15:18,655 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 23:15:23,668 - wandb.wandb_agent - INFO - Running runs: ['2z236xj8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_231523-2z236xj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-40
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/2z236xj8
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55995
wandb:    train_loss 1.49442
wandb: training_time 0.96456
wandb:        val_f1 0.53837
wandb:      val_loss 1.55627
wandb: 
wandb: Synced chocolate-sweep-40: https://wandb.ai/jah377/sffCSX_arxiv/runs/2z236xj8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_231523-2z236xj8/logs
2022-06-19 23:26:39,460 - wandb.wandb_agent - INFO - Cleaning up finished run: 2z236xj8
2022-06-19 23:26:40,080 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:26:40,080 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-19 23:26:40,088 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 23:26:45,100 - wandb.wandb_agent - INFO - Running runs: ['mkpvzeso']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_232645-mkpvzeso
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-41
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/mkpvzeso
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26597
wandb:    train_loss 3.09707
wandb: training_time 1.27797
wandb:        val_f1 0.27081
wandb:      val_loss 2.93194
wandb: 
wandb: Synced spring-sweep-41: https://wandb.ai/jah377/sffCSX_arxiv/runs/mkpvzeso
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_232645-mkpvzeso/logs
2022-06-19 23:39:18,540 - wandb.wandb_agent - INFO - Cleaning up finished run: mkpvzeso
2022-06-19 23:39:18,978 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:39:18,978 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-19 23:39:18,986 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 23:39:23,996 - wandb.wandb_agent - INFO - Running runs: ['d3medhiv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_233924-d3medhiv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-42
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/d3medhiv
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53099
wandb:    train_loss 1.62492
wandb: training_time 1.00013
wandb:        val_f1 0.53163
wandb:      val_loss 1.61475
wandb: 
wandb: Synced generous-sweep-42: https://wandb.ai/jah377/sffCSX_arxiv/runs/d3medhiv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_233924-d3medhiv/logs
2022-06-19 23:50:31,192 - wandb.wandb_agent - INFO - Cleaning up finished run: d3medhiv
2022-06-19 23:50:38,118 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:50:38,119 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-19 23:50:38,125 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 23:50:43,136 - wandb.wandb_agent - INFO - Running runs: ['sspefzl7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220619_235043-sspefzl7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-43
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/sspefzl7
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26926
wandb:    train_loss 2.75836
wandb: training_time 0.8844
wandb:        val_f1 0.27635
wandb:      val_loss 2.70424
wandb: 
wandb: Synced grateful-sweep-43: https://wandb.ai/jah377/sffCSX_arxiv/runs/sspefzl7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_235043-sspefzl7/logs
2022-06-20 00:01:12,550 - wandb.wandb_agent - INFO - Cleaning up finished run: sspefzl7
2022-06-20 00:01:17,941 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:01:17,942 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 00:01:17,950 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 00:01:22,964 - wandb.wandb_agent - INFO - Running runs: ['qakoqlha']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_000123-qakoqlha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-44
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/qakoqlha
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38379
wandb:    train_loss 2.18474
wandb: training_time 1.1221
wandb:        val_f1 0.36642
wandb:      val_loss 2.20776
wandb: 
wandb: Synced skilled-sweep-44: https://wandb.ai/jah377/sffCSX_arxiv/runs/qakoqlha
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_000123-qakoqlha/logs
2022-06-20 00:13:41,770 - wandb.wandb_agent - INFO - Cleaning up finished run: qakoqlha
2022-06-20 00:13:42,281 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:13:42,281 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 00:13:42,288 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 00:13:47,300 - wandb.wandb_agent - INFO - Running runs: ['cx0zg01l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_001347-cx0zg01l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-45
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/cx0zg01l
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.37411
wandb:    train_loss 2.18662
wandb: training_time 1.00875
wandb:        val_f1 0.38441
wandb:      val_loss 2.10641
wandb: 
wandb: Synced curious-sweep-45: https://wandb.ai/jah377/sffCSX_arxiv/runs/cx0zg01l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_001347-cx0zg01l/logs
2022-06-20 00:24:57,808 - wandb.wandb_agent - INFO - Cleaning up finished run: cx0zg01l
2022-06-20 00:24:58,376 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:24:58,376 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 00:24:58,385 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 00:25:03,400 - wandb.wandb_agent - INFO - Running runs: ['d5bdk6px']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_002503-d5bdk6px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-46
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/d5bdk6px
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42343
wandb:    train_loss 2.01573
wandb: training_time 1.08738
wandb:        val_f1 0.42438
wandb:      val_loss 1.97613
wandb: 
wandb: Synced rosy-sweep-46: https://wandb.ai/jah377/sffCSX_arxiv/runs/d5bdk6px
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_002503-d5bdk6px/logs
2022-06-20 00:36:45,527 - wandb.wandb_agent - INFO - Cleaning up finished run: d5bdk6px
2022-06-20 00:36:46,012 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:36:46,012 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 00:36:46,021 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 00:36:51,035 - wandb.wandb_agent - INFO - Running runs: ['piergn76']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_003651-piergn76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-47
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/piergn76
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50787
wandb:    train_loss 1.73264
wandb: training_time 0.99105
wandb:        val_f1 0.51391
wandb:      val_loss 1.70116
wandb: 
wandb: Synced dauntless-sweep-47: https://wandb.ai/jah377/sffCSX_arxiv/runs/piergn76
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_003651-piergn76/logs
2022-06-20 00:47:51,017 - wandb.wandb_agent - INFO - Cleaning up finished run: piergn76
2022-06-20 00:48:00,275 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:48:00,276 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 00:48:00,283 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 00:48:05,297 - wandb.wandb_agent - INFO - Running runs: ['vhjauy7y']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_004805-vhjauy7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-48
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/vhjauy7y
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.58848
wandb:    train_loss 1.35234
wandb: training_time 0.83505
wandb:        val_f1 0.55811
wandb:      val_loss 1.48264
wandb: 
wandb: Synced vibrant-sweep-48: https://wandb.ai/jah377/sffCSX_arxiv/runs/vhjauy7y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_004805-vhjauy7y/logs
2022-06-20 00:58:35,232 - wandb.wandb_agent - INFO - Cleaning up finished run: vhjauy7y
2022-06-20 00:58:35,871 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:58:35,871 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 00:58:35,879 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 00:58:40,892 - wandb.wandb_agent - INFO - Running runs: ['u3vw45ps']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_005841-u3vw45ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-49
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/u3vw45ps
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38582
wandb:    train_loss 2.3684
wandb: training_time 0.85666
wandb:        val_f1 0.39783
wandb:      val_loss 2.32061
wandb: 
wandb: Synced solar-sweep-49: https://wandb.ai/jah377/sffCSX_arxiv/runs/u3vw45ps
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_005841-u3vw45ps/logs
2022-06-20 01:08:34,825 - wandb.wandb_agent - INFO - Cleaning up finished run: u3vw45ps
2022-06-20 01:08:36,921 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:08:36,922 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 01:08:36,929 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 01:08:41,945 - wandb.wandb_agent - INFO - Running runs: ['68u68d2f']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_010842-68u68d2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-50
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/68u68d2f
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4415
wandb:    train_loss 1.90377
wandb: training_time 0.82424
wandb:        val_f1 0.4426
wandb:      val_loss 1.84825
wandb: 
wandb: Synced logical-sweep-50: https://wandb.ai/jah377/sffCSX_arxiv/runs/68u68d2f
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_010842-68u68d2f/logs
2022-06-20 01:18:50,012 - wandb.wandb_agent - INFO - Cleaning up finished run: 68u68d2f
2022-06-20 01:18:50,627 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:18:50,628 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 01:18:50,637 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 01:18:55,653 - wandb.wandb_agent - INFO - Running runs: ['m286ed4a']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_011856-m286ed4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-51
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/m286ed4a
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.48563
wandb:    train_loss 1.81115
wandb: training_time 0.99174
wandb:        val_f1 0.49176
wandb:      val_loss 1.76668
wandb: 
wandb: Synced dark-sweep-51: https://wandb.ai/jah377/sffCSX_arxiv/runs/m286ed4a
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_011856-m286ed4a/logs
2022-06-20 01:29:49,867 - wandb.wandb_agent - INFO - Cleaning up finished run: m286ed4a
2022-06-20 01:29:50,324 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:29:50,325 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 01:29:50,331 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 01:29:55,344 - wandb.wandb_agent - INFO - Running runs: ['zupe14lx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_012955-zupe14lx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-52
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/zupe14lx
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1791
wandb:    train_loss 6.12365
wandb: training_time 0.98658
wandb:        val_f1 0.07624
wandb:      val_loss 5.74987
wandb: 
wandb: Synced rare-sweep-52: https://wandb.ai/jah377/sffCSX_arxiv/runs/zupe14lx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_012955-zupe14lx/logs
2022-06-20 01:40:55,028 - wandb.wandb_agent - INFO - Cleaning up finished run: zupe14lx
2022-06-20 01:40:55,758 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:40:55,759 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 01:40:55,765 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 01:41:00,780 - wandb.wandb_agent - INFO - Running runs: ['7upyy8m9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_014101-7upyy8m9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-53
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/7upyy8m9
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.71573
wandb:    train_loss 0.90359
wandb: training_time 1.45752
wandb:        val_f1 0.61677
wandb:      val_loss 1.2872
wandb: 
wandb: Synced earthy-sweep-53: https://wandb.ai/jah377/sffCSX_arxiv/runs/7upyy8m9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_014101-7upyy8m9/logs
2022-06-20 01:55:10,669 - wandb.wandb_agent - INFO - Cleaning up finished run: 7upyy8m9
2022-06-20 01:55:11,374 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:55:11,375 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 01:55:11,383 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 01:55:16,397 - wandb.wandb_agent - INFO - Running runs: ['27hlaget']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_015516-27hlaget
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-54
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/27hlaget
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53901
wandb:    train_loss 1.56676
wandb: training_time 0.92418
wandb:        val_f1 0.52445
wandb:      val_loss 1.593
wandb: 
wandb: Synced elated-sweep-54: https://wandb.ai/jah377/sffCSX_arxiv/runs/27hlaget
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_015516-27hlaget/logs
2022-06-20 02:05:55,462 - wandb.wandb_agent - INFO - Cleaning up finished run: 27hlaget
2022-06-20 02:05:55,890 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:05:55,890 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-20 02:05:55,899 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 02:06:00,914 - wandb.wandb_agent - INFO - Running runs: ['047vr6wk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_020601-047vr6wk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-55
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/047vr6wk
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64354
wandb:    train_loss 1.21472
wandb: training_time 0.9586
wandb:        val_f1 0.5775
wandb:      val_loss 1.47134
wandb: 
wandb: Synced lilac-sweep-55: https://wandb.ai/jah377/sffCSX_arxiv/runs/047vr6wk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_020601-047vr6wk/logs
2022-06-20 02:16:44,975 - wandb.wandb_agent - INFO - Cleaning up finished run: 047vr6wk
2022-06-20 02:16:45,406 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:16:45,406 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 02:16:45,414 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 02:16:50,428 - wandb.wandb_agent - INFO - Running runs: ['fo72rbfi']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_021650-fo72rbfi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-56
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/fo72rbfi
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.48941
wandb:    train_loss 1.76364
wandb: training_time 1.03186
wandb:        val_f1 0.49213
wandb:      val_loss 1.72324
wandb: 
wandb: Synced lemon-sweep-56: https://wandb.ai/jah377/sffCSX_arxiv/runs/fo72rbfi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_021650-fo72rbfi/logs
2022-06-20 02:28:06,048 - wandb.wandb_agent - INFO - Cleaning up finished run: fo72rbfi
2022-06-20 02:28:06,466 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:28:06,466 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 02:28:06,475 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 02:28:11,488 - wandb.wandb_agent - INFO - Running runs: ['8taqbf2d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_022811-8taqbf2d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-57
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/8taqbf2d
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38148
wandb:    train_loss 2.16002
wandb: training_time 1.06615
wandb:        val_f1 0.39568
wandb:      val_loss 2.07124
wandb: 
wandb: Synced twilight-sweep-57: https://wandb.ai/jah377/sffCSX_arxiv/runs/8taqbf2d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_022811-8taqbf2d/logs
2022-06-20 02:39:11,175 - wandb.wandb_agent - INFO - Cleaning up finished run: 8taqbf2d
2022-06-20 02:39:11,697 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:39:11,698 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 02:39:11,705 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 02:39:16,721 - wandb.wandb_agent - INFO - Running runs: ['b7l00v23']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_023916-b7l00v23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-58
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/b7l00v23
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54058
wandb:    train_loss 1.55606
wandb: training_time 1.04922
wandb:        val_f1 0.53555
wandb:      val_loss 1.57101
wandb: 
wandb: Synced sleek-sweep-58: https://wandb.ai/jah377/sffCSX_arxiv/runs/b7l00v23
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_023916-b7l00v23/logs
2022-06-20 02:49:51,047 - wandb.wandb_agent - INFO - Cleaning up finished run: b7l00v23
2022-06-20 02:49:51,652 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:49:51,652 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 02:49:51,661 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 02:49:56,678 - wandb.wandb_agent - INFO - Running runs: ['u047z17w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_024957-u047z17w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-59
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/u047z17w
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5664
wandb:    train_loss 1.45506
wandb: training_time 0.77538
wandb:        val_f1 0.54928
wandb:      val_loss 1.50751
wandb: 
wandb: Synced glorious-sweep-59: https://wandb.ai/jah377/sffCSX_arxiv/runs/u047z17w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_024957-u047z17w/logs
2022-06-20 03:00:15,285 - wandb.wandb_agent - INFO - Cleaning up finished run: u047z17w
2022-06-20 03:00:15,968 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:00:15,968 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 03:00:15,976 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 03:00:20,992 - wandb.wandb_agent - INFO - Running runs: ['qkouqhr6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_030021-qkouqhr6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-60
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/qkouqhr6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47704
wandb:    train_loss 1.83375
wandb: training_time 0.93803
wandb:        val_f1 0.47663
wandb:      val_loss 1.81402
wandb: 
wandb: Synced lyric-sweep-60: https://wandb.ai/jah377/sffCSX_arxiv/runs/qkouqhr6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_030021-qkouqhr6/logs
2022-06-20 03:10:55,423 - wandb.wandb_agent - INFO - Cleaning up finished run: qkouqhr6
2022-06-20 03:10:55,868 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:10:55,868 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 03:10:55,875 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 03:11:00,888 - wandb.wandb_agent - INFO - Running runs: ['b7smmauc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_031101-b7smmauc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-61
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/b7smmauc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47977
wandb:    train_loss 1.77816
wandb: training_time 0.87383
wandb:        val_f1 0.4829
wandb:      val_loss 1.73566
wandb: 
wandb: Synced smart-sweep-61: https://wandb.ai/jah377/sffCSX_arxiv/runs/b7smmauc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_031101-b7smmauc/logs
2022-06-20 03:21:39,729 - wandb.wandb_agent - INFO - Cleaning up finished run: b7smmauc
2022-06-20 03:21:40,164 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:21:40,164 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 03:21:40,171 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 03:21:45,186 - wandb.wandb_agent - INFO - Running runs: ['8dwutf29']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_032145-8dwutf29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-62
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/8dwutf29
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.49929
wandb:    train_loss 1.77744
wandb: training_time 0.85504
wandb:        val_f1 0.50669
wandb:      val_loss 1.73978
wandb: 
wandb: Synced sunny-sweep-62: https://wandb.ai/jah377/sffCSX_arxiv/runs/8dwutf29
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_032145-8dwutf29/logs
2022-06-20 03:31:37,951 - wandb.wandb_agent - INFO - Cleaning up finished run: 8dwutf29
2022-06-20 03:31:42,809 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:31:42,809 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 03:31:42,816 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 03:31:47,828 - wandb.wandb_agent - INFO - Running runs: ['d9nyd8y6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_033148-d9nyd8y6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-63
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/d9nyd8y6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57217
wandb:    train_loss 1.45512
wandb: training_time 1.15642
wandb:        val_f1 0.5519
wandb:      val_loss 1.54222
wandb: 
wandb: Synced drawn-sweep-63: https://wandb.ai/jah377/sffCSX_arxiv/runs/d9nyd8y6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_033148-d9nyd8y6/logs
2022-06-20 03:43:49,231 - wandb.wandb_agent - INFO - Cleaning up finished run: d9nyd8y6
2022-06-20 03:43:49,657 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:43:49,658 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 03:43:49,665 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 03:43:54,681 - wandb.wandb_agent - INFO - Running runs: ['diootn6d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_034355-diootn6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-64
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/diootn6d
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6703
wandb:    train_loss 1.05921
wandb: training_time 1.16706
wandb:        val_f1 0.60163
wandb:      val_loss 1.33639
wandb: 
wandb: Synced drawn-sweep-64: https://wandb.ai/jah377/sffCSX_arxiv/runs/diootn6d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_034355-diootn6d/logs
2022-06-20 03:55:15,685 - wandb.wandb_agent - INFO - Cleaning up finished run: diootn6d
2022-06-20 03:55:16,102 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:55:16,103 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.1
2022-06-20 03:55:16,113 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 03:55:21,124 - wandb.wandb_agent - INFO - Running runs: ['e69f742p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_035521-e69f742p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-65
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/e69f742p
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27474
wandb:    train_loss 2.81285
wandb: training_time 0.98576
wandb:        val_f1 0.29233
wandb:      val_loss 2.72741
wandb: 
wandb: Synced tough-sweep-65: https://wandb.ai/jah377/sffCSX_arxiv/runs/e69f742p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_035521-e69f742p/logs
2022-06-20 04:06:16,476 - wandb.wandb_agent - INFO - Cleaning up finished run: e69f742p
2022-06-20 04:06:16,941 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:06:16,941 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 04:06:16,950 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 04:06:21,963 - wandb.wandb_agent - INFO - Running runs: ['e6g6l41b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_040622-e6g6l41b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-66
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/e6g6l41b
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45408
wandb:    train_loss 1.94426
wandb: training_time 0.93304
wandb:        val_f1 0.44804
wandb:      val_loss 1.93599
wandb: 
wandb: Synced winter-sweep-66: https://wandb.ai/jah377/sffCSX_arxiv/runs/e6g6l41b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_040622-e6g6l41b/logs
2022-06-20 04:17:29,196 - wandb.wandb_agent - INFO - Cleaning up finished run: e6g6l41b
2022-06-20 04:17:30,011 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:17:30,011 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 04:17:30,019 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 04:17:35,035 - wandb.wandb_agent - INFO - Running runs: ['4hc15muy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_041735-4hc15muy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-67
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/4hc15muy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.61103
wandb:    train_loss 1.30294
wandb: training_time 1.0126
wandb:        val_f1 0.58421
wandb:      val_loss 1.40393
wandb: 
wandb: Synced drawn-sweep-67: https://wandb.ai/jah377/sffCSX_arxiv/runs/4hc15muy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_041735-4hc15muy/logs
2022-06-20 04:28:51,573 - wandb.wandb_agent - INFO - Cleaning up finished run: 4hc15muy
2022-06-20 04:28:52,397 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:28:52,398 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 04:28:52,405 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 04:28:57,419 - wandb.wandb_agent - INFO - Running runs: ['l9q9cjdp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_042857-l9q9cjdp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-68
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/l9q9cjdp
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60059
wandb:    train_loss 1.33298
wandb: training_time 1.0827
wandb:        val_f1 0.59066
wandb:      val_loss 1.34807
wandb: 
wandb: Synced major-sweep-68: https://wandb.ai/jah377/sffCSX_arxiv/runs/l9q9cjdp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_042857-l9q9cjdp/logs
2022-06-20 04:41:13,960 - wandb.wandb_agent - INFO - Cleaning up finished run: l9q9cjdp
2022-06-20 04:41:14,660 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:41:14,661 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 04:41:14,670 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 04:41:19,684 - wandb.wandb_agent - INFO - Running runs: ['k9ok4j8w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_044119-k9ok4j8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-69
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/k9ok4j8w
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.54669
wandb:    train_loss 1.54034
wandb: training_time 0.97416
wandb:        val_f1 0.53666
wandb:      val_loss 1.55947
wandb: 
wandb: Synced dandy-sweep-69: https://wandb.ai/jah377/sffCSX_arxiv/runs/k9ok4j8w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_044119-k9ok4j8w/logs
2022-06-20 04:51:59,876 - wandb.wandb_agent - INFO - Cleaning up finished run: k9ok4j8w
2022-06-20 04:52:03,387 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:52:03,388 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 04:52:03,395 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 04:52:08,411 - wandb.wandb_agent - INFO - Running runs: ['rpavzuar']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_045208-rpavzuar
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-70
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/rpavzuar
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.59503
wandb:    train_loss 1.3442
wandb: training_time 0.86878
wandb:        val_f1 0.55962
wandb:      val_loss 1.47559
wandb: 
wandb: Synced graceful-sweep-70: https://wandb.ai/jah377/sffCSX_arxiv/runs/rpavzuar
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_045208-rpavzuar/logs
2022-06-20 05:02:06,423 - wandb.wandb_agent - INFO - Cleaning up finished run: rpavzuar
2022-06-20 05:02:07,414 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:02:07,415 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-20 05:02:07,423 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 05:02:12,439 - wandb.wandb_agent - INFO - Running runs: ['q2q9xwo4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_050212-q2q9xwo4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-71
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/q2q9xwo4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17897
wandb:    train_loss 3.64536
wandb: training_time 0.91814
wandb:        val_f1 0.07628
wandb:      val_loss 3.64784
wandb: 
wandb: Synced daily-sweep-71: https://wandb.ai/jah377/sffCSX_arxiv/runs/q2q9xwo4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_050212-q2q9xwo4/logs
2022-06-20 05:12:46,916 - wandb.wandb_agent - INFO - Cleaning up finished run: q2q9xwo4
2022-06-20 05:12:47,358 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:12:47,358 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 05:12:47,365 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 05:12:52,376 - wandb.wandb_agent - INFO - Running runs: ['d3wdio32']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_051252-d3wdio32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-72
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/d3wdio32
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51744
wandb:    train_loss 1.66511
wandb: training_time 0.79958
wandb:        val_f1 0.51878
wandb:      val_loss 1.64347
wandb: 
wandb: Synced absurd-sweep-72: https://wandb.ai/jah377/sffCSX_arxiv/runs/d3wdio32
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_051252-d3wdio32/logs
2022-06-20 05:22:41,116 - wandb.wandb_agent - INFO - Cleaning up finished run: d3wdio32
2022-06-20 05:22:41,814 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:22:41,814 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 05:22:41,821 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 05:22:46,836 - wandb.wandb_agent - INFO - Running runs: ['9ap4o7ii']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_052246-9ap4o7ii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-73
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/9ap4o7ii
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45084
wandb:    train_loss 1.90513
wandb: training_time 0.86724
wandb:        val_f1 0.45592
wandb:      val_loss 1.8445
wandb: 
wandb: Synced still-sweep-73: https://wandb.ai/jah377/sffCSX_arxiv/runs/9ap4o7ii
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_052246-9ap4o7ii/logs
2022-06-20 05:33:25,682 - wandb.wandb_agent - INFO - Cleaning up finished run: 9ap4o7ii
2022-06-20 05:33:26,304 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:33:26,305 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 05:33:26,313 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 05:33:31,329 - wandb.wandb_agent - INFO - Running runs: ['g3duyu92']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_053331-g3duyu92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-74
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/g3duyu92
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4587
wandb:    train_loss 1.92517
wandb: training_time 0.93757
wandb:        val_f1 0.46438
wandb:      val_loss 1.8759
wandb: 
wandb: Synced apricot-sweep-74: https://wandb.ai/jah377/sffCSX_arxiv/runs/g3duyu92
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_053331-g3duyu92/logs
2022-06-20 05:44:20,618 - wandb.wandb_agent - INFO - Cleaning up finished run: g3duyu92
2022-06-20 05:44:22,098 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:44:22,098 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-20 05:44:22,107 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 05:44:27,122 - wandb.wandb_agent - INFO - Running runs: ['f7agxbkh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_054427-f7agxbkh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-75
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/f7agxbkh
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50244
wandb:    train_loss 1.88666
wandb: training_time 0.81708
wandb:        val_f1 0.51357
wandb:      val_loss 1.85035
wandb: 
wandb: Synced spring-sweep-75: https://wandb.ai/jah377/sffCSX_arxiv/runs/f7agxbkh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_054427-f7agxbkh/logs
2022-06-20 05:54:30,153 - wandb.wandb_agent - INFO - Cleaning up finished run: f7agxbkh
2022-06-20 05:54:30,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:54:30,878 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 05:54:30,886 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 05:54:35,895 - wandb.wandb_agent - INFO - Running runs: ['97i14ry7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_055436-97i14ry7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-76
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/97i14ry7
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63212
wandb:    train_loss 1.24627
wandb: training_time 0.87611
wandb:        val_f1 0.5668
wandb:      val_loss 1.48069
wandb: 
wandb: Synced logical-sweep-76: https://wandb.ai/jah377/sffCSX_arxiv/runs/97i14ry7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_055436-97i14ry7/logs
2022-06-20 06:04:02,872 - wandb.wandb_agent - INFO - Cleaning up finished run: 97i14ry7
2022-06-20 06:04:03,616 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:04:03,617 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 06:04:03,624 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 06:04:08,639 - wandb.wandb_agent - INFO - Running runs: ['t0dhlona']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_060408-t0dhlona
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-77
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/t0dhlona
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51895
wandb:    train_loss 1.6622
wandb: training_time 1.06299
wandb:        val_f1 0.51512
wandb:      val_loss 1.6517
wandb: 
wandb: Synced good-sweep-77: https://wandb.ai/jah377/sffCSX_arxiv/runs/t0dhlona
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_060408-t0dhlona/logs
2022-06-20 06:15:28,754 - wandb.wandb_agent - INFO - Cleaning up finished run: t0dhlona
2022-06-20 06:15:29,297 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:15:29,297 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 06:15:29,304 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 06:15:34,316 - wandb.wandb_agent - INFO - Running runs: ['x3117evw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_061534-x3117evw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-78
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/x3117evw
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.74881
wandb:    train_loss 0.824
wandb: training_time 1.33415
wandb:        val_f1 0.58566
wandb:      val_loss 1.42202
wandb: 
wandb: Synced major-sweep-78: https://wandb.ai/jah377/sffCSX_arxiv/runs/x3117evw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_061534-x3117evw/logs
2022-06-20 06:27:55,325 - wandb.wandb_agent - INFO - Cleaning up finished run: x3117evw
2022-06-20 06:27:55,880 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:27:55,880 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 06:27:55,888 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 06:28:00,900 - wandb.wandb_agent - INFO - Running runs: ['q4l78gpp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_062801-q4l78gpp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-79
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/q4l78gpp
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68161
wandb:    train_loss 1.01606
wandb: training_time 0.8897
wandb:        val_f1 0.57284
wandb:      val_loss 1.47747
wandb: 
wandb: Synced rose-sweep-79: https://wandb.ai/jah377/sffCSX_arxiv/runs/q4l78gpp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_062801-q4l78gpp/logs
2022-06-20 06:38:50,216 - wandb.wandb_agent - INFO - Cleaning up finished run: q4l78gpp
2022-06-20 06:38:53,755 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:38:53,755 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 06:38:53,762 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 06:38:58,776 - wandb.wandb_agent - INFO - Running runs: ['lceg9564']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_063859-lceg9564
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-80
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/lceg9564
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47038
wandb:    train_loss 1.89526
wandb: training_time 0.80287
wandb:        val_f1 0.47099
wandb:      val_loss 1.8609
wandb: 
wandb: Synced classic-sweep-80: https://wandb.ai/jah377/sffCSX_arxiv/runs/lceg9564
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_063859-lceg9564/logs
2022-06-20 06:49:02,165 - wandb.wandb_agent - INFO - Cleaning up finished run: lceg9564
2022-06-20 06:49:02,689 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:49:02,690 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-20 06:49:02,698 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 06:49:07,712 - wandb.wandb_agent - INFO - Running runs: ['atlp2xdv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_064907-atlp2xdv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-81
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/atlp2xdv
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.76868
wandb:    train_loss 0.81591
wandb: training_time 1.0498
wandb:        val_f1 0.57854
wandb:      val_loss 1.45862
wandb: 
wandb: Synced still-sweep-81: https://wandb.ai/jah377/sffCSX_arxiv/runs/atlp2xdv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_064907-atlp2xdv/logs
2022-06-20 07:00:29,078 - wandb.wandb_agent - INFO - Cleaning up finished run: atlp2xdv
2022-06-20 07:00:29,475 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:00:29,476 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.1
2022-06-20 07:00:29,485 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 07:00:34,499 - wandb.wandb_agent - INFO - Running runs: ['g2ezcg6h']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_070034-g2ezcg6h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-82
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/g2ezcg6h
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51053
wandb:    train_loss 1.70918
wandb: training_time 1.0917
wandb:        val_f1 0.5169
wandb:      val_loss 1.67144
wandb: 
wandb: Synced swift-sweep-82: https://wandb.ai/jah377/sffCSX_arxiv/runs/g2ezcg6h
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_070034-g2ezcg6h/logs
2022-06-20 07:12:37,729 - wandb.wandb_agent - INFO - Cleaning up finished run: g2ezcg6h
2022-06-20 07:12:38,163 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:12:38,163 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-20 07:12:38,171 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 07:12:43,184 - wandb.wandb_agent - INFO - Running runs: ['tfg9b0we']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_071243-tfg9b0we
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-83
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/tfg9b0we
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17918
wandb:    train_loss 3.64533
wandb: training_time 1.09914
wandb:        val_f1 0.07628
wandb:      val_loss 3.64783
wandb: 
wandb: Synced eternal-sweep-83: https://wandb.ai/jah377/sffCSX_arxiv/runs/tfg9b0we
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_071243-tfg9b0we/logs
2022-06-20 07:24:55,377 - wandb.wandb_agent - INFO - Cleaning up finished run: tfg9b0we
2022-06-20 07:25:04,303 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:25:04,303 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 07:25:04,311 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 07:25:09,324 - wandb.wandb_agent - INFO - Running runs: ['diwrzfhs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_072509-diwrzfhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-84
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/diwrzfhs
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47241
wandb:    train_loss 1.82888
wandb: training_time 0.82824
wandb:        val_f1 0.47585
wandb:      val_loss 1.79388
wandb: 
wandb: Synced desert-sweep-84: https://wandb.ai/jah377/sffCSX_arxiv/runs/diwrzfhs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_072509-diwrzfhs/logs
2022-06-20 07:34:37,091 - wandb.wandb_agent - INFO - Cleaning up finished run: diwrzfhs
2022-06-20 07:34:37,542 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:34:37,542 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 07:34:37,550 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 07:34:42,566 - wandb.wandb_agent - INFO - Running runs: ['9i8340wp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_073442-9i8340wp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-85
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/9i8340wp
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.32693
wandb:    train_loss 2.45843
wandb: training_time 0.93192
wandb:        val_f1 0.33169
wandb:      val_loss 2.40544
wandb: 
wandb: Synced lunar-sweep-85: https://wandb.ai/jah377/sffCSX_arxiv/runs/9i8340wp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_073442-9i8340wp/logs
2022-06-20 07:45:11,518 - wandb.wandb_agent - INFO - Cleaning up finished run: 9i8340wp
2022-06-20 07:45:12,024 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:45:12,025 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 07:45:12,032 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 07:45:17,044 - wandb.wandb_agent - INFO - Running runs: ['hb3kntug']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_074517-hb3kntug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-86
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/hb3kntug
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52836
wandb:    train_loss 1.60532
wandb: training_time 0.89075
wandb:        val_f1 0.52992
wandb:      val_loss 1.58503
wandb: 
wandb: Synced resilient-sweep-86: https://wandb.ai/jah377/sffCSX_arxiv/runs/hb3kntug
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_074517-hb3kntug/logs
2022-06-20 07:55:58,022 - wandb.wandb_agent - INFO - Cleaning up finished run: hb3kntug
2022-06-20 07:55:59,249 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:55:59,249 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1
2022-06-20 07:55:59,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-20 07:56:04,271 - wandb.wandb_agent - INFO - Running runs: ['557jmwnk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_075604-557jmwnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-87
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/557jmwnk
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52599
wandb:    train_loss 1.94578
wandb: training_time 0.88468
wandb:        val_f1 0.53589
wandb:      val_loss 1.9225
wandb: 
wandb: Synced prime-sweep-87: https://wandb.ai/jah377/sffCSX_arxiv/runs/557jmwnk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_075604-557jmwnk/logs
2022-06-20 08:07:25,182 - wandb.wandb_agent - INFO - Cleaning up finished run: 557jmwnk
2022-06-20 08:07:25,621 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:07:25,621 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 08:07:25,631 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 08:07:30,644 - wandb.wandb_agent - INFO - Running runs: ['qxn6sg2v']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_080730-qxn6sg2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-88
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/qxn6sg2v
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53668
wandb:    train_loss 1.57416
wandb: training_time 0.96637
wandb:        val_f1 0.53831
wandb:      val_loss 1.56157
wandb: 
wandb: Synced clear-sweep-88: https://wandb.ai/jah377/sffCSX_arxiv/runs/qxn6sg2v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_080730-qxn6sg2v/logs
2022-06-20 08:18:26,188 - wandb.wandb_agent - INFO - Cleaning up finished run: qxn6sg2v
2022-06-20 08:18:27,026 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:18:27,026 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 08:18:27,033 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 08:18:32,048 - wandb.wandb_agent - INFO - Running runs: ['zpipxhw5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_081832-zpipxhw5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-89
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/zpipxhw5
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40555
wandb:    train_loss 2.08311
wandb: training_time 1.05302
wandb:        val_f1 0.40142
wandb:      val_loss 2.07172
wandb: 
wandb: Synced swift-sweep-89: https://wandb.ai/jah377/sffCSX_arxiv/runs/zpipxhw5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_081832-zpipxhw5/logs
2022-06-20 08:29:48,178 - wandb.wandb_agent - INFO - Cleaning up finished run: zpipxhw5
2022-06-20 08:29:48,640 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:29:48,641 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 08:29:48,648 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 08:29:53,663 - wandb.wandb_agent - INFO - Running runs: ['4esx28do']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_082953-4esx28do
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-90
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/4esx28do
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40842
wandb:    train_loss 2.06489
wandb: training_time 0.92351
wandb:        val_f1 0.41783
wandb:      val_loss 2.00251
wandb: 
wandb: Synced glad-sweep-90: https://wandb.ai/jah377/sffCSX_arxiv/runs/4esx28do
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_082953-4esx28do/logs
2022-06-20 08:39:57,760 - wandb.wandb_agent - INFO - Cleaning up finished run: 4esx28do
2022-06-20 08:39:58,815 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:39:58,815 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.0001
2022-06-20 08:39:58,823 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 08:40:03,836 - wandb.wandb_agent - INFO - Running runs: ['qfkdbrpl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_084003-qfkdbrpl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-91
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/qfkdbrpl
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45241
wandb:    train_loss 1.9535
wandb: training_time 0.81081
wandb:        val_f1 0.44226
wandb:      val_loss 1.96247
wandb: 
wandb: Synced atomic-sweep-91: https://wandb.ai/jah377/sffCSX_arxiv/runs/qfkdbrpl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_084003-qfkdbrpl/logs
2022-06-20 08:49:48,805 - wandb.wandb_agent - INFO - Cleaning up finished run: qfkdbrpl
2022-06-20 08:49:49,307 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:49:49,308 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-05
2022-06-20 08:49:49,315 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 08:49:54,331 - wandb.wandb_agent - INFO - Running runs: ['cxlnmogc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_084954-cxlnmogc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-92
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/cxlnmogc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47978
wandb:    train_loss 1.78587
wandb: training_time 0.77605
wandb:        val_f1 0.48726
wandb:      val_loss 1.73275
wandb: 
wandb: Synced resilient-sweep-92: https://wandb.ai/jah377/sffCSX_arxiv/runs/cxlnmogc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_084954-cxlnmogc/logs
2022-06-20 08:59:40,544 - wandb.wandb_agent - INFO - Cleaning up finished run: cxlnmogc
2022-06-20 08:59:41,056 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 08:59:41,057 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 08:59:41,065 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 08:59:46,076 - wandb.wandb_agent - INFO - Running runs: ['186kph74']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_085946-186kph74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-93
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/186kph74
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.62602
wandb:    train_loss 1.26326
wandb: training_time 1.18517
wandb:        val_f1 0.58854
wandb:      val_loss 1.4035
wandb: 
wandb: Synced devout-sweep-93: https://wandb.ai/jah377/sffCSX_arxiv/runs/186kph74
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_085946-186kph74/logs
2022-06-20 09:12:21,468 - wandb.wandb_agent - INFO - Cleaning up finished run: 186kph74
2022-06-20 09:12:22,078 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:12:22,078 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 09:12:22,086 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 09:12:27,102 - wandb.wandb_agent - INFO - Running runs: ['fgp4eq23']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_091227-fgp4eq23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-94
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/fgp4eq23
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57988
wandb:    train_loss 1.44105
wandb: training_time 1.22145
wandb:        val_f1 0.57683
wandb:      val_loss 1.4369
wandb: 
wandb: Synced zany-sweep-94: https://wandb.ai/jah377/sffCSX_arxiv/runs/fgp4eq23
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_091227-fgp4eq23/logs
2022-06-20 09:24:57,680 - wandb.wandb_agent - INFO - Cleaning up finished run: fgp4eq23
2022-06-20 09:24:58,398 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:24:58,399 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 09:24:58,407 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 09:25:03,424 - wandb.wandb_agent - INFO - Running runs: ['0j78r4va']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_092503-0j78r4va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-95
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/0j78r4va
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56724
wandb:    train_loss 1.459
wandb: training_time 0.93497
wandb:        val_f1 0.55639
wandb:      val_loss 1.49564
wandb: 
wandb: Synced stoic-sweep-95: https://wandb.ai/jah377/sffCSX_arxiv/runs/0j78r4va
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_092503-0j78r4va/logs
2022-06-20 09:35:36,865 - wandb.wandb_agent - INFO - Cleaning up finished run: 0j78r4va
2022-06-20 09:35:46,841 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:35:46,841 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.001
2022-06-20 09:35:46,850 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 09:35:51,864 - wandb.wandb_agent - INFO - Running runs: ['8v9zubqy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_093552-8v9zubqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-96
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/8v9zubqy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51417
wandb:    train_loss 1.67991
wandb: training_time 0.80622
wandb:        val_f1 0.50367
wandb:      val_loss 1.6941
wandb: 
wandb: Synced curious-sweep-96: https://wandb.ai/jah377/sffCSX_arxiv/runs/8v9zubqy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_093552-8v9zubqy/logs
2022-06-20 09:45:34,843 - wandb.wandb_agent - INFO - Cleaning up finished run: 8v9zubqy
2022-06-20 09:45:35,357 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:45:35,358 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 09:45:35,365 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 09:45:40,380 - wandb.wandb_agent - INFO - Running runs: ['8357k9c6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_094540-8357k9c6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-97
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/8357k9c6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4744
wandb:    train_loss 1.85916
wandb: training_time 0.8445
wandb:        val_f1 0.48592
wandb:      val_loss 1.80612
wandb: 
wandb: Synced gallant-sweep-97: https://wandb.ai/jah377/sffCSX_arxiv/runs/8357k9c6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_094540-8357k9c6/logs
2022-06-20 09:55:12,857 - wandb.wandb_agent - INFO - Cleaning up finished run: 8357k9c6
2022-06-20 09:55:13,360 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 09:55:13,361 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 0.01
2022-06-20 09:55:13,368 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 09:55:18,380 - wandb.wandb_agent - INFO - Running runs: ['v85s6fqy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_095518-v85s6fqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-98
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/v85s6fqy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65228
wandb:    train_loss 1.15363
wandb: training_time 1.81726
wandb:        val_f1 0.6125
wandb:      val_loss 1.317
wandb: 
wandb: Synced morning-sweep-98: https://wandb.ai/jah377/sffCSX_arxiv/runs/v85s6fqy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_095518-v85s6fqy/logs
2022-06-20 10:10:33,132 - wandb.wandb_agent - INFO - Cleaning up finished run: v85s6fqy
2022-06-20 10:10:37,228 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 10:10:37,229 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-07
2022-06-20 10:10:37,237 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 10:10:42,252 - wandb.wandb_agent - INFO - Running runs: ['l3m9kli2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_101042-l3m9kli2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-99
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/l3m9kli2
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.2484
wandb:    train_loss 2.91999
wandb: training_time 1.30406
wandb:        val_f1 0.26897
wandb:      val_loss 2.99731
wandb: 
wandb: Synced frosty-sweep-99: https://wandb.ai/jah377/sffCSX_arxiv/runs/l3m9kli2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_101042-l3m9kli2/logs
2022-06-20 10:23:24,079 - wandb.wandb_agent - INFO - Cleaning up finished run: l3m9kli2
2022-06-20 10:23:24,766 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 10:23:24,766 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine_per_k
	WEIGHT_DECAY: 1e-06
2022-06-20 10:23:24,774 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine_per_k --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 10:23:29,788 - wandb.wandb_agent - INFO - Running runs: ['g7nbicsd']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCSX_arxiv/wandb/run-20220620_102329-g7nbicsd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-100
wandb:  View project at https://wandb.ai/jah377/sffCSX_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb:  View run at https://wandb.ai/jah377/sffCSX_arxiv/runs/g7nbicsd
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine_per_k'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.61816
wandb:    train_loss 1.26584
wandb: training_time 1.25449
wandb:        val_f1 0.57327
wandb:      val_loss 1.4435
wandb: 
wandb: Synced twilight-sweep-100: https://wandb.ai/jah377/sffCSX_arxiv/runs/g7nbicsd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_102329-g7nbicsd/logs
2022-06-20 10:36:14,311 - wandb.wandb_agent - INFO - Cleaning up finished run: g7nbicsd
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: x3q5jz2a
Sweep URL: https://wandb.ai/jah377/sffCSX_arxiv/sweeps/x3q5jz2a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: \ 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: | 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: / 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: - 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: \ 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: | 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: / 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb: - 0.265 MB of 0.265 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced comic-lake-334: https://wandb.ai/jah377/sffCSX_arxiv/runs/3ew9q5dw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_143118-3ew9q5dw/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 20 hours 05 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
