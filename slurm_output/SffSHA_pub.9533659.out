Thu 16 Jun 2022 05:54:51 AM CEST
r31n4.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: pubmed
method: bayes
model: SIGNff_SHA
iterations: 100
run_trial: false
config: SIGNff_SHA.yaml
train_file: hps_SIGNff_DPA.py
project_name: sffSHA_pubmed
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  ATTN_HEADS:
    value: 1
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 64
    - 128
    - 256
    - 512
    - 1024
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 64
    - 128
    - 256
    - 512
  DATASET:
    value: pubmed
  DPA_NORMALIZATION:
    values:
    - 0
    - 1
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 64
    - 128
    - 256
    - 512
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  TRANSFORMATION:
    value: dot_product
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff_DPA.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_055534-233x4tjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-feather-100
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/233x4tjl
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-16 05:55:42,960 - wandb.wandb_agent - INFO - Running runs: []
2022-06-16 05:55:43,231 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:55:43,231 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 05:55:43,239 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 05:55:48,252 - wandb.wandb_agent - INFO - Running runs: ['swaydm3y']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_055547-swaydm3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-1
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/swaydm3y
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99345
wandb:    train_loss 0.07186
wandb: training_time 1.76696
wandb:        val_f1 0.922
wandb:      val_loss 0.2318
wandb: 
wandb: Synced eternal-sweep-1: https://wandb.ai/jah377/sffSHA_pubmed/runs/swaydm3y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_055547-swaydm3y/logs
2022-06-16 06:09:48,020 - wandb.wandb_agent - INFO - Cleaning up finished run: swaydm3y
2022-06-16 06:09:48,366 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:09:48,366 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 06:09:48,375 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 06:09:53,390 - wandb.wandb_agent - INFO - Running runs: ['5gxcrytj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_060953-5gxcrytj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-2
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/5gxcrytj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.72254
wandb:    train_loss 1.01129
wandb: training_time 0.52952
wandb:        val_f1 0.73
wandb:      val_loss 1.01081
wandb: 
wandb: Synced pretty-sweep-2: https://wandb.ai/jah377/sffSHA_pubmed/runs/5gxcrytj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_060953-5gxcrytj/logs
2022-06-16 06:15:43,765 - wandb.wandb_agent - INFO - Cleaning up finished run: 5gxcrytj
2022-06-16 06:15:44,147 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:15:44,147 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 06:15:44,154 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 06:15:49,168 - wandb.wandb_agent - INFO - Running runs: ['tpluf7dr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_061549-tpluf7dr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-3
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/tpluf7dr
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k1_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93403
wandb:    train_loss 0.1835
wandb: training_time 1.44055
wandb:        val_f1 0.912
wandb:      val_loss 0.2428
wandb: 
wandb: Synced cosmic-sweep-3: https://wandb.ai/jah377/sffSHA_pubmed/runs/tpluf7dr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_061549-tpluf7dr/logs
2022-06-16 06:27:45,332 - wandb.wandb_agent - INFO - Cleaning up finished run: tpluf7dr
2022-06-16 06:27:45,725 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:27:45,725 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 06:27:45,734 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 06:27:50,744 - wandb.wandb_agent - INFO - Running runs: ['s07rs6e7']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_062749-s07rs6e7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-4
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/s07rs6e7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85987
wandb:    train_loss 0.37661
wandb: training_time 3.39104
wandb:        val_f1 0.878
wandb:      val_loss 0.35708
wandb: 
wandb: Synced smooth-sweep-4: https://wandb.ai/jah377/sffSHA_pubmed/runs/s07rs6e7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_062749-s07rs6e7/logs
2022-06-16 06:52:03,479 - wandb.wandb_agent - INFO - Cleaning up finished run: s07rs6e7
2022-06-16 06:52:03,920 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:52:03,921 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 06:52:03,927 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 06:52:08,940 - wandb.wandb_agent - INFO - Running runs: ['ac2zfo21']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_065208-ac2zfo21
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-5
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/ac2zfo21
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.79627
wandb:    train_loss 0.70736
wandb: training_time 1.08985
wandb:        val_f1 0.812
wandb:      val_loss 0.69437
wandb: 
wandb: Synced solar-sweep-5: https://wandb.ai/jah377/sffSHA_pubmed/runs/ac2zfo21
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_065208-ac2zfo21/logs
2022-06-16 07:01:04,876 - wandb.wandb_agent - INFO - Cleaning up finished run: ac2zfo21
2022-06-16 07:01:05,350 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:01:05,350 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 07:01:05,360 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:01:10,372 - wandb.wandb_agent - INFO - Running runs: ['84zperhq']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_070109-84zperhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-6
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/84zperhq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92952
wandb:    train_loss 0.18844
wandb: training_time 0.59409
wandb:        val_f1 0.912
wandb:      val_loss 0.24657
wandb: 
wandb: Synced scarlet-sweep-6: https://wandb.ai/jah377/sffSHA_pubmed/runs/84zperhq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_070109-84zperhq/logs
2022-06-16 07:07:05,789 - wandb.wandb_agent - INFO - Cleaning up finished run: 84zperhq
2022-06-16 07:07:06,159 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:07:06,159 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 07:07:06,168 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 07:07:11,182 - wandb.wandb_agent - INFO - Running runs: ['pqnjbxxa']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_070711-pqnjbxxa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-7
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/pqnjbxxa
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87605
wandb:    train_loss 0.56608
wandb: training_time 1.44667
wandb:        val_f1 0.874
wandb:      val_loss 0.56159
wandb: 
wandb: Synced swift-sweep-7: https://wandb.ai/jah377/sffSHA_pubmed/runs/pqnjbxxa
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_070711-pqnjbxxa/logs
2022-06-16 07:18:51,723 - wandb.wandb_agent - INFO - Cleaning up finished run: pqnjbxxa
2022-06-16 07:18:52,093 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:18:52,093 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 07:18:52,102 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:18:57,117 - wandb.wandb_agent - INFO - Running runs: ['p9h5x8bb']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_071856-p9h5x8bb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-8
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/p9h5x8bb
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91164
wandb:    train_loss 0.23658
wandb: training_time 2.68218
wandb:        val_f1 0.9
wandb:      val_loss 0.26117
wandb: 
wandb: Synced serene-sweep-8: https://wandb.ai/jah377/sffSHA_pubmed/runs/p9h5x8bb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_071856-p9h5x8bb/logs
2022-06-16 07:38:42,874 - wandb.wandb_agent - INFO - Cleaning up finished run: p9h5x8bb
2022-06-16 07:38:43,270 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:38:43,270 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 07:38:43,279 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 07:38:48,292 - wandb.wandb_agent - INFO - Running runs: ['jwggnfda']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_073848-jwggnfda
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-9
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/jwggnfda
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87599
wandb:    train_loss 0.31502
wandb: training_time 1.62409
wandb:        val_f1 0.89
wandb:      val_loss 0.31884
wandb: 
wandb: Synced expert-sweep-9: https://wandb.ai/jah377/sffSHA_pubmed/runs/jwggnfda
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_073848-jwggnfda/logs
2022-06-16 07:51:30,508 - wandb.wandb_agent - INFO - Cleaning up finished run: jwggnfda
2022-06-16 07:51:30,916 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:51:30,917 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 07:51:30,925 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 07:51:35,940 - wandb.wandb_agent - INFO - Running runs: ['txcvd32u']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_075136-txcvd32u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-10
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/txcvd32u
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45537
wandb:    train_loss 0.99815
wandb: training_time 0.62866
wandb:        val_f1 0.46
wandb:      val_loss 0.99286
wandb: 
wandb: Synced comfy-sweep-10: https://wandb.ai/jah377/sffSHA_pubmed/runs/txcvd32u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_075136-txcvd32u/logs
2022-06-16 07:57:42,132 - wandb.wandb_agent - INFO - Cleaning up finished run: txcvd32u
2022-06-16 07:57:42,550 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:57:42,550 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 07:57:42,557 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:57:47,572 - wandb.wandb_agent - INFO - Running runs: ['pwj2krq9']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_075747-pwj2krq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-11
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/pwj2krq9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.84111
wandb:    train_loss 0.54895
wandb: training_time 2.67962
wandb:        val_f1 0.864
wandb:      val_loss 0.51619
wandb: 
wandb: Synced silvery-sweep-11: https://wandb.ai/jah377/sffSHA_pubmed/runs/pwj2krq9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_075747-pwj2krq9/logs
2022-06-16 08:17:02,940 - wandb.wandb_agent - INFO - Cleaning up finished run: pwj2krq9
2022-06-16 08:17:03,396 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:17:03,396 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 08:17:03,405 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 08:17:08,416 - wandb.wandb_agent - INFO - Running runs: ['e69wwwy0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_081708-e69wwwy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-12
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/e69wwwy0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k0_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95978
wandb:    train_loss 0.1202
wandb: training_time 1.22948
wandb:        val_f1 0.888
wandb:      val_loss 0.30081
wandb: 
wandb: Synced driven-sweep-12: https://wandb.ai/jah377/sffSHA_pubmed/runs/e69wwwy0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_081708-e69wwwy0/logs
2022-06-16 08:27:46,975 - wandb.wandb_agent - INFO - Cleaning up finished run: e69wwwy0
2022-06-16 08:27:47,340 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:27:47,340 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 08:27:47,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 08:27:52,360 - wandb.wandb_agent - INFO - Running runs: ['a7976jmr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_082752-a7976jmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-13
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/a7976jmr
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89926
wandb:    train_loss 0.2544
wandb: training_time 0.83647
wandb:        val_f1 0.884
wandb:      val_loss 0.29821
wandb: 
wandb: Synced polar-sweep-13: https://wandb.ai/jah377/sffSHA_pubmed/runs/a7976jmr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_082752-a7976jmr/logs
2022-06-16 08:34:44,628 - wandb.wandb_agent - INFO - Cleaning up finished run: a7976jmr
2022-06-16 08:34:45,068 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:34:45,068 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 08:34:45,077 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 08:34:50,092 - wandb.wandb_agent - INFO - Running runs: ['hpx26gnk']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_083449-hpx26gnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-14
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/hpx26gnk
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99015
wandb:    train_loss 0.03355
wandb: training_time 2.95474
wandb:        val_f1 0.914
wandb:      val_loss 0.30112
wandb: 
wandb: Synced lunar-sweep-14: https://wandb.ai/jah377/sffSHA_pubmed/runs/hpx26gnk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_083449-hpx26gnk/logs
2022-06-16 08:56:20,212 - wandb.wandb_agent - INFO - Cleaning up finished run: hpx26gnk
2022-06-16 08:56:20,656 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:56:20,657 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 08:56:20,665 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 08:56:25,680 - wandb.wandb_agent - INFO - Running runs: ['ugg8amfk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_085625-ugg8amfk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-15
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/ugg8amfk
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97112
wandb:    train_loss 0.0918
wandb: training_time 1.28323
wandb:        val_f1 0.904
wandb:      val_loss 0.2884
wandb: 
wandb: Synced helpful-sweep-15: https://wandb.ai/jah377/sffSHA_pubmed/runs/ugg8amfk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_085625-ugg8amfk/logs
2022-06-16 09:06:59,512 - wandb.wandb_agent - INFO - Cleaning up finished run: ugg8amfk
2022-06-16 09:07:00,009 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:07:00,010 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 09:07:00,016 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 09:07:05,031 - wandb.wandb_agent - INFO - Running runs: ['qgy05v22']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_090705-qgy05v22
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-16
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/qgy05v22
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92009
wandb:    train_loss 0.21959
wandb: training_time 0.42287
wandb:        val_f1 0.884
wandb:      val_loss 0.28475
wandb: 
wandb: Synced zany-sweep-16: https://wandb.ai/jah377/sffSHA_pubmed/runs/qgy05v22
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_090705-qgy05v22/logs
2022-06-16 09:11:58,771 - wandb.wandb_agent - INFO - Cleaning up finished run: qgy05v22
2022-06-16 09:11:59,269 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:11:59,269 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 09:11:59,278 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 09:12:04,293 - wandb.wandb_agent - INFO - Running runs: ['cpie78ps']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_091204-cpie78ps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-17
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/cpie78ps
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89871
wandb:    train_loss 0.27972
wandb: training_time 2.66972
wandb:        val_f1 0.89
wandb:      val_loss 0.29908
wandb: 
wandb: Synced whole-sweep-17: https://wandb.ai/jah377/sffSHA_pubmed/runs/cpie78ps
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_091204-cpie78ps/logs
2022-06-16 09:31:52,203 - wandb.wandb_agent - INFO - Cleaning up finished run: cpie78ps
2022-06-16 09:31:52,635 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:31:52,635 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 09:31:52,644 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 09:31:57,656 - wandb.wandb_agent - INFO - Running runs: ['053a01xd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_093157-053a01xd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-18
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/053a01xd
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95483
wandb:    train_loss 0.12405
wandb: training_time 0.78183
wandb:        val_f1 0.904
wandb:      val_loss 0.25796
wandb: 
wandb: Synced legendary-sweep-18: https://wandb.ai/jah377/sffSHA_pubmed/runs/053a01xd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_093157-053a01xd/logs
2022-06-16 09:39:16,518 - wandb.wandb_agent - INFO - Cleaning up finished run: 053a01xd
2022-06-16 09:39:16,979 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:39:16,979 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 09:39:16,988 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 09:39:22,002 - wandb.wandb_agent - INFO - Running runs: ['l6o50k2b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_093922-l6o50k2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-19
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/l6o50k2b
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99994
wandb:    train_loss 0.00036
wandb: training_time 1.58989
wandb:        val_f1 0.878
wandb:      val_loss 0.78575
wandb: 
wandb: Synced different-sweep-19: https://wandb.ai/jah377/sffSHA_pubmed/runs/l6o50k2b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_093922-l6o50k2b/logs
2022-06-16 09:52:45,392 - wandb.wandb_agent - INFO - Cleaning up finished run: l6o50k2b
2022-06-16 09:52:45,777 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:52:45,777 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 09:52:45,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 09:52:50,796 - wandb.wandb_agent - INFO - Running runs: ['5lkc61cc']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_095249-5lkc61cc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-20
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/5lkc61cc
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9996
wandb:    train_loss 0.00582
wandb: training_time 0.34748
wandb:        val_f1 0.858
wandb:      val_loss 0.50917
wandb: 
wandb: Synced misty-sweep-20: https://wandb.ai/jah377/sffSHA_pubmed/runs/5lkc61cc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_095249-5lkc61cc/logs
2022-06-16 09:57:11,573 - wandb.wandb_agent - INFO - Cleaning up finished run: 5lkc61cc
2022-06-16 09:57:11,982 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:57:11,983 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 09:57:11,990 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 09:57:17,004 - wandb.wandb_agent - INFO - Running runs: ['9mibwhai']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_095717-9mibwhai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-21
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/9mibwhai
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98724
wandb:    train_loss 0.08774
wandb: training_time 0.81362
wandb:        val_f1 0.886
wandb:      val_loss 0.32916
wandb: 
wandb: Synced smooth-sweep-21: https://wandb.ai/jah377/sffSHA_pubmed/runs/9mibwhai
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_095717-9mibwhai/logs
2022-06-16 10:04:29,960 - wandb.wandb_agent - INFO - Cleaning up finished run: 9mibwhai
2022-06-16 10:04:30,545 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:04:30,545 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 10:04:30,552 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 10:04:35,564 - wandb.wandb_agent - INFO - Running runs: ['jxbs2x91']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_100435-jxbs2x91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-22
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/jxbs2x91
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97964
wandb:    train_loss 0.07536
wandb: training_time 0.79864
wandb:        val_f1 0.906
wandb:      val_loss 0.27286
wandb: 
wandb: Synced peachy-sweep-22: https://wandb.ai/jah377/sffSHA_pubmed/runs/jxbs2x91
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_100435-jxbs2x91/logs
2022-06-16 10:11:49,776 - wandb.wandb_agent - INFO - Cleaning up finished run: jxbs2x91
2022-06-16 10:11:50,388 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:11:50,388 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 10:11:50,398 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 10:11:55,412 - wandb.wandb_agent - INFO - Running runs: ['bklgfx3d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_101155-bklgfx3d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-23
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/bklgfx3d
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95461
wandb:    train_loss 0.14058
wandb: training_time 2.14408
wandb:        val_f1 0.924
wandb:      val_loss 0.22894
wandb: 
wandb: Synced good-sweep-23: https://wandb.ai/jah377/sffSHA_pubmed/runs/bklgfx3d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_101155-bklgfx3d/logs
2022-06-16 10:27:43,914 - wandb.wandb_agent - INFO - Cleaning up finished run: bklgfx3d
2022-06-16 10:27:44,393 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:27:44,393 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 10:27:44,402 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 10:27:49,416 - wandb.wandb_agent - INFO - Running runs: ['8e0xxd9b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_102749-8e0xxd9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-24
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/8e0xxd9b
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86609
wandb:    train_loss 0.38316
wandb: training_time 3.28345
wandb:        val_f1 0.836
wandb:      val_loss 0.42978
wandb: 
wandb: Synced divine-sweep-24: https://wandb.ai/jah377/sffSHA_pubmed/runs/8e0xxd9b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_102749-8e0xxd9b/logs
2022-06-16 10:51:06,569 - wandb.wandb_agent - INFO - Cleaning up finished run: 8e0xxd9b
2022-06-16 10:51:07,074 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:51:07,074 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 10:51:07,084 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 10:51:12,096 - wandb.wandb_agent - INFO - Running runs: ['n6khdcyg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_105112-n6khdcyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-25
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/n6khdcyg
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98872
wandb:    train_loss 0.04322
wandb: training_time 2.45388
wandb:        val_f1 0.922
wandb:      val_loss 0.2301
wandb: 
wandb: Synced swift-sweep-25: https://wandb.ai/jah377/sffSHA_pubmed/runs/n6khdcyg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_105112-n6khdcyg/logs
2022-06-16 11:08:48,604 - wandb.wandb_agent - INFO - Cleaning up finished run: n6khdcyg
2022-06-16 11:08:49,188 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:08:49,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 11:08:49,195 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 11:08:54,208 - wandb.wandb_agent - INFO - Running runs: ['0tmrvos6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_110854-0tmrvos6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-26
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/0tmrvos6
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm1_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96358
wandb:    train_loss 0.11521
wandb: training_time 2.38016
wandb:        val_f1 0.926
wandb:      val_loss 0.23741
wandb: 
wandb: Synced light-sweep-26: https://wandb.ai/jah377/sffSHA_pubmed/runs/0tmrvos6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_110854-0tmrvos6/logs
2022-06-16 11:26:45,824 - wandb.wandb_agent - INFO - Cleaning up finished run: 0tmrvos6
2022-06-16 11:26:46,245 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:26:46,245 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 11:26:46,254 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 11:26:51,268 - wandb.wandb_agent - INFO - Running runs: ['m3k5hg4v']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_112651-m3k5hg4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-27
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/m3k5hg4v
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97216
wandb:    train_loss 0.07865
wandb: training_time 5.45697
wandb:        val_f1 0.924
wandb:      val_loss 0.24401
wandb: 
wandb: Synced olive-sweep-27: https://wandb.ai/jah377/sffSHA_pubmed/runs/m3k5hg4v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_112651-m3k5hg4v/logs
2022-06-16 12:03:22,856 - wandb.wandb_agent - INFO - Cleaning up finished run: m3k5hg4v
2022-06-16 12:03:23,434 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:03:23,434 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 12:03:23,442 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 12:03:28,456 - wandb.wandb_agent - INFO - Running runs: ['ml5lm7tr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_120328-ml5lm7tr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-28
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/ml5lm7tr
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93233
wandb:    train_loss 0.18461
wandb: training_time 4.24354
wandb:        val_f1 0.92
wandb:      val_loss 0.22082
wandb: 
wandb: Synced jumping-sweep-28: https://wandb.ai/jah377/sffSHA_pubmed/runs/ml5lm7tr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_120328-ml5lm7tr/logs
2022-06-16 12:32:22,864 - wandb.wandb_agent - INFO - Cleaning up finished run: ml5lm7tr
2022-06-16 12:32:23,363 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:32:23,363 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 12:32:23,370 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 12:32:28,384 - wandb.wandb_agent - INFO - Running runs: ['6upi7xsh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_123228-6upi7xsh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-29
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/6upi7xsh
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39849
wandb:    train_loss 1.06419
wandb: training_time 1.44638
wandb:        val_f1 0.416
wandb:      val_loss 1.05755
wandb: 
wandb: Synced vital-sweep-29: https://wandb.ai/jah377/sffSHA_pubmed/runs/6upi7xsh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_123228-6upi7xsh/logs
2022-06-16 12:44:20,183 - wandb.wandb_agent - INFO - Cleaning up finished run: 6upi7xsh
2022-06-16 12:44:20,611 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:44:20,611 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 12:44:20,619 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 12:44:25,632 - wandb.wandb_agent - INFO - Running runs: ['k2qbg29z']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_124425-k2qbg29z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-30
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/k2qbg29z
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98949
wandb:    train_loss 0.03786
wandb: training_time 2.78288
wandb:        val_f1 0.928
wandb:      val_loss 0.26297
wandb: 
wandb: Synced genial-sweep-30: https://wandb.ai/jah377/sffSHA_pubmed/runs/k2qbg29z
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_124425-k2qbg29z/logs
2022-06-16 13:04:03,879 - wandb.wandb_agent - INFO - Cleaning up finished run: k2qbg29z
2022-06-16 13:04:04,390 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:04:04,390 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 13:04:04,399 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 13:04:09,413 - wandb.wandb_agent - INFO - Running runs: ['s6iac98p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_130409-s6iac98p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-31
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/s6iac98p
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99422
wandb:    train_loss 0.02136
wandb: training_time 5.66024
wandb:        val_f1 0.932
wandb:      val_loss 0.28248
wandb: 
wandb: Synced divine-sweep-31: https://wandb.ai/jah377/sffSHA_pubmed/runs/s6iac98p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_130409-s6iac98p/logs
2022-06-16 13:40:46,592 - wandb.wandb_agent - INFO - Cleaning up finished run: s6iac98p
2022-06-16 13:40:47,030 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:40:47,030 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 13:40:47,039 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 13:40:52,052 - wandb.wandb_agent - INFO - Running runs: ['z46liksa']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_134052-z46liksa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-32
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/z46liksa
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9715
wandb:    train_loss 0.08544
wandb: training_time 3.18396
wandb:        val_f1 0.922
wandb:      val_loss 0.24624
wandb: 
wandb: Synced feasible-sweep-32: https://wandb.ai/jah377/sffSHA_pubmed/runs/z46liksa
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_134052-z46liksa/logs
2022-06-16 14:03:53,893 - wandb.wandb_agent - INFO - Cleaning up finished run: z46liksa
2022-06-16 14:03:54,469 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:03:54,470 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 14:03:54,477 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 14:03:59,488 - wandb.wandb_agent - INFO - Running runs: ['sr3awlai']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_140359-sr3awlai
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-33
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/sr3awlai
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97607
wandb:    train_loss 0.07361
wandb: training_time 4.05695
wandb:        val_f1 0.93
wandb:      val_loss 0.22846
wandb: 
wandb: Synced fragrant-sweep-33: https://wandb.ai/jah377/sffSHA_pubmed/runs/sr3awlai
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_140359-sr3awlai/logs
2022-06-16 14:32:28,007 - wandb.wandb_agent - INFO - Cleaning up finished run: sr3awlai
2022-06-16 14:32:28,823 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:32:28,824 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 14:32:28,830 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 14:32:33,844 - wandb.wandb_agent - INFO - Running runs: ['e4reqrey']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_143234-e4reqrey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-34
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/e4reqrey
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97662
wandb:    train_loss 0.07179
wandb: training_time 6.57561
wandb:        val_f1 0.91
wandb:      val_loss 0.2625
wandb: 
wandb: Synced legendary-sweep-34: https://wandb.ai/jah377/sffSHA_pubmed/runs/e4reqrey
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_143234-e4reqrey/logs
2022-06-16 15:14:20,844 - wandb.wandb_agent - INFO - Cleaning up finished run: e4reqrey
2022-06-16 15:14:21,446 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:14:21,447 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 15:14:21,453 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 15:14:26,468 - wandb.wandb_agent - INFO - Running runs: ['2bd8pccn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_151426-2bd8pccn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-35
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/2bd8pccn
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9973
wandb:    train_loss 0.01585
wandb: training_time 1.8857
wandb:        val_f1 0.924
wandb:      val_loss 0.32083
wandb: 
wandb: Synced stoic-sweep-35: https://wandb.ai/jah377/sffSHA_pubmed/runs/2bd8pccn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_151426-2bd8pccn/logs
2022-06-16 15:28:28,088 - wandb.wandb_agent - INFO - Cleaning up finished run: 2bd8pccn
2022-06-16 15:28:28,599 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:28:28,599 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 15:28:28,606 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 15:28:33,620 - wandb.wandb_agent - INFO - Running runs: ['a4e2vm8t']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_152832-a4e2vm8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-36
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/a4e2vm8t
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98614
wandb:    train_loss 0.042
wandb: training_time 4.80722
wandb:        val_f1 0.936
wandb:      val_loss 0.27755
wandb: 
wandb: Synced clear-sweep-36: https://wandb.ai/jah377/sffSHA_pubmed/runs/a4e2vm8t
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_152832-a4e2vm8t/logs
2022-06-16 16:01:10,883 - wandb.wandb_agent - INFO - Cleaning up finished run: a4e2vm8t
2022-06-16 16:01:11,519 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:01:11,520 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 16:01:11,527 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 16:01:16,540 - wandb.wandb_agent - INFO - Running runs: ['7zuvxtk5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_160116-7zuvxtk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-37
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/7zuvxtk5
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93568
wandb:    train_loss 0.17048
wandb: training_time 8.1666
wandb:        val_f1 0.924
wandb:      val_loss 0.24643
wandb: 
wandb: Synced robust-sweep-37: https://wandb.ai/jah377/sffSHA_pubmed/runs/7zuvxtk5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_160116-7zuvxtk5/logs
2022-06-16 16:45:40,852 - wandb.wandb_agent - INFO - Cleaning up finished run: 7zuvxtk5
2022-06-16 16:45:41,600 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:45:41,600 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 16:45:41,605 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
2022-06-16 16:45:46,620 - wandb.wandb_agent - INFO - Running runs: ['4q7oqyen']
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_164549-4q7oqyen
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-38
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/4q7oqyen
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97975
wandb:    train_loss 0.06441
wandb: training_time 3.97004
wandb:        val_f1 0.906
wandb:      val_loss 0.26057
wandb: 
wandb: Synced stilted-sweep-38: https://wandb.ai/jah377/sffSHA_pubmed/runs/4q7oqyen
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_164549-4q7oqyen/logs
2022-06-16 17:26:20,734 - wandb.wandb_agent - INFO - Cleaning up finished run: 4q7oqyen
2022-06-16 17:26:21,375 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:26:21,375 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 17:26:21,382 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 17:26:26,396 - wandb.wandb_agent - INFO - Running runs: ['ixiewog5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_172626-ixiewog5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-39
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/ixiewog5
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95907
wandb:    train_loss 0.10941
wandb: training_time 1.67655
wandb:        val_f1 0.916
wandb:      val_loss 0.23465
wandb: 
wandb: Synced fragrant-sweep-39: https://wandb.ai/jah377/sffSHA_pubmed/runs/ixiewog5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_172626-ixiewog5/logs
2022-06-16 17:39:04,072 - wandb.wandb_agent - INFO - Cleaning up finished run: ixiewog5
2022-06-16 17:39:04,596 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:39:04,596 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 17:39:04,603 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 17:39:09,616 - wandb.wandb_agent - INFO - Running runs: ['a5mv6kjs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_173909-a5mv6kjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-40
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/a5mv6kjs
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99846
wandb:    train_loss 0.01608
wandb: training_time 1.73689
wandb:        val_f1 0.89
wandb:      val_loss 0.29474
wandb: 
wandb: Synced charmed-sweep-40: https://wandb.ai/jah377/sffSHA_pubmed/runs/a5mv6kjs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_173909-a5mv6kjs/logs
2022-06-16 17:52:36,208 - wandb.wandb_agent - INFO - Cleaning up finished run: a5mv6kjs
2022-06-16 17:52:36,897 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:52:36,897 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 17:52:36,905 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 17:52:41,919 - wandb.wandb_agent - INFO - Running runs: ['msatcep3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_175242-msatcep3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-41
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/msatcep3
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92991
wandb:    train_loss 0.19042
wandb: training_time 6.47498
wandb:        val_f1 0.922
wandb:      val_loss 0.21793
wandb: 
wandb: Synced dandy-sweep-41: https://wandb.ai/jah377/sffSHA_pubmed/runs/msatcep3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_175242-msatcep3/logs
2022-06-16 18:34:36,832 - wandb.wandb_agent - INFO - Cleaning up finished run: msatcep3
2022-06-16 18:34:37,352 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:34:37,352 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 18:34:37,361 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 18:34:42,372 - wandb.wandb_agent - INFO - Running runs: ['syajrdva']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_183441-syajrdva
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-42
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/syajrdva
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94801
wandb:    train_loss 0.14035
wandb: training_time 6.40698
wandb:        val_f1 0.914
wandb:      val_loss 0.25345
wandb: 
wandb: Synced dauntless-sweep-42: https://wandb.ai/jah377/sffSHA_pubmed/runs/syajrdva
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_183441-syajrdva/logs
2022-06-16 19:15:48,220 - wandb.wandb_agent - INFO - Cleaning up finished run: syajrdva
2022-06-16 19:15:48,862 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:15:48,863 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 19:15:48,870 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 19:15:53,884 - wandb.wandb_agent - INFO - Running runs: ['pj0vg9dq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_191554-pj0vg9dq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-43
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/pj0vg9dq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94229
wandb:    train_loss 0.15322
wandb: training_time 2.57764
wandb:        val_f1 0.922
wandb:      val_loss 0.23351
wandb: 
wandb: Synced revived-sweep-43: https://wandb.ai/jah377/sffSHA_pubmed/runs/pj0vg9dq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_191554-pj0vg9dq/logs
2022-06-16 19:34:24,682 - wandb.wandb_agent - INFO - Cleaning up finished run: pj0vg9dq
2022-06-16 19:34:25,192 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:34:25,192 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 19:34:25,200 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 19:34:30,212 - wandb.wandb_agent - INFO - Running runs: ['4yjb1sfy']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_193429-4yjb1sfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-44
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/4yjb1sfy
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95109
wandb:    train_loss 0.13
wandb: training_time 3.2854
wandb:        val_f1 0.92
wandb:      val_loss 0.25322
wandb: 
wandb: Synced mild-sweep-44: https://wandb.ai/jah377/sffSHA_pubmed/runs/4yjb1sfy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_193429-4yjb1sfy/logs
2022-06-16 19:57:24,148 - wandb.wandb_agent - INFO - Cleaning up finished run: 4yjb1sfy
2022-06-16 19:57:24,619 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:57:24,619 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 19:57:24,628 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 19:57:29,643 - wandb.wandb_agent - INFO - Running runs: ['hmlyczoq']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_195729-hmlyczoq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-45
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/hmlyczoq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91203
wandb:    train_loss 0.23427
wandb: training_time 3.3065
wandb:        val_f1 0.908
wandb:      val_loss 0.259
wandb: 
wandb: Synced serene-sweep-45: https://wandb.ai/jah377/sffSHA_pubmed/runs/hmlyczoq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_195729-hmlyczoq/logs
2022-06-16 20:20:22,540 - wandb.wandb_agent - INFO - Cleaning up finished run: hmlyczoq
2022-06-16 20:20:23,149 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:20:23,150 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 20:20:23,158 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 20:20:28,172 - wandb.wandb_agent - INFO - Running runs: ['pgw8vdqw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_202028-pgw8vdqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-46
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/pgw8vdqw
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96534
wandb:    train_loss 0.09257
wandb: training_time 3.30575
wandb:        val_f1 0.926
wandb:      val_loss 0.23578
wandb: 
wandb: Synced solar-sweep-46: https://wandb.ai/jah377/sffSHA_pubmed/runs/pgw8vdqw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_202028-pgw8vdqw/logs
2022-06-16 20:43:29,766 - wandb.wandb_agent - INFO - Cleaning up finished run: pgw8vdqw
2022-06-16 20:43:30,219 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:43:30,220 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 20:43:30,227 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 20:43:35,241 - wandb.wandb_agent - INFO - Running runs: ['t9zdhje4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_204335-t9zdhje4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-47
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/t9zdhje4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97975
wandb:    train_loss 0.07465
wandb: training_time 6.4033
wandb:        val_f1 0.906
wandb:      val_loss 0.28143
wandb: 
wandb: Synced magic-sweep-47: https://wandb.ai/jah377/sffSHA_pubmed/runs/t9zdhje4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_204335-t9zdhje4/logs
2022-06-16 21:24:18,812 - wandb.wandb_agent - INFO - Cleaning up finished run: t9zdhje4
2022-06-16 21:24:19,275 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:24:19,276 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 21:24:19,283 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 21:24:24,296 - wandb.wandb_agent - INFO - Running runs: ['kq43oqd0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_212424-kq43oqd0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-48
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/kq43oqd0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96579
wandb:    train_loss 0.10536
wandb: training_time 0.48966
wandb:        val_f1 0.91
wandb:      val_loss 0.27008
wandb: 
wandb: Synced wandering-sweep-48: https://wandb.ai/jah377/sffSHA_pubmed/runs/kq43oqd0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_212424-kq43oqd0/logs
2022-06-16 21:29:40,984 - wandb.wandb_agent - INFO - Cleaning up finished run: kq43oqd0
2022-06-16 21:29:41,440 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:29:41,441 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 21:29:41,449 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 21:29:46,464 - wandb.wandb_agent - INFO - Running runs: ['dcoj7agb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_212946-dcoj7agb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-49
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/dcoj7agb
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89195
wandb:    train_loss 0.33413
wandb: training_time 6.22336
wandb:        val_f1 0.896
wandb:      val_loss 1.35759
wandb: 
wandb: Synced winter-sweep-49: https://wandb.ai/jah377/sffSHA_pubmed/runs/dcoj7agb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_212946-dcoj7agb/logs
2022-06-16 22:09:54,510 - wandb.wandb_agent - INFO - Cleaning up finished run: dcoj7agb
2022-06-16 22:09:55,145 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:09:55,145 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 22:09:55,154 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 22:10:00,168 - wandb.wandb_agent - INFO - Running runs: ['uortyopq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_221000-uortyopq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-50
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/uortyopq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90168
wandb:    train_loss 0.25037
wandb: training_time 3.34383
wandb:        val_f1 0.906
wandb:      val_loss 0.26441
wandb: 
wandb: Synced resilient-sweep-50: https://wandb.ai/jah377/sffSHA_pubmed/runs/uortyopq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_221000-uortyopq/logs
2022-06-16 22:33:14,840 - wandb.wandb_agent - INFO - Cleaning up finished run: uortyopq
2022-06-16 22:33:15,400 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:33:15,400 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 22:33:15,409 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 22:33:20,420 - wandb.wandb_agent - INFO - Running runs: ['957nmu9i']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_223320-957nmu9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-51
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/957nmu9i
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k0_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.45934
wandb:    train_loss 0.97242
wandb: training_time 2.51124
wandb:        val_f1 0.448
wandb:      val_loss 0.97003
wandb: 
wandb: Synced revived-sweep-51: https://wandb.ai/jah377/sffSHA_pubmed/runs/957nmu9i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_223320-957nmu9i/logs
2022-06-16 22:52:24,235 - wandb.wandb_agent - INFO - Cleaning up finished run: 957nmu9i
2022-06-16 22:52:24,673 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:52:24,674 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 22:52:24,681 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 22:52:29,695 - wandb.wandb_agent - INFO - Running runs: ['pn5r3dao']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_225229-pn5r3dao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-52
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/pn5r3dao
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm0_heads1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5334
wandb:    train_loss 0.97438
wandb: training_time 3.05545
wandb:        val_f1 0.52
wandb:      val_loss 0.96608
wandb: 
wandb: Synced vague-sweep-52: https://wandb.ai/jah377/sffSHA_pubmed/runs/pn5r3dao
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_225229-pn5r3dao/logs
2022-06-16 23:13:17,565 - wandb.wandb_agent - INFO - Cleaning up finished run: pn5r3dao
2022-06-16 23:13:18,022 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:13:18,022 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 23:13:18,030 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 23:13:23,040 - wandb.wandb_agent - INFO - Running runs: ['7e2xw96l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_231323-7e2xw96l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-53
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/7e2xw96l
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9671
wandb:    train_loss 0.09795
wandb: training_time 5.73617
wandb:        val_f1 0.934
wandb:      val_loss 0.22763
wandb: 
wandb: Synced sleek-sweep-53: https://wandb.ai/jah377/sffSHA_pubmed/runs/7e2xw96l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_231323-7e2xw96l/logs
2022-06-16 23:50:04,532 - wandb.wandb_agent - INFO - Cleaning up finished run: 7e2xw96l
2022-06-16 23:50:06,091 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:50:06,091 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 23:50:06,100 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 23:50:11,112 - wandb.wandb_agent - INFO - Running runs: ['2odgzh8k']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220616_235011-2odgzh8k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-54
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/2odgzh8k
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9046
wandb:    train_loss 0.25114
wandb: training_time 5.47628
wandb:        val_f1 0.906
wandb:      val_loss 0.25716
wandb: 
wandb: Synced clear-sweep-54: https://wandb.ai/jah377/sffSHA_pubmed/runs/2odgzh8k
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_235011-2odgzh8k/logs
2022-06-17 00:26:36,572 - wandb.wandb_agent - INFO - Cleaning up finished run: 2odgzh8k
2022-06-17 00:26:37,045 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 00:26:37,045 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-17 00:26:37,055 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-17 00:26:42,068 - wandb.wandb_agent - INFO - Running runs: ['3te40hd8']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_002641-3te40hd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-55
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/3te40hd8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91494
wandb:    train_loss 0.22374
wandb: training_time 6.16089
wandb:        val_f1 0.906
wandb:      val_loss 0.25041
wandb: 
wandb: Synced bumbling-sweep-55: https://wandb.ai/jah377/sffSHA_pubmed/runs/3te40hd8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_002641-3te40hd8/logs
2022-06-17 01:07:30,712 - wandb.wandb_agent - INFO - Cleaning up finished run: 3te40hd8
2022-06-17 01:07:31,183 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 01:07:31,183 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 01:07:31,191 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 01:07:36,206 - wandb.wandb_agent - INFO - Running runs: ['w3wmwubv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_010736-w3wmwubv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-56
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/w3wmwubv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94053
wandb:    train_loss 0.15309
wandb: training_time 4.82665
wandb:        val_f1 0.92
wandb:      val_loss 0.23339
wandb: 
wandb: Synced good-sweep-56: https://wandb.ai/jah377/sffSHA_pubmed/runs/w3wmwubv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_010736-w3wmwubv/logs
2022-06-17 01:39:56,044 - wandb.wandb_agent - INFO - Cleaning up finished run: w3wmwubv
2022-06-17 01:39:56,623 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 01:39:56,623 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-17 01:39:56,632 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-17 01:40:01,644 - wandb.wandb_agent - INFO - Running runs: ['6vhe7zqd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_014001-6vhe7zqd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-57
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/6vhe7zqd
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90295
wandb:    train_loss 0.25516
wandb: training_time 1.80324
wandb:        val_f1 0.902
wandb:      val_loss 0.24833
wandb: 
wandb: Synced dashing-sweep-57: https://wandb.ai/jah377/sffSHA_pubmed/runs/6vhe7zqd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_014001-6vhe7zqd/logs
2022-06-17 01:53:40,212 - wandb.wandb_agent - INFO - Cleaning up finished run: 6vhe7zqd
2022-06-17 01:53:40,697 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 01:53:40,697 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-17 01:53:40,704 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-17 01:53:45,718 - wandb.wandb_agent - INFO - Running runs: ['untf2c7u']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_015345-untf2c7u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-58
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/untf2c7u
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96182
wandb:    train_loss 0.10603
wandb: training_time 1.70899
wandb:        val_f1 0.914
wandb:      val_loss 0.24831
wandb: 
wandb: Synced amber-sweep-58: https://wandb.ai/jah377/sffSHA_pubmed/runs/untf2c7u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_015345-untf2c7u/logs
2022-06-17 02:06:39,844 - wandb.wandb_agent - INFO - Cleaning up finished run: untf2c7u
2022-06-17 02:06:40,442 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 02:06:40,443 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 02:06:40,450 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 02:06:45,465 - wandb.wandb_agent - INFO - Running runs: ['m37bl4rj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_020645-m37bl4rj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-59
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/m37bl4rj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97777
wandb:    train_loss 0.08009
wandb: training_time 6.32367
wandb:        val_f1 0.936
wandb:      val_loss 0.22426
wandb: 
wandb: Synced hearty-sweep-59: https://wandb.ai/jah377/sffSHA_pubmed/runs/m37bl4rj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_020645-m37bl4rj/logs
2022-06-17 02:48:00,932 - wandb.wandb_agent - INFO - Cleaning up finished run: m37bl4rj
2022-06-17 02:48:26,052 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 02:48:26,052 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 02:48:26,062 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 02:48:31,076 - wandb.wandb_agent - INFO - Running runs: ['6vi7snrc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_024831-6vi7snrc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-60
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/6vi7snrc
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89294
wandb:    train_loss 0.27349
wandb: training_time 5.59137
wandb:        val_f1 0.904
wandb:      val_loss 0.28567
wandb: 
wandb: Synced pretty-sweep-60: https://wandb.ai/jah377/sffSHA_pubmed/runs/6vi7snrc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_024831-6vi7snrc/logs
2022-06-17 03:25:32,030 - wandb.wandb_agent - INFO - Cleaning up finished run: 6vi7snrc
2022-06-17 03:25:32,760 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 03:25:32,761 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 03:25:32,768 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 03:25:37,782 - wandb.wandb_agent - INFO - Running runs: ['w1pkfnl8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_032537-w1pkfnl8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-61
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/w1pkfnl8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92066
wandb:    train_loss 0.20082
wandb: training_time 4.12723
wandb:        val_f1 0.91
wandb:      val_loss 0.25109
wandb: 
wandb: Synced breezy-sweep-61: https://wandb.ai/jah377/sffSHA_pubmed/runs/w1pkfnl8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_032537-w1pkfnl8/logs
2022-06-17 03:54:05,319 - wandb.wandb_agent - INFO - Cleaning up finished run: w1pkfnl8
2022-06-17 03:54:05,798 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 03:54:05,799 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 03:54:05,806 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 03:54:10,821 - wandb.wandb_agent - INFO - Running runs: ['79h01tyq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_035410-79h01tyq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-62
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/79h01tyq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90031
wandb:    train_loss 0.25498
wandb: training_time 4.56884
wandb:        val_f1 0.898
wandb:      val_loss 0.26835
wandb: 
wandb: Synced daily-sweep-62: https://wandb.ai/jah377/sffSHA_pubmed/runs/79h01tyq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_035410-79h01tyq/logs
2022-06-17 04:25:32,744 - wandb.wandb_agent - INFO - Cleaning up finished run: 79h01tyq
2022-06-17 04:25:33,236 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 04:25:33,237 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 04:25:33,245 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 04:25:38,256 - wandb.wandb_agent - INFO - Running runs: ['qgs56uli']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_042538-qgs56uli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-63
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/qgs56uli
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94196
wandb:    train_loss 0.14817
wandb: training_time 1.18554
wandb:        val_f1 0.91
wandb:      val_loss 0.23843
wandb: 
wandb: Synced skilled-sweep-63: https://wandb.ai/jah377/sffSHA_pubmed/runs/qgs56uli
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_042538-qgs56uli/logs
2022-06-17 04:35:25,844 - wandb.wandb_agent - INFO - Cleaning up finished run: qgs56uli
2022-06-17 04:35:26,472 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 04:35:26,473 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 04:35:26,482 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-17 04:35:31,496 - wandb.wandb_agent - INFO - Running runs: ['du3c8hlp']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_043530-du3c8hlp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-64
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/du3c8hlp
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92991
wandb:    train_loss 0.18322
wandb: training_time 1.64472
wandb:        val_f1 0.912
wandb:      val_loss 0.23983
wandb: 
wandb: Synced skilled-sweep-64: https://wandb.ai/jah377/sffSHA_pubmed/runs/du3c8hlp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_043530-du3c8hlp/logs
2022-06-17 04:48:14,806 - wandb.wandb_agent - INFO - Cleaning up finished run: du3c8hlp
2022-06-17 04:48:15,401 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 04:48:15,402 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-17 04:48:15,409 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-17 04:48:20,423 - wandb.wandb_agent - INFO - Running runs: ['4pv22pkt']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_044820-4pv22pkt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-65
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/4pv22pkt
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92391
wandb:    train_loss 0.1927
wandb: training_time 2.42758
wandb:        val_f1 0.914
wandb:      val_loss 0.23527
wandb: 
wandb: Synced proud-sweep-65: https://wandb.ai/jah377/sffSHA_pubmed/runs/4pv22pkt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_044820-4pv22pkt/logs
2022-06-17 05:06:22,219 - wandb.wandb_agent - INFO - Cleaning up finished run: 4pv22pkt
2022-06-17 05:06:22,789 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 05:06:22,790 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 05:06:22,797 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 05:06:27,808 - wandb.wandb_agent - INFO - Running runs: ['gw0t8k3s']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_050628-gw0t8k3s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-66
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/gw0t8k3s
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93458
wandb:    train_loss 0.16614
wandb: training_time 1.47208
wandb:        val_f1 0.91
wandb:      val_loss 0.23211
wandb: 
wandb: Synced twilight-sweep-66: https://wandb.ai/jah377/sffSHA_pubmed/runs/gw0t8k3s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_050628-gw0t8k3s/logs
2022-06-17 05:18:55,260 - wandb.wandb_agent - INFO - Cleaning up finished run: gw0t8k3s
2022-06-17 05:18:55,746 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 05:18:55,746 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 05:18:55,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 05:19:00,768 - wandb.wandb_agent - INFO - Running runs: ['i9kzegp9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_051902-i9kzegp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-67
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/i9kzegp9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88879
wandb:    train_loss 0.28321
wandb: training_time 0.55545
wandb:        val_f1 0.896
wandb:      val_loss 0.28069
wandb: 
wandb: Synced firm-sweep-67: https://wandb.ai/jah377/sffSHA_pubmed/runs/i9kzegp9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_051902-i9kzegp9/logs
2022-06-17 05:24:45,974 - wandb.wandb_agent - INFO - Cleaning up finished run: i9kzegp9
2022-06-17 05:24:46,623 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 05:24:46,623 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 05:24:46,631 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 05:24:51,644 - wandb.wandb_agent - INFO - Running runs: ['5wkhq3nf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_052451-5wkhq3nf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-68
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/5wkhq3nf
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94614
wandb:    train_loss 0.14169
wandb: training_time 1.44009
wandb:        val_f1 0.92
wandb:      val_loss 0.23658
wandb: 
wandb: Synced dauntless-sweep-68: https://wandb.ai/jah377/sffSHA_pubmed/runs/5wkhq3nf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_052451-5wkhq3nf/logs
2022-06-17 05:37:03,642 - wandb.wandb_agent - INFO - Cleaning up finished run: 5wkhq3nf
2022-06-17 05:37:04,342 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 05:37:04,343 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 05:37:04,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 05:37:09,364 - wandb.wandb_agent - INFO - Running runs: ['erujb4q9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_053709-erujb4q9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-69
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/erujb4q9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90752
wandb:    train_loss 0.2328
wandb: training_time 1.55661
wandb:        val_f1 0.906
wandb:      val_loss 0.24536
wandb: 
wandb: Synced woven-sweep-69: https://wandb.ai/jah377/sffSHA_pubmed/runs/erujb4q9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_053709-erujb4q9/logs
2022-06-17 05:49:16,414 - wandb.wandb_agent - INFO - Cleaning up finished run: erujb4q9
2022-06-17 05:49:17,212 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 05:49:17,212 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-17 05:49:17,219 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-17 05:49:22,232 - wandb.wandb_agent - INFO - Running runs: ['91pu1eji']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_054922-91pu1eji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-70
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/91pu1eji
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39872
wandb:    train_loss 1.08348
wandb: training_time 1.00022
wandb:        val_f1 0.416
wandb:      val_loss 1.0815
wandb: 
wandb: Synced vital-sweep-70: https://wandb.ai/jah377/sffSHA_pubmed/runs/91pu1eji
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_054922-91pu1eji/logs
2022-06-17 05:57:57,177 - wandb.wandb_agent - INFO - Cleaning up finished run: 91pu1eji
2022-06-17 05:57:57,671 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 05:57:57,672 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 05:57:57,679 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 05:58:02,693 - wandb.wandb_agent - INFO - Running runs: ['12tzxov0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_055803-12tzxov0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-71
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/12tzxov0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92248
wandb:    train_loss 0.1973
wandb: training_time 2.48281
wandb:        val_f1 0.91
wandb:      val_loss 0.24351
wandb: 
wandb: Synced fallen-sweep-71: https://wandb.ai/jah377/sffSHA_pubmed/runs/12tzxov0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_055803-12tzxov0/logs
2022-06-17 06:16:08,297 - wandb.wandb_agent - INFO - Cleaning up finished run: 12tzxov0
2022-06-17 06:16:09,178 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 06:16:09,178 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 06:16:09,186 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 06:16:14,200 - wandb.wandb_agent - INFO - Running runs: ['fbdjqlyw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_061614-fbdjqlyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-72
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/fbdjqlyw
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91852
wandb:    train_loss 0.2102
wandb: training_time 6.18943
wandb:        val_f1 0.914
wandb:      val_loss 0.24693
wandb: 
wandb: Synced polished-sweep-72: https://wandb.ai/jah377/sffSHA_pubmed/runs/fbdjqlyw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_061614-fbdjqlyw/logs
2022-06-17 06:57:08,197 - wandb.wandb_agent - INFO - Cleaning up finished run: fbdjqlyw
2022-06-17 06:57:08,635 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 06:57:08,635 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 06:57:08,642 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 06:57:13,656 - wandb.wandb_agent - INFO - Running runs: ['3z3vbarv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_065713-3z3vbarv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-73
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/3z3vbarv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85739
wandb:    train_loss 0.38272
wandb: training_time 3.39726
wandb:        val_f1 0.878
wandb:      val_loss 0.34876
wandb: 
wandb: Synced lunar-sweep-73: https://wandb.ai/jah377/sffSHA_pubmed/runs/3z3vbarv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_065713-3z3vbarv/logs
2022-06-17 07:20:06,012 - wandb.wandb_agent - INFO - Cleaning up finished run: 3z3vbarv
2022-06-17 07:20:06,695 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 07:20:06,695 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 07:20:06,704 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 07:20:11,716 - wandb.wandb_agent - INFO - Running runs: ['n9n1aqd5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_072012-n9n1aqd5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-74
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/n9n1aqd5
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94537
wandb:    train_loss 0.14212
wandb: training_time 5.96184
wandb:        val_f1 0.918
wandb:      val_loss 0.23373
wandb: 
wandb: Synced fresh-sweep-74: https://wandb.ai/jah377/sffSHA_pubmed/runs/n9n1aqd5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_072012-n9n1aqd5/logs
2022-06-17 07:59:35,701 - wandb.wandb_agent - INFO - Cleaning up finished run: n9n1aqd5
2022-06-17 07:59:36,231 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 07:59:36,232 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 07:59:36,240 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 07:59:41,252 - wandb.wandb_agent - INFO - Running runs: ['9xg8j5md']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_075941-9xg8j5md
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-75
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/9xg8j5md
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92419
wandb:    train_loss 0.20536
wandb: training_time 2.29781
wandb:        val_f1 0.916
wandb:      val_loss 0.23688
wandb: 
wandb: Synced decent-sweep-75: https://wandb.ai/jah377/sffSHA_pubmed/runs/9xg8j5md
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_075941-9xg8j5md/logs
2022-06-17 08:16:40,951 - wandb.wandb_agent - INFO - Cleaning up finished run: 9xg8j5md
2022-06-17 08:16:41,546 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 08:16:41,546 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 08:16:41,556 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 08:16:46,568 - wandb.wandb_agent - INFO - Running runs: ['rmdvrw2x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_081646-rmdvrw2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-76
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/rmdvrw2x
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92055
wandb:    train_loss 0.19727
wandb: training_time 5.95379
wandb:        val_f1 0.91
wandb:      val_loss 0.25199
wandb: 
wandb: Synced worthy-sweep-76: https://wandb.ai/jah377/sffSHA_pubmed/runs/rmdvrw2x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_081646-rmdvrw2x/logs
2022-06-17 08:56:14,728 - wandb.wandb_agent - INFO - Cleaning up finished run: rmdvrw2x
2022-06-17 08:56:15,311 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 08:56:15,311 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-17 08:56:15,318 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-17 08:56:20,328 - wandb.wandb_agent - INFO - Running runs: ['gg8s7tkq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_085620-gg8s7tkq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-77
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/gg8s7tkq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97801
wandb:    train_loss 0.06605
wandb: training_time 0.61781
wandb:        val_f1 0.924
wandb:      val_loss 0.26377
wandb: 
wandb: Synced driven-sweep-77: https://wandb.ai/jah377/sffSHA_pubmed/runs/gg8s7tkq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_085620-gg8s7tkq/logs
2022-06-17 09:02:21,068 - wandb.wandb_agent - INFO - Cleaning up finished run: gg8s7tkq
2022-06-17 09:02:21,587 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 09:02:21,587 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 09:02:21,595 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 09:02:26,609 - wandb.wandb_agent - INFO - Running runs: ['d6i9swnu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_090226-d6i9swnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-78
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/d6i9swnu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86598
wandb:    train_loss 0.36738
wandb: training_time 4.50636
wandb:        val_f1 0.882
wandb:      val_loss 0.30814
wandb: 
wandb: Synced radiant-sweep-78: https://wandb.ai/jah377/sffSHA_pubmed/runs/d6i9swnu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_090226-d6i9swnu/logs
2022-06-17 09:33:38,520 - wandb.wandb_agent - INFO - Cleaning up finished run: d6i9swnu
2022-06-17 09:33:39,108 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 09:33:39,109 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 09:33:39,118 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 09:33:44,132 - wandb.wandb_agent - INFO - Running runs: ['4ud8cqki']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_093344-4ud8cqki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-79
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/4ud8cqki
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94355
wandb:    train_loss 0.15594
wandb: training_time 2.46997
wandb:        val_f1 0.916
wandb:      val_loss 0.23095
wandb: 
wandb: Synced bright-sweep-79: https://wandb.ai/jah377/sffSHA_pubmed/runs/4ud8cqki
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_093344-4ud8cqki/logs
2022-06-17 09:51:52,808 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ud8cqki
2022-06-17 09:51:53,427 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 09:51:53,427 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 09:51:53,435 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 09:51:58,449 - wandb.wandb_agent - INFO - Running runs: ['fkaz01s2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_095158-fkaz01s2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-80
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/fkaz01s2
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88452
wandb:    train_loss 0.30063
wandb: training_time 3.57283
wandb:        val_f1 0.896
wandb:      val_loss 0.28596
wandb: 
wandb: Synced flowing-sweep-80: https://wandb.ai/jah377/sffSHA_pubmed/runs/fkaz01s2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_095158-fkaz01s2/logs
2022-06-17 10:17:47,666 - wandb.wandb_agent - INFO - Cleaning up finished run: fkaz01s2
2022-06-17 10:17:48,281 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 10:17:48,282 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 10:17:48,290 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 10:17:53,305 - wandb.wandb_agent - INFO - Running runs: ['aza8hcd7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_101753-aza8hcd7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-81
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/aza8hcd7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88974
wandb:    train_loss 0.28421
wandb: training_time 2.07979
wandb:        val_f1 0.9
wandb:      val_loss 0.27561
wandb: 
wandb: Synced vivid-sweep-81: https://wandb.ai/jah377/sffSHA_pubmed/runs/aza8hcd7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_101753-aza8hcd7/logs
2022-06-17 10:33:41,844 - wandb.wandb_agent - INFO - Cleaning up finished run: aza8hcd7
2022-06-17 10:33:42,735 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 10:33:42,735 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 10:33:42,742 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 10:33:47,757 - wandb.wandb_agent - INFO - Running runs: ['5zlxuc1r']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_103347-5zlxuc1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-82
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/5zlxuc1r
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91313
wandb:    train_loss 0.22665
wandb: training_time 6.7214
wandb:        val_f1 0.912
wandb:      val_loss 0.25372
wandb: 
wandb: Synced crimson-sweep-82: https://wandb.ai/jah377/sffSHA_pubmed/runs/5zlxuc1r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_103347-5zlxuc1r/logs
2022-06-17 11:15:48,862 - wandb.wandb_agent - INFO - Cleaning up finished run: 5zlxuc1r
2022-06-17 11:15:49,313 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 11:15:49,313 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 11:15:49,321 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 11:15:54,335 - wandb.wandb_agent - INFO - Running runs: ['ogcb7iew']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_111554-ogcb7iew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-83
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/ogcb7iew
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89415
wandb:    train_loss 0.27524
wandb: training_time 4.55185
wandb:        val_f1 0.9
wandb:      val_loss 0.27137
wandb: 
wandb: Synced colorful-sweep-83: https://wandb.ai/jah377/sffSHA_pubmed/runs/ogcb7iew
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_111554-ogcb7iew/logs
2022-06-17 11:47:14,984 - wandb.wandb_agent - INFO - Cleaning up finished run: ogcb7iew
2022-06-17 11:47:15,599 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 11:47:15,600 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 11:47:15,608 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 11:47:20,620 - wandb.wandb_agent - INFO - Running runs: ['jsa03c5a']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_114721-jsa03c5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-84
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/jsa03c5a
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.903
wandb:    train_loss 0.24582
wandb: training_time 3.33928
wandb:        val_f1 0.902
wandb:      val_loss 0.25629
wandb: 
wandb: Synced solar-sweep-84: https://wandb.ai/jah377/sffSHA_pubmed/runs/jsa03c5a
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_114721-jsa03c5a/logs
2022-06-17 12:10:23,748 - wandb.wandb_agent - INFO - Cleaning up finished run: jsa03c5a
2022-06-17 12:10:24,340 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 12:10:24,340 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 12:10:24,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 12:10:29,363 - wandb.wandb_agent - INFO - Running runs: ['j4cdttz0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_121029-j4cdttz0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-85
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/j4cdttz0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92265
wandb:    train_loss 0.19166
wandb: training_time 2.65969
wandb:        val_f1 0.906
wandb:      val_loss 0.23713
wandb: 
wandb: Synced ethereal-sweep-85: https://wandb.ai/jah377/sffSHA_pubmed/runs/j4cdttz0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_121029-j4cdttz0/logs
2022-06-17 12:30:59,535 - wandb.wandb_agent - INFO - Cleaning up finished run: j4cdttz0
2022-06-17 12:31:00,111 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 12:31:00,111 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 12:31:00,120 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 12:31:05,134 - wandb.wandb_agent - INFO - Running runs: ['0s7nwbli']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_123105-0s7nwbli
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-86
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/0s7nwbli
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93326
wandb:    train_loss 0.18829
wandb: training_time 1.3855
wandb:        val_f1 0.924
wandb:      val_loss 0.24513
wandb: 
wandb: Synced fragrant-sweep-86: https://wandb.ai/jah377/sffSHA_pubmed/runs/0s7nwbli
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_123105-0s7nwbli/logs
2022-06-17 12:42:56,330 - wandb.wandb_agent - INFO - Cleaning up finished run: 0s7nwbli
2022-06-17 12:42:57,188 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 12:42:57,188 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 12:42:57,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 12:43:02,211 - wandb.wandb_agent - INFO - Running runs: ['dqibn2cu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_124302-dqibn2cu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-87
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/dqibn2cu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90859
wandb:    train_loss 0.22315
wandb: training_time 0.86677
wandb:        val_f1 0.906
wandb:      val_loss 0.24986
wandb: 
wandb: Synced still-sweep-87: https://wandb.ai/jah377/sffSHA_pubmed/runs/dqibn2cu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_124302-dqibn2cu/logs
2022-06-17 12:51:01,415 - wandb.wandb_agent - INFO - Cleaning up finished run: dqibn2cu
2022-06-17 12:51:02,424 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 12:51:02,425 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 12:51:02,432 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 12:51:07,447 - wandb.wandb_agent - INFO - Running runs: ['nyby18jc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_125107-nyby18jc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-88
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/nyby18jc
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91043
wandb:    train_loss 0.23386
wandb: training_time 1.49378
wandb:        val_f1 0.904
wandb:      val_loss 0.24814
wandb: 
wandb: Synced upbeat-sweep-88: https://wandb.ai/jah377/sffSHA_pubmed/runs/nyby18jc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_125107-nyby18jc/logs
2022-06-17 13:03:32,441 - wandb.wandb_agent - INFO - Cleaning up finished run: nyby18jc
2022-06-17 13:03:32,958 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 13:03:32,958 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 13:03:32,965 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 13:03:37,980 - wandb.wandb_agent - INFO - Running runs: ['icvkf2c7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_130338-icvkf2c7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-89
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/icvkf2c7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.71638
wandb:    train_loss 0.91603
wandb: training_time 2.48548
wandb:        val_f1 0.734
wandb:      val_loss 0.91187
wandb: 
wandb: Synced rural-sweep-89: https://wandb.ai/jah377/sffSHA_pubmed/runs/icvkf2c7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_130338-icvkf2c7/logs
2022-06-17 13:21:36,434 - wandb.wandb_agent - INFO - Cleaning up finished run: icvkf2c7
2022-06-17 13:21:37,289 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 13:21:37,289 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 13:21:37,297 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 13:21:42,311 - wandb.wandb_agent - INFO - Running runs: ['psawk1iv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_132142-psawk1iv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-90
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/psawk1iv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95043
wandb:    train_loss 0.12642
wandb: training_time 2.27023
wandb:        val_f1 0.916
wandb:      val_loss 0.24053
wandb: 
wandb: Synced divine-sweep-90: https://wandb.ai/jah377/sffSHA_pubmed/runs/psawk1iv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_132142-psawk1iv/logs
2022-06-17 13:38:47,619 - wandb.wandb_agent - INFO - Cleaning up finished run: psawk1iv
2022-06-17 13:38:48,156 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 13:38:48,157 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-17 13:38:48,164 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-17 13:38:53,176 - wandb.wandb_agent - INFO - Running runs: ['fgykfp8l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_133853-fgykfp8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-91
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/fgykfp8l
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93502
wandb:    train_loss 0.16069
wandb: training_time 2.45906
wandb:        val_f1 0.912
wandb:      val_loss 0.24451
wandb: 
wandb: Synced earnest-sweep-91: https://wandb.ai/jah377/sffSHA_pubmed/runs/fgykfp8l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_133853-fgykfp8l/logs
2022-06-17 14:08:11,832 - wandb.wandb_agent - INFO - Cleaning up finished run: fgykfp8l
2022-06-17 14:08:12,387 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 14:08:12,387 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 14:08:12,394 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 14:08:17,408 - wandb.wandb_agent - INFO - Running runs: ['lpfuid3t']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_140817-lpfuid3t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-92
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/lpfuid3t
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99686
wandb:    train_loss 0.01283
wandb: training_time 0.75098
wandb:        val_f1 0.9
wandb:      val_loss 0.51892
wandb: 
wandb: Synced elated-sweep-92: https://wandb.ai/jah377/sffSHA_pubmed/runs/lpfuid3t
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_140817-lpfuid3t/logs
2022-06-17 14:15:56,524 - wandb.wandb_agent - INFO - Cleaning up finished run: lpfuid3t
2022-06-17 14:15:57,079 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 14:15:57,079 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 14:15:57,088 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 14:16:02,100 - wandb.wandb_agent - INFO - Running runs: ['6um2tgnk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_141602-6um2tgnk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-93
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/6um2tgnk
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96792
wandb:    train_loss 0.08792
wandb: training_time 1.49455
wandb:        val_f1 0.92
wandb:      val_loss 0.22552
wandb: 
wandb: Synced giddy-sweep-93: https://wandb.ai/jah377/sffSHA_pubmed/runs/6um2tgnk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_141602-6um2tgnk/logs
2022-06-17 14:28:30,400 - wandb.wandb_agent - INFO - Cleaning up finished run: 6um2tgnk
2022-06-17 14:28:30,937 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 14:28:30,938 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-17 14:28:30,947 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-17 14:28:35,960 - wandb.wandb_agent - INFO - Running runs: ['pd8lf8j1']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_142836-pd8lf8j1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-94
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/pd8lf8j1
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98338
wandb:    train_loss 0.0544
wandb: training_time 4.71599
wandb:        val_f1 0.932
wandb:      val_loss 0.25621
wandb: 
wandb: Synced blooming-sweep-94: https://wandb.ai/jah377/sffSHA_pubmed/runs/pd8lf8j1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_142836-pd8lf8j1/logs
2022-06-17 15:01:04,680 - wandb.wandb_agent - INFO - Cleaning up finished run: pd8lf8j1
2022-06-17 15:01:05,555 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 15:01:05,555 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-17 15:01:05,561 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-17 15:01:10,572 - wandb.wandb_agent - INFO - Running runs: ['lwno3wk2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_150110-lwno3wk2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-95
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/lwno3wk2
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93101
wandb:    train_loss 0.17596
wandb: training_time 1.72055
wandb:        val_f1 0.912
wandb:      val_loss 0.24582
wandb: 
wandb: Synced dainty-sweep-95: https://wandb.ai/jah377/sffSHA_pubmed/runs/lwno3wk2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_150110-lwno3wk2/logs
2022-06-17 15:13:18,032 - wandb.wandb_agent - INFO - Cleaning up finished run: lwno3wk2
2022-06-17 15:13:18,595 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 15:13:18,596 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 15:13:18,602 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-17 15:13:23,616 - wandb.wandb_agent - INFO - Running runs: ['nrnz9cfy']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_151323-nrnz9cfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-96
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/nrnz9cfy
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93035
wandb:    train_loss 0.17172
wandb: training_time 2.5728
wandb:        val_f1 0.904
wandb:      val_loss 0.24459
wandb: 
wandb: Synced glorious-sweep-96: https://wandb.ai/jah377/sffSHA_pubmed/runs/nrnz9cfy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_151323-nrnz9cfy/logs
2022-06-17 15:33:19,168 - wandb.wandb_agent - INFO - Cleaning up finished run: nrnz9cfy
2022-06-17 15:33:20,213 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 15:33:20,214 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 15:33:20,221 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 15:33:25,235 - wandb.wandb_agent - INFO - Running runs: ['xiusj799']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_153325-xiusj799
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-97
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/xiusj799
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97068
wandb:    train_loss 0.07978
wandb: training_time 2.51837
wandb:        val_f1 0.916
wandb:      val_loss 0.27284
wandb: 
wandb: Synced cerulean-sweep-97: https://wandb.ai/jah377/sffSHA_pubmed/runs/xiusj799
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_153325-xiusj799/logs
2022-06-17 15:53:10,448 - wandb.wandb_agent - INFO - Cleaning up finished run: xiusj799
2022-06-17 15:53:11,009 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 15:53:11,010 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 15:53:11,017 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 15:53:16,033 - wandb.wandb_agent - INFO - Running runs: ['rcuaqotk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_155316-rcuaqotk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-98
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/rcuaqotk
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90735
wandb:    train_loss 0.23276
wandb: training_time 5.232
wandb:        val_f1 0.9
wandb:      val_loss 0.24804
wandb: 
wandb: Synced vital-sweep-98: https://wandb.ai/jah377/sffSHA_pubmed/runs/rcuaqotk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_155316-rcuaqotk/logs
2022-06-17 16:26:23,904 - wandb.wandb_agent - INFO - Cleaning up finished run: rcuaqotk
2022-06-17 16:26:24,438 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 16:26:24,438 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 16:26:24,447 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 16:26:29,462 - wandb.wandb_agent - INFO - Running runs: ['w2y66j5m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_162629-w2y66j5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-99
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/w2y66j5m
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67011
wandb:    train_loss 0.7724
wandb: training_time 3.90846
wandb:        val_f1 0.71
wandb:      val_loss 0.73934
wandb: 
wandb: Synced glad-sweep-99: https://wandb.ai/jah377/sffSHA_pubmed/runs/w2y66j5m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_162629-w2y66j5m/logs
2022-06-17 16:54:02,275 - wandb.wandb_agent - INFO - Cleaning up finished run: w2y66j5m
2022-06-17 16:54:03,518 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-17 16:54:03,519 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-17 16:54:03,528 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-17 16:54:08,541 - wandb.wandb_agent - INFO - Running runs: ['i0ocn85p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffSHA_pubmed/wandb/run-20220617_165408-i0ocn85p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-100
wandb:  View project at https://wandb.ai/jah377/sffSHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb:  View run at https://wandb.ai/jah377/sffSHA_pubmed/runs/i0ocn85p
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 1, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99895
wandb:    train_loss 0.00816
wandb: training_time 1.59619
wandb:        val_f1 0.914
wandb:      val_loss 0.29623
wandb: 
wandb: Synced chocolate-sweep-100: https://wandb.ai/jah377/sffSHA_pubmed/runs/i0ocn85p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220617_165408-i0ocn85p/logs
2022-06-17 17:07:02,404 - wandb.wandb_agent - INFO - Cleaning up finished run: i0ocn85p
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: jsr2w64p
Sweep URL: https://wandb.ai/jah377/sffSHA_pubmed/sweeps/jsr2w64p
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: / 0.265 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: - 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: \ 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: | 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: / 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: - 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: \ 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: | 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb: / 0.266 MB of 0.266 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced grateful-feather-100: https://wandb.ai/jah377/sffSHA_pubmed/runs/233x4tjl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_055534-233x4tjl/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 35 hours 12 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
