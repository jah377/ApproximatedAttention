Sat 18 Jun 2022 01:11:30 PM CEST
r32n1.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: products
method: bayes
model: SIGNff
iterations: 100
run_trial: false
config: SIGNff.yaml
train_file: hps_SIGNff.py
project_name: sff_products
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 2048
    - 4096
    - 8192
    - 16384
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  DATASET:
    value: products
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_131654-v9gkc1de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-forest-1
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/v9gkc1de
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-18 13:17:02,782 - wandb.wandb_agent - INFO - Running runs: []
2022-06-18 13:17:03,066 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 13:17:03,067 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-18 13:17:03,074 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 13:17:08,082 - wandb.wandb_agent - INFO - Running runs: ['95w5r5lv']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_131707-95w5r5lv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-1
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/95w5r5lv
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88954
wandb:    train_loss 0.4042
wandb: training_time 1.44326
wandb:        val_f1 0.87244
wandb:      val_loss 0.47195
wandb: 
wandb: Synced logical-sweep-1: https://wandb.ai/jah377/sff_products/runs/95w5r5lv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_131707-95w5r5lv/logs
2022-06-18 13:33:33,069 - wandb.wandb_agent - INFO - Cleaning up finished run: 95w5r5lv
2022-06-18 13:33:33,348 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 13:33:33,349 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-18 13:33:33,358 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 13:33:38,370 - wandb.wandb_agent - INFO - Running runs: ['0x7h3xuy']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_133338-0x7h3xuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-2
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/0x7h3xuy
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56251
wandb:    train_loss 1.77543
wandb: training_time 1.32858
wandb:        val_f1 0.56153
wandb:      val_loss 1.79842
wandb: 
wandb: Synced ethereal-sweep-2: https://wandb.ai/jah377/sff_products/runs/0x7h3xuy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_133338-0x7h3xuy/logs
2022-06-18 13:48:55,763 - wandb.wandb_agent - INFO - Cleaning up finished run: 0x7h3xuy
2022-06-18 13:48:56,106 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 13:48:56,107 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-18 13:48:56,116 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 13:49:01,129 - wandb.wandb_agent - INFO - Running runs: ['7vkf4rhg']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_134901-7vkf4rhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-3
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/7vkf4rhg
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.01533
wandb:    train_loss 3.87808
wandb: training_time 1.37419
wandb:        val_f1 0.01584
wandb:      val_loss 3.87769
wandb: 
wandb: Synced visionary-sweep-3: https://wandb.ai/jah377/sff_products/runs/7vkf4rhg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_134901-7vkf4rhg/logs
2022-06-18 14:04:53,002 - wandb.wandb_agent - INFO - Cleaning up finished run: 7vkf4rhg
2022-06-18 14:04:53,324 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 14:04:53,324 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-18 14:04:53,331 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-18 14:04:58,344 - wandb.wandb_agent - INFO - Running runs: ['pxb9tf8w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_140458-pxb9tf8w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-4
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/pxb9tf8w
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.70972
wandb:    train_loss 0.99118
wandb: training_time 1.36708
wandb:        val_f1 0.69812
wandb:      val_loss 1.05032
wandb: 
wandb: Synced major-sweep-4: https://wandb.ai/jah377/sff_products/runs/pxb9tf8w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_140458-pxb9tf8w/logs
2022-06-18 14:20:13,811 - wandb.wandb_agent - INFO - Cleaning up finished run: pxb9tf8w
2022-06-18 14:20:14,123 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 14:20:14,124 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-18 14:20:14,131 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 14:20:19,146 - wandb.wandb_agent - INFO - Running runs: ['5ccdgz4z']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_142019-5ccdgz4z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-5
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/5ccdgz4z
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91997
wandb:    train_loss 0.28093
wandb: training_time 1.63263
wandb:        val_f1 0.89815
wandb:      val_loss 0.36065
wandb: 
wandb: Synced dutiful-sweep-5: https://wandb.ai/jah377/sff_products/runs/5ccdgz4z
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_142019-5ccdgz4z/logs
2022-06-18 14:38:21,784 - wandb.wandb_agent - INFO - Cleaning up finished run: 5ccdgz4z
2022-06-18 14:38:22,435 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 14:38:22,435 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-18 14:38:22,443 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 14:38:27,459 - wandb.wandb_agent - INFO - Running runs: ['yt4h14dq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_143827-yt4h14dq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-6
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/yt4h14dq
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94513
wandb:    train_loss 0.19562
wandb: training_time 2.49282
wandb:        val_f1 0.92363
wandb:      val_loss 0.28335
wandb: 
wandb: Synced olive-sweep-6: https://wandb.ai/jah377/sff_products/runs/yt4h14dq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_143827-yt4h14dq/logs
2022-06-18 15:01:11,264 - wandb.wandb_agent - INFO - Cleaning up finished run: yt4h14dq
2022-06-18 15:01:11,590 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 15:01:11,590 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-18 15:01:11,599 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-18 15:01:16,612 - wandb.wandb_agent - INFO - Running runs: ['oa1i9y00']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_150116-oa1i9y00
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-7
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/oa1i9y00
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9323
wandb:    train_loss 0.2479
wandb: training_time 1.77118
wandb:        val_f1 0.91374
wandb:      val_loss 0.32828
wandb: 
wandb: Synced devoted-sweep-7: https://wandb.ai/jah377/sff_products/runs/oa1i9y00
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_150116-oa1i9y00/logs
2022-06-18 15:20:51,570 - wandb.wandb_agent - INFO - Cleaning up finished run: oa1i9y00
2022-06-18 15:20:51,894 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 15:20:51,895 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-18 15:20:51,904 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 15:20:56,918 - wandb.wandb_agent - INFO - Running runs: ['fjcsjwdh']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_152056-fjcsjwdh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-8
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/fjcsjwdh
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50814
wandb:    train_loss 3.20073
wandb: training_time 1.89801
wandb:        val_f1 0.49421
wandb:      val_loss 3.84328
wandb: 
wandb: Synced amber-sweep-8: https://wandb.ai/jah377/sff_products/runs/fjcsjwdh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_152056-fjcsjwdh/logs
2022-06-18 15:43:28,653 - wandb.wandb_agent - INFO - Cleaning up finished run: fjcsjwdh
2022-06-18 15:43:29,103 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 15:43:29,103 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-18 15:43:29,110 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-18 15:43:34,125 - wandb.wandb_agent - INFO - Running runs: ['y3mgtsbe']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_154334-y3mgtsbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-9
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/y3mgtsbe
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93914
wandb:    train_loss 0.21858
wandb: training_time 2.37007
wandb:        val_f1 0.92086
wandb:      val_loss 0.29808
wandb: 
wandb: Synced smooth-sweep-9: https://wandb.ai/jah377/sff_products/runs/y3mgtsbe
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_154334-y3mgtsbe/logs
2022-06-18 16:13:48,920 - wandb.wandb_agent - INFO - Cleaning up finished run: y3mgtsbe
2022-06-18 16:13:49,246 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 16:13:49,247 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-18 16:13:49,253 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-18 16:13:54,267 - wandb.wandb_agent - INFO - Running runs: ['dhze0h3x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_161354-dhze0h3x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-10
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/dhze0h3x
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.21967
wandb:    train_loss 3.6898
wandb: training_time 1.95993
wandb:        val_f1 0.18536
wandb:      val_loss 3.72864
wandb: 
wandb: Synced deep-sweep-10: https://wandb.ai/jah377/sff_products/runs/dhze0h3x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_161354-dhze0h3x/logs
2022-06-18 16:34:58,195 - wandb.wandb_agent - INFO - Cleaning up finished run: dhze0h3x
2022-06-18 16:34:58,616 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 16:34:58,616 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-18 16:34:58,623 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 16:35:03,638 - wandb.wandb_agent - INFO - Running runs: ['kugm7w9y']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_163503-kugm7w9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-11
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/kugm7w9y
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.71952
wandb:    train_loss 0.99309
wandb: training_time 2.10244
wandb:        val_f1 0.70735
wandb:      val_loss 1.04621
wandb: 
wandb: Synced elated-sweep-11: https://wandb.ai/jah377/sff_products/runs/kugm7w9y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_163503-kugm7w9y/logs
2022-06-18 16:54:54,496 - wandb.wandb_agent - INFO - Cleaning up finished run: kugm7w9y
2022-06-18 16:54:54,840 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 16:54:54,840 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-18 16:54:54,850 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 16:54:59,862 - wandb.wandb_agent - INFO - Running runs: ['ly1yosc1']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_165459-ly1yosc1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-12
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/ly1yosc1
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 12
wandb:      train_f1 0.54531
wandb:    train_loss 1.87746
wandb: training_time 1.57628
wandb:        val_f1 0.50713
wandb:      val_loss 2.03373
wandb: 
wandb: Synced snowy-sweep-12: https://wandb.ai/jah377/sff_products/runs/ly1yosc1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_165459-ly1yosc1/logs
2022-06-18 16:55:57,027 - wandb.wandb_agent - INFO - Cleaning up finished run: ly1yosc1
2022-06-18 16:55:57,419 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 16:55:57,420 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-18 16:55:57,426 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 16:56:02,438 - wandb.wandb_agent - INFO - Running runs: ['r8ddocqx']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_165601-r8ddocqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-13
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/r8ddocqx
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9495
wandb:    train_loss 0.17152
wandb: training_time 1.78459
wandb:        val_f1 0.92208
wandb:      val_loss 0.2832
wandb: 
wandb: Synced genial-sweep-13: https://wandb.ai/jah377/sff_products/runs/r8ddocqx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_165601-r8ddocqx/logs
2022-06-18 17:15:23,990 - wandb.wandb_agent - INFO - Cleaning up finished run: r8ddocqx
2022-06-18 17:15:24,344 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 17:15:24,345 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-18 17:15:24,354 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-18 17:15:29,371 - wandb.wandb_agent - INFO - Running runs: ['q894ztqw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_171529-q894ztqw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-14
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/q894ztqw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89024
wandb:    train_loss 0.4186
wandb: training_time 3.11583
wandb:        val_f1 0.88139
wandb:      val_loss 0.47135
wandb: 
wandb: Synced sleek-sweep-14: https://wandb.ai/jah377/sff_products/runs/q894ztqw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_171529-q894ztqw/logs
2022-06-18 17:43:50,428 - wandb.wandb_agent - INFO - Cleaning up finished run: q894ztqw
2022-06-18 17:43:50,776 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 17:43:50,776 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-18 17:43:50,785 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 17:43:55,799 - wandb.wandb_agent - INFO - Running runs: ['jgfl0iaw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_174355-jgfl0iaw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-15
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/jgfl0iaw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92288
wandb:    train_loss 0.27607
wandb: training_time 2.02332
wandb:        val_f1 0.91249
wandb:      val_loss 0.32306
wandb: 
wandb: Synced blooming-sweep-15: https://wandb.ai/jah377/sff_products/runs/jgfl0iaw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_174355-jgfl0iaw/logs
2022-06-18 18:04:40,774 - wandb.wandb_agent - INFO - Cleaning up finished run: jgfl0iaw
2022-06-18 18:04:41,173 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 18:04:41,173 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-18 18:04:41,183 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 18:04:46,194 - wandb.wandb_agent - INFO - Running runs: ['slfr31li']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_180446-slfr31li
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-16
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/slfr31li
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.11888
wandb:    train_loss 3.81634
wandb: training_time 1.42423
wandb:        val_f1 0.12021
wandb:      val_loss 3.81509
wandb: 
wandb: Synced deep-sweep-16: https://wandb.ai/jah377/sff_products/runs/slfr31li
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_180446-slfr31li/logs
2022-06-18 18:21:20,930 - wandb.wandb_agent - INFO - Cleaning up finished run: slfr31li
2022-06-18 18:21:21,290 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 18:21:21,290 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-18 18:21:21,298 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-18 18:21:26,312 - wandb.wandb_agent - INFO - Running runs: ['c2t8h56l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_182126-c2t8h56l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-17
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/c2t8h56l
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.81448
wandb:    train_loss 0.9242
wandb: training_time 2.89174
wandb:        val_f1 0.80477
wandb:      val_loss 0.98166
wandb: 
wandb: Synced sparkling-sweep-17: https://wandb.ai/jah377/sff_products/runs/c2t8h56l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_182126-c2t8h56l/logs
2022-06-18 18:46:57,312 - wandb.wandb_agent - INFO - Cleaning up finished run: c2t8h56l
2022-06-18 18:46:57,682 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 18:46:57,683 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-18 18:46:57,692 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-18 18:47:02,704 - wandb.wandb_agent - INFO - Running runs: ['veugbc9t']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_184702-veugbc9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-18
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/veugbc9t
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.76455
wandb:    train_loss 0.80799
wandb: training_time 1.50535
wandb:        val_f1 0.7398
wandb:      val_loss 0.89682
wandb: 
wandb: Synced likely-sweep-18: https://wandb.ai/jah377/sff_products/runs/veugbc9t
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_184702-veugbc9t/logs
2022-06-18 19:03:59,323 - wandb.wandb_agent - INFO - Cleaning up finished run: veugbc9t
2022-06-18 19:03:59,719 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 19:03:59,719 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-18 19:03:59,729 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-18 19:04:04,743 - wandb.wandb_agent - INFO - Running runs: ['4zv1k3t3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_190404-4zv1k3t3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-19
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/4zv1k3t3
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90679
wandb:    train_loss 0.43842
wandb: training_time 3.30145
wandb:        val_f1 0.89792
wandb:      val_loss 0.5003
wandb: 
wandb: Synced magic-sweep-19: https://wandb.ai/jah377/sff_products/runs/4zv1k3t3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_190404-4zv1k3t3/logs
2022-06-18 19:33:16,777 - wandb.wandb_agent - INFO - Cleaning up finished run: 4zv1k3t3
2022-06-18 19:33:17,101 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 19:33:17,102 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-18 19:33:17,110 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-18 19:33:22,122 - wandb.wandb_agent - INFO - Running runs: ['3k0z2ys5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_193322-3k0z2ys5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-20
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/3k0z2ys5
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.69039
wandb:    train_loss 1.083
wandb: training_time 1.29462
wandb:        val_f1 0.68532
wandb:      val_loss 1.11959
wandb: 
wandb: Synced lemon-sweep-20: https://wandb.ai/jah377/sff_products/runs/3k0z2ys5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_193322-3k0z2ys5/logs
2022-06-18 19:49:52,146 - wandb.wandb_agent - INFO - Cleaning up finished run: 3k0z2ys5
2022-06-18 19:49:52,555 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 19:49:52,556 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-18 19:49:52,564 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 19:49:57,579 - wandb.wandb_agent - INFO - Running runs: ['5k6pglb0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_194957-5k6pglb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-21
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/5k6pglb0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91449
wandb:    train_loss 0.31608
wandb: training_time 1.80604
wandb:        val_f1 0.90464
wandb:      val_loss 0.36133
wandb: 
wandb: Synced playful-sweep-21: https://wandb.ai/jah377/sff_products/runs/5k6pglb0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_194957-5k6pglb0/logs
2022-06-18 20:12:54,221 - wandb.wandb_agent - INFO - Cleaning up finished run: 5k6pglb0
2022-06-18 20:12:54,637 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 20:12:54,637 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-18 20:12:54,643 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 20:12:59,658 - wandb.wandb_agent - INFO - Running runs: ['6gls65fk']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_201258-6gls65fk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-22
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/6gls65fk
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.62592
wandb:    train_loss 2.73129
wandb: training_time 2.00283
wandb:        val_f1 0.60021
wandb:      val_loss 2.89459
wandb: 
wandb: Synced ruby-sweep-22: https://wandb.ai/jah377/sff_products/runs/6gls65fk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_201258-6gls65fk/logs
2022-06-18 20:35:25,280 - wandb.wandb_agent - INFO - Cleaning up finished run: 6gls65fk
2022-06-18 20:35:25,621 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 20:35:25,621 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-18 20:35:25,630 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-18 20:35:30,642 - wandb.wandb_agent - INFO - Running runs: ['r9mmtyih']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_203530-r9mmtyih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-23
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/r9mmtyih
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94262
wandb:    train_loss 0.19705
wandb: training_time 2.57716
wandb:        val_f1 0.91936
wandb:      val_loss 0.29475
wandb: 
wandb: Synced northern-sweep-23: https://wandb.ai/jah377/sff_products/runs/r9mmtyih
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_203530-r9mmtyih/logs
2022-06-18 20:58:06,030 - wandb.wandb_agent - INFO - Cleaning up finished run: r9mmtyih
2022-06-18 20:58:06,398 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 20:58:06,399 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-18 20:58:06,407 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-18 20:58:11,422 - wandb.wandb_agent - INFO - Running runs: ['01u6wd15']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_205811-01u6wd15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-24
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/01u6wd15
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.0386
wandb:    train_loss 3.81707
wandb: training_time 2.19919
wandb:        val_f1 0.04076
wandb:      val_loss 3.82054
wandb: 
wandb: Synced frosty-sweep-24: https://wandb.ai/jah377/sff_products/runs/01u6wd15
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_205811-01u6wd15/logs
2022-06-18 21:20:07,371 - wandb.wandb_agent - INFO - Cleaning up finished run: 01u6wd15
2022-06-18 21:20:07,705 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 21:20:07,706 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-18 21:20:07,713 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-18 21:20:12,727 - wandb.wandb_agent - INFO - Running runs: ['7z6265d6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_212012-7z6265d6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-25
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/7z6265d6
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.942
wandb:    train_loss 0.19916
wandb: training_time 2.17637
wandb:        val_f1 0.92022
wandb:      val_loss 0.283
wandb: 
wandb: Synced spring-sweep-25: https://wandb.ai/jah377/sff_products/runs/7z6265d6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_212012-7z6265d6/logs
2022-06-18 21:42:23,266 - wandb.wandb_agent - INFO - Cleaning up finished run: 7z6265d6
2022-06-18 21:42:23,691 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 21:42:23,691 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-18 21:42:23,700 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-18 21:42:28,714 - wandb.wandb_agent - INFO - Running runs: ['5s139eq8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_214228-5s139eq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-26
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/5s139eq8
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50918
wandb:    train_loss 1.84151
wandb: training_time 2.36088
wandb:        val_f1 0.50332
wandb:      val_loss 1.88788
wandb: 
wandb: Synced happy-sweep-26: https://wandb.ai/jah377/sff_products/runs/5s139eq8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_214228-5s139eq8/logs
2022-06-18 22:09:19,508 - wandb.wandb_agent - INFO - Cleaning up finished run: 5s139eq8
2022-06-18 22:09:19,873 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 22:09:19,874 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-18 22:09:19,881 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 22:09:24,894 - wandb.wandb_agent - INFO - Running runs: ['1prxbne0']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_220924-1prxbne0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-27
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/1prxbne0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8238
wandb:    train_loss 1.9447
wandb: training_time 2.09207
wandb:        val_f1 0.81489
wandb:      val_loss 2.19585
wandb: 
wandb: Synced bumbling-sweep-27: https://wandb.ai/jah377/sff_products/runs/1prxbne0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_220924-1prxbne0/logs
2022-06-18 22:33:23,729 - wandb.wandb_agent - INFO - Cleaning up finished run: 1prxbne0
2022-06-18 22:33:24,059 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 22:33:24,060 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-18 22:33:24,066 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-18 22:33:29,078 - wandb.wandb_agent - INFO - Running runs: ['kaa3xql4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_223329-kaa3xql4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-28
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/kaa3xql4
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93303
wandb:    train_loss 0.23667
wandb: training_time 1.98788
wandb:        val_f1 0.91883
wandb:      val_loss 0.29812
wandb: 
wandb: Synced eager-sweep-28: https://wandb.ai/jah377/sff_products/runs/kaa3xql4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_223329-kaa3xql4/logs
2022-06-18 22:57:22,594 - wandb.wandb_agent - INFO - Cleaning up finished run: kaa3xql4
2022-06-18 22:57:22,930 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 22:57:22,930 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-18 22:57:22,939 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-18 22:57:27,954 - wandb.wandb_agent - INFO - Running runs: ['oh9zmdcu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_225728-oh9zmdcu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-29
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/oh9zmdcu
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99025
wandb:    train_loss 0.04308
wandb: training_time 4.59043
wandb:        val_f1 0.92386
wandb:      val_loss 0.34578
wandb: 
wandb: Synced solar-sweep-29: https://wandb.ai/jah377/sff_products/runs/oh9zmdcu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_225728-oh9zmdcu/logs
2022-06-18 23:40:26,138 - wandb.wandb_agent - INFO - Cleaning up finished run: oh9zmdcu
2022-06-18 23:40:26,467 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-18 23:40:26,467 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-18 23:40:26,474 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-18 23:40:31,486 - wandb.wandb_agent - INFO - Running runs: ['fdwj0fx0']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220618_234031-fdwj0fx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-30
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/fdwj0fx0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91999
wandb:    train_loss 0.37622
wandb: training_time 1.93595
wandb:        val_f1 0.89001
wandb:      val_loss 0.51226
wandb: 
wandb: Synced autumn-sweep-30: https://wandb.ai/jah377/sff_products/runs/fdwj0fx0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_234031-fdwj0fx0/logs
2022-06-19 00:00:28,286 - wandb.wandb_agent - INFO - Cleaning up finished run: fdwj0fx0
2022-06-19 00:00:28,714 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 00:00:28,715 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 00:00:28,725 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 00:00:33,734 - wandb.wandb_agent - INFO - Running runs: ['thxa6sgr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_000033-thxa6sgr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-31
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/thxa6sgr
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93455
wandb:    train_loss 0.2326
wandb: training_time 3.76965
wandb:        val_f1 0.91928
wandb:      val_loss 0.29975
wandb: 
wandb: Synced wise-sweep-31: https://wandb.ai/jah377/sff_products/runs/thxa6sgr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_000033-thxa6sgr/logs
2022-06-19 00:33:37,580 - wandb.wandb_agent - INFO - Cleaning up finished run: thxa6sgr
2022-06-19 00:33:37,958 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 00:33:37,959 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 00:33:37,965 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 00:33:42,980 - wandb.wandb_agent - INFO - Running runs: ['55whfo2q']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_003342-55whfo2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-32
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/55whfo2q
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9656
wandb:    train_loss 0.11363
wandb: training_time 4.71286
wandb:        val_f1 0.92902
wandb:      val_loss 0.27957
wandb: 
wandb: Synced jolly-sweep-32: https://wandb.ai/jah377/sff_products/runs/55whfo2q
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_003342-55whfo2q/logs
2022-06-19 01:12:12,590 - wandb.wandb_agent - INFO - Cleaning up finished run: 55whfo2q
2022-06-19 01:12:13,133 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 01:12:13,134 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-19 01:12:13,141 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 01:12:18,156 - wandb.wandb_agent - INFO - Running runs: ['tnkj4nqc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_011218-tnkj4nqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-33
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/tnkj4nqc
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94091
wandb:    train_loss 0.20812
wandb: training_time 2.68646
wandb:        val_f1 0.92295
wandb:      val_loss 0.28736
wandb: 
wandb: Synced vague-sweep-33: https://wandb.ai/jah377/sff_products/runs/tnkj4nqc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_011218-tnkj4nqc/logs
2022-06-19 01:38:24,461 - wandb.wandb_agent - INFO - Cleaning up finished run: tnkj4nqc
2022-06-19 01:38:24,837 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 01:38:24,838 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-19 01:38:24,846 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 01:38:29,860 - wandb.wandb_agent - INFO - Running runs: ['lzy5rbqj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_013829-lzy5rbqj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-34
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/lzy5rbqj
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.79026
wandb:    train_loss 7.69841
wandb: training_time 2.80628
wandb:        val_f1 0.77809
wandb:      val_loss 48.21372
wandb: 
wandb: Synced northern-sweep-34: https://wandb.ai/jah377/sff_products/runs/lzy5rbqj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_013829-lzy5rbqj/logs
2022-06-19 02:04:52,763 - wandb.wandb_agent - INFO - Cleaning up finished run: lzy5rbqj
2022-06-19 02:04:53,231 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 02:04:53,231 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 02:04:53,240 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 02:04:58,255 - wandb.wandb_agent - INFO - Running runs: ['gxqcyzug']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_020458-gxqcyzug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-35
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/gxqcyzug
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9214
wandb:    train_loss 0.28984
wandb: training_time 1.78997
wandb:        val_f1 0.91079
wandb:      val_loss 0.33864
wandb: 
wandb: Synced wise-sweep-35: https://wandb.ai/jah377/sff_products/runs/gxqcyzug
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_020458-gxqcyzug/logs
2022-06-19 02:24:28,590 - wandb.wandb_agent - INFO - Cleaning up finished run: gxqcyzug
2022-06-19 02:24:28,995 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 02:24:28,996 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 02:24:29,005 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 02:24:34,019 - wandb.wandb_agent - INFO - Running runs: ['pyoaytlr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_022434-pyoaytlr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-36
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/pyoaytlr
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95233
wandb:    train_loss 0.16076
wandb: training_time 1.90076
wandb:        val_f1 0.92544
wandb:      val_loss 0.27037
wandb: 
wandb: Synced restful-sweep-36: https://wandb.ai/jah377/sff_products/runs/pyoaytlr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_022434-pyoaytlr/logs
2022-06-19 02:43:53,983 - wandb.wandb_agent - INFO - Cleaning up finished run: pyoaytlr
2022-06-19 02:43:54,489 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 02:43:54,489 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 02:43:54,498 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 02:43:59,510 - wandb.wandb_agent - INFO - Running runs: ['ehrwollt']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_024358-ehrwollt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-37
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/ehrwollt
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93676
wandb:    train_loss 0.23071
wandb: training_time 2.66478
wandb:        val_f1 0.91794
wandb:      val_loss 0.30468
wandb: 
wandb: Synced frosty-sweep-37: https://wandb.ai/jah377/sff_products/runs/ehrwollt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_024358-ehrwollt/logs
2022-06-19 03:10:22,161 - wandb.wandb_agent - INFO - Cleaning up finished run: ehrwollt
2022-06-19 03:10:22,584 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 03:10:22,584 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 03:10:22,592 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 03:10:27,607 - wandb.wandb_agent - INFO - Running runs: ['b3gn4ccm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_031027-b3gn4ccm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-38
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/b3gn4ccm
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91441
wandb:    train_loss 0.36971
wandb: training_time 1.61765
wandb:        val_f1 0.90436
wandb:      val_loss 0.4474
wandb: 
wandb: Synced trim-sweep-38: https://wandb.ai/jah377/sff_products/runs/b3gn4ccm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_031027-b3gn4ccm/logs
2022-06-19 03:28:21,699 - wandb.wandb_agent - INFO - Cleaning up finished run: b3gn4ccm
2022-06-19 03:28:22,088 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 03:28:22,088 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 03:28:22,096 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 03:28:27,111 - wandb.wandb_agent - INFO - Running runs: ['e68rh4me']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_032826-e68rh4me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-39
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/e68rh4me
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91356
wandb:    train_loss 0.29774
wandb: training_time 1.87689
wandb:        val_f1 0.90265
wandb:      val_loss 0.34832
wandb: 
wandb: Synced firm-sweep-39: https://wandb.ai/jah377/sff_products/runs/e68rh4me
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_032826-e68rh4me/logs
2022-06-19 03:47:36,914 - wandb.wandb_agent - INFO - Cleaning up finished run: e68rh4me
2022-06-19 03:47:37,296 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 03:47:37,297 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 03:47:37,304 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 03:47:42,318 - wandb.wandb_agent - INFO - Running runs: ['i3391kj0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_034742-i3391kj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-40
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/i3391kj0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94814
wandb:    train_loss 0.17893
wandb: training_time 1.54873
wandb:        val_f1 0.91402
wandb:      val_loss 0.31034
wandb: 
wandb: Synced zany-sweep-40: https://wandb.ai/jah377/sff_products/runs/i3391kj0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_034742-i3391kj0/logs
2022-06-19 04:04:13,058 - wandb.wandb_agent - INFO - Cleaning up finished run: i3391kj0
2022-06-19 04:04:13,506 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 04:04:13,507 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 04:04:13,516 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 04:04:18,529 - wandb.wandb_agent - INFO - Running runs: ['jno3ke5d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_040418-jno3ke5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-41
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/jno3ke5d
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93558
wandb:    train_loss 0.22224
wandb: training_time 1.96692
wandb:        val_f1 0.91974
wandb:      val_loss 0.28811
wandb: 
wandb: Synced dutiful-sweep-41: https://wandb.ai/jah377/sff_products/runs/jno3ke5d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_040418-jno3ke5d/logs
2022-06-19 04:25:49,004 - wandb.wandb_agent - INFO - Cleaning up finished run: jno3ke5d
2022-06-19 04:25:49,593 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 04:25:49,593 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 04:25:49,603 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 04:25:54,618 - wandb.wandb_agent - INFO - Running runs: ['iuowcfni']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_042554-iuowcfni
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-42
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/iuowcfni
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9106
wandb:    train_loss 0.31601
wandb: training_time 1.90219
wandb:        val_f1 0.89973
wandb:      val_loss 0.3659
wandb: 
wandb: Synced whole-sweep-42: https://wandb.ai/jah377/sff_products/runs/iuowcfni
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_042554-iuowcfni/logs
2022-06-19 04:45:35,381 - wandb.wandb_agent - INFO - Cleaning up finished run: iuowcfni
2022-06-19 04:45:35,857 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 04:45:35,858 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-19 04:45:35,865 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 04:45:40,878 - wandb.wandb_agent - INFO - Running runs: ['3od3r9fr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_044540-3od3r9fr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-43
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/3od3r9fr
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89837
wandb:    train_loss 0.382
wandb: training_time 1.72557
wandb:        val_f1 0.89128
wandb:      val_loss 0.4135
wandb: 
wandb: Synced flowing-sweep-43: https://wandb.ai/jah377/sff_products/runs/3od3r9fr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_044540-3od3r9fr/logs
2022-06-19 05:04:24,394 - wandb.wandb_agent - INFO - Cleaning up finished run: 3od3r9fr
2022-06-19 05:04:24,787 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 05:04:24,787 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 05:04:24,797 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 05:04:29,812 - wandb.wandb_agent - INFO - Running runs: ['agrpwy40']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_050429-agrpwy40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-44
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/agrpwy40
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89026
wandb:    train_loss 0.42315
wandb: training_time 2.88942
wandb:        val_f1 0.8801
wandb:      val_loss 0.46042
wandb: 
wandb: Synced ancient-sweep-44: https://wandb.ai/jah377/sff_products/runs/agrpwy40
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_050429-agrpwy40/logs
2022-06-19 05:31:02,907 - wandb.wandb_agent - INFO - Cleaning up finished run: agrpwy40
2022-06-19 05:31:03,359 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 05:31:03,360 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-19 05:31:03,367 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 05:31:08,382 - wandb.wandb_agent - INFO - Running runs: ['1p0eggg6']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_053108-1p0eggg6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-45
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/1p0eggg6
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8811
wandb:    train_loss 0.43117
wandb: training_time 1.60069
wandb:        val_f1 0.86486
wandb:      val_loss 0.49557
wandb: 
wandb: Synced trim-sweep-45: https://wandb.ai/jah377/sff_products/runs/1p0eggg6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_053108-1p0eggg6/logs
2022-06-19 05:49:12,683 - wandb.wandb_agent - INFO - Cleaning up finished run: 1p0eggg6
2022-06-19 05:49:13,141 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 05:49:13,142 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 05:49:13,152 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 05:49:18,165 - wandb.wandb_agent - INFO - Running runs: ['dtviddl2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_054918-dtviddl2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-46
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/dtviddl2
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88034
wandb:    train_loss 0.47627
wandb: training_time 4.90049
wandb:        val_f1 0.87359
wandb:      val_loss 0.49773
wandb: 
wandb: Synced dulcet-sweep-46: https://wandb.ai/jah377/sff_products/runs/dtviddl2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_054918-dtviddl2/logs
2022-06-19 06:19:51,011 - wandb.wandb_agent - INFO - Cleaning up finished run: dtviddl2
2022-06-19 06:19:51,395 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 06:19:51,395 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 06:19:51,402 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 06:19:56,418 - wandb.wandb_agent - INFO - Running runs: ['ce72xkrn']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_061956-ce72xkrn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-47
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/ce72xkrn
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94008
wandb:    train_loss 0.2114
wandb: training_time 2.71029
wandb:        val_f1 0.91944
wandb:      val_loss 0.29678
wandb: 
wandb: Synced laced-sweep-47: https://wandb.ai/jah377/sff_products/runs/ce72xkrn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_061956-ce72xkrn/logs
2022-06-19 06:45:22,970 - wandb.wandb_agent - INFO - Cleaning up finished run: ce72xkrn
2022-06-19 06:45:23,387 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 06:45:23,388 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 06:45:23,395 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 06:45:28,409 - wandb.wandb_agent - INFO - Running runs: ['hn3oqxkx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_064528-hn3oqxkx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-48
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/hn3oqxkx
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93252
wandb:    train_loss 0.26269
wandb: training_time 3.57006
wandb:        val_f1 0.91809
wandb:      val_loss 0.33152
wandb: 
wandb: Synced splendid-sweep-48: https://wandb.ai/jah377/sff_products/runs/hn3oqxkx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_064528-hn3oqxkx/logs
2022-06-19 07:16:41,782 - wandb.wandb_agent - INFO - Cleaning up finished run: hn3oqxkx
2022-06-19 07:16:42,252 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:16:42,252 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 07:16:42,260 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 07:16:47,274 - wandb.wandb_agent - INFO - Running runs: ['pczm2mh5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_071647-pczm2mh5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-49
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/pczm2mh5
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93049
wandb:    train_loss 0.25351
wandb: training_time 1.82248
wandb:        val_f1 0.91532
wandb:      val_loss 0.31772
wandb: 
wandb: Synced autumn-sweep-49: https://wandb.ai/jah377/sff_products/runs/pczm2mh5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_071647-pczm2mh5/logs
2022-06-19 07:36:53,126 - wandb.wandb_agent - INFO - Cleaning up finished run: pczm2mh5
2022-06-19 07:36:53,645 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:36:53,645 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 07:36:53,652 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 07:36:58,666 - wandb.wandb_agent - INFO - Running runs: ['4txfu4t2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_073659-4txfu4t2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-50
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/4txfu4t2
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92141
wandb:    train_loss 0.27357
wandb: training_time 1.63236
wandb:        val_f1 0.90026
wandb:      val_loss 0.35396
wandb: 
wandb: Synced sweet-sweep-50: https://wandb.ai/jah377/sff_products/runs/4txfu4t2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_073659-4txfu4t2/logs
2022-06-19 07:55:16,306 - wandb.wandb_agent - INFO - Cleaning up finished run: 4txfu4t2
2022-06-19 07:55:16,740 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 07:55:16,740 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 07:55:16,748 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 07:55:21,762 - wandb.wandb_agent - INFO - Running runs: ['5p7nh6xw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_075521-5p7nh6xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-51
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/5p7nh6xw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91246
wandb:    train_loss 0.31777
wandb: training_time 2.04869
wandb:        val_f1 0.90405
wandb:      val_loss 0.35453
wandb: 
wandb: Synced desert-sweep-51: https://wandb.ai/jah377/sff_products/runs/5p7nh6xw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_075521-5p7nh6xw/logs
2022-06-19 08:19:56,986 - wandb.wandb_agent - INFO - Cleaning up finished run: 5p7nh6xw
2022-06-19 08:19:57,375 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 08:19:57,375 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 08:19:57,382 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 08:20:02,394 - wandb.wandb_agent - INFO - Running runs: ['bu8vxsyo']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_082002-bu8vxsyo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-52
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/bu8vxsyo
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8629
wandb:    train_loss 0.51427
wandb: training_time 1.84234
wandb:        val_f1 0.8477
wandb:      val_loss 0.57807
wandb: 
wandb: Synced treasured-sweep-52: https://wandb.ai/jah377/sff_products/runs/bu8vxsyo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_082002-bu8vxsyo/logs
2022-06-19 08:39:01,994 - wandb.wandb_agent - INFO - Cleaning up finished run: bu8vxsyo
2022-06-19 08:39:02,390 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 08:39:02,391 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 08:39:02,398 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 08:39:07,410 - wandb.wandb_agent - INFO - Running runs: ['dlnkob6d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_083907-dlnkob6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-53
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/dlnkob6d
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89361
wandb:    train_loss 0.35996
wandb: training_time 2.45134
wandb:        val_f1 0.87364
wandb:      val_loss 0.43715
wandb: 
wandb: Synced fluent-sweep-53: https://wandb.ai/jah377/sff_products/runs/dlnkob6d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_083907-dlnkob6d/logs
2022-06-19 09:01:49,409 - wandb.wandb_agent - INFO - Cleaning up finished run: dlnkob6d
2022-06-19 09:01:50,348 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 09:01:50,349 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 09:01:50,356 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 09:01:55,371 - wandb.wandb_agent - INFO - Running runs: ['xkultrvp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_090155-xkultrvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-54
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/xkultrvp
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90053
wandb:    train_loss 0.35982
wandb: training_time 2.55926
wandb:        val_f1 0.89108
wandb:      val_loss 0.40194
wandb: 
wandb: Synced major-sweep-54: https://wandb.ai/jah377/sff_products/runs/xkultrvp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_090155-xkultrvp/logs
2022-06-19 09:26:05,911 - wandb.wandb_agent - INFO - Cleaning up finished run: xkultrvp
2022-06-19 09:26:07,029 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 09:26:07,030 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 09:26:07,036 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 09:26:12,051 - wandb.wandb_agent - INFO - Running runs: ['atabqk9y']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_092612-atabqk9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-55
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/atabqk9y
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91898
wandb:    train_loss 0.28911
wandb: training_time 2.06496
wandb:        val_f1 0.9069
wandb:      val_loss 0.34116
wandb: 
wandb: Synced good-sweep-55: https://wandb.ai/jah377/sff_products/runs/atabqk9y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_092612-atabqk9y/logs
2022-06-19 09:46:35,183 - wandb.wandb_agent - INFO - Cleaning up finished run: atabqk9y
2022-06-19 09:46:35,717 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 09:46:35,718 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 09:46:35,725 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 09:46:40,738 - wandb.wandb_agent - INFO - Running runs: ['p0r22szw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_094641-p0r22szw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-56
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/p0r22szw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9313
wandb:    train_loss 0.23761
wandb: training_time 3.94687
wandb:        val_f1 0.91664
wandb:      val_loss 0.30114
wandb: 
wandb: Synced azure-sweep-56: https://wandb.ai/jah377/sff_products/runs/p0r22szw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_094641-p0r22szw/logs
2022-06-19 10:22:13,297 - wandb.wandb_agent - INFO - Cleaning up finished run: p0r22szw
2022-06-19 10:22:13,734 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 10:22:13,735 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 10:22:13,754 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 10:22:18,770 - wandb.wandb_agent - INFO - Running runs: ['c3sot7e0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_102219-c3sot7e0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-57
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/c3sot7e0
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88598
wandb:    train_loss 0.50933
wandb: training_time 1.47635
wandb:        val_f1 0.86873
wandb:      val_loss 0.59098
wandb: 
wandb: Synced wandering-sweep-57: https://wandb.ai/jah377/sff_products/runs/c3sot7e0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_102219-c3sot7e0/logs
2022-06-19 10:40:17,294 - wandb.wandb_agent - INFO - Cleaning up finished run: c3sot7e0
2022-06-19 10:40:17,902 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 10:40:17,903 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 10:40:17,909 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 10:40:22,922 - wandb.wandb_agent - INFO - Running runs: ['ayulutii']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_104022-ayulutii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-58
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/ayulutii
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88779
wandb:    train_loss 0.41834
wandb: training_time 2.46563
wandb:        val_f1 0.87648
wandb:      val_loss 0.45698
wandb: 
wandb: Synced devoted-sweep-58: https://wandb.ai/jah377/sff_products/runs/ayulutii
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_104022-ayulutii/logs
2022-06-19 11:06:09,754 - wandb.wandb_agent - INFO - Cleaning up finished run: ayulutii
2022-06-19 11:06:10,191 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:06:10,192 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 11:06:10,201 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 11:06:15,214 - wandb.wandb_agent - INFO - Running runs: ['pz7srx2g']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_110614-pz7srx2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-59
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/pz7srx2g
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97188
wandb:    train_loss 0.08681
wandb: training_time 2.36966
wandb:        val_f1 0.92404
wandb:      val_loss 0.29348
wandb: 
wandb: Synced graceful-sweep-59: https://wandb.ai/jah377/sff_products/runs/pz7srx2g
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_110614-pz7srx2g/logs
2022-06-19 11:31:05,200 - wandb.wandb_agent - INFO - Cleaning up finished run: pz7srx2g
2022-06-19 11:31:05,656 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:31:05,657 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 11:31:05,663 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 11:31:10,678 - wandb.wandb_agent - INFO - Running runs: ['7bmadsyf']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_113110-7bmadsyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-60
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/7bmadsyf
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92969
wandb:    train_loss 0.2377
wandb: training_time 2.03776
wandb:        val_f1 0.91051
wandb:      val_loss 0.31464
wandb: 
wandb: Synced magic-sweep-60: https://wandb.ai/jah377/sff_products/runs/7bmadsyf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_113110-7bmadsyf/logs
2022-06-19 11:54:08,298 - wandb.wandb_agent - INFO - Cleaning up finished run: 7bmadsyf
2022-06-19 11:54:08,996 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:54:08,997 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 11:54:09,005 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 11:54:14,018 - wandb.wandb_agent - INFO - Running runs: ['6fksp6kr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_115414-6fksp6kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-61
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/6fksp6kr
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90261
wandb:    train_loss 0.36263
wandb: training_time 2.23359
wandb:        val_f1 0.89312
wandb:      val_loss 0.40314
wandb: 
wandb: Synced resilient-sweep-61: https://wandb.ai/jah377/sff_products/runs/6fksp6kr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_115414-6fksp6kr/logs
2022-06-19 12:16:34,893 - wandb.wandb_agent - INFO - Cleaning up finished run: 6fksp6kr
2022-06-19 12:16:35,734 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:16:35,735 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 12:16:35,743 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 12:16:40,758 - wandb.wandb_agent - INFO - Running runs: ['2fdxy3vd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_121640-2fdxy3vd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-62
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/2fdxy3vd
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6822
wandb:    train_loss 1.13569
wandb: training_time 2.69391
wandb:        val_f1 0.67497
wandb:      val_loss 1.16985
wandb: 
wandb: Synced good-sweep-62: https://wandb.ai/jah377/sff_products/runs/2fdxy3vd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_121640-2fdxy3vd/logs
2022-06-19 12:39:29,770 - wandb.wandb_agent - INFO - Cleaning up finished run: 2fdxy3vd
2022-06-19 12:39:30,416 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:39:30,416 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 12:39:30,424 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 12:39:35,438 - wandb.wandb_agent - INFO - Running runs: ['4shbpfo7']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_123934-4shbpfo7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-63
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/4shbpfo7
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.75792
wandb:    train_loss 0.83467
wandb: training_time 1.70657
wandb:        val_f1 0.73471
wandb:      val_loss 0.92054
wandb: 
wandb: Synced denim-sweep-63: https://wandb.ai/jah377/sff_products/runs/4shbpfo7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_123934-4shbpfo7/logs
2022-06-19 12:58:10,722 - wandb.wandb_agent - INFO - Cleaning up finished run: 4shbpfo7
2022-06-19 12:58:11,193 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:58:11,194 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-19 12:58:11,202 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 12:58:16,216 - wandb.wandb_agent - INFO - Running runs: ['a0r2bhwn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_125816-a0r2bhwn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-64
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/a0r2bhwn
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90078
wandb:    train_loss 0.38907
wandb: training_time 5.52804
wandb:        val_f1 0.89108
wandb:      val_loss 0.42271
wandb: 
wandb: Synced stellar-sweep-64: https://wandb.ai/jah377/sff_products/runs/a0r2bhwn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_125816-a0r2bhwn/logs
2022-06-19 13:41:25,954 - wandb.wandb_agent - INFO - Cleaning up finished run: a0r2bhwn
2022-06-19 13:41:26,476 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:41:26,476 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 13:41:26,485 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 13:41:31,499 - wandb.wandb_agent - INFO - Running runs: ['yc970y66']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_134131-yc970y66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-65
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/yc970y66
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90934
wandb:    train_loss 0.34394
wandb: training_time 1.79293
wandb:        val_f1 0.89986
wandb:      val_loss 0.38445
wandb: 
wandb: Synced breezy-sweep-65: https://wandb.ai/jah377/sff_products/runs/yc970y66
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_134131-yc970y66/logs
2022-06-19 14:01:53,791 - wandb.wandb_agent - INFO - Cleaning up finished run: yc970y66
2022-06-19 14:01:54,221 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:01:54,222 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 14:01:54,229 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 14:01:59,244 - wandb.wandb_agent - INFO - Running runs: ['k93tlqck']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_140159-k93tlqck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-66
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/k93tlqck
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93466
wandb:    train_loss 0.22297
wandb: training_time 1.76255
wandb:        val_f1 0.91979
wandb:      val_loss 0.29073
wandb: 
wandb: Synced graceful-sweep-66: https://wandb.ai/jah377/sff_products/runs/k93tlqck
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_140159-k93tlqck/logs
2022-06-19 14:23:38,161 - wandb.wandb_agent - INFO - Cleaning up finished run: k93tlqck
2022-06-19 14:23:38,669 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:23:38,670 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 14:23:38,679 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 14:23:43,693 - wandb.wandb_agent - INFO - Running runs: ['x2s5btiq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_142343-x2s5btiq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-67
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/x2s5btiq
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91571
wandb:    train_loss 0.28853
wandb: training_time 1.86102
wandb:        val_f1 0.89566
wandb:      val_loss 0.36499
wandb: 
wandb: Synced gentle-sweep-67: https://wandb.ai/jah377/sff_products/runs/x2s5btiq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_142343-x2s5btiq/logs
2022-06-19 14:43:54,946 - wandb.wandb_agent - INFO - Cleaning up finished run: x2s5btiq
2022-06-19 14:43:55,448 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:43:55,448 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-19 14:43:55,457 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 14:44:00,470 - wandb.wandb_agent - INFO - Running runs: ['s4878lnw']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_144359-s4878lnw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-68
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/s4878lnw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87861
wandb:    train_loss 0.46558
wandb: training_time 1.77005
wandb:        val_f1 0.87028
wandb:      val_loss 0.50368
wandb: 
wandb: Synced fiery-sweep-68: https://wandb.ai/jah377/sff_products/runs/s4878lnw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_144359-s4878lnw/logs
2022-06-19 15:03:35,523 - wandb.wandb_agent - INFO - Cleaning up finished run: s4878lnw
2022-06-19 15:03:35,926 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:03:35,926 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 15:03:35,935 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 15:03:40,946 - wandb.wandb_agent - INFO - Running runs: ['3gvydz7u']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_150341-3gvydz7u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-69
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/3gvydz7u
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92303
wandb:    train_loss 0.26358
wandb: training_time 1.87255
wandb:        val_f1 0.91201
wandb:      val_loss 0.31497
wandb: 
wandb: Synced dark-sweep-69: https://wandb.ai/jah377/sff_products/runs/3gvydz7u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_150341-3gvydz7u/logs
2022-06-19 15:26:16,664 - wandb.wandb_agent - INFO - Cleaning up finished run: 3gvydz7u
2022-06-19 15:26:17,359 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:26:17,360 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 15:26:17,366 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 15:26:22,381 - wandb.wandb_agent - INFO - Running runs: ['3yslvx36']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_152622-3yslvx36
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-70
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/3yslvx36
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9653
wandb:    train_loss 0.11378
wandb: training_time 1.98276
wandb:        val_f1 0.92824
wandb:      val_loss 0.26354
wandb: 
wandb: Synced rare-sweep-70: https://wandb.ai/jah377/sff_products/runs/3yslvx36
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_152622-3yslvx36/logs
2022-06-19 15:47:51,235 - wandb.wandb_agent - INFO - Cleaning up finished run: 3yslvx36
2022-06-19 15:47:51,760 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:47:51,760 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-19 15:47:51,767 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 15:47:56,783 - wandb.wandb_agent - INFO - Running runs: ['3cr0sryd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_154757-3cr0sryd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-71
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/3cr0sryd
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.75084
wandb:    train_loss 0.92084
wandb: training_time 1.71485
wandb:        val_f1 0.73346
wandb:      val_loss 0.98163
wandb: 
wandb: Synced lunar-sweep-71: https://wandb.ai/jah377/sff_products/runs/3cr0sryd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_154757-3cr0sryd/logs
2022-06-19 16:07:33,769 - wandb.wandb_agent - INFO - Cleaning up finished run: 3cr0sryd
2022-06-19 16:07:34,719 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:07:34,719 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 16:07:34,728 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 16:07:39,738 - wandb.wandb_agent - INFO - Running runs: ['u9opc0qb']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_160739-u9opc0qb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-72
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/u9opc0qb
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93371
wandb:    train_loss 0.22564
wandb: training_time 2.11316
wandb:        val_f1 0.91201
wandb:      val_loss 0.30952
wandb: 
wandb: Synced neat-sweep-72: https://wandb.ai/jah377/sff_products/runs/u9opc0qb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_160739-u9opc0qb/logs
2022-06-19 16:27:36,111 - wandb.wandb_agent - INFO - Cleaning up finished run: u9opc0qb
2022-06-19 16:27:36,640 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:27:36,640 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 16:27:36,649 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 16:27:41,658 - wandb.wandb_agent - INFO - Running runs: ['1yim28rg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_162741-1yim28rg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-73
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/1yim28rg
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92893
wandb:    train_loss 0.25396
wandb: training_time 1.41246
wandb:        val_f1 0.90225
wandb:      val_loss 0.35137
wandb: 
wandb: Synced rose-sweep-73: https://wandb.ai/jah377/sff_products/runs/1yim28rg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_162741-1yim28rg/logs
2022-06-19 16:44:19,035 - wandb.wandb_agent - INFO - Cleaning up finished run: 1yim28rg
2022-06-19 16:44:19,451 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:44:19,452 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 16:44:19,461 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 16:44:24,476 - wandb.wandb_agent - INFO - Running runs: ['glg2s5ta']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_164424-glg2s5ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-74
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/glg2s5ta
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9169
wandb:    train_loss 0.30157
wandb: training_time 1.79674
wandb:        val_f1 0.90588
wandb:      val_loss 0.35031
wandb: 
wandb: Synced solar-sweep-74: https://wandb.ai/jah377/sff_products/runs/glg2s5ta
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_164424-glg2s5ta/logs
2022-06-19 17:05:43,664 - wandb.wandb_agent - INFO - Cleaning up finished run: glg2s5ta
2022-06-19 17:05:44,256 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:05:44,256 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 17:05:44,264 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 17:05:49,279 - wandb.wandb_agent - INFO - Running runs: ['ynl3fays']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_170549-ynl3fays
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-75
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/ynl3fays
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92349
wandb:    train_loss 0.27382
wandb: training_time 1.77593
wandb:        val_f1 0.90987
wandb:      val_loss 0.33074
wandb: 
wandb: Synced silver-sweep-75: https://wandb.ai/jah377/sff_products/runs/ynl3fays
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_170549-ynl3fays/logs
2022-06-19 17:25:32,783 - wandb.wandb_agent - INFO - Cleaning up finished run: ynl3fays
2022-06-19 17:25:33,290 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:25:33,290 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 17:25:33,298 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 17:25:38,310 - wandb.wandb_agent - INFO - Running runs: ['loredigs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_172538-loredigs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-76
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/loredigs
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87927
wandb:    train_loss 0.43032
wandb: training_time 2.09509
wandb:        val_f1 0.8583
wandb:      val_loss 0.51058
wandb: 
wandb: Synced rural-sweep-76: https://wandb.ai/jah377/sff_products/runs/loredigs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_172538-loredigs/logs
2022-06-19 17:47:29,233 - wandb.wandb_agent - INFO - Cleaning up finished run: loredigs
2022-06-19 17:47:29,660 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:47:29,660 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 17:47:29,668 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 17:47:34,684 - wandb.wandb_agent - INFO - Running runs: ['nacacxfs']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_174735-nacacxfs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-77
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/nacacxfs
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91212
wandb:    train_loss 0.33906
wandb: training_time 2.16049
wandb:        val_f1 0.90255
wandb:      val_loss 0.37606
wandb: 
wandb: Synced zany-sweep-77: https://wandb.ai/jah377/sff_products/runs/nacacxfs
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_174735-nacacxfs/logs
2022-06-19 18:10:12,062 - wandb.wandb_agent - INFO - Cleaning up finished run: nacacxfs
2022-06-19 18:10:12,511 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:10:12,511 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 18:10:12,518 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 18:10:17,530 - wandb.wandb_agent - INFO - Running runs: ['tqcqnxye']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_181017-tqcqnxye
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-78
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/tqcqnxye
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9039
wandb:    train_loss 0.35252
wandb: training_time 1.6396
wandb:        val_f1 0.8939
wandb:      val_loss 0.39328
wandb: 
wandb: Synced major-sweep-78: https://wandb.ai/jah377/sff_products/runs/tqcqnxye
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_181017-tqcqnxye/logs
2022-06-19 18:28:11,817 - wandb.wandb_agent - INFO - Cleaning up finished run: tqcqnxye
2022-06-19 18:28:12,228 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:28:12,228 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 18:28:12,236 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 18:28:17,251 - wandb.wandb_agent - INFO - Running runs: ['8ydbn1gh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_182817-8ydbn1gh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-79
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/8ydbn1gh
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91995
wandb:    train_loss 0.28151
wandb: training_time 2.05888
wandb:        val_f1 0.90431
wandb:      val_loss 0.33814
wandb: 
wandb: Synced celestial-sweep-79: https://wandb.ai/jah377/sff_products/runs/8ydbn1gh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_182817-8ydbn1gh/logs
2022-06-19 18:51:30,946 - wandb.wandb_agent - INFO - Cleaning up finished run: 8ydbn1gh
2022-06-19 18:51:31,393 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:51:31,394 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 18:51:31,401 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 18:51:36,414 - wandb.wandb_agent - INFO - Running runs: ['1ynx8w3u']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_185135-1ynx8w3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-80
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/1ynx8w3u
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65659
wandb:    train_loss 1.21188
wandb: training_time 1.40949
wandb:        val_f1 0.65135
wandb:      val_loss 1.24394
wandb: 
wandb: Synced valiant-sweep-80: https://wandb.ai/jah377/sff_products/runs/1ynx8w3u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_185135-1ynx8w3u/logs
2022-06-19 19:07:35,852 - wandb.wandb_agent - INFO - Cleaning up finished run: 1ynx8w3u
2022-06-19 19:07:37,108 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:07:37,109 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 19:07:37,116 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 19:07:42,133 - wandb.wandb_agent - INFO - Running runs: ['7z54mhtj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_190742-7z54mhtj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-81
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/7z54mhtj
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93491
wandb:    train_loss 0.22756
wandb: training_time 4.07715
wandb:        val_f1 0.91758
wandb:      val_loss 0.30351
wandb: 
wandb: Synced lilac-sweep-81: https://wandb.ai/jah377/sff_products/runs/7z54mhtj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_190742-7z54mhtj/logs
2022-06-19 19:32:44,589 - wandb.wandb_agent - INFO - Cleaning up finished run: 7z54mhtj
2022-06-19 19:32:52,302 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:32:52,304 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-19 19:32:52,313 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 19:32:57,328 - wandb.wandb_agent - INFO - Running runs: ['92z3u75a']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_193257-92z3u75a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-82
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/92z3u75a
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92832
wandb:    train_loss 0.27625
wandb: training_time 1.79477
wandb:        val_f1 0.90723
wandb:      val_loss 0.37367
wandb: 
wandb: Synced copper-sweep-82: https://wandb.ai/jah377/sff_products/runs/92z3u75a
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_193257-92z3u75a/logs
2022-06-19 19:52:34,211 - wandb.wandb_agent - INFO - Cleaning up finished run: 92z3u75a
2022-06-19 19:52:34,831 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:52:34,831 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 19:52:34,841 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 19:52:39,854 - wandb.wandb_agent - INFO - Running runs: ['bt9tp8fr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_195239-bt9tp8fr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-83
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/bt9tp8fr
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89939
wandb:    train_loss 0.36893
wandb: training_time 1.83653
wandb:        val_f1 0.89057
wandb:      val_loss 0.41053
wandb: 
wandb: Synced autumn-sweep-83: https://wandb.ai/jah377/sff_products/runs/bt9tp8fr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_195239-bt9tp8fr/logs
2022-06-19 20:15:23,246 - wandb.wandb_agent - INFO - Cleaning up finished run: bt9tp8fr
2022-06-19 20:15:23,736 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:15:23,737 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-19 20:15:23,745 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 20:15:28,759 - wandb.wandb_agent - INFO - Running runs: ['pmwgrrwj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_201528-pmwgrrwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-84
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/pmwgrrwj
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30837
wandb:    train_loss 2.60063
wandb: training_time 1.49579
wandb:        val_f1 0.30834
wandb:      val_loss 2.6035
wandb: 
wandb: Synced hardy-sweep-84: https://wandb.ai/jah377/sff_products/runs/pmwgrrwj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_201528-pmwgrrwj/logs
2022-06-19 20:33:30,230 - wandb.wandb_agent - INFO - Cleaning up finished run: pmwgrrwj
2022-06-19 20:33:30,719 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:33:30,719 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 20:33:30,728 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 20:33:35,743 - wandb.wandb_agent - INFO - Running runs: ['xwlqhf34']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_203335-xwlqhf34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-85
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/xwlqhf34
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63122
wandb:    train_loss 2.44624
wandb: training_time 2.11125
wandb:        val_f1 0.61155
wandb:      val_loss 2.61103
wandb: 
wandb: Synced royal-sweep-85: https://wandb.ai/jah377/sff_products/runs/xwlqhf34
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_203335-xwlqhf34/logs
2022-06-19 20:57:01,698 - wandb.wandb_agent - INFO - Cleaning up finished run: xwlqhf34
2022-06-19 20:57:02,212 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:57:02,212 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 20:57:02,219 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 20:57:07,234 - wandb.wandb_agent - INFO - Running runs: ['2dcrp7vw']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_205706-2dcrp7vw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-86
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/2dcrp7vw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.71796
wandb:    train_loss 0.98507
wandb: training_time 1.50673
wandb:        val_f1 0.70737
wandb:      val_loss 1.03381
wandb: 
wandb: Synced clean-sweep-86: https://wandb.ai/jah377/sff_products/runs/2dcrp7vw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_205706-2dcrp7vw/logs
2022-06-19 21:13:53,594 - wandb.wandb_agent - INFO - Cleaning up finished run: 2dcrp7vw
2022-06-19 21:13:54,208 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:13:54,208 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 21:13:54,215 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 21:13:59,230 - wandb.wandb_agent - INFO - Running runs: ['hnoz7d97']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_211359-hnoz7d97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-87
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/hnoz7d97
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92454
wandb:    train_loss 0.26302
wandb: training_time 1.82879
wandb:        val_f1 0.91224
wandb:      val_loss 0.31632
wandb: 
wandb: Synced floral-sweep-87: https://wandb.ai/jah377/sff_products/runs/hnoz7d97
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_211359-hnoz7d97/logs
2022-06-19 21:35:23,878 - wandb.wandb_agent - INFO - Cleaning up finished run: hnoz7d97
2022-06-19 21:35:24,390 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:35:24,390 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 21:35:24,398 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 21:35:29,413 - wandb.wandb_agent - INFO - Running runs: ['qskrvcsi']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_213529-qskrvcsi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-88
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/qskrvcsi
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90014
wandb:    train_loss 0.36166
wandb: training_time 5.25171
wandb:        val_f1 0.8908
wandb:      val_loss 0.39716
wandb: 
wandb: Synced splendid-sweep-88: https://wandb.ai/jah377/sff_products/runs/qskrvcsi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_213529-qskrvcsi/logs
2022-06-19 22:16:31,319 - wandb.wandb_agent - INFO - Cleaning up finished run: qskrvcsi
2022-06-19 22:16:32,077 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:16:32,078 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 22:16:32,086 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 22:16:37,100 - wandb.wandb_agent - INFO - Running runs: ['yali5zq6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_221637-yali5zq6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-89
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/yali5zq6
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91285
wandb:    train_loss 0.29962
wandb: training_time 1.61912
wandb:        val_f1 0.8937
wandb:      val_loss 0.37314
wandb: 
wandb: Synced earthy-sweep-89: https://wandb.ai/jah377/sff_products/runs/yali5zq6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_221637-yali5zq6/logs
2022-06-19 22:34:37,369 - wandb.wandb_agent - INFO - Cleaning up finished run: yali5zq6
2022-06-19 22:34:38,119 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:34:38,120 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-19 22:34:38,127 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 22:34:43,138 - wandb.wandb_agent - INFO - Running runs: ['fy8dhzym']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_223443-fy8dhzym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-90
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/fy8dhzym
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92104
wandb:    train_loss 0.32422
wandb: training_time 2.24362
wandb:        val_f1 0.90835
wandb:      val_loss 0.37378
wandb: 
wandb: Synced treasured-sweep-90: https://wandb.ai/jah377/sff_products/runs/fy8dhzym
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_223443-fy8dhzym/logs
2022-06-19 22:56:53,092 - wandb.wandb_agent - INFO - Cleaning up finished run: fy8dhzym
2022-06-19 22:56:53,611 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:56:53,611 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-19 22:56:53,620 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 22:56:58,634 - wandb.wandb_agent - INFO - Running runs: ['n6orax4s']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_225658-n6orax4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-91
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/n6orax4s
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93671
wandb:    train_loss 0.22219
wandb: training_time 2.17602
wandb:        val_f1 0.91834
wandb:      val_loss 0.29575
wandb: 
wandb: Synced faithful-sweep-91: https://wandb.ai/jah377/sff_products/runs/n6orax4s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_225658-n6orax4s/logs
2022-06-19 23:18:30,080 - wandb.wandb_agent - INFO - Cleaning up finished run: n6orax4s
2022-06-19 23:18:30,627 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:18:30,628 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-19 23:18:30,637 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 23:18:35,650 - wandb.wandb_agent - INFO - Running runs: ['w6yqk8gm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_231835-w6yqk8gm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-92
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/w6yqk8gm
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67623
wandb:    train_loss 1.14726
wandb: training_time 1.96626
wandb:        val_f1 0.66912
wandb:      val_loss 1.18821
wandb: 
wandb: Synced earnest-sweep-92: https://wandb.ai/jah377/sff_products/runs/w6yqk8gm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_231835-w6yqk8gm/logs
2022-06-19 23:39:44,271 - wandb.wandb_agent - INFO - Cleaning up finished run: w6yqk8gm
2022-06-19 23:39:46,073 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:39:46,073 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-19 23:39:46,081 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 23:39:51,094 - wandb.wandb_agent - INFO - Running runs: ['1gybxucx']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220619_233950-1gybxucx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-93
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/1gybxucx
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93618
wandb:    train_loss 0.22277
wandb: training_time 4.01974
wandb:        val_f1 0.92033
wandb:      val_loss 0.29348
wandb: 
wandb: Synced noble-sweep-93: https://wandb.ai/jah377/sff_products/runs/1gybxucx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_233950-1gybxucx/logs
2022-06-20 00:14:12,584 - wandb.wandb_agent - INFO - Cleaning up finished run: 1gybxucx
2022-06-20 00:14:12,998 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:14:12,999 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-20 00:14:13,007 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 00:14:18,022 - wandb.wandb_agent - INFO - Running runs: ['b4xdz7ii']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_001418-b4xdz7ii
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-94
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/b4xdz7ii
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93451
wandb:    train_loss 0.22868
wandb: training_time 1.888
wandb:        val_f1 0.91494
wandb:      val_loss 0.30268
wandb: 
wandb: Synced autumn-sweep-94: https://wandb.ai/jah377/sff_products/runs/b4xdz7ii
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_001418-b4xdz7ii/logs
2022-06-20 00:34:44,834 - wandb.wandb_agent - INFO - Cleaning up finished run: b4xdz7ii
2022-06-20 00:34:45,322 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:34:45,323 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-20 00:34:45,331 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 00:34:50,346 - wandb.wandb_agent - INFO - Running runs: ['ombwk9nv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_003450-ombwk9nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-95
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/ombwk9nv
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93048
wandb:    train_loss 0.25469
wandb: training_time 2.99075
wandb:        val_f1 0.91199
wandb:      val_loss 0.33486
wandb: 
wandb: Synced trim-sweep-95: https://wandb.ai/jah377/sff_products/runs/ombwk9nv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_003450-ombwk9nv/logs
2022-06-20 01:03:48,114 - wandb.wandb_agent - INFO - Cleaning up finished run: ombwk9nv
2022-06-20 01:03:53,322 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:03:53,323 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-20 01:03:53,331 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 01:03:58,345 - wandb.wandb_agent - INFO - Running runs: ['dkjvpsao']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_010358-dkjvpsao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-96
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/dkjvpsao
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94519
wandb:    train_loss 0.1985
wandb: training_time 1.67842
wandb:        val_f1 0.91127
wandb:      val_loss 0.35158
wandb: 
wandb: Synced youthful-sweep-96: https://wandb.ai/jah377/sff_products/runs/dkjvpsao
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_010358-dkjvpsao/logs
2022-06-20 01:23:55,276 - wandb.wandb_agent - INFO - Cleaning up finished run: dkjvpsao
2022-06-20 01:23:58,682 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:23:58,682 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-20 01:23:58,689 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 01:24:03,702 - wandb.wandb_agent - INFO - Running runs: ['y9aabqzw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_012403-y9aabqzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-97
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/y9aabqzw
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9593
wandb:    train_loss 0.15775
wandb: training_time 2.23598
wandb:        val_f1 0.90878
wandb:      val_loss 0.34829
wandb: 
wandb: Synced copper-sweep-97: https://wandb.ai/jah377/sff_products/runs/y9aabqzw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_012403-y9aabqzw/logs
2022-06-20 01:48:23,604 - wandb.wandb_agent - INFO - Cleaning up finished run: y9aabqzw
2022-06-20 01:48:27,677 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:48:27,678 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-20 01:48:27,686 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 01:48:32,701 - wandb.wandb_agent - INFO - Running runs: ['86fupolt']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_014832-86fupolt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-98
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/86fupolt
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91665
wandb:    train_loss 0.29647
wandb: training_time 2.21866
wandb:        val_f1 0.90637
wandb:      val_loss 0.34201
wandb: 
wandb: Synced vital-sweep-98: https://wandb.ai/jah377/sff_products/runs/86fupolt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_014832-86fupolt/logs
2022-06-20 02:11:34,845 - wandb.wandb_agent - INFO - Cleaning up finished run: 86fupolt
2022-06-20 02:11:36,163 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:11:36,163 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-20 02:11:36,170 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 02:11:41,185 - wandb.wandb_agent - INFO - Running runs: ['bbalj10t']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_021141-bbalj10t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-99
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/bbalj10t
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8995
wandb:    train_loss 0.42487
wandb: training_time 1.98462
wandb:        val_f1 0.89141
wandb:      val_loss 0.47665
wandb: 
wandb: Synced copper-sweep-99: https://wandb.ai/jah377/sff_products/runs/bbalj10t
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_021141-bbalj10t/logs
2022-06-20 02:36:09,557 - wandb.wandb_agent - INFO - Cleaning up finished run: bbalj10t
2022-06-20 02:36:10,069 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:36:10,069 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: products
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-20 02:36:10,076 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=products --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 02:36:15,086 - wandb.wandb_agent - INFO - Running runs: ['t36fnf15']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_products/wandb/run-20220620_023615-t36fnf15
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-100
wandb:  View project at https://wandb.ai/jah377/sff_products
wandb:  View sweep at https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb:  View run at https://wandb.ai/jah377/sff_products/runs/t36fnf15
{'DATASET': 'products', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93725
wandb:    train_loss 0.21586
wandb: training_time 2.04048
wandb:        val_f1 0.91547
wandb:      val_loss 0.30875
wandb: 
wandb: Synced flowing-sweep-100: https://wandb.ai/jah377/sff_products/runs/t36fnf15
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_023615-t36fnf15/logs
2022-06-20 03:01:09,879 - wandb.wandb_agent - INFO - Cleaning up finished run: t36fnf15
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: idqhys85
Sweep URL: https://wandb.ai/jah377/sff_products/sweeps/idqhys85
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: - 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: \ 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: | 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: / 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: - 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: \ 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: | 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: / 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb: - 0.247 MB of 0.247 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced celestial-forest-1: https://wandb.ai/jah377/sff_products/runs/v9gkc1de
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220618_131654-v9gkc1de/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 37 hours 49 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
