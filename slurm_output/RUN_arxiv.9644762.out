Fri 24 Jun 2022 10:15:59 AM CEST
r30n2.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

**************************************************
================= SIGN ===========================
**************************************************
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='sign', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.001, INCEPTION_LAYERS=1, INCEPTION_UNITS=128, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=True, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 2.3214
Epoch 10:, Train 0.6202, Val 0.5898, Test 0.5297
Epoch 20:, Train 0.6379, Val 0.5961, Test 0.5359
Epoch 30:, Train 0.6493, Val 0.5986, Test 0.5342
Epoch 40:, Train 0.6587, Val 0.5989, Test 0.5367
Epoch 50:, Train 0.6665, Val 0.6035, Test 0.5426
Epoch 60:, Train 0.6708, Val 0.6044, Test 0.5450
Epoch 70:, Train 0.6729, Val 0.5999, Test 0.5292
Epoch 80:, Train 0.6746, Val 0.6013, Test 0.5305
Epoch 90:, Train 0.6816, Val 0.5975, Test 0.5277
Epoch 100:, Train 0.6830, Val 0.6027, Test 0.5336
Epoch 110:, Train 0.6831, Val 0.6016, Test 0.5404
Epoch 120:, Train 0.6860, Val 0.6020, Test 0.5308
Epoch 130:, Train 0.6846, Val 0.5995, Test 0.5342
Epoch 140:, Train 0.6868, Val 0.6064, Test 0.5461
Epoch 150:, Train 0.6918, Val 0.6037, Test 0.5360
Epoch 160:, Train 0.6922, Val 0.6016, Test 0.5393
Epoch 170:, Train 0.6907, Val 0.6082, Test 0.5411
Epoch 180:, Train 0.6928, Val 0.6054, Test 0.5453
Epoch 190:, Train 0.6950, Val 0.6075, Test 0.5414
Epoch 200:, Train 0.6957, Val 0.6059, Test 0.5407
Epoch 210:, Train 0.6988, Val 0.6081, Test 0.5443
Epoch 220:, Train 0.6961, Val 0.6087, Test 0.5443
Epoch 230:, Train 0.6994, Val 0.6063, Test 0.5400
Epoch 240:, Train 0.6987, Val 0.6031, Test 0.5423
Epoch 250:, Train 0.6972, Val 0.6064, Test 0.5412
Epoch 260:, Train 0.6957, Val 0.6095, Test 0.5468
Epoch 270:, Train 0.6956, Val 0.6039, Test 0.5408
Epoch 280:, Train 0.6994, Val 0.6087, Test 0.5427
Epoch 290:, Train 0.6982, Val 0.6047, Test 0.5284
Epoch 300:, Train 0.6968, Val 0.6101, Test 0.5533
BEST: Epoch 300, Train 0.6968, Val 0.6101, Test 0.5533

RUN #1: seed=4
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 1.3757
Epoch 10:, Train 0.6198, Val 0.5904, Test 0.5320
Epoch 20:, Train 0.6380, Val 0.6005, Test 0.5435
Epoch 30:, Train 0.6505, Val 0.5984, Test 0.5332
Epoch 40:, Train 0.6602, Val 0.6035, Test 0.5412
Epoch 50:, Train 0.6655, Val 0.5974, Test 0.5293
Epoch 60:, Train 0.6736, Val 0.6014, Test 0.5349
Epoch 70:, Train 0.6758, Val 0.6018, Test 0.5390
Epoch 80:, Train 0.6786, Val 0.6023, Test 0.5330
Epoch 90:, Train 0.6788, Val 0.6020, Test 0.5382
Epoch 100:, Train 0.6837, Val 0.6011, Test 0.5349
Epoch 110:, Train 0.6841, Val 0.6017, Test 0.5330
Epoch 120:, Train 0.6882, Val 0.6097, Test 0.5531
Epoch 130:, Train 0.6879, Val 0.6011, Test 0.5305
Epoch 140:, Train 0.6903, Val 0.6019, Test 0.5327
Epoch 150:, Train 0.6879, Val 0.6095, Test 0.5519
Epoch 160:, Train 0.6896, Val 0.6035, Test 0.5371
Epoch 170:, Train 0.6926, Val 0.6053, Test 0.5400
Epoch 180:, Train 0.6948, Val 0.6053, Test 0.5384
Epoch 190:, Train 0.6949, Val 0.6051, Test 0.5412
Epoch 200:, Train 0.6947, Val 0.6060, Test 0.5449
Epoch 210:, Train 0.6949, Val 0.6049, Test 0.5419
Epoch 220:, Train 0.6987, Val 0.6100, Test 0.5491
Epoch 230:, Train 0.6953, Val 0.6037, Test 0.5411
Epoch 240:, Train 0.6981, Val 0.6084, Test 0.5479
Epoch 250:, Train 0.6962, Val 0.6035, Test 0.5342
Epoch 260:, Train 0.6979, Val 0.6076, Test 0.5378
Epoch 270:, Train 0.6986, Val 0.6037, Test 0.5378
Epoch 280:, Train 0.6935, Val 0.6008, Test 0.5384
Epoch 290:, Train 0.6979, Val 0.6037, Test 0.5370
Epoch 300:, Train 0.6989, Val 0.6053, Test 0.5366
BEST: Epoch 220, Train 0.6987, Val 0.6100, Test 0.5491

RUN #2: seed=8
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 1.4700
Epoch 10:, Train 0.6214, Val 0.5904, Test 0.5292
Epoch 20:, Train 0.6358, Val 0.5971, Test 0.5423
Epoch 30:, Train 0.6464, Val 0.5984, Test 0.5373
Epoch 40:, Train 0.6595, Val 0.6055, Test 0.5459
Epoch 50:, Train 0.6640, Val 0.6004, Test 0.5435
Epoch 60:, Train 0.6704, Val 0.6011, Test 0.5352
Epoch 70:, Train 0.6730, Val 0.6039, Test 0.5431
Epoch 80:, Train 0.6775, Val 0.6035, Test 0.5346
Epoch 90:, Train 0.6818, Val 0.6078, Test 0.5451
Epoch 100:, Train 0.6835, Val 0.6047, Test 0.5439
Epoch 110:, Train 0.6853, Val 0.6059, Test 0.5399
Epoch 120:, Train 0.6890, Val 0.6051, Test 0.5434
Epoch 130:, Train 0.6896, Val 0.6058, Test 0.5375
Epoch 140:, Train 0.6873, Val 0.6040, Test 0.5357
Epoch 150:, Train 0.6916, Val 0.6016, Test 0.5352
Epoch 160:, Train 0.6944, Val 0.6054, Test 0.5343
Epoch 170:, Train 0.6914, Val 0.6023, Test 0.5353
Epoch 180:, Train 0.6939, Val 0.6042, Test 0.5437
Epoch 190:, Train 0.6942, Val 0.6076, Test 0.5478
Epoch 200:, Train 0.6904, Val 0.6007, Test 0.5253
Epoch 210:, Train 0.6976, Val 0.6036, Test 0.5385
Epoch 220:, Train 0.6990, Val 0.6043, Test 0.5385
Epoch 230:, Train 0.6982, Val 0.6049, Test 0.5362
Epoch 240:, Train 0.6969, Val 0.6033, Test 0.5365
Epoch 250:, Train 0.6975, Val 0.6066, Test 0.5438
Epoch 260:, Train 0.6991, Val 0.6087, Test 0.5413
Epoch 270:, Train 0.6996, Val 0.5996, Test 0.5332
Epoch 280:, Train 0.6981, Val 0.5990, Test 0.5317
Epoch 290:, Train 0.6979, Val 0.6062, Test 0.5454
Epoch 300:, Train 0.6984, Val 0.6038, Test 0.5349
BEST: Epoch 260, Train 0.6991, Val 0.6087, Test 0.5413

RUN #3: seed=42
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8740
Epoch 10:, Train 0.6217, Val 0.5941, Test 0.5353
Epoch 20:, Train 0.6368, Val 0.5923, Test 0.5246
Epoch 30:, Train 0.6505, Val 0.6022, Test 0.5400
Epoch 40:, Train 0.6575, Val 0.5988, Test 0.5372
Epoch 50:, Train 0.6620, Val 0.6002, Test 0.5392
Epoch 60:, Train 0.6689, Val 0.6040, Test 0.5417
Epoch 70:, Train 0.6743, Val 0.6012, Test 0.5360
Epoch 80:, Train 0.6748, Val 0.5972, Test 0.5253
Epoch 90:, Train 0.6811, Val 0.6053, Test 0.5438
Epoch 100:, Train 0.6841, Val 0.6042, Test 0.5391
Epoch 110:, Train 0.6882, Val 0.6090, Test 0.5426
Epoch 120:, Train 0.6881, Val 0.6089, Test 0.5467
Epoch 130:, Train 0.6884, Val 0.6066, Test 0.5418
Epoch 140:, Train 0.6901, Val 0.6061, Test 0.5447
Epoch 150:, Train 0.6903, Val 0.6058, Test 0.5450
Epoch 160:, Train 0.6918, Val 0.6030, Test 0.5388
Epoch 170:, Train 0.6934, Val 0.6090, Test 0.5487
Epoch 180:, Train 0.6942, Val 0.6041, Test 0.5362
Epoch 190:, Train 0.6926, Val 0.6043, Test 0.5369
Epoch 200:, Train 0.6950, Val 0.6073, Test 0.5475
Epoch 210:, Train 0.6923, Val 0.6015, Test 0.5330
Epoch 220:, Train 0.6964, Val 0.6071, Test 0.5338
Epoch 230:, Train 0.6976, Val 0.6011, Test 0.5326
Epoch 240:, Train 0.6983, Val 0.6030, Test 0.5378
Epoch 250:, Train 0.6979, Val 0.6089, Test 0.5461
Epoch 260:, Train 0.7022, Val 0.6015, Test 0.5314
Epoch 270:, Train 0.6972, Val 0.6110, Test 0.5492
Epoch 280:, Train 0.6980, Val 0.6099, Test 0.5444
Epoch 290:, Train 0.6978, Val 0.6051, Test 0.5382
Epoch 300:, Train 0.7003, Val 0.6035, Test 0.5357
BEST: Epoch 270, Train 0.6972, Val 0.6110, Test 0.5492

RUN #4: seed=64
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8777
Epoch 10:, Train 0.6210, Val 0.5931, Test 0.5418
Epoch 20:, Train 0.6372, Val 0.5905, Test 0.5186
Epoch 30:, Train 0.6473, Val 0.5987, Test 0.5493
Epoch 40:, Train 0.6565, Val 0.5994, Test 0.5332
Epoch 50:, Train 0.6637, Val 0.5957, Test 0.5241
Epoch 60:, Train 0.6686, Val 0.5962, Test 0.5287
Epoch 70:, Train 0.6745, Val 0.5984, Test 0.5362
Epoch 80:, Train 0.6800, Val 0.6050, Test 0.5460
Epoch 90:, Train 0.6826, Val 0.6015, Test 0.5369
Epoch 100:, Train 0.6791, Val 0.6002, Test 0.5320
Epoch 110:, Train 0.6868, Val 0.6080, Test 0.5461
Epoch 120:, Train 0.6866, Val 0.6052, Test 0.5441
Epoch 130:, Train 0.6867, Val 0.6045, Test 0.5424
Epoch 140:, Train 0.6863, Val 0.6042, Test 0.5331
Epoch 150:, Train 0.6926, Val 0.6016, Test 0.5344
Epoch 160:, Train 0.6918, Val 0.6066, Test 0.5440
Epoch 170:, Train 0.6901, Val 0.6035, Test 0.5407
Epoch 180:, Train 0.6938, Val 0.6058, Test 0.5363
Epoch 190:, Train 0.6933, Val 0.6016, Test 0.5364
Epoch 200:, Train 0.6954, Val 0.6071, Test 0.5395
Epoch 210:, Train 0.6955, Val 0.6062, Test 0.5364
Epoch 220:, Train 0.6965, Val 0.6038, Test 0.5365
Epoch 230:, Train 0.6953, Val 0.6027, Test 0.5322
Epoch 240:, Train 0.6990, Val 0.6082, Test 0.5495
Epoch 250:, Train 0.6958, Val 0.6041, Test 0.5404
Epoch 260:, Train 0.6993, Val 0.6062, Test 0.5419
Epoch 270:, Train 0.6949, Val 0.6021, Test 0.5352
Epoch 280:, Train 0.6983, Val 0.6050, Test 0.5443
Epoch 290:, Train 0.7010, Val 0.6062, Test 0.5412
Epoch 300:, Train 0.7003, Val 0.6041, Test 0.5354
BEST: Epoch 240, Train 0.6990, Val 0.6082, Test 0.5495

RUN #5: seed=128
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8761
Epoch 10:, Train 0.6155, Val 0.5845, Test 0.5268
Epoch 20:, Train 0.6370, Val 0.5888, Test 0.5223
Epoch 30:, Train 0.6507, Val 0.5944, Test 0.5262
Epoch 40:, Train 0.6599, Val 0.5961, Test 0.5337
Epoch 50:, Train 0.6675, Val 0.6041, Test 0.5440
Epoch 60:, Train 0.6723, Val 0.6041, Test 0.5416
Epoch 70:, Train 0.6755, Val 0.5957, Test 0.5250
Epoch 80:, Train 0.6769, Val 0.6037, Test 0.5447
Epoch 90:, Train 0.6835, Val 0.6030, Test 0.5438
Epoch 100:, Train 0.6844, Val 0.6068, Test 0.5445
Epoch 110:, Train 0.6866, Val 0.6035, Test 0.5330
Epoch 120:, Train 0.6811, Val 0.6052, Test 0.5363
Epoch 130:, Train 0.6919, Val 0.6030, Test 0.5341
Epoch 140:, Train 0.6895, Val 0.6027, Test 0.5445
Epoch 150:, Train 0.6889, Val 0.6001, Test 0.5379
Epoch 160:, Train 0.6908, Val 0.6070, Test 0.5394
Epoch 170:, Train 0.6913, Val 0.6015, Test 0.5380
Epoch 180:, Train 0.6935, Val 0.6032, Test 0.5354
Epoch 190:, Train 0.6938, Val 0.6071, Test 0.5423
Epoch 200:, Train 0.6944, Val 0.6071, Test 0.5457
Epoch 210:, Train 0.6952, Val 0.6007, Test 0.5329
Epoch 220:, Train 0.6954, Val 0.6048, Test 0.5406
Epoch 230:, Train 0.6961, Val 0.6065, Test 0.5370
Epoch 240:, Train 0.6944, Val 0.6060, Test 0.5376
Epoch 250:, Train 0.6984, Val 0.6101, Test 0.5470
Epoch 260:, Train 0.6965, Val 0.5974, Test 0.5272
Epoch 270:, Train 0.6964, Val 0.6056, Test 0.5392
Epoch 280:, Train 0.6959, Val 0.5976, Test 0.5287
Epoch 290:, Train 0.6982, Val 0.6036, Test 0.5354
Epoch 300:, Train 0.7004, Val 0.6001, Test 0.5307
BEST: Epoch 250, Train 0.6984, Val 0.6101, Test 0.5470

RUN #6: seed=256
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8790
Epoch 10:, Train 0.6195, Val 0.5845, Test 0.5191
Epoch 20:, Train 0.6368, Val 0.5942, Test 0.5319
Epoch 30:, Train 0.6512, Val 0.5966, Test 0.5325
Epoch 40:, Train 0.6600, Val 0.6041, Test 0.5418
Epoch 50:, Train 0.6652, Val 0.5974, Test 0.5259
Epoch 60:, Train 0.6701, Val 0.6009, Test 0.5385
Epoch 70:, Train 0.6740, Val 0.6033, Test 0.5373
Epoch 80:, Train 0.6756, Val 0.6011, Test 0.5324
Epoch 90:, Train 0.6822, Val 0.6024, Test 0.5358
Epoch 100:, Train 0.6829, Val 0.6037, Test 0.5403
Epoch 110:, Train 0.6868, Val 0.6066, Test 0.5414
Epoch 120:, Train 0.6848, Val 0.6024, Test 0.5302
Epoch 130:, Train 0.6875, Val 0.6058, Test 0.5432
Epoch 140:, Train 0.6909, Val 0.6032, Test 0.5421
Epoch 150:, Train 0.6897, Val 0.6058, Test 0.5390
Epoch 160:, Train 0.6917, Val 0.6029, Test 0.5344
Epoch 170:, Train 0.6940, Val 0.6060, Test 0.5411
Epoch 180:, Train 0.6925, Val 0.6070, Test 0.5472
Epoch 190:, Train 0.6962, Val 0.6035, Test 0.5329
Epoch 200:, Train 0.6951, Val 0.6074, Test 0.5411
Epoch 210:, Train 0.6970, Val 0.6002, Test 0.5383
Epoch 220:, Train 0.6965, Val 0.6067, Test 0.5409
Epoch 230:, Train 0.6973, Val 0.6053, Test 0.5425
Epoch 240:, Train 0.6988, Val 0.6031, Test 0.5278
Epoch 250:, Train 0.6980, Val 0.6068, Test 0.5423
Epoch 260:, Train 0.6991, Val 0.6040, Test 0.5378
Epoch 270:, Train 0.6980, Val 0.6055, Test 0.5455
Epoch 280:, Train 0.6970, Val 0.6072, Test 0.5414
Epoch 290:, Train 0.6976, Val 0.6028, Test 0.5361
Epoch 300:, Train 0.6988, Val 0.6043, Test 0.5419
BEST: Epoch 200, Train 0.6951, Val 0.6074, Test 0.5411

RUN #7: seed=512
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8896
Epoch 10:, Train 0.6198, Val 0.5882, Test 0.5317
Epoch 20:, Train 0.6382, Val 0.5910, Test 0.5215
Epoch 30:, Train 0.6449, Val 0.5976, Test 0.5339
Epoch 40:, Train 0.6596, Val 0.6051, Test 0.5400
Epoch 50:, Train 0.6651, Val 0.6044, Test 0.5409
Epoch 60:, Train 0.6708, Val 0.6035, Test 0.5419
Epoch 70:, Train 0.6749, Val 0.6028, Test 0.5332
Epoch 80:, Train 0.6756, Val 0.5938, Test 0.5334
Epoch 90:, Train 0.6806, Val 0.5965, Test 0.5374
Epoch 100:, Train 0.6837, Val 0.6056, Test 0.5419
Epoch 110:, Train 0.6825, Val 0.6097, Test 0.5444
Epoch 120:, Train 0.6854, Val 0.6077, Test 0.5440
Epoch 130:, Train 0.6882, Val 0.6039, Test 0.5355
Epoch 140:, Train 0.6904, Val 0.5987, Test 0.5340
Epoch 150:, Train 0.6899, Val 0.6069, Test 0.5387
Epoch 160:, Train 0.6940, Val 0.6080, Test 0.5464
Epoch 170:, Train 0.6927, Val 0.6040, Test 0.5398
Epoch 180:, Train 0.6950, Val 0.6035, Test 0.5377
Epoch 190:, Train 0.6949, Val 0.6047, Test 0.5405
Epoch 200:, Train 0.6938, Val 0.6058, Test 0.5388
Epoch 210:, Train 0.6954, Val 0.6056, Test 0.5439
Epoch 220:, Train 0.6968, Val 0.6073, Test 0.5494
Epoch 230:, Train 0.6984, Val 0.6087, Test 0.5431
Epoch 240:, Train 0.6994, Val 0.6021, Test 0.5354
Epoch 250:, Train 0.6984, Val 0.6093, Test 0.5455
Epoch 260:, Train 0.6961, Val 0.6069, Test 0.5460
Epoch 270:, Train 0.6988, Val 0.6074, Test 0.5462
Epoch 280:, Train 0.6963, Val 0.6043, Test 0.5391
Epoch 290:, Train 0.7015, Val 0.6029, Test 0.5335
Epoch 300:, Train 0.7011, Val 0.6088, Test 0.5482
BEST: Epoch 110, Train 0.6825, Val 0.6097, Test 0.5444

RUN #8: seed=1024
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8924
Epoch 10:, Train 0.6203, Val 0.5941, Test 0.5369
Epoch 20:, Train 0.6372, Val 0.5896, Test 0.5216
Epoch 30:, Train 0.6509, Val 0.6058, Test 0.5480
Epoch 40:, Train 0.6594, Val 0.6000, Test 0.5301
Epoch 50:, Train 0.6660, Val 0.6070, Test 0.5443
Epoch 60:, Train 0.6684, Val 0.5965, Test 0.5257
Epoch 70:, Train 0.6762, Val 0.6080, Test 0.5434
Epoch 80:, Train 0.6782, Val 0.6016, Test 0.5317
Epoch 90:, Train 0.6808, Val 0.6029, Test 0.5345
Epoch 100:, Train 0.6834, Val 0.6058, Test 0.5416
Epoch 110:, Train 0.6832, Val 0.6020, Test 0.5349
Epoch 120:, Train 0.6843, Val 0.6000, Test 0.5287
Epoch 130:, Train 0.6892, Val 0.6054, Test 0.5383
Epoch 140:, Train 0.6904, Val 0.6031, Test 0.5374
Epoch 150:, Train 0.6917, Val 0.6028, Test 0.5301
Epoch 160:, Train 0.6950, Val 0.6067, Test 0.5413
Epoch 170:, Train 0.6930, Val 0.6059, Test 0.5385
Epoch 180:, Train 0.6936, Val 0.6067, Test 0.5405
Epoch 190:, Train 0.6975, Val 0.6044, Test 0.5430
Epoch 200:, Train 0.6964, Val 0.6082, Test 0.5502
Epoch 210:, Train 0.6980, Val 0.6093, Test 0.5475
Epoch 220:, Train 0.6960, Val 0.6063, Test 0.5335
Epoch 230:, Train 0.6971, Val 0.6071, Test 0.5374
Epoch 240:, Train 0.6960, Val 0.6070, Test 0.5450
Epoch 250:, Train 0.6963, Val 0.6068, Test 0.5457
Epoch 260:, Train 0.6999, Val 0.6041, Test 0.5344
Epoch 270:, Train 0.6996, Val 0.6052, Test 0.5341
Epoch 280:, Train 0.7005, Val 0.6057, Test 0.5346
Epoch 290:, Train 0.6987, Val 0.6092, Test 0.5425
Epoch 300:, Train 0.7010, Val 0.6053, Test 0.5403
BEST: Epoch 210, Train 0.6980, Val 0.6093, Test 0.5475

RUN #9: seed=2048
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Total Transformation Time: 0.8790
Epoch 10:, Train 0.6219, Val 0.5905, Test 0.5253
Epoch 20:, Train 0.6390, Val 0.5982, Test 0.5412
Epoch 30:, Train 0.6503, Val 0.5969, Test 0.5397
Epoch 40:, Train 0.6604, Val 0.5934, Test 0.5185
Epoch 50:, Train 0.6668, Val 0.5997, Test 0.5400
Epoch 60:, Train 0.6714, Val 0.6045, Test 0.5429
Epoch 70:, Train 0.6761, Val 0.6056, Test 0.5408
Epoch 80:, Train 0.6787, Val 0.6027, Test 0.5316
Epoch 90:, Train 0.6775, Val 0.6014, Test 0.5324
Epoch 100:, Train 0.6850, Val 0.6011, Test 0.5350
Epoch 110:, Train 0.6853, Val 0.6061, Test 0.5467
Epoch 120:, Train 0.6868, Val 0.6032, Test 0.5463
Epoch 130:, Train 0.6909, Val 0.6067, Test 0.5392
Epoch 140:, Train 0.6897, Val 0.6010, Test 0.5391
Epoch 150:, Train 0.6907, Val 0.6026, Test 0.5393
Epoch 160:, Train 0.6948, Val 0.6087, Test 0.5484
Epoch 170:, Train 0.6938, Val 0.6057, Test 0.5373
Epoch 180:, Train 0.6943, Val 0.6029, Test 0.5408
Epoch 190:, Train 0.6961, Val 0.6028, Test 0.5412
Epoch 200:, Train 0.6900, Val 0.6039, Test 0.5386
Epoch 210:, Train 0.6989, Val 0.6035, Test 0.5413
Epoch 220:, Train 0.6967, Val 0.6017, Test 0.5359
Epoch 230:, Train 0.6988, Val 0.6045, Test 0.5420
Epoch 240:, Train 0.6982, Val 0.6083, Test 0.5439
Epoch 250:, Train 0.6992, Val 0.6032, Test 0.5359
Epoch 260:, Train 0.6981, Val 0.6026, Test 0.5405
Epoch 270:, Train 0.6999, Val 0.6055, Test 0.5402
Epoch 280:, Train 0.6976, Val 0.6073, Test 0.5431
Epoch 290:, Train 0.7002, Val 0.6060, Test 0.5450
Epoch 300:, Train 0.7014, Val 0.6120, Test 0.5471
BEST: Epoch 300, Train 0.7014, Val 0.6120, Test 0.5471




==================================================
Model Parameters: 531885

Avg. Preaggregation Time (s): 1.1335 +/- 0.4505
Avg. Training Time (epoch) (s): 1.2837 +/- 0.4857
Avg. Inference Time (s): 0.0754 +/- 0.0054

Avg. Training Acc: 0.6966 +/- 0.0050
Avg. Validation Acc: 0.6096 +/- 0.0013
Avg. Test Acc: 0.5469 +/- 0.0036

**************************************************

**************************************************
================= SIGN+CS ========================
**************************************************
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='cosine', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=1e-07, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.0, NODE_DROPOUT=0.6, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Normalization Time: 0.3326
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3682
Epoch 10:, Train 0.6329, Val 0.6212, Test 0.5730
Epoch 20:, Train 0.6679, Val 0.6297, Test 0.5856
Epoch 30:, Train 0.6955, Val 0.6363, Test 0.5820
Epoch 40:, Train 0.7177, Val 0.6398, Test 0.5885
Epoch 50:, Train 0.7370, Val 0.6428, Test 0.5923
Epoch 60:, Train 0.7549, Val 0.6435, Test 0.5945
Epoch 70:, Train 0.7700, Val 0.6453, Test 0.5947
Epoch 80:, Train 0.7854, Val 0.6463, Test 0.5951
Epoch 90:, Train 0.7981, Val 0.6446, Test 0.5903
Epoch 100:, Train 0.8090, Val 0.6467, Test 0.5977
Epoch 110:, Train 0.8197, Val 0.6431, Test 0.5908
Epoch 120:, Train 0.8331, Val 0.6428, Test 0.5861
Epoch 130:, Train 0.8420, Val 0.6448, Test 0.5890
Epoch 140:, Train 0.8530, Val 0.6429, Test 0.5846
Epoch 150:, Train 0.8594, Val 0.6420, Test 0.5876
Epoch 160:, Train 0.8664, Val 0.6434, Test 0.5920
Epoch 170:, Train 0.8756, Val 0.6447, Test 0.5910
Epoch 180:, Train 0.8821, Val 0.6432, Test 0.5885
Epoch 190:, Train 0.8867, Val 0.6451, Test 0.5905
Epoch 200:, Train 0.8929, Val 0.6402, Test 0.5834
Epoch 210:, Train 0.8990, Val 0.6407, Test 0.5836
Epoch 220:, Train 0.9033, Val 0.6425, Test 0.5851
Epoch 230:, Train 0.9052, Val 0.6414, Test 0.5837
Epoch 240:, Train 0.9116, Val 0.6417, Test 0.5829
Epoch 250:, Train 0.9143, Val 0.6405, Test 0.5797
Epoch 260:, Train 0.9171, Val 0.6440, Test 0.5872
Epoch 270:, Train 0.9221, Val 0.6422, Test 0.5841
Epoch 280:, Train 0.9250, Val 0.6416, Test 0.5852
Epoch 290:, Train 0.9279, Val 0.6402, Test 0.5825
Epoch 300:, Train 0.9308, Val 0.6386, Test 0.5806
BEST: Epoch 100, Train 0.8090, Val 0.6467, Test 0.5977

RUN #1: seed=4
Normalization Time: 0.3198
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3303
Epoch 10:, Train 0.6311, Val 0.6176, Test 0.5724
Epoch 20:, Train 0.6699, Val 0.6312, Test 0.5783
Epoch 30:, Train 0.6956, Val 0.6402, Test 0.5925
Epoch 40:, Train 0.7182, Val 0.6372, Test 0.5867
Epoch 50:, Train 0.7367, Val 0.6458, Test 0.5972
Epoch 60:, Train 0.7544, Val 0.6436, Test 0.5915
Epoch 70:, Train 0.7702, Val 0.6452, Test 0.5893
Epoch 80:, Train 0.7859, Val 0.6446, Test 0.5929
Epoch 90:, Train 0.7971, Val 0.6436, Test 0.5922
Epoch 100:, Train 0.8093, Val 0.6450, Test 0.5943
Epoch 110:, Train 0.8204, Val 0.6467, Test 0.5946
Epoch 120:, Train 0.8329, Val 0.6445, Test 0.5922
Epoch 130:, Train 0.8426, Val 0.6430, Test 0.5896
Epoch 140:, Train 0.8536, Val 0.6455, Test 0.5939
Epoch 150:, Train 0.8584, Val 0.6453, Test 0.5930
Epoch 160:, Train 0.8673, Val 0.6431, Test 0.5901
Epoch 170:, Train 0.8742, Val 0.6432, Test 0.5918
Epoch 180:, Train 0.8819, Val 0.6442, Test 0.5921
Epoch 190:, Train 0.8857, Val 0.6416, Test 0.5841
Epoch 200:, Train 0.8926, Val 0.6421, Test 0.5868
Epoch 210:, Train 0.8964, Val 0.6431, Test 0.5886
Epoch 220:, Train 0.9010, Val 0.6437, Test 0.5840
Epoch 230:, Train 0.9053, Val 0.6449, Test 0.5900
Epoch 240:, Train 0.9087, Val 0.6429, Test 0.5873
Epoch 250:, Train 0.9160, Val 0.6427, Test 0.5860
Epoch 260:, Train 0.9164, Val 0.6386, Test 0.5821
Epoch 270:, Train 0.9211, Val 0.6414, Test 0.5857
Epoch 280:, Train 0.9245, Val 0.6420, Test 0.5835
Epoch 290:, Train 0.9278, Val 0.6425, Test 0.5834
Epoch 300:, Train 0.9298, Val 0.6402, Test 0.5865
BEST: Epoch 110, Train 0.8204, Val 0.6467, Test 0.5946

RUN #2: seed=8
Normalization Time: 0.3179
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3156
Epoch 10:, Train 0.6350, Val 0.6220, Test 0.5769
Epoch 20:, Train 0.6682, Val 0.6297, Test 0.5765
Epoch 30:, Train 0.6960, Val 0.6405, Test 0.5937
Epoch 40:, Train 0.7171, Val 0.6399, Test 0.5966
Epoch 50:, Train 0.7383, Val 0.6435, Test 0.5957
Epoch 60:, Train 0.7567, Val 0.6434, Test 0.5928
Epoch 70:, Train 0.7707, Val 0.6434, Test 0.5962
Epoch 80:, Train 0.7822, Val 0.6440, Test 0.5941
Epoch 90:, Train 0.7992, Val 0.6418, Test 0.5912
Epoch 100:, Train 0.8130, Val 0.6443, Test 0.5951
Epoch 110:, Train 0.8235, Val 0.6382, Test 0.5873
Epoch 120:, Train 0.8349, Val 0.6427, Test 0.5933
Epoch 130:, Train 0.8412, Val 0.6408, Test 0.5896
Epoch 140:, Train 0.8529, Val 0.6427, Test 0.5924
Epoch 150:, Train 0.8605, Val 0.6404, Test 0.5879
Epoch 160:, Train 0.8668, Val 0.6423, Test 0.5825
Epoch 170:, Train 0.8753, Val 0.6404, Test 0.5853
Epoch 180:, Train 0.8833, Val 0.6433, Test 0.5896
Epoch 190:, Train 0.8853, Val 0.6435, Test 0.5921
Epoch 200:, Train 0.8921, Val 0.6432, Test 0.5903
Epoch 210:, Train 0.8978, Val 0.6425, Test 0.5840
Epoch 220:, Train 0.9022, Val 0.6425, Test 0.5861
Epoch 230:, Train 0.9070, Val 0.6397, Test 0.5865
Epoch 240:, Train 0.9114, Val 0.6385, Test 0.5825
Epoch 250:, Train 0.9150, Val 0.6419, Test 0.5846
Epoch 260:, Train 0.9190, Val 0.6406, Test 0.5833
Epoch 270:, Train 0.9228, Val 0.6404, Test 0.5871
Epoch 280:, Train 0.9257, Val 0.6435, Test 0.5910
Epoch 290:, Train 0.9267, Val 0.6415, Test 0.5872
Epoch 300:, Train 0.9299, Val 0.6398, Test 0.5846
BEST: Epoch 100, Train 0.8130, Val 0.6443, Test 0.5951

RUN #3: seed=42
Normalization Time: 0.3215
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3425
Epoch 10:, Train 0.6319, Val 0.6224, Test 0.5763
Epoch 20:, Train 0.6709, Val 0.6372, Test 0.5904
Epoch 30:, Train 0.6959, Val 0.6376, Test 0.5844
Epoch 40:, Train 0.7185, Val 0.6433, Test 0.5953
Epoch 50:, Train 0.7375, Val 0.6408, Test 0.5875
Epoch 60:, Train 0.7540, Val 0.6410, Test 0.5883
Epoch 70:, Train 0.7693, Val 0.6446, Test 0.5956
Epoch 80:, Train 0.7833, Val 0.6448, Test 0.5955
Epoch 90:, Train 0.7985, Val 0.6471, Test 0.5929
Epoch 100:, Train 0.8100, Val 0.6453, Test 0.5939
Epoch 110:, Train 0.8222, Val 0.6429, Test 0.5914
Epoch 120:, Train 0.8311, Val 0.6458, Test 0.5911
Epoch 130:, Train 0.8441, Val 0.6444, Test 0.5878
Epoch 140:, Train 0.8528, Val 0.6453, Test 0.5906
Epoch 150:, Train 0.8589, Val 0.6438, Test 0.5930
Epoch 160:, Train 0.8671, Val 0.6413, Test 0.5871
Epoch 170:, Train 0.8739, Val 0.6447, Test 0.5915
Epoch 180:, Train 0.8809, Val 0.6419, Test 0.5872
Epoch 190:, Train 0.8868, Val 0.6458, Test 0.5897
Epoch 200:, Train 0.8911, Val 0.6428, Test 0.5862
Epoch 210:, Train 0.8963, Val 0.6460, Test 0.5899
Epoch 220:, Train 0.9045, Val 0.6412, Test 0.5884
Epoch 230:, Train 0.9052, Val 0.6407, Test 0.5829
Epoch 240:, Train 0.9118, Val 0.6401, Test 0.5863
Epoch 250:, Train 0.9178, Val 0.6420, Test 0.5869
Epoch 260:, Train 0.9200, Val 0.6423, Test 0.5837
Epoch 270:, Train 0.9231, Val 0.6384, Test 0.5807
Epoch 280:, Train 0.9252, Val 0.6431, Test 0.5854
Epoch 290:, Train 0.9294, Val 0.6387, Test 0.5856
Epoch 300:, Train 0.9305, Val 0.6445, Test 0.5884
BEST: Epoch 90, Train 0.7985, Val 0.6471, Test 0.5929

RUN #4: seed=64
Normalization Time: 0.3126
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.2954
Epoch 10:, Train 0.6325, Val 0.6256, Test 0.5821
Epoch 20:, Train 0.6702, Val 0.6321, Test 0.5822
Epoch 30:, Train 0.6951, Val 0.6417, Test 0.5977
Epoch 40:, Train 0.7180, Val 0.6400, Test 0.5912
Epoch 50:, Train 0.7373, Val 0.6450, Test 0.5943
Epoch 60:, Train 0.7552, Val 0.6417, Test 0.5875
Epoch 70:, Train 0.7709, Val 0.6440, Test 0.5930
Epoch 80:, Train 0.7868, Val 0.6460, Test 0.5942
Epoch 90:, Train 0.7978, Val 0.6445, Test 0.5902
Epoch 100:, Train 0.8126, Val 0.6446, Test 0.5931
Epoch 110:, Train 0.8224, Val 0.6484, Test 0.5956
Epoch 120:, Train 0.8329, Val 0.6487, Test 0.5954
Epoch 130:, Train 0.8457, Val 0.6438, Test 0.5901
Epoch 140:, Train 0.8520, Val 0.6432, Test 0.5868
Epoch 150:, Train 0.8583, Val 0.6433, Test 0.5927
Epoch 160:, Train 0.8697, Val 0.6453, Test 0.5864
Epoch 170:, Train 0.8752, Val 0.6417, Test 0.5845
Epoch 180:, Train 0.8833, Val 0.6424, Test 0.5864
Epoch 190:, Train 0.8894, Val 0.6429, Test 0.5812
Epoch 200:, Train 0.8944, Val 0.6435, Test 0.5863
Epoch 210:, Train 0.8995, Val 0.6440, Test 0.5851
Epoch 220:, Train 0.9044, Val 0.6461, Test 0.5880
Epoch 230:, Train 0.9078, Val 0.6434, Test 0.5860
Epoch 240:, Train 0.9144, Val 0.6391, Test 0.5780
Epoch 250:, Train 0.9152, Val 0.6444, Test 0.5821
Epoch 260:, Train 0.9206, Val 0.6430, Test 0.5871
Epoch 270:, Train 0.9230, Val 0.6452, Test 0.5825
Epoch 280:, Train 0.9264, Val 0.6420, Test 0.5838
Epoch 290:, Train 0.9301, Val 0.6452, Test 0.5868
Epoch 300:, Train 0.9334, Val 0.6399, Test 0.5820
BEST: Epoch 120, Train 0.8329, Val 0.6487, Test 0.5954

RUN #5: seed=128
Normalization Time: 0.3194
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3281
Epoch 10:, Train 0.6323, Val 0.6208, Test 0.5723
Epoch 20:, Train 0.6706, Val 0.6351, Test 0.5871
Epoch 30:, Train 0.6963, Val 0.6385, Test 0.5905
Epoch 40:, Train 0.7177, Val 0.6397, Test 0.5876
Epoch 50:, Train 0.7371, Val 0.6412, Test 0.5914
Epoch 60:, Train 0.7518, Val 0.6426, Test 0.5917
Epoch 70:, Train 0.7702, Val 0.6451, Test 0.5980
Epoch 80:, Train 0.7868, Val 0.6465, Test 0.5960
Epoch 90:, Train 0.7976, Val 0.6467, Test 0.6027
Epoch 100:, Train 0.8094, Val 0.6472, Test 0.5965
Epoch 110:, Train 0.8217, Val 0.6433, Test 0.5922
Epoch 120:, Train 0.8342, Val 0.6432, Test 0.5883
Epoch 130:, Train 0.8430, Val 0.6438, Test 0.5924
Epoch 140:, Train 0.8535, Val 0.6451, Test 0.5936
Epoch 150:, Train 0.8603, Val 0.6401, Test 0.5847
Epoch 160:, Train 0.8670, Val 0.6437, Test 0.5903
Epoch 170:, Train 0.8755, Val 0.6439, Test 0.5878
Epoch 180:, Train 0.8819, Val 0.6409, Test 0.5877
Epoch 190:, Train 0.8876, Val 0.6426, Test 0.5888
Epoch 200:, Train 0.8930, Val 0.6422, Test 0.5868
Epoch 210:, Train 0.8981, Val 0.6396, Test 0.5832
Epoch 220:, Train 0.9019, Val 0.6436, Test 0.5852
Epoch 230:, Train 0.9067, Val 0.6421, Test 0.5887
Epoch 240:, Train 0.9118, Val 0.6443, Test 0.5881
Epoch 250:, Train 0.9143, Val 0.6406, Test 0.5818
Epoch 260:, Train 0.9154, Val 0.6420, Test 0.5834
Epoch 270:, Train 0.9219, Val 0.6408, Test 0.5834
Epoch 280:, Train 0.9239, Val 0.6413, Test 0.5860
Epoch 290:, Train 0.9284, Val 0.6407, Test 0.5841
Epoch 300:, Train 0.9307, Val 0.6406, Test 0.5842
BEST: Epoch 100, Train 0.8094, Val 0.6472, Test 0.5965

RUN #6: seed=256
Normalization Time: 0.3152
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3075
Epoch 10:, Train 0.6324, Val 0.6195, Test 0.5731
Epoch 20:, Train 0.6689, Val 0.6341, Test 0.5855
Epoch 30:, Train 0.6967, Val 0.6389, Test 0.5947
Epoch 40:, Train 0.7170, Val 0.6403, Test 0.5934
Epoch 50:, Train 0.7370, Val 0.6415, Test 0.5892
Epoch 60:, Train 0.7556, Val 0.6454, Test 0.5926
Epoch 70:, Train 0.7703, Val 0.6449, Test 0.5912
Epoch 80:, Train 0.7840, Val 0.6451, Test 0.5935
Epoch 90:, Train 0.7986, Val 0.6438, Test 0.5955
Epoch 100:, Train 0.8112, Val 0.6455, Test 0.5945
Epoch 110:, Train 0.8219, Val 0.6454, Test 0.5987
Epoch 120:, Train 0.8316, Val 0.6463, Test 0.5954
Epoch 130:, Train 0.8429, Val 0.6422, Test 0.5914
Epoch 140:, Train 0.8505, Val 0.6457, Test 0.5961
Epoch 150:, Train 0.8591, Val 0.6445, Test 0.5921
Epoch 160:, Train 0.8670, Val 0.6437, Test 0.5909
Epoch 170:, Train 0.8742, Val 0.6437, Test 0.5892
Epoch 180:, Train 0.8809, Val 0.6399, Test 0.5896
Epoch 190:, Train 0.8864, Val 0.6395, Test 0.5864
Epoch 200:, Train 0.8910, Val 0.6428, Test 0.5880
Epoch 210:, Train 0.8972, Val 0.6422, Test 0.5893
Epoch 220:, Train 0.9025, Val 0.6433, Test 0.5911
Epoch 230:, Train 0.9057, Val 0.6406, Test 0.5846
Epoch 240:, Train 0.9124, Val 0.6388, Test 0.5801
Epoch 250:, Train 0.9132, Val 0.6378, Test 0.5817
Epoch 260:, Train 0.9169, Val 0.6414, Test 0.5867
Epoch 270:, Train 0.9219, Val 0.6413, Test 0.5880
Epoch 280:, Train 0.9243, Val 0.6407, Test 0.5874
Epoch 290:, Train 0.9270, Val 0.6403, Test 0.5873
Epoch 300:, Train 0.9299, Val 0.6376, Test 0.5838
BEST: Epoch 120, Train 0.8316, Val 0.6463, Test 0.5954

RUN #7: seed=512
Normalization Time: 0.3178
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3329
Epoch 10:, Train 0.6310, Val 0.6187, Test 0.5692
Epoch 20:, Train 0.6704, Val 0.6328, Test 0.5799
Epoch 30:, Train 0.6956, Val 0.6430, Test 0.5940
Epoch 40:, Train 0.7172, Val 0.6444, Test 0.5964
Epoch 50:, Train 0.7377, Val 0.6446, Test 0.5986
Epoch 60:, Train 0.7531, Val 0.6409, Test 0.5869
Epoch 70:, Train 0.7693, Val 0.6469, Test 0.5968
Epoch 80:, Train 0.7850, Val 0.6400, Test 0.5896
Epoch 90:, Train 0.7989, Val 0.6458, Test 0.5911
Epoch 100:, Train 0.8100, Val 0.6438, Test 0.5915
Epoch 110:, Train 0.8233, Val 0.6444, Test 0.5929
Epoch 120:, Train 0.8326, Val 0.6442, Test 0.5911
Epoch 130:, Train 0.8406, Val 0.6453, Test 0.5936
Epoch 140:, Train 0.8534, Val 0.6436, Test 0.5876
Epoch 150:, Train 0.8593, Val 0.6440, Test 0.5874
Epoch 160:, Train 0.8679, Val 0.6466, Test 0.5932
Epoch 170:, Train 0.8744, Val 0.6443, Test 0.5900
Epoch 180:, Train 0.8811, Val 0.6423, Test 0.5861
Epoch 190:, Train 0.8843, Val 0.6403, Test 0.5816
Epoch 200:, Train 0.8927, Val 0.6425, Test 0.5869
Epoch 210:, Train 0.8968, Val 0.6431, Test 0.5871
Epoch 220:, Train 0.9013, Val 0.6418, Test 0.5872
Epoch 230:, Train 0.9072, Val 0.6422, Test 0.5852
Epoch 240:, Train 0.9094, Val 0.6434, Test 0.5877
Epoch 250:, Train 0.9148, Val 0.6427, Test 0.5866
Epoch 260:, Train 0.9183, Val 0.6424, Test 0.5829
Epoch 270:, Train 0.9223, Val 0.6411, Test 0.5819
Epoch 280:, Train 0.9246, Val 0.6417, Test 0.5864
Epoch 290:, Train 0.9276, Val 0.6431, Test 0.5859
Epoch 300:, Train 0.9312, Val 0.6406, Test 0.5865
BEST: Epoch 70, Train 0.7693, Val 0.6469, Test 0.5968

RUN #8: seed=1024
Normalization Time: 0.3233
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.3874
Epoch 10:, Train 0.6324, Val 0.6204, Test 0.5763
Epoch 20:, Train 0.6706, Val 0.6333, Test 0.5881
Epoch 30:, Train 0.6964, Val 0.6390, Test 0.5918
Epoch 40:, Train 0.7183, Val 0.6423, Test 0.5952
Epoch 50:, Train 0.7362, Val 0.6449, Test 0.5948
Epoch 60:, Train 0.7533, Val 0.6479, Test 0.5983
Epoch 70:, Train 0.7710, Val 0.6481, Test 0.5973
Epoch 80:, Train 0.7844, Val 0.6427, Test 0.5906
Epoch 90:, Train 0.8005, Val 0.6418, Test 0.5905
Epoch 100:, Train 0.8112, Val 0.6441, Test 0.5907
Epoch 110:, Train 0.8234, Val 0.6435, Test 0.5908
Epoch 120:, Train 0.8333, Val 0.6457, Test 0.5942
Epoch 130:, Train 0.8420, Val 0.6400, Test 0.5832
Epoch 140:, Train 0.8524, Val 0.6464, Test 0.5941
Epoch 150:, Train 0.8595, Val 0.6453, Test 0.5883
Epoch 160:, Train 0.8687, Val 0.6399, Test 0.5864
Epoch 170:, Train 0.8740, Val 0.6402, Test 0.5837
Epoch 180:, Train 0.8811, Val 0.6418, Test 0.5831
Epoch 190:, Train 0.8881, Val 0.6434, Test 0.5905
Epoch 200:, Train 0.8918, Val 0.6430, Test 0.5907
Epoch 210:, Train 0.8972, Val 0.6425, Test 0.5866
Epoch 220:, Train 0.9026, Val 0.6419, Test 0.5841
Epoch 230:, Train 0.9089, Val 0.6427, Test 0.5844
Epoch 240:, Train 0.9100, Val 0.6432, Test 0.5880
Epoch 250:, Train 0.9158, Val 0.6436, Test 0.5861
Epoch 260:, Train 0.9182, Val 0.6431, Test 0.5889
Epoch 270:, Train 0.9228, Val 0.6414, Test 0.5848
Epoch 280:, Train 0.9268, Val 0.6406, Test 0.5841
Epoch 290:, Train 0.9275, Val 0.6420, Test 0.5852
Epoch 300:, Train 0.9296, Val 0.6394, Test 0.5850
BEST: Epoch 70, Train 0.7710, Val 0.6481, Test 0.5973

RUN #9: seed=2048
Normalization Time: 0.3231
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Total Transformation Time: 2.4003
Epoch 10:, Train 0.6321, Val 0.6150, Test 0.5653
Epoch 20:, Train 0.6689, Val 0.6346, Test 0.5845
Epoch 30:, Train 0.6959, Val 0.6408, Test 0.5944
Epoch 40:, Train 0.7180, Val 0.6401, Test 0.5891
Epoch 50:, Train 0.7376, Val 0.6458, Test 0.5991
Epoch 60:, Train 0.7555, Val 0.6448, Test 0.5950
Epoch 70:, Train 0.7677, Val 0.6452, Test 0.5932
Epoch 80:, Train 0.7858, Val 0.6439, Test 0.5945
Epoch 90:, Train 0.7984, Val 0.6446, Test 0.5914
Epoch 100:, Train 0.8108, Val 0.6432, Test 0.5883
Epoch 110:, Train 0.8228, Val 0.6461, Test 0.5937
Epoch 120:, Train 0.8347, Val 0.6423, Test 0.5901
Epoch 130:, Train 0.8447, Val 0.6437, Test 0.5919
Epoch 140:, Train 0.8521, Val 0.6435, Test 0.5925
Epoch 150:, Train 0.8595, Val 0.6396, Test 0.5838
Epoch 160:, Train 0.8700, Val 0.6457, Test 0.5929
Epoch 170:, Train 0.8736, Val 0.6429, Test 0.5904
Epoch 180:, Train 0.8822, Val 0.6427, Test 0.5904
Epoch 190:, Train 0.8859, Val 0.6431, Test 0.5884
Epoch 200:, Train 0.8915, Val 0.6428, Test 0.5878
Epoch 210:, Train 0.8959, Val 0.6422, Test 0.5886
Epoch 220:, Train 0.9029, Val 0.6407, Test 0.5851
Epoch 230:, Train 0.9081, Val 0.6430, Test 0.5894
Epoch 240:, Train 0.9114, Val 0.6408, Test 0.5842
Epoch 250:, Train 0.9171, Val 0.6402, Test 0.5844
Epoch 260:, Train 0.9185, Val 0.6398, Test 0.5809
Epoch 270:, Train 0.9226, Val 0.6409, Test 0.5873
Epoch 280:, Train 0.9251, Val 0.6390, Test 0.5826
Epoch 290:, Train 0.9277, Val 0.6380, Test 0.5841
Epoch 300:, Train 0.9300, Val 0.6421, Test 0.5847
BEST: Epoch 110, Train 0.8228, Val 0.6461, Test 0.5937




==================================================
Model Parameters: 10947629

Avg. Preaggregation Time (s): 2.3408 +/- 0.0326
Avg. Training Time (epoch) (s): 2.0399 +/- 0.0793
Avg. Inference Time (s): 0.1496 +/- 0.0059

Avg. Training Acc: 0.8078 +/- 0.0213
Avg. Validation Acc: 0.6468 +/- 0.0011
Avg. Test Acc: 0.5956 +/- 0.0015

**************************************************

**************************************************
================= SIGN+SHA =======================
**************************************************
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=16384, LEARNING_RATE=0.001, WEIGHT_DECAY=0.0001, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.0, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Normalization Time: 0.0943
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.100 [0.256-1.000]
Total Transformation Time: 1.9344
Epoch 10:, Train 0.5363, Val 0.5722, Test 0.5542
Epoch 20:, Train 0.6713, Val 0.6318, Test 0.5855
Epoch 30:, Train 0.7384, Val 0.6392, Test 0.5906
Epoch 40:, Train 0.8122, Val 0.6448, Test 0.5948
Epoch 50:, Train 0.8890, Val 0.6317, Test 0.5711
Epoch 60:, Train 0.9369, Val 0.6347, Test 0.5829
Epoch 70:, Train 0.9650, Val 0.6309, Test 0.5747
Epoch 80:, Train 0.9783, Val 0.6277, Test 0.5742
Epoch 90:, Train 0.9862, Val 0.6335, Test 0.5828
Epoch 100:, Train 0.9922, Val 0.6262, Test 0.5708
Epoch 110:, Train 0.9947, Val 0.6258, Test 0.5682
Epoch 120:, Train 0.9959, Val 0.6261, Test 0.5745
Epoch 130:, Train 0.9970, Val 0.6270, Test 0.5732
Epoch 140:, Train 0.9976, Val 0.6276, Test 0.5760
Epoch 150:, Train 0.9978, Val 0.6303, Test 0.5750
Epoch 160:, Train 0.9982, Val 0.6288, Test 0.5791
Epoch 170:, Train 0.9985, Val 0.6246, Test 0.5717
Epoch 180:, Train 0.9982, Val 0.6288, Test 0.5761
Epoch 190:, Train 0.9984, Val 0.6270, Test 0.5739
Epoch 200:, Train 0.9988, Val 0.6287, Test 0.5722
Epoch 210:, Train 0.9989, Val 0.6270, Test 0.5719
Epoch 220:, Train 0.9990, Val 0.6272, Test 0.5722
Epoch 230:, Train 0.9991, Val 0.6257, Test 0.5681
Epoch 240:, Train 0.9991, Val 0.6300, Test 0.5752
Epoch 250:, Train 0.9991, Val 0.6286, Test 0.5782
Epoch 260:, Train 0.9992, Val 0.6291, Test 0.5758
Epoch 270:, Train 0.9993, Val 0.6228, Test 0.5688
Epoch 280:, Train 0.9993, Val 0.6248, Test 0.5669
Epoch 290:, Train 0.9994, Val 0.6261, Test 0.5696
Epoch 300:, Train 0.9994, Val 0.6282, Test 0.5718
BEST: Epoch 40, Train 0.8122, Val 0.6448, Test 0.5948

RUN #1: seed=4
Normalization Time: 0.0939
DOT_PRODUCT
Attention Filter (n=1166243): 0.872 +\- 0.093 [0.203-1.000]
Total Transformation Time: 1.8742
Epoch 10:, Train 0.5281, Val 0.5632, Test 0.5446
Epoch 20:, Train 0.6744, Val 0.6362, Test 0.5943
Epoch 30:, Train 0.7389, Val 0.6366, Test 0.5831
Epoch 40:, Train 0.8195, Val 0.6351, Test 0.5820
Epoch 50:, Train 0.8962, Val 0.6324, Test 0.5798
Epoch 60:, Train 0.9427, Val 0.6319, Test 0.5745
Epoch 70:, Train 0.9651, Val 0.6338, Test 0.5785
Epoch 80:, Train 0.9804, Val 0.6326, Test 0.5766
Epoch 90:, Train 0.9880, Val 0.6257, Test 0.5659
Epoch 100:, Train 0.9928, Val 0.6286, Test 0.5722
Epoch 110:, Train 0.9938, Val 0.6243, Test 0.5634
Epoch 120:, Train 0.9958, Val 0.6269, Test 0.5748
Epoch 130:, Train 0.9965, Val 0.6311, Test 0.5756
Epoch 140:, Train 0.9967, Val 0.6282, Test 0.5744
Epoch 150:, Train 0.9970, Val 0.6272, Test 0.5719
Epoch 160:, Train 0.9981, Val 0.6250, Test 0.5778
Epoch 170:, Train 0.9982, Val 0.6279, Test 0.5747
Epoch 180:, Train 0.9983, Val 0.6314, Test 0.5811
Epoch 190:, Train 0.9988, Val 0.6286, Test 0.5762
Epoch 200:, Train 0.9988, Val 0.6286, Test 0.5754
Epoch 210:, Train 0.9989, Val 0.6243, Test 0.5724
Epoch 220:, Train 0.9988, Val 0.6256, Test 0.5710
Epoch 230:, Train 0.9991, Val 0.6296, Test 0.5790
Epoch 240:, Train 0.9990, Val 0.6285, Test 0.5743
Epoch 250:, Train 0.9989, Val 0.6261, Test 0.5719
Epoch 260:, Train 0.9992, Val 0.6265, Test 0.5724
Epoch 270:, Train 0.9992, Val 0.6298, Test 0.5734
Epoch 280:, Train 0.9990, Val 0.6284, Test 0.5761
Epoch 290:, Train 0.9993, Val 0.6253, Test 0.5699
Epoch 300:, Train 0.9993, Val 0.6266, Test 0.5705
BEST: Epoch 30, Train 0.7389, Val 0.6366, Test 0.5831

RUN #2: seed=8
Normalization Time: 0.0954
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.210-1.000]
Total Transformation Time: 1.9091
Epoch 10:, Train 0.5213, Val 0.5571, Test 0.5359
Epoch 20:, Train 0.6751, Val 0.6324, Test 0.5844
Epoch 30:, Train 0.7360, Val 0.6418, Test 0.5961
Epoch 40:, Train 0.8211, Val 0.6410, Test 0.5875
Epoch 50:, Train 0.8921, Val 0.6370, Test 0.5786
Epoch 60:, Train 0.9364, Val 0.6304, Test 0.5801
Epoch 70:, Train 0.9659, Val 0.6300, Test 0.5700
Epoch 80:, Train 0.9809, Val 0.6301, Test 0.5752
Epoch 90:, Train 0.9874, Val 0.6310, Test 0.5702
Epoch 100:, Train 0.9921, Val 0.6297, Test 0.5718
Epoch 110:, Train 0.9951, Val 0.6283, Test 0.5708
Epoch 120:, Train 0.9959, Val 0.6276, Test 0.5711
Epoch 130:, Train 0.9970, Val 0.6311, Test 0.5741
Epoch 140:, Train 0.9976, Val 0.6317, Test 0.5759
Epoch 150:, Train 0.9981, Val 0.6308, Test 0.5774
Epoch 160:, Train 0.9982, Val 0.6321, Test 0.5715
Epoch 170:, Train 0.9985, Val 0.6306, Test 0.5724
Epoch 180:, Train 0.9985, Val 0.6258, Test 0.5675
Epoch 190:, Train 0.9988, Val 0.6288, Test 0.5710
Epoch 200:, Train 0.9984, Val 0.6272, Test 0.5714
Epoch 210:, Train 0.9990, Val 0.6299, Test 0.5732
Epoch 220:, Train 0.9990, Val 0.6286, Test 0.5723
Epoch 230:, Train 0.9991, Val 0.6289, Test 0.5680
Epoch 240:, Train 0.9990, Val 0.6247, Test 0.5647
Epoch 250:, Train 0.9991, Val 0.6285, Test 0.5679
Epoch 260:, Train 0.9991, Val 0.6296, Test 0.5766
Epoch 270:, Train 0.9993, Val 0.6300, Test 0.5713
Epoch 280:, Train 0.9992, Val 0.6258, Test 0.5684
Epoch 290:, Train 0.9993, Val 0.6274, Test 0.5732
Epoch 300:, Train 0.9994, Val 0.6261, Test 0.5724
BEST: Epoch 30, Train 0.7360, Val 0.6418, Test 0.5961

RUN #3: seed=42
Normalization Time: 0.0940
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.270-1.000]
Total Transformation Time: 1.8844
Epoch 10:, Train 0.5165, Val 0.5468, Test 0.5248
Epoch 20:, Train 0.6779, Val 0.6339, Test 0.5809
Epoch 30:, Train 0.7402, Val 0.6346, Test 0.5793
Epoch 40:, Train 0.8237, Val 0.6391, Test 0.5887
Epoch 50:, Train 0.8987, Val 0.6304, Test 0.5725
Epoch 60:, Train 0.9433, Val 0.6318, Test 0.5788
Epoch 70:, Train 0.9658, Val 0.6276, Test 0.5743
Epoch 80:, Train 0.9806, Val 0.6284, Test 0.5693
Epoch 90:, Train 0.9873, Val 0.6278, Test 0.5709
Epoch 100:, Train 0.9928, Val 0.6301, Test 0.5771
Epoch 110:, Train 0.9937, Val 0.6271, Test 0.5749
Epoch 120:, Train 0.9948, Val 0.6260, Test 0.5703
Epoch 130:, Train 0.9963, Val 0.6313, Test 0.5770
Epoch 140:, Train 0.9967, Val 0.6233, Test 0.5691
Epoch 150:, Train 0.9981, Val 0.6239, Test 0.5734
Epoch 160:, Train 0.9978, Val 0.6273, Test 0.5711
Epoch 170:, Train 0.9983, Val 0.6266, Test 0.5759
Epoch 180:, Train 0.9985, Val 0.6283, Test 0.5738
Epoch 190:, Train 0.9987, Val 0.6267, Test 0.5736
Epoch 200:, Train 0.9988, Val 0.6313, Test 0.5772
Epoch 210:, Train 0.9988, Val 0.6256, Test 0.5643
Epoch 220:, Train 0.9989, Val 0.6280, Test 0.5718
Epoch 230:, Train 0.9990, Val 0.6304, Test 0.5730
Epoch 240:, Train 0.9991, Val 0.6257, Test 0.5738
Epoch 250:, Train 0.9992, Val 0.6303, Test 0.5726
Epoch 260:, Train 0.9991, Val 0.6221, Test 0.5646
Epoch 270:, Train 0.9992, Val 0.6282, Test 0.5681
Epoch 280:, Train 0.9993, Val 0.6303, Test 0.5765
Epoch 290:, Train 0.9992, Val 0.6252, Test 0.5680
Epoch 300:, Train 0.9993, Val 0.6271, Test 0.5701
BEST: Epoch 40, Train 0.8237, Val 0.6391, Test 0.5887

RUN #4: seed=64
Normalization Time: 0.0968
DOT_PRODUCT
Attention Filter (n=1166243): 0.863 +\- 0.099 [0.275-1.000]
Total Transformation Time: 1.8663
Epoch 10:, Train 0.5159, Val 0.5534, Test 0.5216
Epoch 20:, Train 0.6761, Val 0.6325, Test 0.5840
Epoch 30:, Train 0.7427, Val 0.6386, Test 0.5892
Epoch 40:, Train 0.8233, Val 0.6352, Test 0.5835
Epoch 50:, Train 0.8974, Val 0.6317, Test 0.5816
Epoch 60:, Train 0.9413, Val 0.6252, Test 0.5685
Epoch 70:, Train 0.9682, Val 0.6268, Test 0.5723
Epoch 80:, Train 0.9803, Val 0.6303, Test 0.5809
Epoch 90:, Train 0.9884, Val 0.6276, Test 0.5773
Epoch 100:, Train 0.9926, Val 0.6274, Test 0.5770
Epoch 110:, Train 0.9955, Val 0.6265, Test 0.5757
Epoch 120:, Train 0.9963, Val 0.6269, Test 0.5746
Epoch 130:, Train 0.9974, Val 0.6289, Test 0.5762
Epoch 140:, Train 0.9978, Val 0.6300, Test 0.5729
Epoch 150:, Train 0.9978, Val 0.6303, Test 0.5790
Epoch 160:, Train 0.9983, Val 0.6278, Test 0.5762
Epoch 170:, Train 0.9984, Val 0.6252, Test 0.5661
Epoch 180:, Train 0.9986, Val 0.6287, Test 0.5746
Epoch 190:, Train 0.9988, Val 0.6253, Test 0.5734
Epoch 200:, Train 0.9988, Val 0.6275, Test 0.5790
Epoch 210:, Train 0.9990, Val 0.6293, Test 0.5761
Epoch 220:, Train 0.9990, Val 0.6225, Test 0.5700
Epoch 230:, Train 0.9991, Val 0.6256, Test 0.5714
Epoch 240:, Train 0.9989, Val 0.6251, Test 0.5718
Epoch 250:, Train 0.9990, Val 0.6263, Test 0.5782
Epoch 260:, Train 0.9992, Val 0.6272, Test 0.5771
Epoch 270:, Train 0.9993, Val 0.6260, Test 0.5723
Epoch 280:, Train 0.9990, Val 0.6279, Test 0.5756
Epoch 290:, Train 0.9994, Val 0.6256, Test 0.5718
Epoch 300:, Train 0.9993, Val 0.6258, Test 0.5691
BEST: Epoch 30, Train 0.7427, Val 0.6386, Test 0.5892

RUN #5: seed=128
Normalization Time: 0.0936
DOT_PRODUCT
Attention Filter (n=1166243): 0.876 +\- 0.092 [0.280-1.000]
Total Transformation Time: 1.8747
Epoch 10:, Train 0.5147, Val 0.5501, Test 0.5182
Epoch 20:, Train 0.6730, Val 0.6319, Test 0.5821
Epoch 30:, Train 0.7368, Val 0.6366, Test 0.5888
Epoch 40:, Train 0.8092, Val 0.6347, Test 0.5823
Epoch 50:, Train 0.8902, Val 0.6366, Test 0.5931
Epoch 60:, Train 0.9374, Val 0.6325, Test 0.5822
Epoch 70:, Train 0.9676, Val 0.6272, Test 0.5749
Epoch 80:, Train 0.9806, Val 0.6320, Test 0.5789
Epoch 90:, Train 0.9851, Val 0.6269, Test 0.5726
Epoch 100:, Train 0.9912, Val 0.6284, Test 0.5777
Epoch 110:, Train 0.9945, Val 0.6279, Test 0.5747
Epoch 120:, Train 0.9959, Val 0.6316, Test 0.5767
Epoch 130:, Train 0.9967, Val 0.6297, Test 0.5751
Epoch 140:, Train 0.9979, Val 0.6292, Test 0.5702
Epoch 150:, Train 0.9981, Val 0.6290, Test 0.5751
Epoch 160:, Train 0.9977, Val 0.6292, Test 0.5706
Epoch 170:, Train 0.9978, Val 0.6274, Test 0.5728
Epoch 180:, Train 0.9987, Val 0.6333, Test 0.5827
Epoch 190:, Train 0.9986, Val 0.6256, Test 0.5705
Epoch 200:, Train 0.9990, Val 0.6266, Test 0.5778
Epoch 210:, Train 0.9991, Val 0.6313, Test 0.5753
Epoch 220:, Train 0.9989, Val 0.6290, Test 0.5743
Epoch 230:, Train 0.9990, Val 0.6270, Test 0.5728
Epoch 240:, Train 0.9992, Val 0.6282, Test 0.5690
Epoch 250:, Train 0.9993, Val 0.6276, Test 0.5741
Epoch 260:, Train 0.9991, Val 0.6322, Test 0.5743
Epoch 270:, Train 0.9992, Val 0.6298, Test 0.5748
Epoch 280:, Train 0.9992, Val 0.6303, Test 0.5766
Epoch 290:, Train 0.9994, Val 0.6301, Test 0.5737
Epoch 300:, Train 0.9992, Val 0.6305, Test 0.5746
BEST: Epoch 30, Train 0.7368, Val 0.6366, Test 0.5888

RUN #6: seed=256
Normalization Time: 0.0934
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.098 [0.294-1.000]
Total Transformation Time: 1.8556
Epoch 10:, Train 0.5317, Val 0.5678, Test 0.5436
Epoch 20:, Train 0.6728, Val 0.6340, Test 0.5886
Epoch 30:, Train 0.7379, Val 0.6418, Test 0.5977
Epoch 40:, Train 0.8196, Val 0.6398, Test 0.5863
Epoch 50:, Train 0.8947, Val 0.6291, Test 0.5710
Epoch 60:, Train 0.9424, Val 0.6309, Test 0.5730
Epoch 70:, Train 0.9669, Val 0.6290, Test 0.5779
Epoch 80:, Train 0.9782, Val 0.6248, Test 0.5684
Epoch 90:, Train 0.9882, Val 0.6282, Test 0.5729
Epoch 100:, Train 0.9920, Val 0.6277, Test 0.5736
Epoch 110:, Train 0.9945, Val 0.6248, Test 0.5704
Epoch 120:, Train 0.9960, Val 0.6260, Test 0.5702
Epoch 130:, Train 0.9973, Val 0.6279, Test 0.5705
Epoch 140:, Train 0.9976, Val 0.6288, Test 0.5748
Epoch 150:, Train 0.9978, Val 0.6290, Test 0.5739
Epoch 160:, Train 0.9984, Val 0.6262, Test 0.5721
Epoch 170:, Train 0.9984, Val 0.6300, Test 0.5744
Epoch 180:, Train 0.9985, Val 0.6303, Test 0.5779
Epoch 190:, Train 0.9986, Val 0.6289, Test 0.5761
Epoch 200:, Train 0.9988, Val 0.6288, Test 0.5765
Epoch 210:, Train 0.9987, Val 0.6247, Test 0.5669
Epoch 220:, Train 0.9989, Val 0.6247, Test 0.5691
Epoch 230:, Train 0.9991, Val 0.6252, Test 0.5711
Epoch 240:, Train 0.9993, Val 0.6269, Test 0.5676
Epoch 250:, Train 0.9992, Val 0.6253, Test 0.5717
Epoch 260:, Train 0.9994, Val 0.6258, Test 0.5690
Epoch 270:, Train 0.9993, Val 0.6285, Test 0.5756
Epoch 280:, Train 0.9993, Val 0.6279, Test 0.5737
Epoch 290:, Train 0.9994, Val 0.6266, Test 0.5754
Epoch 300:, Train 0.9993, Val 0.6250, Test 0.5709
BEST: Epoch 30, Train 0.7379, Val 0.6418, Test 0.5977

RUN #7: seed=512
Normalization Time: 0.0934
DOT_PRODUCT
Attention Filter (n=1166243): 0.858 +\- 0.102 [0.269-1.000]
Total Transformation Time: 1.8970
Epoch 10:, Train 0.5190, Val 0.5468, Test 0.5166
Epoch 20:, Train 0.6778, Val 0.6333, Test 0.5854
Epoch 30:, Train 0.7418, Val 0.6351, Test 0.5850
Epoch 40:, Train 0.8262, Val 0.6404, Test 0.5911
Epoch 50:, Train 0.9002, Val 0.6359, Test 0.5803
Epoch 60:, Train 0.9443, Val 0.6335, Test 0.5828
Epoch 70:, Train 0.9671, Val 0.6314, Test 0.5776
Epoch 80:, Train 0.9825, Val 0.6272, Test 0.5727
Epoch 90:, Train 0.9883, Val 0.6355, Test 0.5818
Epoch 100:, Train 0.9928, Val 0.6320, Test 0.5774
Epoch 110:, Train 0.9938, Val 0.6301, Test 0.5739
Epoch 120:, Train 0.9965, Val 0.6320, Test 0.5776
Epoch 130:, Train 0.9967, Val 0.6344, Test 0.5824
Epoch 140:, Train 0.9975, Val 0.6277, Test 0.5727
Epoch 150:, Train 0.9979, Val 0.6276, Test 0.5731
Epoch 160:, Train 0.9983, Val 0.6289, Test 0.5749
Epoch 170:, Train 0.9986, Val 0.6311, Test 0.5771
Epoch 180:, Train 0.9986, Val 0.6291, Test 0.5704
Epoch 190:, Train 0.9988, Val 0.6281, Test 0.5715
Epoch 200:, Train 0.9987, Val 0.6298, Test 0.5776
Epoch 210:, Train 0.9988, Val 0.6291, Test 0.5698
Epoch 220:, Train 0.9990, Val 0.6289, Test 0.5720
Epoch 230:, Train 0.9988, Val 0.6273, Test 0.5706
Epoch 240:, Train 0.9991, Val 0.6269, Test 0.5750
Epoch 250:, Train 0.9990, Val 0.6313, Test 0.5709
Epoch 260:, Train 0.9992, Val 0.6258, Test 0.5715
Epoch 270:, Train 0.9993, Val 0.6304, Test 0.5719
Epoch 280:, Train 0.9994, Val 0.6284, Test 0.5717
Epoch 290:, Train 0.9994, Val 0.6306, Test 0.5726
Epoch 300:, Train 0.9993, Val 0.6362, Test 0.5796
BEST: Epoch 40, Train 0.8262, Val 0.6404, Test 0.5911

RUN #8: seed=1024
Normalization Time: 0.0971
DOT_PRODUCT
Attention Filter (n=1166243): 0.866 +\- 0.097 [0.261-1.000]
Total Transformation Time: 1.9866
Epoch 10:, Train 0.5299, Val 0.5608, Test 0.5340
Epoch 20:, Train 0.6770, Val 0.6313, Test 0.5836
Epoch 30:, Train 0.7390, Val 0.6383, Test 0.5868
Epoch 40:, Train 0.8182, Val 0.6394, Test 0.5881
Epoch 50:, Train 0.8927, Val 0.6396, Test 0.5900
Epoch 60:, Train 0.9388, Val 0.6373, Test 0.5857
Epoch 70:, Train 0.9665, Val 0.6363, Test 0.5874
Epoch 80:, Train 0.9797, Val 0.6248, Test 0.5669
Epoch 90:, Train 0.9884, Val 0.6316, Test 0.5791
Epoch 100:, Train 0.9920, Val 0.6320, Test 0.5771
Epoch 110:, Train 0.9948, Val 0.6307, Test 0.5762
Epoch 120:, Train 0.9956, Val 0.6274, Test 0.5735
Epoch 130:, Train 0.9973, Val 0.6288, Test 0.5755
Epoch 140:, Train 0.9974, Val 0.6265, Test 0.5743
Epoch 150:, Train 0.9982, Val 0.6301, Test 0.5746
Epoch 160:, Train 0.9978, Val 0.6303, Test 0.5722
Epoch 170:, Train 0.9986, Val 0.6274, Test 0.5739
Epoch 180:, Train 0.9987, Val 0.6297, Test 0.5793
Epoch 190:, Train 0.9988, Val 0.6250, Test 0.5674
Epoch 200:, Train 0.9988, Val 0.6253, Test 0.5677
Epoch 210:, Train 0.9988, Val 0.6269, Test 0.5705
Epoch 220:, Train 0.9989, Val 0.6246, Test 0.5699
Epoch 230:, Train 0.9991, Val 0.6290, Test 0.5749
Epoch 240:, Train 0.9989, Val 0.6292, Test 0.5750
Epoch 250:, Train 0.9992, Val 0.6276, Test 0.5728
Epoch 260:, Train 0.9993, Val 0.6303, Test 0.5763
Epoch 270:, Train 0.9992, Val 0.6245, Test 0.5712
Epoch 280:, Train 0.9994, Val 0.6260, Test 0.5653
Epoch 290:, Train 0.9995, Val 0.6265, Test 0.5702
Epoch 300:, Train 0.9994, Val 0.6288, Test 0.5740
BEST: Epoch 50, Train 0.8927, Val 0.6396, Test 0.5900

RUN #9: seed=2048
Normalization Time: 0.0972
DOT_PRODUCT
Attention Filter (n=1166243): 0.871 +\- 0.094 [0.242-1.000]
Total Transformation Time: 1.9040
Epoch 10:, Train 0.5223, Val 0.5575, Test 0.5366
Epoch 20:, Train 0.6792, Val 0.6346, Test 0.5899
Epoch 30:, Train 0.7410, Val 0.6374, Test 0.5905
Epoch 40:, Train 0.8242, Val 0.6363, Test 0.5837
Epoch 50:, Train 0.8979, Val 0.6338, Test 0.5826
Epoch 60:, Train 0.9417, Val 0.6309, Test 0.5760
Epoch 70:, Train 0.9662, Val 0.6330, Test 0.5823
Epoch 80:, Train 0.9812, Val 0.6339, Test 0.5760
Epoch 90:, Train 0.9888, Val 0.6347, Test 0.5822
Epoch 100:, Train 0.9927, Val 0.6312, Test 0.5801
Epoch 110:, Train 0.9940, Val 0.6279, Test 0.5767
Epoch 120:, Train 0.9962, Val 0.6305, Test 0.5728
Epoch 130:, Train 0.9970, Val 0.6332, Test 0.5785
Epoch 140:, Train 0.9974, Val 0.6282, Test 0.5727
Epoch 150:, Train 0.9978, Val 0.6282, Test 0.5760
Epoch 160:, Train 0.9982, Val 0.6292, Test 0.5727
Epoch 170:, Train 0.9985, Val 0.6314, Test 0.5782
Epoch 180:, Train 0.9986, Val 0.6291, Test 0.5732
Epoch 190:, Train 0.9987, Val 0.6265, Test 0.5765
Epoch 200:, Train 0.9989, Val 0.6314, Test 0.5750
Epoch 210:, Train 0.9989, Val 0.6255, Test 0.5653
Epoch 220:, Train 0.9989, Val 0.6266, Test 0.5708
Epoch 230:, Train 0.9989, Val 0.6278, Test 0.5707
Epoch 240:, Train 0.9991, Val 0.6299, Test 0.5757
Epoch 250:, Train 0.9993, Val 0.6304, Test 0.5754
Epoch 260:, Train 0.9992, Val 0.6299, Test 0.5760
Epoch 270:, Train 0.9992, Val 0.6298, Test 0.5730
Epoch 280:, Train 0.9994, Val 0.6251, Test 0.5682
Epoch 290:, Train 0.9992, Val 0.6283, Test 0.5753
Epoch 300:, Train 0.9992, Val 0.6295, Test 0.5747
BEST: Epoch 30, Train 0.7410, Val 0.6374, Test 0.5905




==================================================
Model Parameters: 10947629

Avg. Preaggregation Time (s): 1.8986 +/- 0.0366
Avg. Training Time (epoch) (s): 1.4344 +/- 0.0832
Avg. Inference Time (s): 0.0245 +/- 0.0030

Avg. Training Acc: 0.7788 +/- 0.0529
Avg. Validation Acc: 0.6397 +/- 0.0025
Avg. Test Acc: 0.5910 +/- 0.0040

**************************************************
**************************************************

**************************************************
================= SIGN+MHA =======================
**************************************************
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=4096, LEARNING_RATE=0.001, WEIGHT_DECAY=1e-06, INCEPTION_LAYERS=1, INCEPTION_UNITS=512, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.2, NODE_DROPOUT=0.2, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=5, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Normalization Time: 0.0945
DOT_PRODUCT
Attention Filter (n=1166243): 0.934 +\- 0.049 [0.563-1.000]
Total Transformation Time: 6.0703
Epoch 10:, Train 0.6179, Val 0.6139, Test 0.5637
Epoch 20:, Train 0.6515, Val 0.6199, Test 0.5618
Epoch 30:, Train 0.6788, Val 0.6265, Test 0.5735
Epoch 40:, Train 0.7032, Val 0.6298, Test 0.5715
Epoch 50:, Train 0.7275, Val 0.6311, Test 0.5696
Epoch 60:, Train 0.7465, Val 0.6243, Test 0.5590
Epoch 70:, Train 0.7646, Val 0.6180, Test 0.5494
Epoch 80:, Train 0.7791, Val 0.6271, Test 0.5695
Epoch 90:, Train 0.7949, Val 0.6199, Test 0.5573
Epoch 100:, Train 0.8052, Val 0.6225, Test 0.5550
Epoch 110:, Train 0.8118, Val 0.6228, Test 0.5577
Epoch 120:, Train 0.8234, Val 0.6257, Test 0.5627
Epoch 130:, Train 0.8334, Val 0.6224, Test 0.5564
Epoch 140:, Train 0.8403, Val 0.6245, Test 0.5555
Epoch 150:, Train 0.8461, Val 0.6219, Test 0.5574
Epoch 160:, Train 0.8521, Val 0.6204, Test 0.5545
Epoch 170:, Train 0.8562, Val 0.6248, Test 0.5666
Epoch 180:, Train 0.8625, Val 0.6195, Test 0.5584
Epoch 190:, Train 0.8649, Val 0.6186, Test 0.5532
Epoch 200:, Train 0.8701, Val 0.6209, Test 0.5535
Epoch 210:, Train 0.8741, Val 0.6230, Test 0.5583
Epoch 220:, Train 0.8750, Val 0.6193, Test 0.5550
Epoch 230:, Train 0.8808, Val 0.6192, Test 0.5497
Epoch 240:, Train 0.8833, Val 0.6167, Test 0.5522
Epoch 250:, Train 0.8871, Val 0.6162, Test 0.5483
Epoch 260:, Train 0.8900, Val 0.6182, Test 0.5520
Epoch 270:, Train 0.8888, Val 0.6207, Test 0.5531
Epoch 280:, Train 0.8947, Val 0.6205, Test 0.5555
Epoch 290:, Train 0.8972, Val 0.6190, Test 0.5512
Epoch 300:, Train 0.8984, Val 0.6166, Test 0.5499
BEST: Epoch 50, Train 0.7275, Val 0.6311, Test 0.5696

RUN #1: seed=4
Normalization Time: 0.0960
DOT_PRODUCT
Attention Filter (n=1166243): 0.930 +\- 0.053 [0.569-1.000]
Total Transformation Time: 6.0524
Epoch 10:, Train 0.6155, Val 0.6141, Test 0.5685
Epoch 20:, Train 0.6492, Val 0.6176, Test 0.5637
Epoch 30:, Train 0.6793, Val 0.6261, Test 0.5767
Epoch 40:, Train 0.7044, Val 0.6289, Test 0.5747
Epoch 50:, Train 0.7276, Val 0.6324, Test 0.5772
Epoch 60:, Train 0.7471, Val 0.6278, Test 0.5706
Epoch 70:, Train 0.7647, Val 0.6224, Test 0.5605
Epoch 80:, Train 0.7828, Val 0.6294, Test 0.5711
Epoch 90:, Train 0.7945, Val 0.6239, Test 0.5617
Epoch 100:, Train 0.8060, Val 0.6255, Test 0.5675
Epoch 110:, Train 0.8162, Val 0.6216, Test 0.5582
Epoch 120:, Train 0.8253, Val 0.6237, Test 0.5652
Epoch 130:, Train 0.8316, Val 0.6252, Test 0.5606
Epoch 140:, Train 0.8399, Val 0.6237, Test 0.5575
Epoch 150:, Train 0.8482, Val 0.6215, Test 0.5540
Epoch 160:, Train 0.8548, Val 0.6209, Test 0.5560
Epoch 170:, Train 0.8574, Val 0.6183, Test 0.5482
Epoch 180:, Train 0.8613, Val 0.6235, Test 0.5583
Epoch 190:, Train 0.8691, Val 0.6171, Test 0.5486
Epoch 200:, Train 0.8705, Val 0.6248, Test 0.5603
Epoch 210:, Train 0.8728, Val 0.6188, Test 0.5520
Epoch 220:, Train 0.8764, Val 0.6197, Test 0.5554
Epoch 230:, Train 0.8783, Val 0.6144, Test 0.5429
Epoch 240:, Train 0.8855, Val 0.6209, Test 0.5551
Epoch 250:, Train 0.8835, Val 0.6169, Test 0.5513
Epoch 260:, Train 0.8901, Val 0.6164, Test 0.5454
Epoch 270:, Train 0.8918, Val 0.6196, Test 0.5516
Epoch 280:, Train 0.8933, Val 0.6183, Test 0.5527
Epoch 290:, Train 0.8960, Val 0.6185, Test 0.5520
Epoch 300:, Train 0.8984, Val 0.6164, Test 0.5480
BEST: Epoch 50, Train 0.7276, Val 0.6324, Test 0.5772

RUN #2: seed=8
Normalization Time: 0.0947
DOT_PRODUCT
Attention Filter (n=1166243): 0.924 +\- 0.056 [0.536-1.000]
Total Transformation Time: 6.1016
Epoch 10:, Train 0.6160, Val 0.6086, Test 0.5578
Epoch 20:, Train 0.6536, Val 0.6188, Test 0.5642
Epoch 30:, Train 0.6789, Val 0.6257, Test 0.5729
Epoch 40:, Train 0.7013, Val 0.6272, Test 0.5705
Epoch 50:, Train 0.7284, Val 0.6265, Test 0.5638
Epoch 60:, Train 0.7497, Val 0.6225, Test 0.5551
Epoch 70:, Train 0.7614, Val 0.6265, Test 0.5715
Epoch 80:, Train 0.7783, Val 0.6282, Test 0.5708
Epoch 90:, Train 0.7945, Val 0.6259, Test 0.5669
Epoch 100:, Train 0.8083, Val 0.6253, Test 0.5641
Epoch 110:, Train 0.8162, Val 0.6262, Test 0.5670
Epoch 120:, Train 0.8252, Val 0.6198, Test 0.5575
Epoch 130:, Train 0.8369, Val 0.6243, Test 0.5634
Epoch 140:, Train 0.8432, Val 0.6178, Test 0.5553
Epoch 150:, Train 0.8460, Val 0.6187, Test 0.5548
Epoch 160:, Train 0.8523, Val 0.6196, Test 0.5599
Epoch 170:, Train 0.8565, Val 0.6227, Test 0.5617
Epoch 180:, Train 0.8595, Val 0.6197, Test 0.5582
Epoch 190:, Train 0.8650, Val 0.6192, Test 0.5578
Epoch 200:, Train 0.8728, Val 0.6219, Test 0.5649
Epoch 210:, Train 0.8714, Val 0.6177, Test 0.5542
Epoch 220:, Train 0.8769, Val 0.6179, Test 0.5573
Epoch 230:, Train 0.8806, Val 0.6229, Test 0.5577
Epoch 240:, Train 0.8831, Val 0.6207, Test 0.5597
Epoch 250:, Train 0.8875, Val 0.6206, Test 0.5568
Epoch 260:, Train 0.8869, Val 0.6137, Test 0.5467
Epoch 270:, Train 0.8914, Val 0.6148, Test 0.5495
Epoch 280:, Train 0.8923, Val 0.6196, Test 0.5577
Epoch 290:, Train 0.8997, Val 0.6182, Test 0.5523
Epoch 300:, Train 0.8944, Val 0.6163, Test 0.5499
BEST: Epoch 80, Train 0.7783, Val 0.6282, Test 0.5708

RUN #3: seed=42
Normalization Time: 0.0935
DOT_PRODUCT
Attention Filter (n=1166243): 0.927 +\- 0.055 [0.507-1.000]
Total Transformation Time: 5.9320
Epoch 10:, Train 0.6187, Val 0.6161, Test 0.5696
Epoch 20:, Train 0.6493, Val 0.6221, Test 0.5670
Epoch 30:, Train 0.6794, Val 0.6287, Test 0.5762
Epoch 40:, Train 0.7060, Val 0.6284, Test 0.5719
Epoch 50:, Train 0.7297, Val 0.6289, Test 0.5678
Epoch 60:, Train 0.7465, Val 0.6288, Test 0.5699
Epoch 70:, Train 0.7651, Val 0.6292, Test 0.5681
Epoch 80:, Train 0.7808, Val 0.6270, Test 0.5659
Epoch 90:, Train 0.7926, Val 0.6265, Test 0.5589
Epoch 100:, Train 0.8043, Val 0.6282, Test 0.5709
Epoch 110:, Train 0.8153, Val 0.6231, Test 0.5583
Epoch 120:, Train 0.8254, Val 0.6240, Test 0.5586
Epoch 130:, Train 0.8336, Val 0.6250, Test 0.5626
Epoch 140:, Train 0.8399, Val 0.6225, Test 0.5564
Epoch 150:, Train 0.8451, Val 0.6213, Test 0.5535
Epoch 160:, Train 0.8518, Val 0.6230, Test 0.5648
Epoch 170:, Train 0.8530, Val 0.6256, Test 0.5650
Epoch 180:, Train 0.8628, Val 0.6203, Test 0.5486
Epoch 190:, Train 0.8637, Val 0.6215, Test 0.5528
Epoch 200:, Train 0.8709, Val 0.6224, Test 0.5495
Epoch 210:, Train 0.8720, Val 0.6227, Test 0.5545
Epoch 220:, Train 0.8745, Val 0.6200, Test 0.5506
Epoch 230:, Train 0.8814, Val 0.6207, Test 0.5582
Epoch 240:, Train 0.8809, Val 0.6190, Test 0.5512
Epoch 250:, Train 0.8832, Val 0.6204, Test 0.5551
Epoch 260:, Train 0.8917, Val 0.6243, Test 0.5581
Epoch 270:, Train 0.8914, Val 0.6196, Test 0.5542
Epoch 280:, Train 0.8913, Val 0.6171, Test 0.5443
Epoch 290:, Train 0.8959, Val 0.6235, Test 0.5554
Epoch 300:, Train 0.8975, Val 0.6207, Test 0.5533
BEST: Epoch 70, Train 0.7651, Val 0.6292, Test 0.5681

RUN #4: seed=64
Normalization Time: 0.0940
DOT_PRODUCT
Attention Filter (n=1166243): 0.929 +\- 0.052 [0.512-1.000]
Total Transformation Time: 5.9874
Epoch 10:, Train 0.6173, Val 0.6081, Test 0.5584
Epoch 20:, Train 0.6520, Val 0.6236, Test 0.5715
Epoch 30:, Train 0.6773, Val 0.6218, Test 0.5614
Epoch 40:, Train 0.7043, Val 0.6272, Test 0.5685
Epoch 50:, Train 0.7282, Val 0.6242, Test 0.5549
Epoch 60:, Train 0.7509, Val 0.6260, Test 0.5617
Epoch 70:, Train 0.7676, Val 0.6308, Test 0.5659
Epoch 80:, Train 0.7828, Val 0.6256, Test 0.5611
Epoch 90:, Train 0.7943, Val 0.6218, Test 0.5574
Epoch 100:, Train 0.8058, Val 0.6163, Test 0.5486
Epoch 110:, Train 0.8212, Val 0.6283, Test 0.5657
Epoch 120:, Train 0.8240, Val 0.6280, Test 0.5610
Epoch 130:, Train 0.8318, Val 0.6240, Test 0.5593
Epoch 140:, Train 0.8430, Val 0.6271, Test 0.5625
Epoch 150:, Train 0.8455, Val 0.6207, Test 0.5514
Epoch 160:, Train 0.8512, Val 0.6256, Test 0.5613
Epoch 170:, Train 0.8595, Val 0.6224, Test 0.5557
Epoch 180:, Train 0.8637, Val 0.6248, Test 0.5629
Epoch 190:, Train 0.8706, Val 0.6230, Test 0.5553
Epoch 200:, Train 0.8728, Val 0.6241, Test 0.5563
Epoch 210:, Train 0.8757, Val 0.6211, Test 0.5571
Epoch 220:, Train 0.8752, Val 0.6198, Test 0.5534
Epoch 230:, Train 0.8845, Val 0.6192, Test 0.5540
Epoch 240:, Train 0.8837, Val 0.6186, Test 0.5543
Epoch 250:, Train 0.8893, Val 0.6202, Test 0.5540
Epoch 260:, Train 0.8901, Val 0.6167, Test 0.5491
Epoch 270:, Train 0.8914, Val 0.6200, Test 0.5561
Epoch 280:, Train 0.8918, Val 0.6196, Test 0.5549
Epoch 290:, Train 0.8992, Val 0.6219, Test 0.5577
Epoch 300:, Train 0.9021, Val 0.6142, Test 0.5502
BEST: Epoch 70, Train 0.7676, Val 0.6308, Test 0.5659

RUN #5: seed=128
Normalization Time: 0.0956
DOT_PRODUCT
Attention Filter (n=1166243): 0.918 +\- 0.064 [0.530-1.000]
Total Transformation Time: 5.9748
Epoch 10:, Train 0.6159, Val 0.6120, Test 0.5640
Epoch 20:, Train 0.6508, Val 0.6253, Test 0.5757
Epoch 30:, Train 0.6789, Val 0.6262, Test 0.5755
Epoch 40:, Train 0.7059, Val 0.6284, Test 0.5680
Epoch 50:, Train 0.7289, Val 0.6296, Test 0.5701
Epoch 60:, Train 0.7483, Val 0.6268, Test 0.5681
Epoch 70:, Train 0.7647, Val 0.6292, Test 0.5694
Epoch 80:, Train 0.7796, Val 0.6271, Test 0.5685
Epoch 90:, Train 0.7931, Val 0.6270, Test 0.5695
Epoch 100:, Train 0.8052, Val 0.6249, Test 0.5642
Epoch 110:, Train 0.8159, Val 0.6257, Test 0.5636
Epoch 120:, Train 0.8235, Val 0.6240, Test 0.5578
Epoch 130:, Train 0.8337, Val 0.6255, Test 0.5611
Epoch 140:, Train 0.8391, Val 0.6260, Test 0.5592
Epoch 150:, Train 0.8454, Val 0.6225, Test 0.5562
Epoch 160:, Train 0.8488, Val 0.6225, Test 0.5564
Epoch 170:, Train 0.8577, Val 0.6247, Test 0.5614
Epoch 180:, Train 0.8618, Val 0.6201, Test 0.5523
Epoch 190:, Train 0.8662, Val 0.6211, Test 0.5596
Epoch 200:, Train 0.8685, Val 0.6200, Test 0.5557
Epoch 210:, Train 0.8744, Val 0.6203, Test 0.5542
Epoch 220:, Train 0.8803, Val 0.6204, Test 0.5562
Epoch 230:, Train 0.8808, Val 0.6251, Test 0.5617
Epoch 240:, Train 0.8826, Val 0.6192, Test 0.5578
Epoch 250:, Train 0.8878, Val 0.6176, Test 0.5477
Epoch 260:, Train 0.8855, Val 0.6187, Test 0.5549
Epoch 270:, Train 0.8929, Val 0.6186, Test 0.5550
Epoch 280:, Train 0.8931, Val 0.6191, Test 0.5504
Epoch 290:, Train 0.8954, Val 0.6221, Test 0.5546
Epoch 300:, Train 0.8977, Val 0.6198, Test 0.5542
BEST: Epoch 50, Train 0.7289, Val 0.6296, Test 0.5701

RUN #6: seed=256
Normalization Time: 0.0897
DOT_PRODUCT
Attention Filter (n=1166243): 0.937 +\- 0.048 [0.556-1.000]
Total Transformation Time: 6.8357
Epoch 10:, Train 0.6152, Val 0.6080, Test 0.5625
Epoch 20:, Train 0.6474, Val 0.6149, Test 0.5572
Epoch 30:, Train 0.6790, Val 0.6250, Test 0.5693
Epoch 40:, Train 0.7041, Val 0.6251, Test 0.5671
Epoch 50:, Train 0.7282, Val 0.6272, Test 0.5620
Epoch 60:, Train 0.7497, Val 0.6246, Test 0.5682
Epoch 70:, Train 0.7677, Val 0.6261, Test 0.5706
Epoch 80:, Train 0.7820, Val 0.6293, Test 0.5672
Epoch 90:, Train 0.7942, Val 0.6221, Test 0.5616
Epoch 100:, Train 0.8063, Val 0.6214, Test 0.5608
Epoch 110:, Train 0.8151, Val 0.6278, Test 0.5681
Epoch 120:, Train 0.8263, Val 0.6241, Test 0.5624
Epoch 130:, Train 0.8357, Val 0.6227, Test 0.5620
Epoch 140:, Train 0.8412, Val 0.6230, Test 0.5622
Epoch 150:, Train 0.8471, Val 0.6207, Test 0.5591
Epoch 160:, Train 0.8518, Val 0.6224, Test 0.5651
Epoch 170:, Train 0.8581, Val 0.6215, Test 0.5600
Epoch 180:, Train 0.8639, Val 0.6234, Test 0.5602
Epoch 190:, Train 0.8633, Val 0.6223, Test 0.5564
Epoch 200:, Train 0.8677, Val 0.6214, Test 0.5588
Epoch 210:, Train 0.8716, Val 0.6236, Test 0.5606
Epoch 220:, Train 0.8715, Val 0.6204, Test 0.5586
Epoch 230:, Train 0.8791, Val 0.6215, Test 0.5554
Epoch 240:, Train 0.8865, Val 0.6213, Test 0.5570
Epoch 250:, Train 0.8865, Val 0.6177, Test 0.5552
Epoch 260:, Train 0.8909, Val 0.6170, Test 0.5534
Epoch 270:, Train 0.8938, Val 0.6160, Test 0.5543
Epoch 280:, Train 0.8936, Val 0.6126, Test 0.5489
Epoch 290:, Train 0.8942, Val 0.6132, Test 0.5485
Epoch 300:, Train 0.8979, Val 0.6185, Test 0.5545
BEST: Epoch 80, Train 0.7820, Val 0.6293, Test 0.5672

RUN #7: seed=512
Normalization Time: 0.0895
DOT_PRODUCT
Attention Filter (n=1166243): 0.928 +\- 0.057 [0.520-1.000]
Total Transformation Time: 9.7919
Epoch 10:, Train 0.6150, Val 0.6101, Test 0.5592
Epoch 20:, Train 0.6457, Val 0.6206, Test 0.5709
Epoch 30:, Train 0.6773, Val 0.6255, Test 0.5677
Epoch 40:, Train 0.7024, Val 0.6250, Test 0.5689
Epoch 50:, Train 0.7259, Val 0.6290, Test 0.5740
Epoch 60:, Train 0.7491, Val 0.6286, Test 0.5674
Epoch 70:, Train 0.7612, Val 0.6247, Test 0.5659
Epoch 80:, Train 0.7813, Val 0.6259, Test 0.5624
Epoch 90:, Train 0.7923, Val 0.6257, Test 0.5615
Epoch 100:, Train 0.8038, Val 0.6265, Test 0.5629
Epoch 110:, Train 0.8117, Val 0.6226, Test 0.5591
Epoch 120:, Train 0.8251, Val 0.6256, Test 0.5588
Epoch 130:, Train 0.8321, Val 0.6255, Test 0.5614
Epoch 140:, Train 0.8372, Val 0.6229, Test 0.5602
Epoch 150:, Train 0.8436, Val 0.6246, Test 0.5604
Epoch 160:, Train 0.8518, Val 0.6235, Test 0.5576
Epoch 170:, Train 0.8558, Val 0.6189, Test 0.5497
Epoch 180:, Train 0.8617, Val 0.6215, Test 0.5543
Epoch 190:, Train 0.8654, Val 0.6201, Test 0.5589
Epoch 200:, Train 0.8698, Val 0.6204, Test 0.5537
Epoch 210:, Train 0.8755, Val 0.6200, Test 0.5537
Epoch 220:, Train 0.8792, Val 0.6217, Test 0.5514
Epoch 230:, Train 0.8802, Val 0.6223, Test 0.5575
Epoch 240:, Train 0.8811, Val 0.6227, Test 0.5576
Epoch 250:, Train 0.8843, Val 0.6208, Test 0.5549
Epoch 260:, Train 0.8889, Val 0.6202, Test 0.5522
Epoch 270:, Train 0.8919, Val 0.6174, Test 0.5508
Epoch 280:, Train 0.8969, Val 0.6187, Test 0.5567
Epoch 290:, Train 0.8937, Val 0.6238, Test 0.5553
Epoch 300:, Train 0.8965, Val 0.6207, Test 0.5551
BEST: Epoch 50, Train 0.7259, Val 0.6290, Test 0.5740

RUN #8: seed=1024
Normalization Time: 0.0908
DOT_PRODUCT
Attention Filter (n=1166243): 0.928 +\- 0.054 [0.568-1.000]
Total Transformation Time: 10.2523
Epoch 10:, Train 0.6153, Val 0.6106, Test 0.5615
Epoch 20:, Train 0.6513, Val 0.6215, Test 0.5708
Epoch 30:, Train 0.6800, Val 0.6265, Test 0.5717
Epoch 40:, Train 0.7021, Val 0.6278, Test 0.5717
Epoch 50:, Train 0.7276, Val 0.6256, Test 0.5646
Epoch 60:, Train 0.7471, Val 0.6260, Test 0.5699
Epoch 70:, Train 0.7669, Val 0.6264, Test 0.5649
Epoch 80:, Train 0.7813, Val 0.6256, Test 0.5648
Epoch 90:, Train 0.7949, Val 0.6250, Test 0.5617
Epoch 100:, Train 0.8044, Val 0.6272, Test 0.5662
Epoch 110:, Train 0.8164, Val 0.6196, Test 0.5565
Epoch 120:, Train 0.8285, Val 0.6253, Test 0.5611
Epoch 130:, Train 0.8314, Val 0.6236, Test 0.5578
Epoch 140:, Train 0.8384, Val 0.6214, Test 0.5565
Epoch 150:, Train 0.8498, Val 0.6242, Test 0.5623
Epoch 160:, Train 0.8504, Val 0.6243, Test 0.5591
Epoch 170:, Train 0.8587, Val 0.6189, Test 0.5563
Epoch 180:, Train 0.8623, Val 0.6220, Test 0.5572
Epoch 190:, Train 0.8680, Val 0.6203, Test 0.5598
Epoch 200:, Train 0.8717, Val 0.6212, Test 0.5595
Epoch 210:, Train 0.8730, Val 0.6189, Test 0.5526
Epoch 220:, Train 0.8762, Val 0.6182, Test 0.5539
Epoch 230:, Train 0.8831, Val 0.6183, Test 0.5553
Epoch 240:, Train 0.8868, Val 0.6225, Test 0.5603
Epoch 250:, Train 0.8855, Val 0.6191, Test 0.5543
Epoch 260:, Train 0.8900, Val 0.6171, Test 0.5503
Epoch 270:, Train 0.8892, Val 0.6199, Test 0.5543
Epoch 280:, Train 0.8920, Val 0.6175, Test 0.5506
Epoch 290:, Train 0.8958, Val 0.6201, Test 0.5532
Epoch 300:, Train 0.8993, Val 0.6183, Test 0.5531
BEST: Epoch 40, Train 0.7021, Val 0.6278, Test 0.5717

RUN #9: seed=2048
Normalization Time: 0.0890
DOT_PRODUCT
Attention Filter (n=1166243): 0.931 +\- 0.052 [0.537-1.000]
Total Transformation Time: 8.8157
Epoch 10:, Train 0.6162, Val 0.6106, Test 0.5610
Epoch 20:, Train 0.6493, Val 0.6180, Test 0.5607
Epoch 30:, Train 0.6775, Val 0.6245, Test 0.5693
Epoch 40:, Train 0.6999, Val 0.6184, Test 0.5569
Epoch 50:, Train 0.7263, Val 0.6289, Test 0.5712
Epoch 60:, Train 0.7476, Val 0.6297, Test 0.5733
Epoch 70:, Train 0.7614, Val 0.6258, Test 0.5658
Epoch 80:, Train 0.7804, Val 0.6249, Test 0.5590
Epoch 90:, Train 0.7950, Val 0.6272, Test 0.5602
Epoch 100:, Train 0.8060, Val 0.6268, Test 0.5546
Epoch 110:, Train 0.8157, Val 0.6269, Test 0.5617
Epoch 120:, Train 0.8246, Val 0.6255, Test 0.5604
Epoch 130:, Train 0.8330, Val 0.6229, Test 0.5586
Epoch 140:, Train 0.8414, Val 0.6248, Test 0.5633
Epoch 150:, Train 0.8464, Val 0.6243, Test 0.5572
Epoch 160:, Train 0.8513, Val 0.6221, Test 0.5540
Epoch 170:, Train 0.8575, Val 0.6218, Test 0.5586
Epoch 180:, Train 0.8637, Val 0.6222, Test 0.5591
Epoch 190:, Train 0.8683, Val 0.6217, Test 0.5578
Epoch 200:, Train 0.8704, Val 0.6193, Test 0.5542
Epoch 210:, Train 0.8740, Val 0.6152, Test 0.5498
Epoch 220:, Train 0.8791, Val 0.6192, Test 0.5516
Epoch 230:, Train 0.8843, Val 0.6213, Test 0.5565
Epoch 240:, Train 0.8822, Val 0.6188, Test 0.5489
Epoch 250:, Train 0.8857, Val 0.6197, Test 0.5499
Epoch 260:, Train 0.8886, Val 0.6201, Test 0.5521
Epoch 270:, Train 0.8941, Val 0.6224, Test 0.5587
Epoch 280:, Train 0.8946, Val 0.6167, Test 0.5470
Epoch 290:, Train 0.8980, Val 0.6176, Test 0.5503
Epoch 300:, Train 0.9017, Val 0.6175, Test 0.5481
BEST: Epoch 60, Train 0.7476, Val 0.6297, Test 0.5733




==================================================
Model Parameters: 1270317

Avg. Preaggregation Time (s): 7.1814 +/- 1.6478
Avg. Training Time (epoch) (s): 1.2855 +/- 0.4728
Avg. Inference Time (s): 0.0440 +/- 0.0104

Avg. Training Acc: 0.7452 +/- 0.0254
Avg. Validation Acc: 0.6297 +/- 0.0013
Avg. Test Acc: 0.5708 +/- 0.0032

**************************************************

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 5 hours 37 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
