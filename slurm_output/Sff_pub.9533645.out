Thu 16 Jun 2022 12:59:42 AM CEST
r32n7.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: pubmed
method: bayes
model: SIGNff
iterations: 100
run_trial: false
config: SIGNff.yaml
train_file: hps_SIGNff.py
project_name: sff_pubmed
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 64
    - 128
    - 256
    - 512
    - 1024
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 64
    - 128
    - 256
    - 512
  DATASET:
    value: pubmed
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 64
    - 128
    - 256
    - 512
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_010032-3i1ylvyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-capybara-204
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/3i1ylvyz
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-16 01:00:40,859 - wandb.wandb_agent - INFO - Running runs: []
2022-06-16 01:00:41,152 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:00:41,152 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 01:00:41,159 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:00:46,171 - wandb.wandb_agent - INFO - Running runs: ['i95ms8rl']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_010045-i95ms8rl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-1
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/i95ms8rl
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85932
wandb:    train_loss 0.36753
wandb: training_time 1.14638
wandb:        val_f1 0.87
wandb:      val_loss 0.35489
wandb: 
wandb: Synced likely-sweep-1: https://wandb.ai/jah377/sff_pubmed/runs/i95ms8rl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_010045-i95ms8rl/logs
2022-06-16 01:09:52,642 - wandb.wandb_agent - INFO - Cleaning up finished run: i95ms8rl
2022-06-16 01:09:53,048 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:09:53,048 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 01:09:53,055 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:09:58,067 - wandb.wandb_agent - INFO - Running runs: ['r3gbyxja']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_010958-r3gbyxja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-2
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/r3gbyxja
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87704
wandb:    train_loss 0.32912
wandb: training_time 2.11336
wandb:        val_f1 0.9
wandb:      val_loss 0.31171
wandb: 
wandb: Synced brisk-sweep-2: https://wandb.ai/jah377/sff_pubmed/runs/r3gbyxja
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_010958-r3gbyxja/logs
2022-06-16 01:26:58,629 - wandb.wandb_agent - INFO - Cleaning up finished run: r3gbyxja
2022-06-16 01:26:59,051 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:26:59,052 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 01:26:59,058 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:27:04,071 - wandb.wandb_agent - INFO - Running runs: ['kqiby5i1']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_012704-kqiby5i1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-3
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/kqiby5i1
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39871
wandb:    train_loss 1.08353
wandb: training_time 3.25163
wandb:        val_f1 0.416
wandb:      val_loss 1.0815
wandb: 
wandb: Synced earnest-sweep-3: https://wandb.ai/jah377/sff_pubmed/runs/kqiby5i1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_012704-kqiby5i1/logs
2022-06-16 01:49:08,463 - wandb.wandb_agent - INFO - Cleaning up finished run: kqiby5i1
2022-06-16 01:49:08,880 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:49:08,881 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 01:49:08,889 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 01:49:13,902 - wandb.wandb_agent - INFO - Running runs: ['oetwq8md']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_014914-oetwq8md
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-4
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/oetwq8md
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8882
wandb:    train_loss 0.30617
wandb: training_time 0.93241
wandb:        val_f1 0.902
wandb:      val_loss 0.29762
wandb: 
wandb: Synced magic-sweep-4: https://wandb.ai/jah377/sff_pubmed/runs/oetwq8md
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_014914-oetwq8md/logs
2022-06-16 01:57:49,057 - wandb.wandb_agent - INFO - Cleaning up finished run: oetwq8md
2022-06-16 01:57:49,468 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 01:57:49,468 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 01:57:49,475 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 01:57:54,487 - wandb.wandb_agent - INFO - Running runs: ['cappjl4j']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_015754-cappjl4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-5
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/cappjl4j
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88815
wandb:    train_loss 0.32459
wandb: training_time 4.14204
wandb:        val_f1 0.886
wandb:      val_loss 0.32418
wandb: 
wandb: Synced honest-sweep-5: https://wandb.ai/jah377/sff_pubmed/runs/cappjl4j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_015754-cappjl4j/logs
2022-06-16 02:26:24,557 - wandb.wandb_agent - INFO - Cleaning up finished run: cappjl4j
2022-06-16 02:26:24,933 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:26:24,933 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 02:26:24,941 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 02:26:29,955 - wandb.wandb_agent - INFO - Running runs: ['1itoytrh']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_022629-1itoytrh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-6
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/1itoytrh
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95637
wandb:    train_loss 0.11552
wandb: training_time 3.11449
wandb:        val_f1 0.92
wandb:      val_loss 0.22838
wandb: 
wandb: Synced hardy-sweep-6: https://wandb.ai/jah377/sff_pubmed/runs/1itoytrh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_022629-1itoytrh/logs
2022-06-16 02:49:09,314 - wandb.wandb_agent - INFO - Cleaning up finished run: 1itoytrh
2022-06-16 02:49:09,707 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 02:49:09,707 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 02:49:09,714 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 02:49:14,726 - wandb.wandb_agent - INFO - Running runs: ['b8e4r2zu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_024914-b8e4r2zu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-7
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/b8e4r2zu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.84507
wandb:    train_loss 0.40614
wandb: training_time 1.91048
wandb:        val_f1 0.844
wandb:      val_loss 0.41497
wandb: 
wandb: Synced silver-sweep-7: https://wandb.ai/jah377/sff_pubmed/runs/b8e4r2zu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_024914-b8e4r2zu/logs
2022-06-16 03:04:31,235 - wandb.wandb_agent - INFO - Cleaning up finished run: b8e4r2zu
2022-06-16 03:04:31,673 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:04:31,673 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 03:04:31,680 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 03:04:36,695 - wandb.wandb_agent - INFO - Running runs: ['ie8h8kth']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_030436-ie8h8kth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-8
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ie8h8kth
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99873
wandb:    train_loss 0.00964
wandb: training_time 0.98415
wandb:        val_f1 0.93
wandb:      val_loss 0.27822
wandb: 
wandb: Synced devout-sweep-8: https://wandb.ai/jah377/sff_pubmed/runs/ie8h8kth
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_030436-ie8h8kth/logs
2022-06-16 03:13:01,337 - wandb.wandb_agent - INFO - Cleaning up finished run: ie8h8kth
2022-06-16 03:13:01,745 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:13:01,745 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 03:13:01,753 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 03:13:06,767 - wandb.wandb_agent - INFO - Running runs: ['l2bj1jzd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_031306-l2bj1jzd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-9
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/l2bj1jzd
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86064
wandb:    train_loss 0.33484
wandb: training_time 2.142
wandb:        val_f1 0.838
wandb:      val_loss 0.35346
wandb: 
wandb: Synced lively-sweep-9: https://wandb.ai/jah377/sff_pubmed/runs/l2bj1jzd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_031306-l2bj1jzd/logs
2022-06-16 03:29:38,920 - wandb.wandb_agent - INFO - Cleaning up finished run: l2bj1jzd
2022-06-16 03:29:55,989 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:29:55,989 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 03:29:55,994 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 03:30:01,008 - wandb.wandb_agent - INFO - Running runs: ['j2ejramw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_033001-j2ejramw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-10
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/j2ejramw
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.69761
wandb:    train_loss 0.89483
wandb: training_time 0.39378
wandb:        val_f1 0.684
wandb:      val_loss 0.89797
wandb: 
wandb: Synced wandering-sweep-10: https://wandb.ai/jah377/sff_pubmed/runs/j2ejramw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_033001-j2ejramw/logs
2022-06-16 03:34:34,049 - wandb.wandb_agent - INFO - Cleaning up finished run: j2ejramw
2022-06-16 03:34:34,708 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:34:34,708 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 03:34:34,713 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 03:34:39,723 - wandb.wandb_agent - INFO - Running runs: ['vzchy2wb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_033439-vzchy2wb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-11
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/vzchy2wb
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92281
wandb:    train_loss 0.20368
wandb: training_time 1.81045
wandb:        val_f1 0.906
wandb:      val_loss 0.25582
wandb: 
wandb: Synced playful-sweep-11: https://wandb.ai/jah377/sff_pubmed/runs/vzchy2wb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_033439-vzchy2wb/logs
2022-06-16 03:47:59,197 - wandb.wandb_agent - INFO - Cleaning up finished run: vzchy2wb
2022-06-16 03:47:59,721 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:47:59,721 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 03:47:59,728 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 03:48:04,741 - wandb.wandb_agent - INFO - Running runs: ['q52mu6zx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_034804-q52mu6zx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-12
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/q52mu6zx
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99945
wandb:    train_loss 0.00324
wandb: training_time 4.16813
wandb:        val_f1 0.918
wandb:      val_loss 0.35593
wandb: 
wandb: Synced breezy-sweep-12: https://wandb.ai/jah377/sff_pubmed/runs/q52mu6zx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_034804-q52mu6zx/logs
2022-06-16 04:16:15,039 - wandb.wandb_agent - INFO - Cleaning up finished run: q52mu6zx
2022-06-16 04:16:15,474 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:16:15,475 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 04:16:15,482 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 04:16:20,496 - wandb.wandb_agent - INFO - Running runs: ['d1cye99l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_041620-d1cye99l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-13
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/d1cye99l
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99125
wandb:    train_loss 0.05132
wandb: training_time 1.21096
wandb:        val_f1 0.884
wandb:      val_loss 0.30442
wandb: 
wandb: Synced copper-sweep-13: https://wandb.ai/jah377/sff_pubmed/runs/d1cye99l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_041620-d1cye99l/logs
2022-06-16 04:27:35,745 - wandb.wandb_agent - INFO - Cleaning up finished run: d1cye99l
2022-06-16 04:27:36,221 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:27:36,222 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 04:27:36,230 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 04:27:41,243 - wandb.wandb_agent - INFO - Running runs: ['6fimf9nx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_042741-6fimf9nx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-14
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/6fimf9nx
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99884
wandb:    train_loss 0.01161
wandb: training_time 2.14871
wandb:        val_f1 0.886
wandb:      val_loss 0.36596
wandb: 
wandb: Synced bumbling-sweep-14: https://wandb.ai/jah377/sff_pubmed/runs/6fimf9nx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_042741-6fimf9nx/logs
2022-06-16 04:44:29,223 - wandb.wandb_agent - INFO - Cleaning up finished run: 6fimf9nx
2022-06-16 04:44:29,637 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:44:29,638 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 04:44:29,645 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 04:44:34,659 - wandb.wandb_agent - INFO - Running runs: ['19sxk92p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_044434-19sxk92p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-15
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/19sxk92p
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86158
wandb:    train_loss 0.41839
wandb: training_time 2.3721
wandb:        val_f1 0.874
wandb:      val_loss 0.4205
wandb: 
wandb: Synced vocal-sweep-15: https://wandb.ai/jah377/sff_pubmed/runs/19sxk92p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_044434-19sxk92p/logs
2022-06-16 05:02:41,319 - wandb.wandb_agent - INFO - Cleaning up finished run: 19sxk92p
2022-06-16 05:02:41,706 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:02:41,706 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 05:02:41,712 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 05:02:46,723 - wandb.wandb_agent - INFO - Running runs: ['29k2fgmw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_050246-29k2fgmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-16
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/29k2fgmw
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88842
wandb:    train_loss 0.28634
wandb: training_time 2.44656
wandb:        val_f1 0.898
wandb:      val_loss 0.28443
wandb: 
wandb: Synced hardy-sweep-16: https://wandb.ai/jah377/sff_pubmed/runs/29k2fgmw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_050246-29k2fgmw/logs
2022-06-16 05:21:00,098 - wandb.wandb_agent - INFO - Cleaning up finished run: 29k2fgmw
2022-06-16 05:21:00,484 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:21:00,485 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 05:21:00,492 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 05:21:05,505 - wandb.wandb_agent - INFO - Running runs: ['s9tut50b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_052105-s9tut50b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-17
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/s9tut50b
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.84155
wandb:    train_loss 0.41776
wandb: training_time 1.93226
wandb:        val_f1 0.84
wandb:      val_loss 0.42633
wandb: 
wandb: Synced apricot-sweep-17: https://wandb.ai/jah377/sff_pubmed/runs/s9tut50b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_052105-s9tut50b/logs
2022-06-16 05:36:11,548 - wandb.wandb_agent - INFO - Cleaning up finished run: s9tut50b
2022-06-16 05:36:12,001 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:36:12,002 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 05:36:12,008 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 05:36:17,021 - wandb.wandb_agent - INFO - Running runs: ['8jzut7t7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_053617-8jzut7t7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-18
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/8jzut7t7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86801
wandb:    train_loss 0.34018
wandb: training_time 0.79478
wandb:        val_f1 0.854
wandb:      val_loss 0.34192
wandb: 
wandb: Synced chocolate-sweep-18: https://wandb.ai/jah377/sff_pubmed/runs/8jzut7t7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_053617-8jzut7t7/logs
2022-06-16 05:43:40,152 - wandb.wandb_agent - INFO - Cleaning up finished run: 8jzut7t7
2022-06-16 05:43:40,549 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:43:40,549 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 05:43:40,557 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 05:43:45,567 - wandb.wandb_agent - INFO - Running runs: ['nypsg5yi']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_054345-nypsg5yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-19
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/nypsg5yi
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.83456
wandb:    train_loss 0.63974
wandb: training_time 3.88165
wandb:        val_f1 0.836
wandb:      val_loss 0.55828
wandb: 
wandb: Synced eager-sweep-19: https://wandb.ai/jah377/sff_pubmed/runs/nypsg5yi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_054345-nypsg5yi/logs
2022-06-16 06:11:16,722 - wandb.wandb_agent - INFO - Cleaning up finished run: nypsg5yi
2022-06-16 06:11:17,204 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:11:17,204 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 06:11:17,211 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 06:11:22,225 - wandb.wandb_agent - INFO - Running runs: ['q6k1orne']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_061122-q6k1orne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-20
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/q6k1orne
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88545
wandb:    train_loss 0.28583
wandb: training_time 1.62033
wandb:        val_f1 0.862
wandb:      val_loss 0.33065
wandb: 
wandb: Synced vague-sweep-20: https://wandb.ai/jah377/sff_pubmed/runs/q6k1orne
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_061122-q6k1orne/logs
2022-06-16 06:24:50,715 - wandb.wandb_agent - INFO - Cleaning up finished run: q6k1orne
2022-06-16 06:24:51,131 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:24:51,131 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 06:24:51,139 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 06:24:56,151 - wandb.wandb_agent - INFO - Running runs: ['i4rhxyjq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_062456-i4rhxyjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-21
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/i4rhxyjq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.79154
wandb:    train_loss 0.75665
wandb: training_time 1.61647
wandb:        val_f1 0.79
wandb:      val_loss 0.74648
wandb: 
wandb: Synced robust-sweep-21: https://wandb.ai/jah377/sff_pubmed/runs/i4rhxyjq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_062456-i4rhxyjq/logs
2022-06-16 06:38:40,562 - wandb.wandb_agent - INFO - Cleaning up finished run: i4rhxyjq
2022-06-16 06:38:41,554 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:38:41,554 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 06:38:41,561 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 06:38:46,571 - wandb.wandb_agent - INFO - Running runs: ['gh6uk2l9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_063846-gh6uk2l9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-22
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/gh6uk2l9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99543
wandb:    train_loss 0.02787
wandb: training_time 1.2322
wandb:        val_f1 0.886
wandb:      val_loss 0.29767
wandb: 
wandb: Synced smart-sweep-22: https://wandb.ai/jah377/sff_pubmed/runs/gh6uk2l9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_063846-gh6uk2l9/logs
2022-06-16 06:49:15,798 - wandb.wandb_agent - INFO - Cleaning up finished run: gh6uk2l9
2022-06-16 06:49:16,216 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:49:16,217 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 06:49:16,223 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 06:49:21,238 - wandb.wandb_agent - INFO - Running runs: ['x5o3xfuw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_064921-x5o3xfuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-23
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/x5o3xfuw
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.83951
wandb:    train_loss 0.37894
wandb: training_time 2.48491
wandb:        val_f1 0.844
wandb:      val_loss 0.38089
wandb: 
wandb: Synced ruby-sweep-23: https://wandb.ai/jah377/sff_pubmed/runs/x5o3xfuw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_064921-x5o3xfuw/logs
2022-06-16 07:08:21,292 - wandb.wandb_agent - INFO - Cleaning up finished run: x5o3xfuw
2022-06-16 07:08:21,830 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:08:21,830 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 07:08:21,838 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 07:08:26,851 - wandb.wandb_agent - INFO - Running runs: ['445o2eex']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_070826-445o2eex
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-24
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/445o2eex
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99015
wandb:    train_loss 0.04314
wandb: training_time 3.11228
wandb:        val_f1 0.906
wandb:      val_loss 0.26088
wandb: 
wandb: Synced fancy-sweep-24: https://wandb.ai/jah377/sff_pubmed/runs/445o2eex
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_070826-445o2eex/logs
2022-06-16 07:31:05,247 - wandb.wandb_agent - INFO - Cleaning up finished run: 445o2eex
2022-06-16 07:31:05,737 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:31:05,738 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 07:31:05,744 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 07:31:10,758 - wandb.wandb_agent - INFO - Running runs: ['3iaclljt']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_073110-3iaclljt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-25
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/3iaclljt
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90757
wandb:    train_loss 0.24311
wandb: training_time 2.14376
wandb:        val_f1 0.904
wandb:      val_loss 0.26543
wandb: 
wandb: Synced olive-sweep-25: https://wandb.ai/jah377/sff_pubmed/runs/3iaclljt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_073110-3iaclljt/logs
2022-06-16 07:47:06,442 - wandb.wandb_agent - INFO - Cleaning up finished run: 3iaclljt
2022-06-16 07:47:06,926 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:47:06,926 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 07:47:06,933 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 07:47:11,946 - wandb.wandb_agent - INFO - Running runs: ['tuatjlg4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_074712-tuatjlg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-26
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/tuatjlg4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99747
wandb:    train_loss 0.01668
wandb: training_time 3.22677
wandb:        val_f1 0.91
wandb:      val_loss 0.26609
wandb: 
wandb: Synced wise-sweep-26: https://wandb.ai/jah377/sff_pubmed/runs/tuatjlg4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_074712-tuatjlg4/logs
2022-06-16 08:10:34,112 - wandb.wandb_agent - INFO - Cleaning up finished run: tuatjlg4
2022-06-16 08:10:34,565 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:10:34,566 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 08:10:34,573 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 08:10:39,583 - wandb.wandb_agent - INFO - Running runs: ['6g85zur0']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_081038-6g85zur0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-27
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/6g85zur0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9737
wandb:    train_loss 0.07641
wandb: training_time 4.07125
wandb:        val_f1 0.926
wandb:      val_loss 0.24242
wandb: 
wandb: Synced devoted-sweep-27: https://wandb.ai/jah377/sff_pubmed/runs/6g85zur0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_081038-6g85zur0/logs
2022-06-16 08:38:34,024 - wandb.wandb_agent - INFO - Cleaning up finished run: 6g85zur0
2022-06-16 08:38:34,449 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:38:34,450 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 08:38:34,456 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 08:38:39,467 - wandb.wandb_agent - INFO - Running runs: ['gxf8nfna']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_083839-gxf8nfna
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-28
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/gxf8nfna
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.49637
wandb:    train_loss 1.05338
wandb: training_time 1.74759
wandb:        val_f1 0.496
wandb:      val_loss 1.04767
wandb: 
wandb: Synced comfy-sweep-28: https://wandb.ai/jah377/sff_pubmed/runs/gxf8nfna
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_083839-gxf8nfna/logs
2022-06-16 08:52:09,589 - wandb.wandb_agent - INFO - Cleaning up finished run: gxf8nfna
2022-06-16 08:52:10,033 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:52:10,033 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 08:52:10,041 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 08:52:15,056 - wandb.wandb_agent - INFO - Running runs: ['nhqv4epu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_085215-nhqv4epu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-29
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/nhqv4epu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96759
wandb:    train_loss 0.09364
wandb: training_time 4.95344
wandb:        val_f1 0.926
wandb:      val_loss 0.23101
wandb: 
wandb: Synced swift-sweep-29: https://wandb.ai/jah377/sff_pubmed/runs/nhqv4epu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_085215-nhqv4epu/logs
2022-06-16 09:24:44,657 - wandb.wandb_agent - INFO - Cleaning up finished run: nhqv4epu
2022-06-16 09:24:45,119 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:24:45,119 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 09:24:45,127 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 09:24:50,139 - wandb.wandb_agent - INFO - Running runs: ['of61b6a9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_092450-of61b6a9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-30
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/of61b6a9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96479
wandb:    train_loss 0.09246
wandb: training_time 2.21173
wandb:        val_f1 0.918
wandb:      val_loss 0.28245
wandb: 
wandb: Synced treasured-sweep-30: https://wandb.ai/jah377/sff_pubmed/runs/of61b6a9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_092450-of61b6a9/logs
2022-06-16 09:41:27,408 - wandb.wandb_agent - INFO - Cleaning up finished run: of61b6a9
2022-06-16 09:41:28,619 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:41:28,620 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 09:41:28,627 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 09:41:33,639 - wandb.wandb_agent - INFO - Running runs: ['3a6z9ero']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_094133-3a6z9ero
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-31
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/3a6z9ero
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9836
wandb:    train_loss 0.05367
wandb: training_time 2.42801
wandb:        val_f1 0.92
wandb:      val_loss 0.27435
wandb: 
wandb: Synced daily-sweep-31: https://wandb.ai/jah377/sff_pubmed/runs/3a6z9ero
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_094133-3a6z9ero/logs
2022-06-16 09:59:11,337 - wandb.wandb_agent - INFO - Cleaning up finished run: 3a6z9ero
2022-06-16 09:59:11,984 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:59:11,984 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 09:59:11,990 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 09:59:17,004 - wandb.wandb_agent - INFO - Running runs: ['lc58m4f7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_095917-lc58m4f7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-32
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/lc58m4f7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91769
wandb:    train_loss 0.21455
wandb: training_time 2.01646
wandb:        val_f1 0.912
wandb:      val_loss 0.24684
wandb: 
wandb: Synced avid-sweep-32: https://wandb.ai/jah377/sff_pubmed/runs/lc58m4f7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_095917-lc58m4f7/logs
2022-06-16 10:15:21,768 - wandb.wandb_agent - INFO - Cleaning up finished run: lc58m4f7
2022-06-16 10:15:22,380 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:15:22,381 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 10:15:22,389 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 10:15:27,399 - wandb.wandb_agent - INFO - Running runs: ['9rh7bdxn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_101527-9rh7bdxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-33
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/9rh7bdxn
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97486
wandb:    train_loss 0.08013
wandb: training_time 4.41513
wandb:        val_f1 0.91
wandb:      val_loss 0.29344
wandb: 
wandb: Synced devoted-sweep-33: https://wandb.ai/jah377/sff_pubmed/runs/9rh7bdxn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_101527-9rh7bdxn/logs
2022-06-16 10:45:31,049 - wandb.wandb_agent - INFO - Cleaning up finished run: 9rh7bdxn
2022-06-16 10:45:31,741 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:45:31,742 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 10:45:31,748 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 10:45:36,759 - wandb.wandb_agent - INFO - Running runs: ['ql41cjc7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_104536-ql41cjc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-34
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ql41cjc7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92787
wandb:    train_loss 0.18896
wandb: training_time 4.13831
wandb:        val_f1 0.91
wandb:      val_loss 0.24608
wandb: 
wandb: Synced hopeful-sweep-34: https://wandb.ai/jah377/sff_pubmed/runs/ql41cjc7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_104536-ql41cjc7/logs
2022-06-16 11:14:32,924 - wandb.wandb_agent - INFO - Cleaning up finished run: ql41cjc7
2022-06-16 11:14:33,395 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:14:33,395 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 11:14:33,403 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 11:14:38,417 - wandb.wandb_agent - INFO - Running runs: ['mk99qe97']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_111438-mk99qe97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-35
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/mk99qe97
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99065
wandb:    train_loss 0.04083
wandb: training_time 0.7353
wandb:        val_f1 0.908
wandb:      val_loss 0.29081
wandb: 
wandb: Synced hearty-sweep-35: https://wandb.ai/jah377/sff_pubmed/runs/mk99qe97
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_111438-mk99qe97/logs
2022-06-16 11:21:40,806 - wandb.wandb_agent - INFO - Cleaning up finished run: mk99qe97
2022-06-16 11:21:41,333 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:21:41,333 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 11:21:41,339 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 11:21:46,353 - wandb.wandb_agent - INFO - Running runs: ['8n01bt1d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_112146-8n01bt1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-36
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/8n01bt1d
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98471
wandb:    train_loss 0.0487
wandb: training_time 3.05934
wandb:        val_f1 0.906
wandb:      val_loss 0.27072
wandb: 
wandb: Synced divine-sweep-36: https://wandb.ai/jah377/sff_pubmed/runs/8n01bt1d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_112146-8n01bt1d/logs
2022-06-16 11:44:01,962 - wandb.wandb_agent - INFO - Cleaning up finished run: 8n01bt1d
2022-06-16 11:44:02,683 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:44:02,684 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 11:44:02,692 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 11:44:07,706 - wandb.wandb_agent - INFO - Running runs: ['cunwt2u8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_114407-cunwt2u8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-37
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/cunwt2u8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9984
wandb:    train_loss 0.00972
wandb: training_time 3.68759
wandb:        val_f1 0.904
wandb:      val_loss 0.35925
wandb: 
wandb: Synced golden-sweep-37: https://wandb.ai/jah377/sff_pubmed/runs/cunwt2u8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_114407-cunwt2u8/logs
2022-06-16 12:10:12,311 - wandb.wandb_agent - INFO - Cleaning up finished run: cunwt2u8
2022-06-16 12:10:13,043 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:10:13,043 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 12:10:13,050 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 12:10:18,064 - wandb.wandb_agent - INFO - Running runs: ['v974ufv6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_121018-v974ufv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-38
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/v974ufv6
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87252
wandb:    train_loss 0.34855
wandb: training_time 2.52389
wandb:        val_f1 0.87
wandb:      val_loss 0.34352
wandb: 
wandb: Synced silvery-sweep-38: https://wandb.ai/jah377/sff_pubmed/runs/v974ufv6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_121018-v974ufv6/logs
2022-06-16 12:29:07,035 - wandb.wandb_agent - INFO - Cleaning up finished run: v974ufv6
2022-06-16 12:29:07,516 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:29:07,516 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 12:29:07,524 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 12:29:12,535 - wandb.wandb_agent - INFO - Running runs: ['j1mbjfly']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_122912-j1mbjfly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-39
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/j1mbjfly
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97568
wandb:    train_loss 0.07007
wandb: training_time 2.20336
wandb:        val_f1 0.93
wandb:      val_loss 0.23986
wandb: 
wandb: Synced apricot-sweep-39: https://wandb.ai/jah377/sff_pubmed/runs/j1mbjfly
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_122912-j1mbjfly/logs
2022-06-16 12:45:06,895 - wandb.wandb_agent - INFO - Cleaning up finished run: j1mbjfly
2022-06-16 12:45:07,439 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:45:07,439 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 12:45:07,447 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 12:45:12,459 - wandb.wandb_agent - INFO - Running runs: ['9zrdwko3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_124512-9zrdwko3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-40
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/9zrdwko3
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93612
wandb:    train_loss 0.16808
wandb: training_time 2.54636
wandb:        val_f1 0.908
wandb:      val_loss 0.23279
wandb: 
wandb: Synced proud-sweep-40: https://wandb.ai/jah377/sff_pubmed/runs/9zrdwko3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_124512-9zrdwko3/logs
2022-06-16 13:03:22,032 - wandb.wandb_agent - INFO - Cleaning up finished run: 9zrdwko3
2022-06-16 13:03:22,730 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:03:22,731 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 13:03:22,737 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 13:03:27,747 - wandb.wandb_agent - INFO - Running runs: ['ps0w07g4']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_130327-ps0w07g4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-41
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ps0w07g4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91087
wandb:    train_loss 0.23017
wandb: training_time 4.73623
wandb:        val_f1 0.912
wandb:      val_loss 0.23503
wandb: 
wandb: Synced vivid-sweep-41: https://wandb.ai/jah377/sff_pubmed/runs/ps0w07g4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_130327-ps0w07g4/logs
2022-06-16 13:34:49,283 - wandb.wandb_agent - INFO - Cleaning up finished run: ps0w07g4
2022-06-16 13:34:49,824 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:34:49,824 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 13:34:49,832 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 13:34:54,843 - wandb.wandb_agent - INFO - Running runs: ['cs0hpozj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_133454-cs0hpozj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-42
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/cs0hpozj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88831
wandb:    train_loss 0.30224
wandb: training_time 1.51605
wandb:        val_f1 0.896
wandb:      val_loss 0.29612
wandb: 
wandb: Synced likely-sweep-42: https://wandb.ai/jah377/sff_pubmed/runs/cs0hpozj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_133454-cs0hpozj/logs
2022-06-16 13:47:17,069 - wandb.wandb_agent - INFO - Cleaning up finished run: cs0hpozj
2022-06-16 13:47:17,942 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:47:17,943 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 13:47:17,949 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 13:47:22,962 - wandb.wandb_agent - INFO - Running runs: ['w33lyfgi']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_134723-w33lyfgi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-43
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/w33lyfgi
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97761
wandb:    train_loss 0.06723
wandb: training_time 2.96463
wandb:        val_f1 0.916
wandb:      val_loss 0.25454
wandb: 
wandb: Synced amber-sweep-43: https://wandb.ai/jah377/sff_pubmed/runs/w33lyfgi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_134723-w33lyfgi/logs
2022-06-16 14:07:58,072 - wandb.wandb_agent - INFO - Cleaning up finished run: w33lyfgi
2022-06-16 14:07:58,664 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:07:58,665 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 14:07:58,671 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 14:08:03,685 - wandb.wandb_agent - INFO - Running runs: ['qkwlhif0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_140803-qkwlhif0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-44
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/qkwlhif0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85453
wandb:    train_loss 6.65482
wandb: training_time 1.65383
wandb:        val_f1 0.87
wandb:      val_loss 6.14714
wandb: 
wandb: Synced solar-sweep-44: https://wandb.ai/jah377/sff_pubmed/runs/qkwlhif0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_140803-qkwlhif0/logs
2022-06-16 14:20:37,955 - wandb.wandb_agent - INFO - Cleaning up finished run: qkwlhif0
2022-06-16 14:20:38,485 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:20:38,485 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 14:20:38,491 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 14:20:43,504 - wandb.wandb_agent - INFO - Running runs: ['ui1z5qus']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_142043-ui1z5qus
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-45
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ui1z5qus
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98085
wandb:    train_loss 0.062
wandb: training_time 2.18269
wandb:        val_f1 0.918
wandb:      val_loss 0.25335
wandb: 
wandb: Synced unique-sweep-45: https://wandb.ai/jah377/sff_pubmed/runs/ui1z5qus
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_142043-ui1z5qus/logs
2022-06-16 14:36:53,082 - wandb.wandb_agent - INFO - Cleaning up finished run: ui1z5qus
2022-06-16 14:36:53,611 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:36:53,611 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 14:36:53,618 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 14:36:58,632 - wandb.wandb_agent - INFO - Running runs: ['s732jvog']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_143658-s732jvog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-46
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/s732jvog
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3974
wandb:    train_loss 1.08374
wandb: training_time 0.48922
wandb:        val_f1 0.416
wandb:      val_loss 1.0815
wandb: 
wandb: Synced azure-sweep-46: https://wandb.ai/jah377/sff_pubmed/runs/s732jvog
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_143658-s732jvog/logs
2022-06-16 14:42:19,163 - wandb.wandb_agent - INFO - Cleaning up finished run: s732jvog
2022-06-16 14:42:19,603 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:42:19,604 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 14:42:19,610 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 14:42:24,623 - wandb.wandb_agent - INFO - Running runs: ['yeo71jtu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_144224-yeo71jtu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-47
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/yeo71jtu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9189
wandb:    train_loss 0.23552
wandb: training_time 0.5748
wandb:        val_f1 0.892
wandb:      val_loss 0.285
wandb: 
wandb: Synced ruby-sweep-47: https://wandb.ai/jah377/sff_pubmed/runs/yeo71jtu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_144224-yeo71jtu/logs
2022-06-16 14:48:30,394 - wandb.wandb_agent - INFO - Cleaning up finished run: yeo71jtu
2022-06-16 14:48:31,073 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:48:31,073 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 14:48:31,079 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 14:48:36,093 - wandb.wandb_agent - INFO - Running runs: ['py0bseof']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_144836-py0bseof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-48
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/py0bseof
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8004
wandb:    train_loss 0.65134
wandb: training_time 2.24945
wandb:        val_f1 0.832
wandb:      val_loss 0.65157
wandb: 
wandb: Synced crimson-sweep-48: https://wandb.ai/jah377/sff_pubmed/runs/py0bseof
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_144836-py0bseof/logs
2022-06-16 15:06:44,696 - wandb.wandb_agent - INFO - Cleaning up finished run: py0bseof
2022-06-16 15:06:45,162 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:06:45,163 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 15:06:45,169 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 15:06:50,184 - wandb.wandb_agent - INFO - Running runs: ['tkkct8s3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_150650-tkkct8s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-49
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/tkkct8s3
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.66272
wandb:    train_loss 0.98187
wandb: training_time 0.75176
wandb:        val_f1 0.674
wandb:      val_loss 0.98089
wandb: 
wandb: Synced rural-sweep-49: https://wandb.ai/jah377/sff_pubmed/runs/tkkct8s3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_150650-tkkct8s3/logs
2022-06-16 15:13:17,167 - wandb.wandb_agent - INFO - Cleaning up finished run: tkkct8s3
2022-06-16 15:13:17,956 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:13:17,956 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 15:13:17,964 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 15:13:22,978 - wandb.wandb_agent - INFO - Running runs: ['g59ef9on']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_151323-g59ef9on
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-50
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/g59ef9on
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99543
wandb:    train_loss 0.02729
wandb: training_time 1.98542
wandb:        val_f1 0.908
wandb:      val_loss 0.28
wandb: 
wandb: Synced young-sweep-50: https://wandb.ai/jah377/sff_pubmed/runs/g59ef9on
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_151323-g59ef9on/logs
2022-06-16 15:29:43,307 - wandb.wandb_agent - INFO - Cleaning up finished run: g59ef9on
2022-06-16 15:29:43,814 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:29:43,815 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 15:29:43,821 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 15:29:48,835 - wandb.wandb_agent - INFO - Running runs: ['5a1l2u2x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_152948-5a1l2u2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-sweep-51
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/5a1l2u2x
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39771
wandb:    train_loss 1.08615
wandb: training_time 0.48227
wandb:        val_f1 0.388
wandb:      val_loss 1.08551
wandb: 
wandb: Synced quiet-sweep-51: https://wandb.ai/jah377/sff_pubmed/runs/5a1l2u2x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_152948-5a1l2u2x/logs
2022-06-16 15:35:39,579 - wandb.wandb_agent - INFO - Cleaning up finished run: 5a1l2u2x
2022-06-16 15:35:40,108 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:35:40,108 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 15:35:40,115 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 15:35:45,128 - wandb.wandb_agent - INFO - Running runs: ['g36yg0rq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_153545-g36yg0rq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-52
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/g36yg0rq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99274
wandb:    train_loss 0.0367
wandb: training_time 0.93702
wandb:        val_f1 0.918
wandb:      val_loss 0.26731
wandb: 
wandb: Synced dulcet-sweep-52: https://wandb.ai/jah377/sff_pubmed/runs/g36yg0rq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_153545-g36yg0rq/logs
2022-06-16 15:43:55,687 - wandb.wandb_agent - INFO - Cleaning up finished run: g36yg0rq
2022-06-16 15:43:56,317 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:43:56,317 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 15:43:56,324 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 15:44:01,337 - wandb.wandb_agent - INFO - Running runs: ['404c240s']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_154401-404c240s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-53
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/404c240s
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88092
wandb:    train_loss 0.513
wandb: training_time 0.50491
wandb:        val_f1 0.89
wandb:      val_loss 0.50596
wandb: 
wandb: Synced dry-sweep-53: https://wandb.ai/jah377/sff_pubmed/runs/404c240s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_154401-404c240s/logs
2022-06-16 15:49:42,203 - wandb.wandb_agent - INFO - Cleaning up finished run: 404c240s
2022-06-16 15:49:42,851 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:49:42,851 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 15:49:42,859 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 15:49:47,872 - wandb.wandb_agent - INFO - Running runs: ['37qwvzv5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_154947-37qwvzv5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-54
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/37qwvzv5
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67917
wandb:    train_loss 0.95734
wandb: training_time 0.54855
wandb:        val_f1 0.67
wandb:      val_loss 0.95173
wandb: 
wandb: Synced ancient-sweep-54: https://wandb.ai/jah377/sff_pubmed/runs/37qwvzv5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_154947-37qwvzv5/logs
2022-06-16 15:55:28,246 - wandb.wandb_agent - INFO - Cleaning up finished run: 37qwvzv5
2022-06-16 15:55:28,861 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:55:28,861 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 15:55:28,868 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 15:55:33,881 - wandb.wandb_agent - INFO - Running runs: ['t6j18n1m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_155534-t6j18n1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-55
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/t6j18n1m
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40895
wandb:    train_loss 1.04754
wandb: training_time 3.13768
wandb:        val_f1 0.416
wandb:      val_loss 1.04827
wandb: 
wandb: Synced fresh-sweep-55: https://wandb.ai/jah377/sff_pubmed/runs/t6j18n1m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_155534-t6j18n1m/logs
2022-06-16 16:16:17,895 - wandb.wandb_agent - INFO - Cleaning up finished run: t6j18n1m
2022-06-16 16:16:18,663 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:16:18,664 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 16:16:18,670 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 16:16:23,685 - wandb.wandb_agent - INFO - Running runs: ['i92pl4h2']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_161623-i92pl4h2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-56
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/i92pl4h2
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97871
wandb:    train_loss 0.06591
wandb: training_time 2.07483
wandb:        val_f1 0.918
wandb:      val_loss 0.25615
wandb: 
wandb: Synced confused-sweep-56: https://wandb.ai/jah377/sff_pubmed/runs/i92pl4h2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_161623-i92pl4h2/logs
2022-06-16 16:31:46,771 - wandb.wandb_agent - INFO - Cleaning up finished run: i92pl4h2
2022-06-16 16:31:47,267 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:31:47,268 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 16:31:47,276 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 16:31:52,287 - wandb.wandb_agent - INFO - Running runs: ['n68w7ulo']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_163152-n68w7ulo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-57
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/n68w7ulo
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3986
wandb:    train_loss 1.07766
wandb: training_time 0.57486
wandb:        val_f1 0.416
wandb:      val_loss 1.07482
wandb: 
wandb: Synced bright-sweep-57: https://wandb.ai/jah377/sff_pubmed/runs/n68w7ulo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_163152-n68w7ulo/logs
2022-06-16 16:37:53,180 - wandb.wandb_agent - INFO - Cleaning up finished run: n68w7ulo
2022-06-16 16:37:53,677 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:37:53,677 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 16:37:53,685 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 16:37:58,699 - wandb.wandb_agent - INFO - Running runs: ['00votqyb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_163758-00votqyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-58
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/00votqyb
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86939
wandb:    train_loss 0.52526
wandb: training_time 3.32703
wandb:        val_f1 0.882
wandb:      val_loss 0.50338
wandb: 
wandb: Synced grateful-sweep-58: https://wandb.ai/jah377/sff_pubmed/runs/00votqyb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_163758-00votqyb/logs
2022-06-16 17:02:07,057 - wandb.wandb_agent - INFO - Cleaning up finished run: 00votqyb
2022-06-16 17:02:07,628 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:02:07,628 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 17:02:07,635 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 17:02:12,648 - wandb.wandb_agent - INFO - Running runs: ['6yx5y4qa']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_170212-6yx5y4qa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-59
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/6yx5y4qa
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85987
wandb:    train_loss 0.36391
wandb: training_time 1.59502
wandb:        val_f1 0.87
wandb:      val_loss 0.3314
wandb: 
wandb: Synced sweet-sweep-59: https://wandb.ai/jah377/sff_pubmed/runs/6yx5y4qa
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_170212-6yx5y4qa/logs
2022-06-16 17:14:36,533 - wandb.wandb_agent - INFO - Cleaning up finished run: 6yx5y4qa
2022-06-16 17:14:37,060 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:14:37,061 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 17:14:37,068 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 17:14:42,079 - wandb.wandb_agent - INFO - Running runs: ['7ocvrl45']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_171441-7ocvrl45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-60
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/7ocvrl45
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86284
wandb:    train_loss 0.43158
wandb: training_time 1.63208
wandb:        val_f1 0.872
wandb:      val_loss 0.40385
wandb: 
wandb: Synced northern-sweep-60: https://wandb.ai/jah377/sff_pubmed/runs/7ocvrl45
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_171441-7ocvrl45/logs
2022-06-16 17:27:32,351 - wandb.wandb_agent - INFO - Cleaning up finished run: 7ocvrl45
2022-06-16 17:27:32,830 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:27:32,830 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 17:27:32,839 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 17:27:37,853 - wandb.wandb_agent - INFO - Running runs: ['m1qtdpwm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_172737-m1qtdpwm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-61
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/m1qtdpwm
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.9178
wandb:    train_loss 0.22699
wandb: training_time 0.41897
wandb:        val_f1 0.906
wandb:      val_loss 0.25474
wandb: 
wandb: Synced super-sweep-61: https://wandb.ai/jah377/sff_pubmed/runs/m1qtdpwm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_172737-m1qtdpwm/logs
2022-06-16 17:32:22,388 - wandb.wandb_agent - INFO - Cleaning up finished run: m1qtdpwm
2022-06-16 17:32:23,269 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:32:23,270 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 17:32:23,275 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 17:32:28,289 - wandb.wandb_agent - INFO - Running runs: ['22rbdfyj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_173228-22rbdfyj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-62
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/22rbdfyj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68273
wandb:    train_loss 0.9286
wandb: training_time 0.34278
wandb:        val_f1 0.688
wandb:      val_loss 0.92372
wandb: 
wandb: Synced olive-sweep-62: https://wandb.ai/jah377/sff_pubmed/runs/22rbdfyj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_173228-22rbdfyj/logs
2022-06-16 17:36:46,555 - wandb.wandb_agent - INFO - Cleaning up finished run: 22rbdfyj
2022-06-16 17:36:47,890 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:36:47,891 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 17:36:47,899 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 17:36:52,913 - wandb.wandb_agent - INFO - Running runs: ['1kspk28x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_173652-1kspk28x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-63
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/1kspk28x
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.82807
wandb:    train_loss 0.47824
wandb: training_time 0.57353
wandb:        val_f1 0.846
wandb:      val_loss 0.4588
wandb: 
wandb: Synced charmed-sweep-63: https://wandb.ai/jah377/sff_pubmed/runs/1kspk28x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_173652-1kspk28x/logs
2022-06-16 17:43:00,771 - wandb.wandb_agent - INFO - Cleaning up finished run: 1kspk28x
2022-06-16 17:43:01,304 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:43:01,305 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 17:43:01,311 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 17:43:06,324 - wandb.wandb_agent - INFO - Running runs: ['lpllftvp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_174306-lpllftvp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-64
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/lpllftvp
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92402
wandb:    train_loss 0.20833
wandb: training_time 1.26333
wandb:        val_f1 0.896
wandb:      val_loss 0.27095
wandb: 
wandb: Synced dainty-sweep-64: https://wandb.ai/jah377/sff_pubmed/runs/lpllftvp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_174306-lpllftvp/logs
2022-06-16 17:53:30,523 - wandb.wandb_agent - INFO - Cleaning up finished run: lpllftvp
2022-06-16 17:53:31,120 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:53:31,120 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 17:53:31,127 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 17:53:36,139 - wandb.wandb_agent - INFO - Running runs: ['gj8ddawp']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_175336-gj8ddawp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-65
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/gj8ddawp
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93959
wandb:    train_loss 0.17245
wandb: training_time 0.92792
wandb:        val_f1 0.92
wandb:      val_loss 0.23837
wandb: 
wandb: Synced hardy-sweep-65: https://wandb.ai/jah377/sff_pubmed/runs/gj8ddawp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_175336-gj8ddawp/logs
2022-06-16 18:01:52,185 - wandb.wandb_agent - INFO - Cleaning up finished run: gj8ddawp
2022-06-16 18:01:52,734 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:01:52,734 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 18:01:52,742 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 18:01:57,751 - wandb.wandb_agent - INFO - Running runs: ['ykmyva55']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_180157-ykmyva55
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-66
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ykmyva55
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93834
wandb:    train_loss 0.17451
wandb: training_time 0.45159
wandb:        val_f1 0.882
wandb:      val_loss 0.2712
wandb: 
wandb: Synced usual-sweep-66: https://wandb.ai/jah377/sff_pubmed/runs/ykmyva55
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_180157-ykmyva55/logs
2022-06-16 18:06:56,819 - wandb.wandb_agent - INFO - Cleaning up finished run: ykmyva55
2022-06-16 18:06:57,307 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:06:57,307 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 18:06:57,313 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 18:07:02,327 - wandb.wandb_agent - INFO - Running runs: ['ldmugc13']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_180702-ldmugc13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-67
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ldmugc13
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92584
wandb:    train_loss 0.21028
wandb: training_time 0.64905
wandb:        val_f1 0.926
wandb:      val_loss 0.24838
wandb: 
wandb: Synced treasured-sweep-67: https://wandb.ai/jah377/sff_pubmed/runs/ldmugc13
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_180702-ldmugc13/logs
2022-06-16 18:13:35,446 - wandb.wandb_agent - INFO - Cleaning up finished run: ldmugc13
2022-06-16 18:13:36,057 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:13:36,058 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 18:13:36,065 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 18:13:41,075 - wandb.wandb_agent - INFO - Running runs: ['2ck8lbgh']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_181341-2ck8lbgh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-68
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/2ck8lbgh
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4742
wandb:    train_loss 1.02562
wandb: training_time 0.97441
wandb:        val_f1 0.494
wandb:      val_loss 1.00161
wandb: 
wandb: Synced sage-sweep-68: https://wandb.ai/jah377/sff_pubmed/runs/2ck8lbgh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_181341-2ck8lbgh/logs
2022-06-16 18:22:02,887 - wandb.wandb_agent - INFO - Cleaning up finished run: 2ck8lbgh
2022-06-16 18:22:03,433 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:22:03,434 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 18:22:03,439 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 18:22:08,452 - wandb.wandb_agent - INFO - Running runs: ['hhytyj0g']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_182208-hhytyj0g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-69
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/hhytyj0g
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.83354
wandb:    train_loss 0.42803
wandb: training_time 0.49583
wandb:        val_f1 0.838
wandb:      val_loss 0.4423
wandb: 
wandb: Synced fanciful-sweep-69: https://wandb.ai/jah377/sff_pubmed/runs/hhytyj0g
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_182208-hhytyj0g/logs
2022-06-16 18:27:36,097 - wandb.wandb_agent - INFO - Cleaning up finished run: hhytyj0g
2022-06-16 18:27:37,240 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:27:37,240 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 18:27:37,247 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 18:27:42,260 - wandb.wandb_agent - INFO - Running runs: ['5okgvnij']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_182742-5okgvnij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-70
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/5okgvnij
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98344
wandb:    train_loss 0.06233
wandb: training_time 0.86221
wandb:        val_f1 0.91
wandb:      val_loss 0.25584
wandb: 
wandb: Synced fiery-sweep-70: https://wandb.ai/jah377/sff_pubmed/runs/5okgvnij
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_182742-5okgvnij/logs
2022-06-16 18:35:29,573 - wandb.wandb_agent - INFO - Cleaning up finished run: 5okgvnij
2022-06-16 18:35:30,138 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:35:30,138 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 18:35:30,146 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 18:35:35,159 - wandb.wandb_agent - INFO - Running runs: ['7ratljt2']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_183535-7ratljt2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-71
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/7ratljt2
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88782
wandb:    train_loss 0.30561
wandb: training_time 0.75193
wandb:        val_f1 0.872
wandb:      val_loss 0.34182
wandb: 
wandb: Synced feasible-sweep-71: https://wandb.ai/jah377/sff_pubmed/runs/7ratljt2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_183535-7ratljt2/logs
2022-06-16 18:42:40,115 - wandb.wandb_agent - INFO - Cleaning up finished run: 7ratljt2
2022-06-16 18:42:40,710 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:42:40,710 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 18:42:40,718 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 18:42:45,732 - wandb.wandb_agent - INFO - Running runs: ['bhtjo97v']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_184245-bhtjo97v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-72
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/bhtjo97v
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88666
wandb:    train_loss 0.31401
wandb: training_time 0.53925
wandb:        val_f1 0.898
wandb:      val_loss 0.29781
wandb: 
wandb: Synced feasible-sweep-72: https://wandb.ai/jah377/sff_pubmed/runs/bhtjo97v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_184245-bhtjo97v/logs
2022-06-16 18:48:41,789 - wandb.wandb_agent - INFO - Cleaning up finished run: bhtjo97v
2022-06-16 18:48:42,807 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:48:42,807 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 18:48:42,815 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 18:48:47,827 - wandb.wandb_agent - INFO - Running runs: ['zsngtitu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_184847-zsngtitu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-73
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/zsngtitu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39866
wandb:    train_loss 1.06485
wandb: training_time 0.89999
wandb:        val_f1 0.416
wandb:      val_loss 1.05866
wandb: 
wandb: Synced easy-sweep-73: https://wandb.ai/jah377/sff_pubmed/runs/zsngtitu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_184847-zsngtitu/logs
2022-06-16 18:57:31,631 - wandb.wandb_agent - INFO - Cleaning up finished run: zsngtitu
2022-06-16 18:57:32,119 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:57:32,120 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 18:57:32,128 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 18:57:37,139 - wandb.wandb_agent - INFO - Running runs: ['eap1xqrr']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_185737-eap1xqrr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-74
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/eap1xqrr
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.66637
wandb:    train_loss 0.93171
wandb: training_time 0.91665
wandb:        val_f1 0.664
wandb:      val_loss 0.92901
wandb: 
wandb: Synced polar-sweep-74: https://wandb.ai/jah377/sff_pubmed/runs/eap1xqrr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_185737-eap1xqrr/logs
2022-06-16 19:05:30,224 - wandb.wandb_agent - INFO - Cleaning up finished run: eap1xqrr
2022-06-16 19:05:30,902 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:05:30,903 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 19:05:30,910 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 19:05:35,923 - wandb.wandb_agent - INFO - Running runs: ['bvqm7aj8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_190536-bvqm7aj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-75
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/bvqm7aj8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92963
wandb:    train_loss 0.19156
wandb: training_time 1.04655
wandb:        val_f1 0.922
wandb:      val_loss 0.23224
wandb: 
wandb: Synced rosy-sweep-75: https://wandb.ai/jah377/sff_pubmed/runs/bvqm7aj8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_190536-bvqm7aj8/logs
2022-06-16 19:15:40,585 - wandb.wandb_agent - INFO - Cleaning up finished run: bvqm7aj8
2022-06-16 19:15:41,102 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:15:41,102 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 19:15:41,110 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 19:15:46,123 - wandb.wandb_agent - INFO - Running runs: ['4kvsx6qu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_191546-4kvsx6qu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-76
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/4kvsx6qu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98995
wandb:    train_loss 0.04249
wandb: training_time 0.43938
wandb:        val_f1 0.928
wandb:      val_loss 0.23502
wandb: 
wandb: Synced spring-sweep-76: https://wandb.ai/jah377/sff_pubmed/runs/4kvsx6qu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_191546-4kvsx6qu/logs
2022-06-16 19:20:40,627 - wandb.wandb_agent - INFO - Cleaning up finished run: 4kvsx6qu
2022-06-16 19:20:41,140 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:20:41,141 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 19:20:41,146 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 19:20:46,160 - wandb.wandb_agent - INFO - Running runs: ['afwnu1ww']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_192046-afwnu1ww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-77
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/afwnu1ww
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.82333
wandb:    train_loss 0.47285
wandb: training_time 0.71648
wandb:        val_f1 0.838
wandb:      val_loss 0.45246
wandb: 
wandb: Synced laced-sweep-77: https://wandb.ai/jah377/sff_pubmed/runs/afwnu1ww
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_192046-afwnu1ww/logs
2022-06-16 19:27:38,799 - wandb.wandb_agent - INFO - Cleaning up finished run: afwnu1ww
2022-06-16 19:27:39,262 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:27:39,262 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 19:27:39,270 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 19:27:44,284 - wandb.wandb_agent - INFO - Running runs: ['c98ggur3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_192744-c98ggur3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-78
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/c98ggur3
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93959
wandb:    train_loss 0.1649
wandb: training_time 2.36663
wandb:        val_f1 0.922
wandb:      val_loss 0.24642
wandb: 
wandb: Synced confused-sweep-78: https://wandb.ai/jah377/sff_pubmed/runs/c98ggur3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_192744-c98ggur3/logs
2022-06-16 19:45:13,434 - wandb.wandb_agent - INFO - Cleaning up finished run: c98ggur3
2022-06-16 19:45:13,927 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:45:13,927 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 19:45:13,935 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 19:45:18,947 - wandb.wandb_agent - INFO - Running runs: ['9hzj2ocb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_194518-9hzj2ocb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-79
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/9hzj2ocb
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91802
wandb:    train_loss 0.2223
wandb: training_time 0.64105
wandb:        val_f1 0.914
wandb:      val_loss 0.23533
wandb: 
wandb: Synced zesty-sweep-79: https://wandb.ai/jah377/sff_pubmed/runs/9hzj2ocb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_194518-9hzj2ocb/logs
2022-06-16 19:51:48,415 - wandb.wandb_agent - INFO - Cleaning up finished run: 9hzj2ocb
2022-06-16 19:51:48,959 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:51:48,960 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 19:51:48,967 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 19:51:53,979 - wandb.wandb_agent - INFO - Running runs: ['8mqyfjoj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_195154-8mqyfjoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-80
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/8mqyfjoj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97909
wandb:    train_loss 0.07316
wandb: training_time 1.8762
wandb:        val_f1 0.918
wandb:      val_loss 0.24116
wandb: 
wandb: Synced genial-sweep-80: https://wandb.ai/jah377/sff_pubmed/runs/8mqyfjoj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_195154-8mqyfjoj/logs
2022-06-16 20:05:53,251 - wandb.wandb_agent - INFO - Cleaning up finished run: 8mqyfjoj
2022-06-16 20:05:53,702 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:05:53,702 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 20:05:53,710 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 20:05:58,723 - wandb.wandb_agent - INFO - Running runs: ['4nhoyg93']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_200558-4nhoyg93
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-81
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/4nhoyg93
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96286
wandb:    train_loss 0.10714
wandb: training_time 2.34879
wandb:        val_f1 0.914
wandb:      val_loss 0.22945
wandb: 
wandb: Synced devout-sweep-81: https://wandb.ai/jah377/sff_pubmed/runs/4nhoyg93
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_200558-4nhoyg93/logs
2022-06-16 20:23:14,011 - wandb.wandb_agent - INFO - Cleaning up finished run: 4nhoyg93
2022-06-16 20:23:14,487 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:23:14,488 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 20:23:14,495 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 20:23:19,508 - wandb.wandb_agent - INFO - Running runs: ['ohmr0rfd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_202319-ohmr0rfd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-82
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/ohmr0rfd
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 512, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88052
wandb:    train_loss 0.32888
wandb: training_time 0.60965
wandb:        val_f1 0.89
wandb:      val_loss 0.31857
wandb: 
wandb: Synced genial-sweep-82: https://wandb.ai/jah377/sff_pubmed/runs/ohmr0rfd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_202319-ohmr0rfd/logs
2022-06-16 20:29:51,533 - wandb.wandb_agent - INFO - Cleaning up finished run: ohmr0rfd
2022-06-16 20:29:52,042 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:29:52,042 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-07
2022-06-16 20:29:52,050 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 20:29:57,064 - wandb.wandb_agent - INFO - Running runs: ['w4bwuz0d']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_202957-w4bwuz0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-83
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/w4bwuz0d
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89924
wandb:    train_loss 0.26924
wandb: training_time 0.3559
wandb:        val_f1 0.908
wandb:      val_loss 0.27981
wandb: 
wandb: Synced good-sweep-83: https://wandb.ai/jah377/sff_pubmed/runs/w4bwuz0d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_202957-w4bwuz0d/logs
2022-06-16 20:34:41,607 - wandb.wandb_agent - INFO - Cleaning up finished run: w4bwuz0d
2022-06-16 20:34:42,112 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:34:42,113 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 20:34:42,119 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 20:34:47,131 - wandb.wandb_agent - INFO - Running runs: ['qvk8rsrz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_203447-qvk8rsrz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-84
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/qvk8rsrz
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90074
wandb:    train_loss 0.26691
wandb: training_time 0.35559
wandb:        val_f1 0.886
wandb:      val_loss 0.30093
wandb: 
wandb: Synced fiery-sweep-84: https://wandb.ai/jah377/sff_pubmed/runs/qvk8rsrz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_203447-qvk8rsrz/logs
2022-06-16 20:39:15,205 - wandb.wandb_agent - INFO - Cleaning up finished run: qvk8rsrz
2022-06-16 20:39:15,744 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:39:15,745 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-05
2022-06-16 20:39:15,751 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 20:39:20,763 - wandb.wandb_agent - INFO - Running runs: ['m71rcdsk']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_203920-m71rcdsk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-85
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/m71rcdsk
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52785
wandb:    train_loss 1.07264
wandb: training_time 0.6845
wandb:        val_f1 0.524
wandb:      val_loss 1.07079
wandb: 
wandb: Synced autumn-sweep-85: https://wandb.ai/jah377/sff_pubmed/runs/m71rcdsk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_203920-m71rcdsk/logs
2022-06-16 20:45:53,418 - wandb.wandb_agent - INFO - Cleaning up finished run: m71rcdsk
2022-06-16 20:45:55,480 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:45:55,480 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 20:45:55,488 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 20:46:00,502 - wandb.wandb_agent - INFO - Running runs: ['3th0d2kp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_204600-3th0d2kp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-86
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/3th0d2kp
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92199
wandb:    train_loss 0.21602
wandb: training_time 2.93999
wandb:        val_f1 0.918
wandb:      val_loss 0.26761
wandb: 
wandb: Synced sweet-sweep-86: https://wandb.ai/jah377/sff_pubmed/runs/3th0d2kp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_204600-3th0d2kp/logs
2022-06-16 21:06:54,412 - wandb.wandb_agent - INFO - Cleaning up finished run: 3th0d2kp
2022-06-16 21:06:54,893 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:06:54,893 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 21:06:54,901 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 21:06:59,914 - wandb.wandb_agent - INFO - Running runs: ['nu9u48x6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_210659-nu9u48x6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-87
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/nu9u48x6
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39833
wandb:    train_loss 1.10148
wandb: training_time 0.49955
wandb:        val_f1 0.416
wandb:      val_loss 1.09902
wandb: 
wandb: Synced classic-sweep-87: https://wandb.ai/jah377/sff_pubmed/runs/nu9u48x6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_210659-nu9u48x6/logs
2022-06-16 21:12:35,357 - wandb.wandb_agent - INFO - Cleaning up finished run: nu9u48x6
2022-06-16 21:12:35,862 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:12:35,862 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 21:12:35,869 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 21:12:40,879 - wandb.wandb_agent - INFO - Running runs: ['wvqrswlr']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_211240-wvqrswlr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-88
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/wvqrswlr
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98636
wandb:    train_loss 0.05422
wandb: training_time 1.24955
wandb:        val_f1 0.92
wandb:      val_loss 0.25446
wandb: 
wandb: Synced rose-sweep-88: https://wandb.ai/jah377/sff_pubmed/runs/wvqrswlr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_211240-wvqrswlr/logs
2022-06-16 21:23:15,043 - wandb.wandb_agent - INFO - Cleaning up finished run: wvqrswlr
2022-06-16 21:23:16,684 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:23:16,685 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 21:23:16,692 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 21:23:21,705 - wandb.wandb_agent - INFO - Running runs: ['5egjpu83']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_212322-5egjpu83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-89
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/5egjpu83
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.41803
wandb:    train_loss 1.08224
wandb: training_time 0.58837
wandb:        val_f1 0.41
wandb:      val_loss 1.082
wandb: 
wandb: Synced major-sweep-89: https://wandb.ai/jah377/sff_pubmed/runs/5egjpu83
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_212322-5egjpu83/logs
2022-06-16 21:29:32,597 - wandb.wandb_agent - INFO - Cleaning up finished run: 5egjpu83
2022-06-16 21:29:33,128 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:29:33,129 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1e-06
2022-06-16 21:29:33,136 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 21:29:38,150 - wandb.wandb_agent - INFO - Running runs: ['2vdau88n']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_212938-2vdau88n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-90
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/2vdau88n
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85018
wandb:    train_loss 0.39873
wandb: training_time 0.45694
wandb:        val_f1 0.862
wandb:      val_loss 0.35971
wandb: 
wandb: Synced fearless-sweep-90: https://wandb.ai/jah377/sff_pubmed/runs/2vdau88n
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_212938-2vdau88n/logs
2022-06-16 21:34:57,906 - wandb.wandb_agent - INFO - Cleaning up finished run: 2vdau88n
2022-06-16 21:34:58,341 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:34:58,341 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 21:34:58,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 21:35:03,363 - wandb.wandb_agent - INFO - Running runs: ['gdxkpjge']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_213503-gdxkpjge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-91
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/gdxkpjge
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89135
wandb:    train_loss 0.33753
wandb: training_time 0.57309
wandb:        val_f1 0.9
wandb:      val_loss 0.33084
wandb: 
wandb: Synced breezy-sweep-91: https://wandb.ai/jah377/sff_pubmed/runs/gdxkpjge
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_213503-gdxkpjge/logs
2022-06-16 21:41:14,394 - wandb.wandb_agent - INFO - Cleaning up finished run: gdxkpjge
2022-06-16 21:41:15,051 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:41:15,052 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 21:41:15,058 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 21:41:20,067 - wandb.wandb_agent - INFO - Running runs: ['1lrdmpwl']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_214120-1lrdmpwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-92
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/1lrdmpwl
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.92507
wandb:    train_loss 0.19896
wandb: training_time 0.87082
wandb:        val_f1 0.922
wandb:      val_loss 0.22989
wandb: 
wandb: Synced balmy-sweep-92: https://wandb.ai/jah377/sff_pubmed/runs/1lrdmpwl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_214120-1lrdmpwl/logs
2022-06-16 21:49:09,871 - wandb.wandb_agent - INFO - Cleaning up finished run: 1lrdmpwl
2022-06-16 21:49:10,433 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:49:10,434 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.001
2022-06-16 21:49:10,441 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 21:49:15,451 - wandb.wandb_agent - INFO - Running runs: ['egw63ed4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_214915-egw63ed4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-93
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/egw63ed4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90752
wandb:    train_loss 0.24349
wandb: training_time 3.06485
wandb:        val_f1 0.906
wandb:      val_loss 0.25293
wandb: 
wandb: Synced lemon-sweep-93: https://wandb.ai/jah377/sff_pubmed/runs/egw63ed4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_214915-egw63ed4/logs
2022-06-16 22:10:34,412 - wandb.wandb_agent - INFO - Cleaning up finished run: egw63ed4
2022-06-16 22:10:34,867 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:10:34,867 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.01
2022-06-16 22:10:34,875 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 22:10:39,888 - wandb.wandb_agent - INFO - Running runs: ['68lzv8wz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_221039-68lzv8wz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-94
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/68lzv8wz
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.80628
wandb:    train_loss 0.71368
wandb: training_time 0.54434
wandb:        val_f1 0.81
wandb:      val_loss 0.71037
wandb: 
wandb: Synced clear-sweep-94: https://wandb.ai/jah377/sff_pubmed/runs/68lzv8wz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_221039-68lzv8wz/logs
2022-06-16 22:16:40,585 - wandb.wandb_agent - INFO - Cleaning up finished run: 68lzv8wz
2022-06-16 22:16:41,130 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:16:41,131 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 22:16:41,137 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 22:16:46,150 - wandb.wandb_agent - INFO - Running runs: ['xj66rqk7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_221646-xj66rqk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-95
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/xj66rqk7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95621
wandb:    train_loss 0.12078
wandb: training_time 0.68179
wandb:        val_f1 0.922
wandb:      val_loss 0.25415
wandb: 
wandb: Synced deep-sweep-95: https://wandb.ai/jah377/sff_pubmed/runs/xj66rqk7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_221646-xj66rqk7/logs
2022-06-16 22:23:33,779 - wandb.wandb_agent - INFO - Cleaning up finished run: xj66rqk7
2022-06-16 22:23:34,305 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:23:34,306 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 22:23:34,313 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 22:23:39,326 - wandb.wandb_agent - INFO - Running runs: ['h5ms4bdk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_222339-h5ms4bdk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-96
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/h5ms4bdk
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39838
wandb:    train_loss 1.0642
wandb: training_time 0.91651
wandb:        val_f1 0.416
wandb:      val_loss 1.0576
wandb: 
wandb: Synced vital-sweep-96: https://wandb.ai/jah377/sff_pubmed/runs/h5ms4bdk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_222339-h5ms4bdk/logs
2022-06-16 22:32:09,365 - wandb.wandb_agent - INFO - Cleaning up finished run: h5ms4bdk
2022-06-16 22:32:18,430 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:32:18,431 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.1
2022-06-16 22:32:18,437 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 22:32:23,450 - wandb.wandb_agent - INFO - Running runs: ['pwh0d3op']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_223223-pwh0d3op
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-97
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/pwh0d3op
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39855
wandb:    train_loss 1.06404
wandb: training_time 1.83027
wandb:        val_f1 0.416
wandb:      val_loss 1.05763
wandb: 
wandb: Synced celestial-sweep-97: https://wandb.ai/jah377/sff_pubmed/runs/pwh0d3op
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_223223-pwh0d3op/logs
2022-06-16 22:46:34,077 - wandb.wandb_agent - INFO - Cleaning up finished run: pwh0d3op
2022-06-16 22:46:34,774 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:46:34,775 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 22:46:34,782 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 22:46:39,796 - wandb.wandb_agent - INFO - Running runs: ['723utzwf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_224639-723utzwf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-98
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/723utzwf
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39878
wandb:    train_loss 1.08348
wandb: training_time 0.41739
wandb:        val_f1 0.416
wandb:      val_loss 1.0814
wandb: 
wandb: Synced clear-sweep-98: https://wandb.ai/jah377/sff_pubmed/runs/723utzwf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_224639-723utzwf/logs
2022-06-16 22:51:28,697 - wandb.wandb_agent - INFO - Cleaning up finished run: 723utzwf
2022-06-16 22:51:29,131 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:51:29,131 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 1
2022-06-16 22:51:29,138 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 22:51:34,151 - wandb.wandb_agent - INFO - Running runs: ['q5yrfhcx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_225134-q5yrfhcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-99
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/q5yrfhcx
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.34013
wandb:    train_loss 1.10994
wandb: training_time 0.45662
wandb:        val_f1 0.376
wandb:      val_loss 1.11001
wandb: 
wandb: Synced solar-sweep-99: https://wandb.ai/jah377/sff_pubmed/runs/q5yrfhcx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_225134-q5yrfhcx/logs
2022-06-16 22:56:53,699 - wandb.wandb_agent - INFO - Cleaning up finished run: q5yrfhcx
2022-06-16 22:56:54,198 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:56:54,198 - wandb.wandb_agent - INFO - Agent starting run with config:
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	WEIGHT_DECAY: 0.0001
2022-06-16 22:56:54,204 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff.py --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 22:56:59,218 - wandb.wandb_agent - INFO - Running runs: ['k6u5yjw6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sff_pubmed/wandb/run-20220616_225659-k6u5yjw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-100
wandb:  View project at https://wandb.ai/jah377/sff_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb:  View run at https://wandb.ai/jah377/sff_pubmed/runs/k6u5yjw6
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96138
wandb:    train_loss 0.1217
wandb: training_time 1.07509
wandb:        val_f1 0.902
wandb:      val_loss 0.27921
wandb: 
wandb: Synced jolly-sweep-100: https://wandb.ai/jah377/sff_pubmed/runs/k6u5yjw6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_225659-k6u5yjw6/logs
2022-06-16 23:06:36,108 - wandb.wandb_agent - INFO - Cleaning up finished run: k6u5yjw6
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: xcvx1frt
Sweep URL: https://wandb.ai/jah377/sff_pubmed/sweeps/xcvx1frt
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: - 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: \ 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: | 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: / 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: - 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: \ 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: | 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: / 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: - 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb: \ 0.244 MB of 0.244 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced polar-capybara-204: https://wandb.ai/jah377/sff_pubmed/runs/3i1ylvyz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_010032-3i1ylvyz/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 22 hours 07 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
