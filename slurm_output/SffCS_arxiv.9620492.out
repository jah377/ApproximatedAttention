Sun 19 Jun 2022 11:30:19 AM CEST
r32n1.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: arxiv
method: bayes
model: SIGNff_CS
iterations: 100
run_trial: false
config: SIGNff_CS.yaml
train_file: hps_SIGNff_CS.py
project_name: sffCS_arxiv
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  ATTN_NORMALIZATION:
    values:
    - 0
    - 1
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 2048
    - 4096
    - 8192
    - 16384
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  DATASET:
    value: arxiv
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 128
    - 256
    - 512
    - 1024
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  TRANSFORMATION:
    value: cosine
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff_CS.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_113109-2t3nua9p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-serenity-371
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/2t3nua9p
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-19 11:31:17,746 - wandb.wandb_agent - INFO - Running runs: []
2022-06-19 11:31:18,030 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:31:18,031 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1
2022-06-19 11:31:18,038 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 11:31:23,052 - wandb.wandb_agent - INFO - Running runs: ['y343j9gc']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_113122-y343j9gc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-1
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/y343j9gc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k3_cosine_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.25726
wandb:    train_loss 3.25074
wandb: training_time 1.17824
wandb:        val_f1 0.25615
wandb:      val_loss 3.48982
wandb: 
wandb: Synced pleasant-sweep-1: https://wandb.ai/jah377/sffCS_arxiv/runs/y343j9gc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_113122-y343j9gc/logs
2022-06-19 11:58:53,061 - wandb.wandb_agent - INFO - Cleaning up finished run: y343j9gc
2022-06-19 11:58:53,335 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 11:58:53,335 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1
2022-06-19 11:58:53,343 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-19 11:58:58,354 - wandb.wandb_agent - INFO - Running runs: ['hnv8rtl6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_115858-hnv8rtl6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-2
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/hnv8rtl6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k5_cosine_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17899
wandb:    train_loss 3.64535
wandb: training_time 1.3024
wandb:        val_f1 0.07628
wandb:      val_loss 3.64781
wandb: 
wandb: Synced vital-sweep-2: https://wandb.ai/jah377/sffCS_arxiv/runs/hnv8rtl6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_115858-hnv8rtl6/logs
2022-06-19 12:28:39,097 - wandb.wandb_agent - INFO - Cleaning up finished run: hnv8rtl6
2022-06-19 12:28:39,872 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:28:39,873 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.1
2022-06-19 12:28:39,882 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 12:28:44,894 - wandb.wandb_agent - INFO - Running runs: ['z08225a7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_122845-z08225a7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-3
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/z08225a7
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k0_cosine_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17907
wandb:    train_loss 3.23846
wandb: training_time 0.70949
wandb:        val_f1 0.07628
wandb:      val_loss 3.2311
wandb: 
wandb: Synced colorful-sweep-3: https://wandb.ai/jah377/sffCS_arxiv/runs/z08225a7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_122845-z08225a7/logs
2022-06-19 12:52:34,247 - wandb.wandb_agent - INFO - Cleaning up finished run: z08225a7
2022-06-19 12:52:34,558 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 12:52:34,558 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.01
2022-06-19 12:52:34,568 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-19 12:52:39,578 - wandb.wandb_agent - INFO - Running runs: ['vsvgfw9k']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_125239-vsvgfw9k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-4
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/vsvgfw9k
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17909
wandb:    train_loss 3.31877
wandb: training_time 0.70625
wandb:        val_f1 0.07631
wandb:      val_loss 3.31387
wandb: 
wandb: Synced balmy-sweep-4: https://wandb.ai/jah377/sffCS_arxiv/runs/vsvgfw9k
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_125239-vsvgfw9k/logs
2022-06-19 13:00:54,229 - wandb.wandb_agent - INFO - Cleaning up finished run: vsvgfw9k
2022-06-19 13:00:54,645 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:00:54,645 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 13:00:54,654 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 13:00:59,666 - wandb.wandb_agent - INFO - Running runs: ['0ywt95r3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_130059-0ywt95r3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-5
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/0ywt95r3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.01787
wandb:    train_loss 3.681
wandb: training_time 0.69716
wandb:        val_f1 0.01178
wandb:      val_loss 3.68682
wandb: 
wandb: Synced stilted-sweep-5: https://wandb.ai/jah377/sffCS_arxiv/runs/0ywt95r3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_130059-0ywt95r3/logs
2022-06-19 13:09:35,126 - wandb.wandb_agent - INFO - Cleaning up finished run: 0ywt95r3
2022-06-19 13:09:35,482 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:09:35,482 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 13:09:35,490 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 13:09:40,503 - wandb.wandb_agent - INFO - Running runs: ['wfjo2er6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_130940-wfjo2er6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-6
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/wfjo2er6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k2_cosine_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.72956
wandb:    train_loss 0.85317
wandb: training_time 0.97933
wandb:        val_f1 0.63865
wandb:      val_loss 1.18942
wandb: 
wandb: Synced glamorous-sweep-6: https://wandb.ai/jah377/sffCS_arxiv/runs/wfjo2er6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_130940-wfjo2er6/logs
2022-06-19 13:36:48,551 - wandb.wandb_agent - INFO - Cleaning up finished run: wfjo2er6
2022-06-19 13:36:48,905 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 13:36:48,905 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 13:36:48,912 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 13:36:53,926 - wandb.wandb_agent - INFO - Running runs: ['a5t089a5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_133654-a5t089a5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-7
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/a5t089a5
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k1_cosine_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6089
wandb:    train_loss 1.30109
wandb: training_time 1.12568
wandb:        val_f1 0.60838
wandb:      val_loss 1.29796
wandb: 
wandb: Synced atomic-sweep-7: https://wandb.ai/jah377/sffCS_arxiv/runs/a5t089a5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_133654-a5t089a5/logs
2022-06-19 14:03:31,490 - wandb.wandb_agent - INFO - Cleaning up finished run: a5t089a5
2022-06-19 14:03:31,834 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:03:31,835 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 14:03:31,844 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 14:03:36,854 - wandb.wandb_agent - INFO - Running runs: ['9lfwtt05']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_140336-9lfwtt05
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-8
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/9lfwtt05
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k2_cosine_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.71009
wandb:    train_loss 0.91734
wandb: training_time 1.24089
wandb:        val_f1 0.63848
wandb:      val_loss 1.20467
wandb: 
wandb: Synced fallen-sweep-8: https://wandb.ai/jah377/sffCS_arxiv/runs/9lfwtt05
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_140336-9lfwtt05/logs
2022-06-19 14:30:51,226 - wandb.wandb_agent - INFO - Cleaning up finished run: 9lfwtt05
2022-06-19 14:30:51,551 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:30:51,552 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 14:30:51,559 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 14:30:56,573 - wandb.wandb_agent - INFO - Running runs: ['1e4twd2e']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_143056-1e4twd2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-9
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/1e4twd2e
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68645
wandb:    train_loss 1.02184
wandb: training_time 1.24067
wandb:        val_f1 0.62969
wandb:      val_loss 1.24073
wandb: 
wandb: Synced gallant-sweep-9: https://wandb.ai/jah377/sffCS_arxiv/runs/1e4twd2e
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_143056-1e4twd2e/logs
2022-06-19 14:43:08,706 - wandb.wandb_agent - INFO - Cleaning up finished run: 1e4twd2e
2022-06-19 14:43:09,163 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 14:43:09,163 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 14:43:09,170 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 14:43:14,184 - wandb.wandb_agent - INFO - Running runs: ['p91u4b7w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_144314-p91u4b7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-10
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/p91u4b7w
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k0_cosine_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60316
wandb:    train_loss 1.32551
wandb: training_time 0.84409
wandb:        val_f1 0.56431
wandb:      val_loss 1.47209
wandb: 
wandb: Synced vibrant-sweep-10: https://wandb.ai/jah377/sffCS_arxiv/runs/p91u4b7w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_144314-p91u4b7w/logs
2022-06-19 15:07:11,742 - wandb.wandb_agent - INFO - Cleaning up finished run: p91u4b7w
2022-06-19 15:07:12,102 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:07:12,103 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.0001
2022-06-19 15:07:12,112 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 15:07:17,126 - wandb.wandb_agent - INFO - Running runs: ['vzbf13sb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_150717-vzbf13sb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-11
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/vzbf13sb
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k3_cosine_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57216
wandb:    train_loss 1.48411
wandb: training_time 1.02611
wandb:        val_f1 0.58368
wandb:      val_loss 1.43141
wandb: 
wandb: Synced dulcet-sweep-11: https://wandb.ai/jah377/sffCS_arxiv/runs/vzbf13sb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_150717-vzbf13sb/logs
2022-06-19 15:33:18,938 - wandb.wandb_agent - INFO - Cleaning up finished run: vzbf13sb
2022-06-19 15:33:19,279 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:33:19,279 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 15:33:19,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 15:33:24,302 - wandb.wandb_agent - INFO - Running runs: ['efnpipwt']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_153324-efnpipwt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-12
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/efnpipwt
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k5_cosine_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26993
wandb:    train_loss 3.12015
wandb: training_time 1.09573
wandb:        val_f1 0.29065
wandb:      val_loss 2.98588
wandb: 
wandb: Synced splendid-sweep-12: https://wandb.ai/jah377/sffCS_arxiv/runs/efnpipwt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_153324-efnpipwt/logs
2022-06-19 15:59:43,380 - wandb.wandb_agent - INFO - Cleaning up finished run: efnpipwt
2022-06-19 15:59:43,767 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 15:59:43,768 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 15:59:43,774 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 15:59:48,786 - wandb.wandb_agent - INFO - Running runs: ['mawpy3p6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_155948-mawpy3p6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-13
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/mawpy3p6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.73317
wandb:    train_loss 0.84546
wandb: training_time 2.12773
wandb:        val_f1 0.64596
wandb:      val_loss 1.17475
wandb: 
wandb: Synced serene-sweep-13: https://wandb.ai/jah377/sffCS_arxiv/runs/mawpy3p6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_155948-mawpy3p6/logs
2022-06-19 16:17:26,139 - wandb.wandb_agent - INFO - Cleaning up finished run: mawpy3p6
2022-06-19 16:17:26,488 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:17:26,489 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 16:17:26,496 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 16:17:31,510 - wandb.wandb_agent - INFO - Running runs: ['txql65a5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_161731-txql65a5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-14
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/txql65a5
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 38
wandb:      train_f1 0.71222
wandb:    train_loss 0.94583
wandb: training_time 1.14084
wandb:        val_f1 0.58321
wandb:      val_loss 1.52691
wandb: 
wandb: Synced spring-sweep-14: https://wandb.ai/jah377/sffCS_arxiv/runs/txql65a5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_161731-txql65a5/logs
2022-06-19 16:19:14,957 - wandb.wandb_agent - INFO - Cleaning up finished run: txql65a5
2022-06-19 16:19:15,317 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:19:15,317 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 16:19:15,326 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 16:19:20,340 - wandb.wandb_agent - INFO - Running runs: ['gu9dr4cp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_161920-gu9dr4cp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-15
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/gu9dr4cp
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64714
wandb:    train_loss 1.11775
wandb: training_time 0.83911
wandb:        val_f1 0.58331
wandb:      val_loss 1.40443
wandb: 
wandb: Synced giddy-sweep-15: https://wandb.ai/jah377/sffCS_arxiv/runs/gu9dr4cp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_161920-gu9dr4cp/logs
2022-06-19 16:28:42,344 - wandb.wandb_agent - INFO - Cleaning up finished run: gu9dr4cp
2022-06-19 16:28:43,691 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:28:43,691 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 16:28:43,700 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 16:28:48,710 - wandb.wandb_agent - INFO - Running runs: ['ul4eszj6']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_162848-ul4eszj6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-sweep-16
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/ul4eszj6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k4_cosine_norm1.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60985
wandb:    train_loss 1.33998
wandb: training_time 1.18138
wandb:        val_f1 0.5827
wandb:      val_loss 1.44785
wandb: 
wandb: Synced crimson-sweep-16: https://wandb.ai/jah377/sffCS_arxiv/runs/ul4eszj6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_162848-ul4eszj6/logs
2022-06-19 16:55:27,633 - wandb.wandb_agent - INFO - Cleaning up finished run: ul4eszj6
2022-06-19 16:55:28,021 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 16:55:28,022 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 16:55:28,029 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 16:55:33,042 - wandb.wandb_agent - INFO - Running runs: ['yllpjlk6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_165533-yllpjlk6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-17
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/yllpjlk6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.43605
wandb:    train_loss 2.18847
wandb: training_time 1.06762
wandb:        val_f1 0.45861
wandb:      val_loss 2.09766
wandb: 
wandb: Synced curious-sweep-17: https://wandb.ai/jah377/sffCS_arxiv/runs/yllpjlk6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_165533-yllpjlk6/logs
2022-06-19 17:06:37,709 - wandb.wandb_agent - INFO - Cleaning up finished run: yllpjlk6
2022-06-19 17:06:38,128 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:06:38,128 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 17:06:38,135 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-19 17:06:43,146 - wandb.wandb_agent - INFO - Running runs: ['zh13dj0d']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_170642-zh13dj0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-18
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/zh13dj0d
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.3819
wandb:    train_loss 2.51475
wandb: training_time 1.0128
wandb:        val_f1 0.41468
wandb:      val_loss 2.40732
wandb: 
wandb: Synced confused-sweep-18: https://wandb.ai/jah377/sffCS_arxiv/runs/zh13dj0d
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_170642-zh13dj0d/logs
2022-06-19 17:17:57,302 - wandb.wandb_agent - INFO - Cleaning up finished run: zh13dj0d
2022-06-19 17:17:57,760 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:17:57,760 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.001
2022-06-19 17:17:57,768 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-19 17:18:02,782 - wandb.wandb_agent - INFO - Running runs: ['axzlph01']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_171802-axzlph01
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-19
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/axzlph01
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.47949
wandb:    train_loss 2.04593
wandb: training_time 1.5193
wandb:        val_f1 0.51002
wandb:      val_loss 1.93884
wandb: 
wandb: Synced sweepy-sweep-19: https://wandb.ai/jah377/sffCS_arxiv/runs/axzlph01
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_171802-axzlph01/logs
2022-06-19 17:32:49,380 - wandb.wandb_agent - INFO - Cleaning up finished run: axzlph01
2022-06-19 17:32:49,752 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:32:49,753 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 17:32:49,760 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 17:32:54,773 - wandb.wandb_agent - INFO - Running runs: ['lvuiyb2p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_173254-lvuiyb2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-20
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/lvuiyb2p
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.31722
wandb:    train_loss 2.83118
wandb: training_time 1.00001
wandb:        val_f1 0.32414
wandb:      val_loss 2.77329
wandb: 
wandb: Synced silver-sweep-20: https://wandb.ai/jah377/sffCS_arxiv/runs/lvuiyb2p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_173254-lvuiyb2p/logs
2022-06-19 17:43:44,415 - wandb.wandb_agent - INFO - Cleaning up finished run: lvuiyb2p
2022-06-19 17:43:44,921 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:43:44,922 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 17:43:44,929 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 17:43:49,944 - wandb.wandb_agent - INFO - Running runs: ['1towtow2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_174350-1towtow2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-21
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/1towtow2
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55138
wandb:    train_loss 1.52597
wandb: training_time 0.90368
wandb:        val_f1 0.54955
wandb:      val_loss 1.52625
wandb: 
wandb: Synced glamorous-sweep-21: https://wandb.ai/jah377/sffCS_arxiv/runs/1towtow2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_174350-1towtow2/logs
2022-06-19 17:53:22,606 - wandb.wandb_agent - INFO - Cleaning up finished run: 1towtow2
2022-06-19 17:53:22,997 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 17:53:22,997 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 17:53:23,004 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 17:53:28,018 - wandb.wandb_agent - INFO - Running runs: ['5hl75lyf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_175328-5hl75lyf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-22
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/5hl75lyf
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65663
wandb:    train_loss 1.14322
wandb: training_time 0.87902
wandb:        val_f1 0.58129
wandb:      val_loss 1.44793
wandb: 
wandb: Synced polished-sweep-22: https://wandb.ai/jah377/sffCS_arxiv/runs/5hl75lyf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_175328-5hl75lyf/logs
2022-06-19 18:02:45,674 - wandb.wandb_agent - INFO - Cleaning up finished run: 5hl75lyf
2022-06-19 18:02:46,052 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:02:46,053 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 18:02:46,060 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 18:02:51,072 - wandb.wandb_agent - INFO - Running runs: ['jhrf2toj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_180251-jhrf2toj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-23
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/jhrf2toj
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.24801
wandb:    train_loss 4.18492
wandb: training_time 3.50499
wandb:        val_f1 0.23434
wandb:      val_loss 5.36407
wandb: 
wandb: Synced fragrant-sweep-23: https://wandb.ai/jah377/sffCS_arxiv/runs/jhrf2toj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_180251-jhrf2toj/logs
2022-06-19 18:30:08,760 - wandb.wandb_agent - INFO - Cleaning up finished run: jhrf2toj
2022-06-19 18:30:09,161 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:30:09,161 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 18:30:09,168 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 18:30:14,182 - wandb.wandb_agent - INFO - Running runs: ['hpsfyv7x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_183014-hpsfyv7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-24
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/hpsfyv7x
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42473
wandb:    train_loss 2.28015
wandb: training_time 0.91032
wandb:        val_f1 0.44085
wandb:      val_loss 2.22813
wandb: 
wandb: Synced sparkling-sweep-24: https://wandb.ai/jah377/sffCS_arxiv/runs/hpsfyv7x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_183014-hpsfyv7x/logs
2022-06-19 18:40:23,179 - wandb.wandb_agent - INFO - Cleaning up finished run: hpsfyv7x
2022-06-19 18:40:23,558 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:40:23,559 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 18:40:23,565 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 18:40:28,581 - wandb.wandb_agent - INFO - Running runs: ['i25vv35g']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_184028-i25vv35g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-25
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/i25vv35g
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.79398
wandb:    train_loss 0.65064
wandb: training_time 0.93371
wandb:        val_f1 0.57066
wandb:      val_loss 1.63163
wandb: 
wandb: Synced wandering-sweep-25: https://wandb.ai/jah377/sffCS_arxiv/runs/i25vv35g
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_184028-i25vv35g/logs
2022-06-19 18:51:04,208 - wandb.wandb_agent - INFO - Cleaning up finished run: i25vv35g
2022-06-19 18:51:04,602 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 18:51:04,602 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.1
2022-06-19 18:51:04,610 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 18:51:09,626 - wandb.wandb_agent - INFO - Running runs: ['6qe9atsu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_185109-6qe9atsu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-26
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/6qe9atsu
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.5917
wandb:    train_loss 1.42404
wandb: training_time 0.90716
wandb:        val_f1 0.57183
wandb:      val_loss 1.48041
wandb: 
wandb: Synced jolly-sweep-26: https://wandb.ai/jah377/sffCS_arxiv/runs/6qe9atsu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_185109-6qe9atsu/logs
2022-06-19 19:00:36,484 - wandb.wandb_agent - INFO - Cleaning up finished run: 6qe9atsu
2022-06-19 19:00:36,842 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:00:36,842 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.1
2022-06-19 19:00:36,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-19 19:00:41,862 - wandb.wandb_agent - INFO - Running runs: ['f50tb2cf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_190042-f50tb2cf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-27
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/f50tb2cf
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40659
wandb:    train_loss 2.46697
wandb: training_time 1.22509
wandb:        val_f1 0.43246
wandb:      val_loss 2.34062
wandb: 
wandb: Synced sparkling-sweep-27: https://wandb.ai/jah377/sffCS_arxiv/runs/f50tb2cf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_190042-f50tb2cf/logs
2022-06-19 19:12:54,467 - wandb.wandb_agent - INFO - Cleaning up finished run: f50tb2cf
2022-06-19 19:12:54,836 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:12:54,837 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 19:12:54,843 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 19:12:59,858 - wandb.wandb_agent - INFO - Running runs: ['z8wuaatg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_191259-z8wuaatg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-28
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/z8wuaatg
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}

TRANSFORMED FILE: data/arxiv_k1_cosine_norm0.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.55633
wandb:    train_loss 1.51388
wandb: training_time 0.77268
wandb:        val_f1 0.57186
wandb:      val_loss 1.44802
wandb: 
wandb: Synced lyric-sweep-28: https://wandb.ai/jah377/sffCS_arxiv/runs/z8wuaatg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_191259-z8wuaatg/logs
2022-06-19 19:37:14,040 - wandb.wandb_agent - INFO - Cleaning up finished run: z8wuaatg
2022-06-19 19:37:14,481 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:37:14,481 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 19:37:14,489 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 19:37:19,503 - wandb.wandb_agent - INFO - Running runs: ['fdipkbel']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_193719-fdipkbel
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-29
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/fdipkbel
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.61377
wandb:    train_loss 1.27917
wandb: training_time 1.35115
wandb:        val_f1 0.61056
wandb:      val_loss 1.28667
wandb: 
wandb: Synced sage-sweep-29: https://wandb.ai/jah377/sffCS_arxiv/runs/fdipkbel
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_193719-fdipkbel/logs
2022-06-19 19:50:23,336 - wandb.wandb_agent - INFO - Cleaning up finished run: fdipkbel
2022-06-19 19:50:23,743 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 19:50:23,744 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 19:50:23,750 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 19:50:28,764 - wandb.wandb_agent - INFO - Running runs: ['41dvu11a']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_195028-41dvu11a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-30
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/41dvu11a
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60925
wandb:    train_loss 1.30117
wandb: training_time 1.03425
wandb:        val_f1 0.60227
wandb:      val_loss 1.32414
wandb: 
wandb: Synced sweepy-sweep-30: https://wandb.ai/jah377/sffCS_arxiv/runs/41dvu11a
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_195028-41dvu11a/logs
2022-06-19 20:01:33,965 - wandb.wandb_agent - INFO - Cleaning up finished run: 41dvu11a
2022-06-19 20:01:34,341 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:01:34,341 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 20:01:34,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 20:01:39,365 - wandb.wandb_agent - INFO - Running runs: ['a20evcih']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_200139-a20evcih
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-31
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/a20evcih
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4748
wandb:    train_loss 2.14124
wandb: training_time 0.99634
wandb:        val_f1 0.49773
wandb:      val_loss 2.05937
wandb: 
wandb: Synced azure-sweep-31: https://wandb.ai/jah377/sffCS_arxiv/runs/a20evcih
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_200139-a20evcih/logs
2022-06-19 20:12:45,710 - wandb.wandb_agent - INFO - Cleaning up finished run: a20evcih
2022-06-19 20:12:46,079 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:12:46,079 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 20:12:46,088 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 20:12:51,098 - wandb.wandb_agent - INFO - Running runs: ['usbbep18']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_201251-usbbep18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-sweep-32
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/usbbep18
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67092
wandb:    train_loss 1.08234
wandb: training_time 1.1133
wandb:        val_f1 0.63163
wandb:      val_loss 1.23271
wandb: 
wandb: Synced revived-sweep-32: https://wandb.ai/jah377/sffCS_arxiv/runs/usbbep18
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_201251-usbbep18/logs
2022-06-19 20:24:42,227 - wandb.wandb_agent - INFO - Cleaning up finished run: usbbep18
2022-06-19 20:24:42,930 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:24:42,930 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 20:24:42,939 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 20:24:47,953 - wandb.wandb_agent - INFO - Running runs: ['m1xygt3x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_202448-m1xygt3x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-33
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/m1xygt3x
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.49345
wandb:    train_loss 1.77064
wandb: training_time 1.0314
wandb:        val_f1 0.50649
wandb:      val_loss 1.72314
wandb: 
wandb: Synced silvery-sweep-33: https://wandb.ai/jah377/sffCS_arxiv/runs/m1xygt3x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_202448-m1xygt3x/logs
2022-06-19 20:35:58,550 - wandb.wandb_agent - INFO - Cleaning up finished run: m1xygt3x
2022-06-19 20:35:59,002 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:35:59,002 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 20:35:59,010 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 20:36:04,024 - wandb.wandb_agent - INFO - Running runs: ['4gmtw17s']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_203604-4gmtw17s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-sweep-34
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/4gmtw17s
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.1673
wandb:    train_loss 3.25902
wandb: training_time 0.99499
wandb:        val_f1 0.25008
wandb:      val_loss 3.14518
wandb: 
wandb: Synced blooming-sweep-34: https://wandb.ai/jah377/sffCS_arxiv/runs/4gmtw17s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_203604-4gmtw17s/logs
2022-06-19 20:47:30,128 - wandb.wandb_agent - INFO - Cleaning up finished run: 4gmtw17s
2022-06-19 20:47:30,731 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:47:30,732 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 20:47:30,740 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 20:47:35,755 - wandb.wandb_agent - INFO - Running runs: ['3lcf5hvu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_204735-3lcf5hvu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-35
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3lcf5hvu
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53489
wandb:    train_loss 1.59411
wandb: training_time 0.84326
wandb:        val_f1 0.53569
wandb:      val_loss 1.58037
wandb: 
wandb: Synced honest-sweep-35: https://wandb.ai/jah377/sffCS_arxiv/runs/3lcf5hvu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_204735-3lcf5hvu/logs
2022-06-19 20:56:57,530 - wandb.wandb_agent - INFO - Cleaning up finished run: 3lcf5hvu
2022-06-19 20:56:58,028 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 20:56:58,029 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.0001
2022-06-19 20:56:58,036 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 20:57:03,051 - wandb.wandb_agent - INFO - Running runs: ['5p6wec4w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_205703-5p6wec4w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-36
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/5p6wec4w
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.56127
wandb:    train_loss 1.53888
wandb: training_time 0.85292
wandb:        val_f1 0.55217
wandb:      val_loss 1.56777
wandb: 
wandb: Synced iconic-sweep-36: https://wandb.ai/jah377/sffCS_arxiv/runs/5p6wec4w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_205703-5p6wec4w/logs
2022-06-19 21:06:50,736 - wandb.wandb_agent - INFO - Cleaning up finished run: 5p6wec4w
2022-06-19 21:06:51,401 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:06:51,401 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 21:06:51,410 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 21:06:56,422 - wandb.wandb_agent - INFO - Running runs: ['3lagz0m1']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_210656-3lagz0m1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-37
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3lagz0m1
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64148
wandb:    train_loss 1.14882
wandb: training_time 0.75504
wandb:        val_f1 0.57549
wandb:      val_loss 1.43282
wandb: 
wandb: Synced expert-sweep-37: https://wandb.ai/jah377/sffCS_arxiv/runs/3lagz0m1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_210656-3lagz0m1/logs
2022-06-19 21:16:11,840 - wandb.wandb_agent - INFO - Cleaning up finished run: 3lagz0m1
2022-06-19 21:16:12,358 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:16:12,358 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 21:16:12,367 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 21:16:17,380 - wandb.wandb_agent - INFO - Running runs: ['698eyyjp']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_211617-698eyyjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-38
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/698eyyjp
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.25129
wandb:    train_loss 3.46856
wandb: training_time 0.91358
wandb:        val_f1 0.24877
wandb:      val_loss 3.48344
wandb: 
wandb: Synced young-sweep-38: https://wandb.ai/jah377/sffCS_arxiv/runs/698eyyjp
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_211617-698eyyjp/logs
2022-06-19 21:26:35,776 - wandb.wandb_agent - INFO - Cleaning up finished run: 698eyyjp
2022-06-19 21:26:40,639 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:26:40,640 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 21:26:40,646 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 21:26:45,658 - wandb.wandb_agent - INFO - Running runs: ['bxd5bmh4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_212645-bxd5bmh4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-39
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/bxd5bmh4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.66367
wandb:    train_loss 1.06781
wandb: training_time 1.10812
wandb:        val_f1 0.62559
wandb:      val_loss 1.22904
wandb: 
wandb: Synced dazzling-sweep-39: https://wandb.ai/jah377/sffCS_arxiv/runs/bxd5bmh4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_212645-bxd5bmh4/logs
2022-06-19 21:38:31,746 - wandb.wandb_agent - INFO - Cleaning up finished run: bxd5bmh4
2022-06-19 21:38:32,202 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:38:32,202 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 21:38:32,209 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 21:38:37,223 - wandb.wandb_agent - INFO - Running runs: ['6fwybdte']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_213837-6fwybdte
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-40
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/6fwybdte
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63461
wandb:    train_loss 1.20056
wandb: training_time 0.89363
wandb:        val_f1 0.62177
wandb:      val_loss 1.24012
wandb: 
wandb: Synced happy-sweep-40: https://wandb.ai/jah377/sffCS_arxiv/runs/6fwybdte
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_213837-6fwybdte/logs
2022-06-19 21:48:54,108 - wandb.wandb_agent - INFO - Cleaning up finished run: 6fwybdte
2022-06-19 21:48:54,637 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:48:54,637 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.0001
2022-06-19 21:48:54,646 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-19 21:48:59,660 - wandb.wandb_agent - INFO - Running runs: ['jjq3yamm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_214859-jjq3yamm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-41
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/jjq3yamm
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.48969
wandb:    train_loss 1.79941
wandb: training_time 0.81001
wandb:        val_f1 0.49351
wandb:      val_loss 1.76856
wandb: 
wandb: Synced serene-sweep-41: https://wandb.ai/jah377/sffCS_arxiv/runs/jjq3yamm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_214859-jjq3yamm/logs
2022-06-19 21:58:26,807 - wandb.wandb_agent - INFO - Cleaning up finished run: jjq3yamm
2022-06-19 21:58:27,542 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 21:58:27,542 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 21:58:27,550 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 21:58:32,566 - wandb.wandb_agent - INFO - Running runs: ['r56tfgiy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_215832-r56tfgiy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-42
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/r56tfgiy
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.58193
wandb:    train_loss 1.43329
wandb: training_time 0.92548
wandb:        val_f1 0.59116
wandb:      val_loss 1.40253
wandb: 
wandb: Synced polar-sweep-42: https://wandb.ai/jah377/sffCS_arxiv/runs/r56tfgiy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_215832-r56tfgiy/logs
2022-06-19 22:09:06,776 - wandb.wandb_agent - INFO - Cleaning up finished run: r56tfgiy
2022-06-19 22:09:07,202 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:09:07,203 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 22:09:07,209 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 22:09:12,224 - wandb.wandb_agent - INFO - Running runs: ['0mb6f5ca']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_220912-0mb6f5ca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-43
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/0mb6f5ca
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26676
wandb:    train_loss 3.80081
wandb: training_time 0.87483
wandb:        val_f1 0.26816
wandb:      val_loss 4.02326
wandb: 
wandb: Synced playful-sweep-43: https://wandb.ai/jah377/sffCS_arxiv/runs/0mb6f5ca
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_220912-0mb6f5ca/logs
2022-06-19 22:19:25,830 - wandb.wandb_agent - INFO - Cleaning up finished run: 0mb6f5ca
2022-06-19 22:19:26,410 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:19:26,410 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 22:19:26,418 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 22:19:31,432 - wandb.wandb_agent - INFO - Running runs: ['flszaky9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_221931-flszaky9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-44
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/flszaky9
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26466
wandb:    train_loss 4.91979
wandb: training_time 0.87729
wandb:        val_f1 0.29162
wandb:      val_loss 5.8811
wandb: 
wandb: Synced deep-sweep-44: https://wandb.ai/jah377/sffCS_arxiv/runs/flszaky9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_221931-flszaky9/logs
2022-06-19 22:29:49,806 - wandb.wandb_agent - INFO - Cleaning up finished run: flszaky9
2022-06-19 22:29:50,399 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:29:50,399 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 22:29:50,406 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 22:29:55,420 - wandb.wandb_agent - INFO - Running runs: ['3hyh57nz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_222955-3hyh57nz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-45
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3hyh57nz
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64559
wandb:    train_loss 1.1791
wandb: training_time 0.84477
wandb:        val_f1 0.62304
wandb:      val_loss 1.24984
wandb: 
wandb: Synced tough-sweep-45: https://wandb.ai/jah377/sffCS_arxiv/runs/3hyh57nz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_222955-3hyh57nz/logs
2022-06-19 22:39:43,218 - wandb.wandb_agent - INFO - Cleaning up finished run: 3hyh57nz
2022-06-19 22:39:43,591 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:39:43,591 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 22:39:43,598 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 22:39:48,610 - wandb.wandb_agent - INFO - Running runs: ['yba68itv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_223948-yba68itv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-46
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/yba68itv
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.61419
wandb:    train_loss 1.26328
wandb: training_time 1.05242
wandb:        val_f1 0.60566
wandb:      val_loss 1.29491
wandb: 
wandb: Synced brisk-sweep-46: https://wandb.ai/jah377/sffCS_arxiv/runs/yba68itv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_223948-yba68itv/logs
2022-06-19 22:50:43,647 - wandb.wandb_agent - INFO - Cleaning up finished run: yba68itv
2022-06-19 22:50:44,176 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 22:50:44,177 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 22:50:44,183 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 22:50:49,196 - wandb.wandb_agent - INFO - Running runs: ['vmqp05b8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_225049-vmqp05b8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-47
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/vmqp05b8
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53467
wandb:    train_loss 1.6034
wandb: training_time 1.00519
wandb:        val_f1 0.54056
wandb:      val_loss 1.57291
wandb: 
wandb: Synced astral-sweep-47: https://wandb.ai/jah377/sffCS_arxiv/runs/vmqp05b8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_225049-vmqp05b8/logs
2022-06-19 23:01:29,722 - wandb.wandb_agent - INFO - Cleaning up finished run: vmqp05b8
2022-06-19 23:01:33,487 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:01:33,488 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 23:01:33,495 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 23:01:38,510 - wandb.wandb_agent - INFO - Running runs: ['lb3qjpxz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_230138-lb3qjpxz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-48
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/lb3qjpxz
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.002 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.43247
wandb:    train_loss 2.00778
wandb: training_time 0.86636
wandb:        val_f1 0.44602
wandb:      val_loss 1.93317
wandb: 
wandb: Synced devout-sweep-48: https://wandb.ai/jah377/sffCS_arxiv/runs/lb3qjpxz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_230138-lb3qjpxz/logs
2022-06-19 23:11:41,756 - wandb.wandb_agent - INFO - Cleaning up finished run: lb3qjpxz
2022-06-19 23:11:47,478 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:11:47,479 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 23:11:47,488 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 23:11:52,502 - wandb.wandb_agent - INFO - Running runs: ['07zqhoif']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_231152-07zqhoif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-49
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/07zqhoif
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.41498
wandb:    train_loss 2.21291
wandb: training_time 1.71247
wandb:        val_f1 0.45757
wandb:      val_loss 2.24752
wandb: 
wandb: Synced distinctive-sweep-49: https://wandb.ai/jah377/sffCS_arxiv/runs/07zqhoif
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_231152-07zqhoif/logs
2022-06-19 23:26:38,729 - wandb.wandb_agent - INFO - Cleaning up finished run: 07zqhoif
2022-06-19 23:26:39,386 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:26:39,387 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-19 23:26:39,394 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-19 23:26:44,406 - wandb.wandb_agent - INFO - Running runs: ['i3wepxps']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_232644-i3wepxps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-50
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/i3wepxps
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.17909
wandb:    train_loss 2.97543
wandb: training_time 0.80822
wandb:        val_f1 0.07641
wandb:      val_loss 2.94181
wandb: 
wandb: Synced astral-sweep-50: https://wandb.ai/jah377/sffCS_arxiv/runs/i3wepxps
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_232644-i3wepxps/logs
2022-06-19 23:36:21,682 - wandb.wandb_agent - INFO - Cleaning up finished run: i3wepxps
2022-06-19 23:36:22,110 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:36:22,111 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-19 23:36:22,117 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-19 23:36:27,131 - wandb.wandb_agent - INFO - Running runs: ['k0557l0x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_233627-k0557l0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-51
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/k0557l0x
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6817
wandb:    train_loss 1.0355
wandb: training_time 1.34198
wandb:        val_f1 0.63103
wandb:      val_loss 1.24754
wandb: 
wandb: Synced summer-sweep-51: https://wandb.ai/jah377/sffCS_arxiv/runs/k0557l0x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_233627-k0557l0x/logs
2022-06-19 23:49:57,663 - wandb.wandb_agent - INFO - Cleaning up finished run: k0557l0x
2022-06-19 23:49:58,253 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-19 23:49:58,254 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-19 23:49:58,262 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-19 23:50:03,276 - wandb.wandb_agent - INFO - Running runs: ['aws121nz']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220619_235003-aws121nz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-52
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/aws121nz
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57207
wandb:    train_loss 1.4211
wandb: training_time 0.94699
wandb:        val_f1 0.55623
wandb:      val_loss 1.48169
wandb: 
wandb: Synced dark-sweep-52: https://wandb.ai/jah377/sffCS_arxiv/runs/aws121nz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_235003-aws121nz/logs
2022-06-20 00:00:32,086 - wandb.wandb_agent - INFO - Cleaning up finished run: aws121nz
2022-06-20 00:00:32,553 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:00:32,553 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 00:00:32,560 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 00:00:37,574 - wandb.wandb_agent - INFO - Running runs: ['1r72bhgx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_000037-1r72bhgx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-53
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/1r72bhgx
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68205
wandb:    train_loss 1.04075
wandb: training_time 1.06395
wandb:        val_f1 0.59331
wandb:      val_loss 1.38155
wandb: 
wandb: Synced unique-sweep-53: https://wandb.ai/jah377/sffCS_arxiv/runs/1r72bhgx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_000037-1r72bhgx/logs
2022-06-20 00:11:47,358 - wandb.wandb_agent - INFO - Cleaning up finished run: 1r72bhgx
2022-06-20 00:11:47,774 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:11:47,774 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 00:11:47,782 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 00:11:52,796 - wandb.wandb_agent - INFO - Running runs: ['oo5nz8hg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_001152-oo5nz8hg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-54
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/oo5nz8hg
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.69172
wandb:    train_loss 0.98534
wandb: training_time 0.89523
wandb:        val_f1 0.63673
wandb:      val_loss 1.18938
wandb: 
wandb: Synced vague-sweep-54: https://wandb.ai/jah377/sffCS_arxiv/runs/oo5nz8hg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_001152-oo5nz8hg/logs
2022-06-20 00:22:05,833 - wandb.wandb_agent - INFO - Cleaning up finished run: oo5nz8hg
2022-06-20 00:22:06,296 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:22:06,296 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 00:22:06,305 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 00:22:11,318 - wandb.wandb_agent - INFO - Running runs: ['ngo0p450']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_002211-ngo0p450
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-55
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/ngo0p450
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6033
wandb:    train_loss 1.32204
wandb: training_time 0.94448
wandb:        val_f1 0.57502
wandb:      val_loss 1.44368
wandb: 
wandb: Synced woven-sweep-55: https://wandb.ai/jah377/sffCS_arxiv/runs/ngo0p450
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_002211-ngo0p450/logs
2022-06-20 00:32:19,393 - wandb.wandb_agent - INFO - Cleaning up finished run: ngo0p450
2022-06-20 00:32:19,891 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:32:19,891 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.0001
2022-06-20 00:32:19,899 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 00:32:24,914 - wandb.wandb_agent - INFO - Running runs: ['3b787bl6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_003225-3b787bl6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-56
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3b787bl6
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.66252
wandb:    train_loss 1.11065
wandb: training_time 0.79547
wandb:        val_f1 0.58666
wandb:      val_loss 1.39542
wandb: 
wandb: Synced amber-sweep-56: https://wandb.ai/jah377/sffCS_arxiv/runs/3b787bl6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_003225-3b787bl6/logs
2022-06-20 00:41:57,034 - wandb.wandb_agent - INFO - Cleaning up finished run: 3b787bl6
2022-06-20 00:42:06,192 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:42:06,192 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 00:42:06,201 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 00:42:11,214 - wandb.wandb_agent - INFO - Running runs: ['ckuoz2md']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_004211-ckuoz2md
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-57
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/ckuoz2md
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30601
wandb:    train_loss 2.75372
wandb: training_time 1.15423
wandb:        val_f1 0.32578
wandb:      val_loss 2.67541
wandb: 
wandb: Synced cerulean-sweep-57: https://wandb.ai/jah377/sffCS_arxiv/runs/ckuoz2md
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_004211-ckuoz2md/logs
2022-06-20 00:54:02,428 - wandb.wandb_agent - INFO - Cleaning up finished run: ckuoz2md
2022-06-20 00:54:02,835 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 00:54:02,836 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 00:54:02,844 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 00:54:07,858 - wandb.wandb_agent - INFO - Running runs: ['utghqp6x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_005407-utghqp6x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-58
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/utghqp6x
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52479
wandb:    train_loss 1.63479
wandb: training_time 0.82434
wandb:        val_f1 0.5322
wandb:      val_loss 1.60246
wandb: 
wandb: Synced clear-sweep-58: https://wandb.ai/jah377/sffCS_arxiv/runs/utghqp6x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_005407-utghqp6x/logs
2022-06-20 01:04:02,986 - wandb.wandb_agent - INFO - Cleaning up finished run: utghqp6x
2022-06-20 01:04:03,445 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:04:03,445 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 01:04:03,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 01:04:08,466 - wandb.wandb_agent - INFO - Running runs: ['e6bs0193']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_010407-e6bs0193
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-59
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/e6bs0193
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63052
wandb:    train_loss 1.20757
wandb: training_time 0.79216
wandb:        val_f1 0.57636
wandb:      val_loss 1.44243
wandb: 
wandb: Synced fanciful-sweep-59: https://wandb.ai/jah377/sffCS_arxiv/runs/e6bs0193
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_010407-e6bs0193/logs
2022-06-20 01:13:15,746 - wandb.wandb_agent - INFO - Cleaning up finished run: e6bs0193
2022-06-20 01:13:16,318 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:13:16,318 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.01
2022-06-20 01:13:16,325 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-20 01:13:21,339 - wandb.wandb_agent - INFO - Running runs: ['jc1zcf1i']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_011321-jc1zcf1i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-60
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/jc1zcf1i
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.62352
wandb:    train_loss 1.33047
wandb: training_time 0.74152
wandb:        val_f1 0.60975
wandb:      val_loss 1.36733
wandb: 
wandb: Synced dark-sweep-60: https://wandb.ai/jah377/sffCS_arxiv/runs/jc1zcf1i
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_011321-jc1zcf1i/logs
2022-06-20 01:22:28,314 - wandb.wandb_agent - INFO - Cleaning up finished run: jc1zcf1i
2022-06-20 01:22:29,154 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:22:29,154 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 01:22:29,163 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 01:22:34,177 - wandb.wandb_agent - INFO - Running runs: ['dehyy3ao']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_012234-dehyy3ao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-61
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/dehyy3ao
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57846
wandb:    train_loss 1.40037
wandb: training_time 0.82538
wandb:        val_f1 0.56593
wandb:      val_loss 1.45599
wandb: 
wandb: Synced wise-sweep-61: https://wandb.ai/jah377/sffCS_arxiv/runs/dehyy3ao
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_012234-dehyy3ao/logs
2022-06-20 01:31:30,566 - wandb.wandb_agent - INFO - Cleaning up finished run: dehyy3ao
2022-06-20 01:31:31,045 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:31:31,045 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 01:31:31,053 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 01:31:36,067 - wandb.wandb_agent - INFO - Running runs: ['flv464k3']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_013136-flv464k3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-62
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/flv464k3
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.11569
wandb:    train_loss 3.60696
wandb: training_time 0.80684
wandb:        val_f1 0.07175
wandb:      val_loss 3.61155
wandb: 
wandb: Synced dutiful-sweep-62: https://wandb.ai/jah377/sffCS_arxiv/runs/flv464k3
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_013136-flv464k3/logs
2022-06-20 01:41:18,587 - wandb.wandb_agent - INFO - Cleaning up finished run: flv464k3
2022-06-20 01:41:19,044 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:41:19,044 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 01:41:19,053 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 01:41:24,067 - wandb.wandb_agent - INFO - Running runs: ['ozzvnu20']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_014124-ozzvnu20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-63
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/ozzvnu20
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.44177
wandb:    train_loss 1.96625
wandb: training_time 0.8545
wandb:        val_f1 0.44924
wandb:      val_loss 1.90073
wandb: 
wandb: Synced splendid-sweep-63: https://wandb.ai/jah377/sffCS_arxiv/runs/ozzvnu20
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_014124-ozzvnu20/logs
2022-06-20 01:50:35,727 - wandb.wandb_agent - INFO - Cleaning up finished run: ozzvnu20
2022-06-20 01:50:36,232 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 01:50:36,233 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.001
2022-06-20 01:50:36,239 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 01:50:41,254 - wandb.wandb_agent - INFO - Running runs: ['2tsl9g1r']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_015041-2tsl9g1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-64
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/2tsl9g1r
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60223
wandb:    train_loss 1.34167
wandb: training_time 0.80849
wandb:        val_f1 0.57237
wandb:      val_loss 1.44471
wandb: 
wandb: Synced absurd-sweep-64: https://wandb.ai/jah377/sffCS_arxiv/runs/2tsl9g1r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_015041-2tsl9g1r/logs
2022-06-20 02:00:28,622 - wandb.wandb_agent - INFO - Cleaning up finished run: 2tsl9g1r
2022-06-20 02:00:29,664 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:00:29,665 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 02:00:29,671 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 02:00:34,685 - wandb.wandb_agent - INFO - Running runs: ['13m4z7fd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_020034-13m4z7fd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-65
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/13m4z7fd
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6315
wandb:    train_loss 1.21335
wandb: training_time 1.17427
wandb:        val_f1 0.62079
wandb:      val_loss 1.25541
wandb: 
wandb: Synced prime-sweep-65: https://wandb.ai/jah377/sffCS_arxiv/runs/13m4z7fd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_020034-13m4z7fd/logs
2022-06-20 02:12:17,685 - wandb.wandb_agent - INFO - Cleaning up finished run: 13m4z7fd
2022-06-20 02:12:18,166 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:12:18,166 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 02:12:18,173 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 02:12:23,186 - wandb.wandb_agent - INFO - Running runs: ['23zpzcb8']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_021222-23zpzcb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-66
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/23zpzcb8
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.73191
wandb:    train_loss 0.85223
wandb: training_time 0.92849
wandb:        val_f1 0.6222
wandb:      val_loss 1.24949
wandb: 
wandb: Synced avid-sweep-66: https://wandb.ai/jah377/sffCS_arxiv/runs/23zpzcb8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_021222-23zpzcb8/logs
2022-06-20 02:23:01,822 - wandb.wandb_agent - INFO - Cleaning up finished run: 23zpzcb8
2022-06-20 02:23:02,328 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:23:02,328 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 02:23:02,335 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 02:23:07,346 - wandb.wandb_agent - INFO - Running runs: ['pt3zdf5u']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_022307-pt3zdf5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-67
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/pt3zdf5u
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.53889
wandb:    train_loss 1.60609
wandb: training_time 0.81716
wandb:        val_f1 0.54535
wandb:      val_loss 1.57691
wandb: 
wandb: Synced atomic-sweep-67: https://wandb.ai/jah377/sffCS_arxiv/runs/pt3zdf5u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_022307-pt3zdf5u/logs
2022-06-20 02:32:29,210 - wandb.wandb_agent - INFO - Cleaning up finished run: pt3zdf5u
2022-06-20 02:32:30,061 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:32:30,061 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 02:32:30,068 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 02:32:35,082 - wandb.wandb_agent - INFO - Running runs: ['3g5abhzj']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_023234-3g5abhzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-68
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3g5abhzj
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.41485
wandb:    train_loss 2.25903
wandb: training_time 0.9166
wandb:        val_f1 0.43109
wandb:      val_loss 2.14733
wandb: 
wandb: Synced earnest-sweep-68: https://wandb.ai/jah377/sffCS_arxiv/runs/3g5abhzj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_023234-3g5abhzj/logs
2022-06-20 02:43:25,004 - wandb.wandb_agent - INFO - Cleaning up finished run: 3g5abhzj
2022-06-20 02:43:25,516 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:43:25,516 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.001
2022-06-20 02:43:25,524 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-20 02:43:30,534 - wandb.wandb_agent - INFO - Running runs: ['2wbhbyg4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_024330-2wbhbyg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sweep-69
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/2wbhbyg4
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.42709
wandb:    train_loss 1.96673
wandb: training_time 0.89518
wandb:        val_f1 0.43334
wandb:      val_loss 1.88897
wandb: 
wandb: Synced hearty-sweep-69: https://wandb.ai/jah377/sffCS_arxiv/runs/2wbhbyg4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_024330-2wbhbyg4/logs
2022-06-20 02:53:28,613 - wandb.wandb_agent - INFO - Cleaning up finished run: 2wbhbyg4
2022-06-20 02:53:29,071 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 02:53:29,072 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 02:53:29,080 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 02:53:34,095 - wandb.wandb_agent - INFO - Running runs: ['ioou2c0m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_025334-ioou2c0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-70
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/ioou2c0m
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57405
wandb:    train_loss 1.4268
wandb: training_time 0.73504
wandb:        val_f1 0.5625
wandb:      val_loss 1.46305
wandb: 
wandb: Synced ethereal-sweep-70: https://wandb.ai/jah377/sffCS_arxiv/runs/ioou2c0m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_025334-ioou2c0m/logs
2022-06-20 03:02:25,122 - wandb.wandb_agent - INFO - Cleaning up finished run: ioou2c0m
2022-06-20 03:02:25,606 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:02:25,607 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 03:02:25,614 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 03:02:30,627 - wandb.wandb_agent - INFO - Running runs: ['qq67a8ze']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_030230-qq67a8ze
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-71
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/qq67a8ze
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.61505
wandb:    train_loss 1.28245
wandb: training_time 0.91402
wandb:        val_f1 0.61019
wandb:      val_loss 1.28679
wandb: 
wandb: Synced dandy-sweep-71: https://wandb.ai/jah377/sffCS_arxiv/runs/qq67a8ze
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_030230-qq67a8ze/logs
2022-06-20 03:12:38,912 - wandb.wandb_agent - INFO - Cleaning up finished run: qq67a8ze
2022-06-20 03:12:39,353 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:12:39,354 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.0001
2022-06-20 03:12:39,361 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.0001
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 03:12:44,374 - wandb.wandb_agent - INFO - Running runs: ['ipwlvnec']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_031243-ipwlvnec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-72
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/ipwlvnec
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57148
wandb:    train_loss 1.42845
wandb: training_time 0.71787
wandb:        val_f1 0.56049
wandb:      val_loss 1.47102
wandb: 
wandb: Synced cerulean-sweep-72: https://wandb.ai/jah377/sffCS_arxiv/runs/ipwlvnec
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_031243-ipwlvnec/logs
2022-06-20 03:21:20,143 - wandb.wandb_agent - INFO - Cleaning up finished run: ipwlvnec
2022-06-20 03:21:20,667 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:21:20,667 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.1
2022-06-20 03:21:20,676 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.1
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 03:21:25,690 - wandb.wandb_agent - INFO - Running runs: ['n6mygbz7']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_032125-n6mygbz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-73
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/n6mygbz7
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.27781
wandb:    train_loss 2.85773
wandb: training_time 0.92479
wandb:        val_f1 0.29662
wandb:      val_loss 2.76726
wandb: 
wandb: Synced snowy-sweep-73: https://wandb.ai/jah377/sffCS_arxiv/runs/n6mygbz7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_032125-n6mygbz7/logs
2022-06-20 03:32:11,405 - wandb.wandb_agent - INFO - Cleaning up finished run: n6mygbz7
2022-06-20 03:32:11,854 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:32:11,854 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 03:32:11,860 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 03:32:16,874 - wandb.wandb_agent - INFO - Running runs: ['nv7pzc0k']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_033216-nv7pzc0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run distinctive-sweep-74
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/nv7pzc0k
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52599
wandb:    train_loss 1.61446
wandb: training_time 1.00267
wandb:        val_f1 0.52904
wandb:      val_loss 1.59076
wandb: 
wandb: Synced distinctive-sweep-74: https://wandb.ai/jah377/sffCS_arxiv/runs/nv7pzc0k
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_033216-nv7pzc0k/logs
2022-06-20 03:43:06,152 - wandb.wandb_agent - INFO - Cleaning up finished run: nv7pzc0k
2022-06-20 03:43:07,232 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:43:07,232 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 03:43:07,241 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 03:43:12,255 - wandb.wandb_agent - INFO - Running runs: ['3r0apeog']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_034312-3r0apeog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-75
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3r0apeog
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68167
wandb:    train_loss 1.02064
wandb: training_time 0.82878
wandb:        val_f1 0.6219
wandb:      val_loss 1.26434
wandb: 
wandb: Synced hardy-sweep-75: https://wandb.ai/jah377/sffCS_arxiv/runs/3r0apeog
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_034312-3r0apeog/logs
2022-06-20 03:53:04,692 - wandb.wandb_agent - INFO - Cleaning up finished run: 3r0apeog
2022-06-20 03:53:05,179 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 03:53:05,179 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 03:53:05,186 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 03:53:10,198 - wandb.wandb_agent - INFO - Running runs: ['azygos32']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_035310-azygos32
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-76
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/azygos32
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4539
wandb:    train_loss 1.9879
wandb: training_time 0.98221
wandb:        val_f1 0.47394
wandb:      val_loss 1.89529
wandb: 
wandb: Synced frosty-sweep-76: https://wandb.ai/jah377/sffCS_arxiv/runs/azygos32
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_035310-azygos32/logs
2022-06-20 04:03:34,250 - wandb.wandb_agent - INFO - Cleaning up finished run: azygos32
2022-06-20 04:03:35,247 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:03:35,247 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 04:03:35,253 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 04:03:40,269 - wandb.wandb_agent - INFO - Running runs: ['5gy2sjcr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_040340-5gy2sjcr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-77
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/5gy2sjcr
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.59315
wandb:    train_loss 1.38045
wandb: training_time 1.27608
wandb:        val_f1 0.60274
wandb:      val_loss 1.35646
wandb: 
wandb: Synced worthy-sweep-77: https://wandb.ai/jah377/sffCS_arxiv/runs/5gy2sjcr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_040340-5gy2sjcr/logs
2022-06-20 04:16:27,916 - wandb.wandb_agent - INFO - Cleaning up finished run: 5gy2sjcr
2022-06-20 04:16:30,979 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:16:30,979 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 04:16:30,988 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 04:16:36,002 - wandb.wandb_agent - INFO - Running runs: ['p2ud4zct']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_041636-p2ud4zct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-78
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/p2ud4zct
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63459
wandb:    train_loss 1.24069
wandb: training_time 0.76611
wandb:        val_f1 0.58022
wandb:      val_loss 1.43528
wandb: 
wandb: Synced stellar-sweep-78: https://wandb.ai/jah377/sffCS_arxiv/runs/p2ud4zct
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_041636-p2ud4zct/logs
2022-06-20 04:26:02,615 - wandb.wandb_agent - INFO - Cleaning up finished run: p2ud4zct
2022-06-20 04:26:03,162 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:26:03,162 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 04:26:03,169 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 04:26:08,183 - wandb.wandb_agent - INFO - Running runs: ['3kpi4awc']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_042607-3kpi4awc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-79
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/3kpi4awc
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.6687
wandb:    train_loss 1.04182
wandb: training_time 0.72929
wandb:        val_f1 0.58015
wandb:      val_loss 1.42286
wandb: 
wandb: Synced skilled-sweep-79: https://wandb.ai/jah377/sffCS_arxiv/runs/3kpi4awc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_042607-3kpi4awc/logs
2022-06-20 04:34:58,592 - wandb.wandb_agent - INFO - Cleaning up finished run: 3kpi4awc
2022-06-20 04:34:59,073 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:34:59,073 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 04:34:59,080 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 04:35:04,095 - wandb.wandb_agent - INFO - Running runs: ['yuw99zge']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_043504-yuw99zge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-80
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/yuw99zge
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.35383
wandb:    train_loss 2.72073
wandb: training_time 0.8642
wandb:        val_f1 0.37854
wandb:      val_loss 2.5688
wandb: 
wandb: Synced avid-sweep-80: https://wandb.ai/jah377/sffCS_arxiv/runs/yuw99zge
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_043504-yuw99zge/logs
2022-06-20 04:45:02,281 - wandb.wandb_agent - INFO - Cleaning up finished run: yuw99zge
2022-06-20 04:45:02,771 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:45:02,772 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 04:45:02,778 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 04:45:07,790 - wandb.wandb_agent - INFO - Running runs: ['65kcv482']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_044507-65kcv482
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-81
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/65kcv482
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67939
wandb:    train_loss 1.03696
wandb: training_time 1.52733
wandb:        val_f1 0.64052
wandb:      val_loss 1.19718
wandb: 
wandb: Synced feasible-sweep-81: https://wandb.ai/jah377/sffCS_arxiv/runs/65kcv482
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_044507-65kcv482/logs
2022-06-20 04:59:53,546 - wandb.wandb_agent - INFO - Cleaning up finished run: 65kcv482
2022-06-20 04:59:54,880 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 04:59:54,881 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 04:59:54,888 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 04:59:59,902 - wandb.wandb_agent - INFO - Running runs: ['v6axzs0m']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_045959-v6axzs0m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-82
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/v6axzs0m
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.59498
wandb:    train_loss 1.35206
wandb: training_time 1.01096
wandb:        val_f1 0.60022
wandb:      val_loss 1.32088
wandb: 
wandb: Synced splendid-sweep-82: https://wandb.ai/jah377/sffCS_arxiv/runs/v6axzs0m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_045959-v6axzs0m/logs
2022-06-20 05:11:05,311 - wandb.wandb_agent - INFO - Cleaning up finished run: v6axzs0m
2022-06-20 05:11:05,841 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:11:05,841 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.0001
2022-06-20 05:11:05,849 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-20 05:11:10,862 - wandb.wandb_agent - INFO - Running runs: ['qpvh7rl1']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_051110-qpvh7rl1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-83
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/qpvh7rl1
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 64
wandb:      train_f1 0.72224
wandb:    train_loss 0.8811
wandb: training_time 1.07052
wandb:        val_f1 0.61448
wandb:      val_loss 1.28101
wandb: 
wandb: Synced gentle-sweep-83: https://wandb.ai/jah377/sffCS_arxiv/runs/qpvh7rl1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_051110-qpvh7rl1/logs
2022-06-20 05:13:51,472 - wandb.wandb_agent - INFO - Cleaning up finished run: qpvh7rl1
2022-06-20 05:13:52,275 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:13:52,275 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 05:13:52,283 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 05:13:57,296 - wandb.wandb_agent - INFO - Running runs: ['2d5yrarl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_051357-2d5yrarl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-84
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/2d5yrarl
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.50786
wandb:    train_loss 1.72988
wandb: training_time 1.81723
wandb:        val_f1 0.53549
wandb:      val_loss 1.64907
wandb: 
wandb: Synced apricot-sweep-84: https://wandb.ai/jah377/sffCS_arxiv/runs/2d5yrarl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_051357-2d5yrarl/logs
2022-06-20 05:31:13,202 - wandb.wandb_agent - INFO - Cleaning up finished run: 2d5yrarl
2022-06-20 05:31:15,808 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:31:15,808 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 0.1
2022-06-20 05:31:15,816 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-20 05:31:20,826 - wandb.wandb_agent - INFO - Running runs: ['2fe40ntk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_053120-2fe40ntk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-85
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/2fe40ntk
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64463
wandb:    train_loss 1.24261
wandb: training_time 1.09065
wandb:        val_f1 0.62073
wandb:      val_loss 1.30347
wandb: 
wandb: Synced amber-sweep-85: https://wandb.ai/jah377/sffCS_arxiv/runs/2fe40ntk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_053120-2fe40ntk/logs
2022-06-20 05:43:02,518 - wandb.wandb_agent - INFO - Cleaning up finished run: 2fe40ntk
2022-06-20 05:43:07,710 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:43:07,710 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 05:43:07,717 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 05:43:12,731 - wandb.wandb_agent - INFO - Running runs: ['h3v8vsrh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_054312-h3v8vsrh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-86
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/h3v8vsrh
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.62373
wandb:    train_loss 1.25139
wandb: training_time 0.98429
wandb:        val_f1 0.57186
wandb:      val_loss 1.43075
wandb: 
wandb: Synced earthy-sweep-86: https://wandb.ai/jah377/sffCS_arxiv/runs/h3v8vsrh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_054312-h3v8vsrh/logs
2022-06-20 05:53:31,755 - wandb.wandb_agent - INFO - Cleaning up finished run: h3v8vsrh
2022-06-20 05:53:32,365 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 05:53:32,366 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 05:53:32,372 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 05:53:37,386 - wandb.wandb_agent - INFO - Running runs: ['gzd0slej']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_055337-gzd0slej
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-87
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/gzd0slej
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64021
wandb:    train_loss 1.1772
wandb: training_time 0.88178
wandb:        val_f1 0.62136
wandb:      val_loss 1.23629
wandb: 
wandb: Synced swift-sweep-87: https://wandb.ai/jah377/sffCS_arxiv/runs/gzd0slej
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_055337-gzd0slej/logs
2022-06-20 06:03:47,057 - wandb.wandb_agent - INFO - Cleaning up finished run: gzd0slej
2022-06-20 06:03:56,589 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:03:56,590 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 8192
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 06:03:56,596 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=8192 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 06:04:01,610 - wandb.wandb_agent - INFO - Running runs: ['7blqlsgh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_060401-7blqlsgh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-88
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/7blqlsgh
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 8192, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.69654
wandb:    train_loss 0.95745
wandb: training_time 0.79392
wandb:        val_f1 0.62952
wandb:      val_loss 1.23368
wandb: 
wandb: Synced polished-sweep-88: https://wandb.ai/jah377/sffCS_arxiv/runs/7blqlsgh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_060401-7blqlsgh/logs
2022-06-20 06:13:54,397 - wandb.wandb_agent - INFO - Cleaning up finished run: 7blqlsgh
2022-06-20 06:13:54,951 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:13:54,952 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 06:13:54,960 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 06:13:59,974 - wandb.wandb_agent - INFO - Running runs: ['2aavkrsi']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_061400-2aavkrsi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-89
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/2aavkrsi
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67322
wandb:    train_loss 1.05784
wandb: training_time 1.46278
wandb:        val_f1 0.63891
wandb:      val_loss 1.19953
wandb: 
wandb: Synced upbeat-sweep-89: https://wandb.ai/jah377/sffCS_arxiv/runs/2aavkrsi
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_061400-2aavkrsi/logs
2022-06-20 06:28:47,550 - wandb.wandb_agent - INFO - Cleaning up finished run: 2aavkrsi
2022-06-20 06:28:48,166 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:28:48,166 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 06:28:48,173 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 06:28:53,186 - wandb.wandb_agent - INFO - Running runs: ['knm56lfg']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_062852-knm56lfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-90
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/knm56lfg
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68073
wandb:    train_loss 1.00477
wandb: training_time 0.77592
wandb:        val_f1 0.62838
wandb:      val_loss 1.22688
wandb: 
wandb: Synced lilac-sweep-90: https://wandb.ai/jah377/sffCS_arxiv/runs/knm56lfg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_062852-knm56lfg/logs
2022-06-20 06:37:59,658 - wandb.wandb_agent - INFO - Cleaning up finished run: knm56lfg
2022-06-20 06:38:00,116 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:38:00,116 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 06:38:00,125 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 06:38:05,138 - wandb.wandb_agent - INFO - Running runs: ['f6pwfsd1']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_063805-f6pwfsd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-91
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/f6pwfsd1
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 45
wandb:      train_f1 0.73074
wandb:    train_loss 0.86512
wandb: training_time 0.81684
wandb:        val_f1 0.62116
wandb:      val_loss 1.29193
wandb: 
wandb: Synced jolly-sweep-91: https://wandb.ai/jah377/sffCS_arxiv/runs/f6pwfsd1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_063805-f6pwfsd1/logs
2022-06-20 06:39:43,018 - wandb.wandb_agent - INFO - Cleaning up finished run: f6pwfsd1
2022-06-20 06:39:43,540 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:39:43,540 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 06:39:43,546 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 06:39:48,561 - wandb.wandb_agent - INFO - Running runs: ['59s6q5h8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_063948-59s6q5h8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-92
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/59s6q5h8
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.62346
wandb:    train_loss 1.22983
wandb: training_time 0.71119
wandb:        val_f1 0.57881
wandb:      val_loss 1.41205
wandb: 
wandb: Synced rosy-sweep-92: https://wandb.ai/jah377/sffCS_arxiv/runs/59s6q5h8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_063948-59s6q5h8/logs
2022-06-20 06:48:49,814 - wandb.wandb_agent - INFO - Cleaning up finished run: 59s6q5h8
2022-06-20 06:48:50,275 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:48:50,275 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 06:48:50,282 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 06:48:55,296 - wandb.wandb_agent - INFO - Running runs: ['b3n6xx7r']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_064855-b3n6xx7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-93
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/b3n6xx7r
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.38966
wandb:    train_loss 2.28474
wandb: training_time 0.82058
wandb:        val_f1 0.41602
wandb:      val_loss 2.18616
wandb: 
wandb: Synced dainty-sweep-93: https://wandb.ai/jah377/sffCS_arxiv/runs/b3n6xx7r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_064855-b3n6xx7r/logs
2022-06-20 06:58:48,842 - wandb.wandb_agent - INFO - Cleaning up finished run: b3n6xx7r
2022-06-20 06:58:49,510 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 06:58:49,510 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 06:58:49,517 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 06:58:54,530 - wandb.wandb_agent - INFO - Running runs: ['c9d429gk']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_065854-c9d429gk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-94
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/c9d429gk
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60733
wandb:    train_loss 1.30619
wandb: training_time 0.9301
wandb:        val_f1 0.6024
wandb:      val_loss 1.31853
wandb: 
wandb: Synced fresh-sweep-94: https://wandb.ai/jah377/sffCS_arxiv/runs/c9d429gk
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_065854-c9d429gk/logs
2022-06-20 07:09:10,674 - wandb.wandb_agent - INFO - Cleaning up finished run: c9d429gk
2022-06-20 07:09:11,174 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:09:11,174 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 07:09:11,181 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-20 07:09:16,194 - wandb.wandb_agent - INFO - Running runs: ['iai1m9sw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_070916-iai1m9sw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-95
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/iai1m9sw
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.57478
wandb:    train_loss 1.43224
wandb: training_time 0.81305
wandb:        val_f1 0.55962
wandb:      val_loss 1.48001
wandb: 
wandb: Synced comic-sweep-95: https://wandb.ai/jah377/sffCS_arxiv/runs/iai1m9sw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_070916-iai1m9sw/logs
2022-06-20 07:18:23,081 - wandb.wandb_agent - INFO - Cleaning up finished run: iai1m9sw
2022-06-20 07:18:23,510 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:18:23,510 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 07:18:23,517 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-20 07:18:28,533 - wandb.wandb_agent - INFO - Running runs: ['jvifxfkj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_071828-jvifxfkj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-96
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/jvifxfkj
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.63524
wandb:    train_loss 1.20561
wandb: training_time 0.77236
wandb:        val_f1 0.57626
wandb:      val_loss 1.43219
wandb: 
wandb: Synced kind-sweep-96: https://wandb.ai/jah377/sffCS_arxiv/runs/jvifxfkj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_071828-jvifxfkj/logs
2022-06-20 07:27:24,654 - wandb.wandb_agent - INFO - Cleaning up finished run: jvifxfkj
2022-06-20 07:27:26,766 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:27:26,766 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 07:27:26,774 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 07:27:31,788 - wandb.wandb_agent - INFO - Running runs: ['7a9q6t23']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_072731-7a9q6t23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-97
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/7a9q6t23
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.59384
wandb:    train_loss 1.33797
wandb: training_time 0.90861
wandb:        val_f1 0.5625
wandb:      val_loss 1.47651
wandb: 
wandb: Synced pretty-sweep-97: https://wandb.ai/jah377/sffCS_arxiv/runs/7a9q6t23
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_072731-7a9q6t23/logs
2022-06-20 07:37:19,651 - wandb.wandb_agent - INFO - Cleaning up finished run: 7a9q6t23
2022-06-20 07:37:20,131 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:37:20,132 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 16384
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 1024
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 1024
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-05
2022-06-20 07:37:20,140 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=16384 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=1024 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=1024 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-20 07:37:25,154 - wandb.wandb_agent - INFO - Running runs: ['s7jmwfqu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_073725-s7jmwfqu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-98
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/s7jmwfqu
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 16384, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 1024, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 1024, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 47
wandb:      train_f1 0.74259
wandb:    train_loss 0.81633
wandb: training_time 0.93532
wandb:        val_f1 0.62371
wandb:      val_loss 1.30627
wandb: 
wandb: Synced rosy-sweep-98: https://wandb.ai/jah377/sffCS_arxiv/runs/s7jmwfqu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_073725-s7jmwfqu/logs
2022-06-20 07:39:23,644 - wandb.wandb_agent - INFO - Cleaning up finished run: s7jmwfqu
2022-06-20 07:39:24,104 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:39:24,104 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 1
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 4096
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-07
2022-06-20 07:39:24,111 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=1 --BATCH_NORMALIZATION=1 --BATCH_SIZE=4096 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 07:39:29,122 - wandb.wandb_agent - INFO - Running runs: ['w5rr8gag']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_073929-w5rr8gag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-99
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/w5rr8gag
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 4096, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 1, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60352
wandb:    train_loss 1.34357
wandb: training_time 0.82032
wandb:        val_f1 0.57465
wandb:      val_loss 1.45218
wandb: 
wandb: Synced clean-sweep-99: https://wandb.ai/jah377/sffCS_arxiv/runs/w5rr8gag
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_073929-w5rr8gag/logs
2022-06-20 07:48:09,478 - wandb.wandb_agent - INFO - Cleaning up finished run: w5rr8gag
2022-06-20 07:48:10,082 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-20 07:48:10,082 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_NORMALIZATION: 0
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 2048
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: arxiv
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: cosine
	WEIGHT_DECAY: 1e-06
2022-06-20 07:48:10,090 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_CS.py --ATTN_NORMALIZATION=0 --BATCH_NORMALIZATION=1 --BATCH_SIZE=2048 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=arxiv --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=cosine --WEIGHT_DECAY=1e-06
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-20 07:48:15,102 - wandb.wandb_agent - INFO - Running runs: ['520h9w35']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffCS_arxiv/wandb/run-20220620_074814-520h9w35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-100
wandb:  View project at https://wandb.ai/jah377/sffCS_arxiv
wandb:  View sweep at https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb:  View run at https://wandb.ai/jah377/sffCS_arxiv/runs/520h9w35
{'DATASET': 'arxiv', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 2048, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'CS_BATCH_SIZE': 10000, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'ATTN_NORMALIZATION': 0, 'TRANSFORMATION': 'cosine'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.60339
wandb:    train_loss 1.29469
wandb: training_time 0.85996
wandb:        val_f1 0.57136
wandb:      val_loss 1.44299
wandb: 
wandb: Synced devoted-sweep-100: https://wandb.ai/jah377/sffCS_arxiv/runs/520h9w35
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220620_074814-520h9w35/logs
2022-06-20 07:58:08,442 - wandb.wandb_agent - INFO - Cleaning up finished run: 520h9w35
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: 1svg1i9t
Sweep URL: https://wandb.ai/jah377/sffCS_arxiv/sweeps/1svg1i9t
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: \ 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: | 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: / 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: - 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: \ 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: | 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: / 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: - 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb: \ 0.263 MB of 0.263 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced helpful-serenity-371: https://wandb.ai/jah377/sffCS_arxiv/runs/2t3nua9p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220619_113109-2t3nua9p/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 20 hours 27 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
