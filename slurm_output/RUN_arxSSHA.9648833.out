Mon 27 Jun 2022 05:42:22 PM CEST
r32n5.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
Using backend: pytorch

===== ARXIV_NEW =====

Namespace(DATASET='arxiv_new', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=20, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=16384, LEARNING_RATE=0.001, WEIGHT_DECAY=0.0001, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.0, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5304709672927856
coalesce scoo: 1.645e-05
convert to csr_matrix: 0.02476
calc min-max per row: 0.03371
vectorization: 0.02065
Normalization Time: 0.0968
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.100 [0.256-1.000]
Total Transformation Time: 1.9361
Epoch 20:, Train 0.6719, Val 0.6281, Test 0.5746
Epoch 40:, Train 0.8146, Val 0.6361, Test 0.5837
Epoch 60:, Train 0.9410, Val 0.6329, Test 0.5822
Epoch 80:, Train 0.9787, Val 0.6272, Test 0.5721
Epoch 100:, Train 0.9924, Val 0.6305, Test 0.5777
Epoch 120:, Train 0.9953, Val 0.6251, Test 0.5680
Epoch 140:, Train 0.9967, Val 0.6283, Test 0.5703
Epoch 160:, Train 0.9982, Val 0.6297, Test 0.5734
Epoch 180:, Train 0.9987, Val 0.6272, Test 0.5759
Epoch 200:, Train 0.9989, Val 0.6268, Test 0.5753
Epoch 220:, Train 0.9987, Val 0.6273, Test 0.5686
Epoch 240:, Train 0.9991, Val 0.6285, Test 0.5746
Epoch 260:, Train 0.9992, Val 0.6254, Test 0.5686
Epoch 280:, Train 0.9992, Val 0.6282, Test 0.5705
Epoch 300:, Train 0.9993, Val 0.6294, Test 0.5750
BEST: Epoch 40, Train 0.8146, Val 0.6361, Test 0.5837

RUN #1: seed=4
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4955138564109802
coalesce scoo: 8.583e-06
convert to csr_matrix: 0.02389
calc min-max per row: 0.03371
vectorization: 0.02038
Normalization Time: 0.0943
DOT_PRODUCT
Attention Filter (n=1166243): 0.872 +\- 0.093 [0.203-1.000]
Total Transformation Time: 1.8687
Epoch 20:, Train 0.6772, Val 0.6318, Test 0.5848
Epoch 40:, Train 0.8198, Val 0.6415, Test 0.5892
Epoch 60:, Train 0.9422, Val 0.6280, Test 0.5662
Epoch 80:, Train 0.9800, Val 0.6305, Test 0.5779
Epoch 100:, Train 0.9922, Val 0.6292, Test 0.5793
Epoch 120:, Train 0.9946, Val 0.6277, Test 0.5701
Epoch 140:, Train 0.9971, Val 0.6302, Test 0.5755
Epoch 160:, Train 0.9980, Val 0.6282, Test 0.5755
Epoch 180:, Train 0.9987, Val 0.6248, Test 0.5712
Epoch 200:, Train 0.9987, Val 0.6311, Test 0.5773
Epoch 220:, Train 0.9989, Val 0.6296, Test 0.5767
Epoch 240:, Train 0.9987, Val 0.6290, Test 0.5744
Epoch 260:, Train 0.9992, Val 0.6279, Test 0.5692
Epoch 280:, Train 0.9992, Val 0.6277, Test 0.5697
Epoch 300:, Train 0.9992, Val 0.6296, Test 0.5760
BEST: Epoch 40, Train 0.8198, Val 0.6415, Test 0.5892

RUN #2: seed=8
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5231907963752747
coalesce scoo: 1.526e-05
convert to csr_matrix: 0.02396
calc min-max per row: 0.03394
vectorization: 0.02038
Normalization Time: 0.0950
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.210-1.000]
Total Transformation Time: 1.8772
Epoch 20:, Train 0.6737, Val 0.6346, Test 0.5846
Epoch 40:, Train 0.8137, Val 0.6352, Test 0.5800
Epoch 60:, Train 0.9397, Val 0.6328, Test 0.5842
Epoch 80:, Train 0.9807, Val 0.6253, Test 0.5663
Epoch 100:, Train 0.9926, Val 0.6287, Test 0.5722
Epoch 120:, Train 0.9963, Val 0.6309, Test 0.5735
Epoch 140:, Train 0.9981, Val 0.6309, Test 0.5762
Epoch 160:, Train 0.9985, Val 0.6287, Test 0.5728
Epoch 180:, Train 0.9988, Val 0.6303, Test 0.5751
Epoch 200:, Train 0.9989, Val 0.6304, Test 0.5763
Epoch 220:, Train 0.9990, Val 0.6308, Test 0.5764
Epoch 240:, Train 0.9993, Val 0.6277, Test 0.5738
Epoch 260:, Train 0.9993, Val 0.6281, Test 0.5730
Epoch 280:, Train 0.9994, Val 0.6297, Test 0.5738
Epoch 300:, Train 0.9994, Val 0.6285, Test 0.5743
BEST: Epoch 40, Train 0.8137, Val 0.6352, Test 0.5800

RUN #3: seed=42
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5119524598121643
coalesce scoo: 1.478e-05
convert to csr_matrix: 0.02426
calc min-max per row: 0.0339
vectorization: 0.02046
Normalization Time: 0.0945
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.270-1.000]
Total Transformation Time: 1.8762
Epoch 20:, Train 0.6789, Val 0.6344, Test 0.5854
Epoch 40:, Train 0.8183, Val 0.6355, Test 0.5830
Epoch 60:, Train 0.9393, Val 0.6215, Test 0.5622
Epoch 80:, Train 0.9809, Val 0.6290, Test 0.5781
Epoch 100:, Train 0.9914, Val 0.6297, Test 0.5744
Epoch 120:, Train 0.9963, Val 0.6280, Test 0.5731
Epoch 140:, Train 0.9974, Val 0.6299, Test 0.5767
Epoch 160:, Train 0.9981, Val 0.6257, Test 0.5663
Epoch 180:, Train 0.9986, Val 0.6245, Test 0.5753
Epoch 200:, Train 0.9986, Val 0.6295, Test 0.5752
Epoch 220:, Train 0.9990, Val 0.6236, Test 0.5720
Epoch 240:, Train 0.9991, Val 0.6266, Test 0.5730
Epoch 260:, Train 0.9992, Val 0.6266, Test 0.5720
Epoch 280:, Train 0.9991, Val 0.6217, Test 0.5692
Epoch 300:, Train 0.9994, Val 0.6240, Test 0.5717
BEST: Epoch 40, Train 0.8183, Val 0.6355, Test 0.5830

RUN #4: seed=64
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5308823585510254
coalesce scoo: 1.431e-05
convert to csr_matrix: 0.02361
calc min-max per row: 0.03519
vectorization: 0.02028
Normalization Time: 0.0943
DOT_PRODUCT
Attention Filter (n=1166243): 0.863 +\- 0.099 [0.275-1.000]
Total Transformation Time: 1.8781
Epoch 20:, Train 0.6780, Val 0.6358, Test 0.5914
Epoch 40:, Train 0.8229, Val 0.6409, Test 0.5938
Epoch 60:, Train 0.9435, Val 0.6278, Test 0.5782
Epoch 80:, Train 0.9818, Val 0.6277, Test 0.5761
Epoch 100:, Train 0.9920, Val 0.6296, Test 0.5770
Epoch 120:, Train 0.9964, Val 0.6278, Test 0.5772
Epoch 140:, Train 0.9974, Val 0.6257, Test 0.5732
Epoch 160:, Train 0.9982, Val 0.6266, Test 0.5762
Epoch 180:, Train 0.9987, Val 0.6262, Test 0.5747
Epoch 200:, Train 0.9985, Val 0.6212, Test 0.5689
Epoch 220:, Train 0.9990, Val 0.6261, Test 0.5716
Epoch 240:, Train 0.9992, Val 0.6242, Test 0.5740
Epoch 260:, Train 0.9992, Val 0.6272, Test 0.5715
Epoch 280:, Train 0.9993, Val 0.6259, Test 0.5727
Epoch 300:, Train 0.9993, Val 0.6259, Test 0.5675
BEST: Epoch 40, Train 0.8229, Val 0.6409, Test 0.5938

RUN #5: seed=128
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.48565471172332764
coalesce scoo: 1.049e-05
convert to csr_matrix: 0.02379
calc min-max per row: 0.03364
vectorization: 0.02056
Normalization Time: 0.0941
DOT_PRODUCT
Attention Filter (n=1166243): 0.876 +\- 0.092 [0.280-1.000]
Total Transformation Time: 1.8927
Epoch 20:, Train 0.6716, Val 0.6328, Test 0.5873
Epoch 40:, Train 0.8093, Val 0.6397, Test 0.5887
Epoch 60:, Train 0.9383, Val 0.6333, Test 0.5844
Epoch 80:, Train 0.9788, Val 0.6289, Test 0.5743
Epoch 100:, Train 0.9915, Val 0.6281, Test 0.5740
Epoch 120:, Train 0.9949, Val 0.6323, Test 0.5809
Epoch 140:, Train 0.9975, Val 0.6313, Test 0.5755
Epoch 160:, Train 0.9979, Val 0.6270, Test 0.5706
Epoch 180:, Train 0.9986, Val 0.6305, Test 0.5734
Epoch 200:, Train 0.9988, Val 0.6270, Test 0.5740
Epoch 220:, Train 0.9991, Val 0.6308, Test 0.5805
Epoch 240:, Train 0.9991, Val 0.6301, Test 0.5722
Epoch 260:, Train 0.9993, Val 0.6270, Test 0.5737
Epoch 280:, Train 0.9994, Val 0.6315, Test 0.5733
Epoch 300:, Train 0.9993, Val 0.6262, Test 0.5667
BEST: Epoch 40, Train 0.8093, Val 0.6397, Test 0.5887

RUN #6: seed=256
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5099418759346008
coalesce scoo: 8.821e-06
convert to csr_matrix: 0.02367
calc min-max per row: 0.03415
vectorization: 0.02041
Normalization Time: 0.0945
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.098 [0.294-1.000]
Total Transformation Time: 1.9020
Epoch 20:, Train 0.6752, Val 0.6310, Test 0.5850
Epoch 40:, Train 0.8220, Val 0.6353, Test 0.5802
Epoch 60:, Train 0.9397, Val 0.6323, Test 0.5817
Epoch 80:, Train 0.9784, Val 0.6299, Test 0.5739
Epoch 100:, Train 0.9928, Val 0.6292, Test 0.5701
Epoch 120:, Train 0.9955, Val 0.6303, Test 0.5766
Epoch 140:, Train 0.9972, Val 0.6270, Test 0.5709
Epoch 160:, Train 0.9983, Val 0.6279, Test 0.5750
Epoch 180:, Train 0.9983, Val 0.6280, Test 0.5660
Epoch 200:, Train 0.9988, Val 0.6278, Test 0.5752
Epoch 220:, Train 0.9991, Val 0.6289, Test 0.5755
Epoch 240:, Train 0.9991, Val 0.6271, Test 0.5745
Epoch 260:, Train 0.9992, Val 0.6275, Test 0.5714
Epoch 280:, Train 0.9994, Val 0.6302, Test 0.5768
Epoch 300:, Train 0.9995, Val 0.6286, Test 0.5706
BEST: Epoch 40, Train 0.8220, Val 0.6353, Test 0.5802

RUN #7: seed=512
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5254026651382446
coalesce scoo: 1.025e-05
convert to csr_matrix: 0.02355
calc min-max per row: 0.03426
vectorization: 0.02055
Normalization Time: 0.0947
DOT_PRODUCT
Attention Filter (n=1166243): 0.858 +\- 0.102 [0.269-1.000]
Total Transformation Time: 1.8962
Epoch 20:, Train 0.6787, Val 0.6310, Test 0.5783
Epoch 40:, Train 0.8228, Val 0.6402, Test 0.5860
Epoch 60:, Train 0.9435, Val 0.6302, Test 0.5673
Epoch 80:, Train 0.9818, Val 0.6303, Test 0.5702
Epoch 100:, Train 0.9922, Val 0.6297, Test 0.5714
Epoch 120:, Train 0.9960, Val 0.6295, Test 0.5708
Epoch 140:, Train 0.9976, Val 0.6296, Test 0.5738
Epoch 160:, Train 0.9983, Val 0.6264, Test 0.5688
Epoch 180:, Train 0.9987, Val 0.6256, Test 0.5722
Epoch 200:, Train 0.9988, Val 0.6300, Test 0.5778
Epoch 220:, Train 0.9989, Val 0.6319, Test 0.5751
Epoch 240:, Train 0.9990, Val 0.6296, Test 0.5739
Epoch 260:, Train 0.9990, Val 0.6274, Test 0.5669
Epoch 280:, Train 0.9993, Val 0.6294, Test 0.5714
Epoch 300:, Train 0.9994, Val 0.6260, Test 0.5655
BEST: Epoch 40, Train 0.8228, Val 0.6402, Test 0.5860

RUN #8: seed=1024
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.45444992184638977
coalesce scoo: 6.914e-06
convert to csr_matrix: 0.02341
calc min-max per row: 0.03439
vectorization: 0.02043
Normalization Time: 0.0952
DOT_PRODUCT
Attention Filter (n=1166243): 0.866 +\- 0.097 [0.261-1.000]
Total Transformation Time: 1.8916
Epoch 20:, Train 0.6760, Val 0.6314, Test 0.5817
Epoch 40:, Train 0.8199, Val 0.6404, Test 0.5931
Epoch 60:, Train 0.9416, Val 0.6297, Test 0.5695
Epoch 80:, Train 0.9812, Val 0.6272, Test 0.5731
Epoch 100:, Train 0.9929, Val 0.6319, Test 0.5757
Epoch 120:, Train 0.9963, Val 0.6292, Test 0.5700
Epoch 140:, Train 0.9976, Val 0.6294, Test 0.5727
Epoch 160:, Train 0.9980, Val 0.6296, Test 0.5751
Epoch 180:, Train 0.9986, Val 0.6285, Test 0.5698
Epoch 200:, Train 0.9989, Val 0.6279, Test 0.5716
Epoch 220:, Train 0.9989, Val 0.6315, Test 0.5708
Epoch 240:, Train 0.9991, Val 0.6280, Test 0.5700
Epoch 260:, Train 0.9993, Val 0.6283, Test 0.5745
Epoch 280:, Train 0.9993, Val 0.6313, Test 0.5711
Epoch 300:, Train 0.9992, Val 0.6278, Test 0.5663
BEST: Epoch 40, Train 0.8199, Val 0.6404, Test 0.5931

RUN #9: seed=2048
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4948199987411499
coalesce scoo: 6.914e-06
convert to csr_matrix: 0.02532
calc min-max per row: 0.03386
vectorization: 0.02042
Normalization Time: 0.0933
DOT_PRODUCT
Attention Filter (n=1166243): 0.871 +\- 0.094 [0.242-1.000]
Total Transformation Time: 1.8956
Epoch 20:, Train 0.6784, Val 0.6331, Test 0.5887
Epoch 40:, Train 0.8244, Val 0.6335, Test 0.5818
Epoch 60:, Train 0.9442, Val 0.6355, Test 0.5807
Epoch 80:, Train 0.9798, Val 0.6313, Test 0.5777
Epoch 100:, Train 0.9917, Val 0.6309, Test 0.5791
Epoch 120:, Train 0.9958, Val 0.6292, Test 0.5741
Epoch 140:, Train 0.9973, Val 0.6299, Test 0.5778
Epoch 160:, Train 0.9983, Val 0.6274, Test 0.5757
Epoch 180:, Train 0.9986, Val 0.6303, Test 0.5788
Epoch 200:, Train 0.9988, Val 0.6297, Test 0.5734
Epoch 220:, Train 0.9989, Val 0.6293, Test 0.5729
Epoch 240:, Train 0.9990, Val 0.6250, Test 0.5698
Epoch 260:, Train 0.9992, Val 0.6266, Test 0.5671
Epoch 280:, Train 0.9992, Val 0.6325, Test 0.5800
Epoch 300:, Train 0.9993, Val 0.6296, Test 0.5797
BEST: Epoch 60, Train 0.9442, Val 0.6355, Test 0.5807




==================================================
Model Parameters: 10947629

Avg. Filter Time (s): 1.0808 +/- 0.0149
Avg. Preaggregation Time (s): 1.8915 +/- 0.0181
Avg. Training Time (epoch) (s): 1.4287 +/- 0.0856
Avg. Inference Time (s): 0.0244 +/- 0.0027

Avg. Training Acc: 0.8308 +/- 0.0380
Avg. Validation Acc: 0.6380 +/- 0.0026
Avg. Test Acc: 0.5859 +/- 0.0049

==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 1 hours 16 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
