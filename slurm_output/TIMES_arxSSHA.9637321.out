Tue 21 Jun 2022 09:13:02 PM CEST
r32n1.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=20, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.001, INCEPTION_LAYERS=1, INCEPTION_UNITS=128, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.100 [0.256-1.000]
244.44854140281677
Epoch 20:, Train 0.6263, Val 0.6139, Test 0.5679
Epoch 40:, Train 0.6435, Val 0.6231, Test 0.5767
Epoch 60:, Train 0.6559, Val 0.6226, Test 0.5674
Epoch 80:, Train 0.6597, Val 0.6217, Test 0.5676
Epoch 100:, Train 0.6639, Val 0.6237, Test 0.5710
Epoch 120:, Train 0.6674, Val 0.6261, Test 0.5728
Epoch 140:, Train 0.6677, Val 0.6231, Test 0.5715
Epoch 160:, Train 0.6691, Val 0.6246, Test 0.5690
Epoch 180:, Train 0.6754, Val 0.6279, Test 0.5757
Epoch 200:, Train 0.6753, Val 0.6213, Test 0.5605
Epoch 220:, Train 0.6774, Val 0.6233, Test 0.5715
Epoch 240:, Train 0.6766, Val 0.6231, Test 0.5728
Epoch 260:, Train 0.6743, Val 0.6238, Test 0.5719
Epoch 280:, Train 0.6781, Val 0.6305, Test 0.5869
Epoch 300:, Train 0.6757, Val 0.6280, Test 0.5797
BEST: Epoch 280, Train 0.6781, Val 0.6305, Test 0.5869

RUN #1: seed=4
DOT_PRODUCT
Attention Filter (n=1166243): 0.872 +\- 0.093 [0.203-1.000]
240.2378032207489
Epoch 20:, Train 0.6218, Val 0.6100, Test 0.5636
Epoch 40:, Train 0.6410, Val 0.6250, Test 0.5800
Epoch 60:, Train 0.6538, Val 0.6204, Test 0.5749
Epoch 80:, Train 0.6642, Val 0.6232, Test 0.5747
Epoch 100:, Train 0.6652, Val 0.6217, Test 0.5724
Epoch 120:, Train 0.6709, Val 0.6220, Test 0.5639
Epoch 140:, Train 0.6704, Val 0.6241, Test 0.5726
Epoch 160:, Train 0.6701, Val 0.6209, Test 0.5718
Epoch 180:, Train 0.6729, Val 0.6228, Test 0.5716
Epoch 200:, Train 0.6731, Val 0.6203, Test 0.5658
Epoch 220:, Train 0.6741, Val 0.6289, Test 0.5836
Epoch 240:, Train 0.6754, Val 0.6291, Test 0.5892
Epoch 260:, Train 0.6776, Val 0.6271, Test 0.5689
Epoch 280:, Train 0.6781, Val 0.6267, Test 0.5776
Epoch 300:, Train 0.6781, Val 0.6259, Test 0.5738
BEST: Epoch 240, Train 0.6754, Val 0.6291, Test 0.5892

RUN #2: seed=8
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.210-1.000]
242.91981410980225
Epoch 20:, Train 0.6235, Val 0.6110, Test 0.5592
Epoch 40:, Train 0.6439, Val 0.6207, Test 0.5750
Epoch 60:, Train 0.6518, Val 0.6191, Test 0.5701
Epoch 80:, Train 0.6501, Val 0.6120, Test 0.5612
Epoch 100:, Train 0.6629, Val 0.6248, Test 0.5775
Epoch 120:, Train 0.6670, Val 0.6146, Test 0.5652
Epoch 140:, Train 0.6706, Val 0.6197, Test 0.5700
Epoch 160:, Train 0.6709, Val 0.6209, Test 0.5702
Epoch 180:, Train 0.6735, Val 0.6239, Test 0.5705
Epoch 200:, Train 0.6700, Val 0.6213, Test 0.5686
Epoch 220:, Train 0.6712, Val 0.6233, Test 0.5686
Epoch 240:, Train 0.6780, Val 0.6227, Test 0.5747
Epoch 260:, Train 0.6766, Val 0.6299, Test 0.5814
Epoch 280:, Train 0.6753, Val 0.6174, Test 0.5630
Epoch 300:, Train 0.6772, Val 0.6284, Test 0.5806
BEST: Epoch 260, Train 0.6766, Val 0.6299, Test 0.5814

RUN #3: seed=42
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.270-1.000]
242.9289219379425
Epoch 20:, Train 0.6258, Val 0.6118, Test 0.5608
Epoch 40:, Train 0.6461, Val 0.6198, Test 0.5668
Epoch 60:, Train 0.6541, Val 0.6171, Test 0.5612
Epoch 80:, Train 0.6613, Val 0.6252, Test 0.5741
Epoch 100:, Train 0.6648, Val 0.6236, Test 0.5741
Epoch 120:, Train 0.6685, Val 0.6294, Test 0.5826
Epoch 140:, Train 0.6721, Val 0.6257, Test 0.5728
Epoch 160:, Train 0.6722, Val 0.6249, Test 0.5686
Epoch 180:, Train 0.6716, Val 0.6256, Test 0.5803
Epoch 200:, Train 0.6728, Val 0.6280, Test 0.5736
Epoch 220:, Train 0.6696, Val 0.6217, Test 0.5713
Epoch 240:, Train 0.6746, Val 0.6229, Test 0.5684
Epoch 260:, Train 0.6751, Val 0.6211, Test 0.5680
Epoch 280:, Train 0.6748, Val 0.6257, Test 0.5766
Epoch 300:, Train 0.6744, Val 0.6219, Test 0.5685
BEST: Epoch 120, Train 0.6685, Val 0.6294, Test 0.5826

RUN #4: seed=64
DOT_PRODUCT
Attention Filter (n=1166243): 0.863 +\- 0.099 [0.275-1.000]
242.3877923488617
Epoch 20:, Train 0.6248, Val 0.6124, Test 0.5617
Epoch 40:, Train 0.6420, Val 0.6205, Test 0.5753
Epoch 60:, Train 0.6546, Val 0.6246, Test 0.5788
Epoch 80:, Train 0.6624, Val 0.6212, Test 0.5710
Epoch 100:, Train 0.6616, Val 0.6203, Test 0.5702
Epoch 120:, Train 0.6663, Val 0.6265, Test 0.5739
Epoch 140:, Train 0.6738, Val 0.6241, Test 0.5750
Epoch 160:, Train 0.6720, Val 0.6162, Test 0.5581
Epoch 180:, Train 0.6734, Val 0.6224, Test 0.5657
Epoch 200:, Train 0.6740, Val 0.6187, Test 0.5548
Epoch 220:, Train 0.6757, Val 0.6264, Test 0.5785
Epoch 240:, Train 0.6742, Val 0.6265, Test 0.5752
Epoch 260:, Train 0.6736, Val 0.6236, Test 0.5725
Epoch 280:, Train 0.6791, Val 0.6233, Test 0.5663
Epoch 300:, Train 0.6757, Val 0.6234, Test 0.5640
BEST: Epoch 120, Train 0.6663, Val 0.6265, Test 0.5739

RUN #5: seed=128
DOT_PRODUCT
Attention Filter (n=1166243): 0.876 +\- 0.092 [0.280-1.000]
243.70484828948975
Epoch 20:, Train 0.6218, Val 0.6089, Test 0.5552
Epoch 40:, Train 0.6441, Val 0.6205, Test 0.5728
Epoch 60:, Train 0.6540, Val 0.6194, Test 0.5691
Epoch 80:, Train 0.6627, Val 0.6202, Test 0.5739
Epoch 100:, Train 0.6667, Val 0.6171, Test 0.5594
Epoch 120:, Train 0.6686, Val 0.6255, Test 0.5764
Epoch 140:, Train 0.6668, Val 0.6258, Test 0.5781
Epoch 160:, Train 0.6705, Val 0.6232, Test 0.5777
Epoch 180:, Train 0.6756, Val 0.6275, Test 0.5740
Epoch 200:, Train 0.6738, Val 0.6267, Test 0.5794
Epoch 220:, Train 0.6718, Val 0.6264, Test 0.5763
Epoch 240:, Train 0.6723, Val 0.6226, Test 0.5727
Epoch 260:, Train 0.6752, Val 0.6231, Test 0.5728
Epoch 280:, Train 0.6773, Val 0.6255, Test 0.5805
Epoch 300:, Train 0.6763, Val 0.6218, Test 0.5693
BEST: Epoch 180, Train 0.6756, Val 0.6275, Test 0.5740

RUN #6: seed=256
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.098 [0.294-1.000]
241.94472098350525
Epoch 20:, Train 0.6200, Val 0.6124, Test 0.5618
Epoch 40:, Train 0.6433, Val 0.6157, Test 0.5639
Epoch 60:, Train 0.6582, Val 0.6198, Test 0.5763
Epoch 80:, Train 0.6614, Val 0.6191, Test 0.5633
Epoch 100:, Train 0.6663, Val 0.6232, Test 0.5753
Epoch 120:, Train 0.6689, Val 0.6224, Test 0.5731
Epoch 140:, Train 0.6686, Val 0.6172, Test 0.5695
Epoch 160:, Train 0.6735, Val 0.6247, Test 0.5789
Epoch 180:, Train 0.6736, Val 0.6246, Test 0.5755
Epoch 200:, Train 0.6758, Val 0.6271, Test 0.5839
Epoch 220:, Train 0.6732, Val 0.6217, Test 0.5721
Epoch 240:, Train 0.6772, Val 0.6251, Test 0.5742
Epoch 260:, Train 0.6733, Val 0.6263, Test 0.5765
Epoch 280:, Train 0.6752, Val 0.6227, Test 0.5718
Epoch 300:, Train 0.6782, Val 0.6247, Test 0.5692
BEST: Epoch 200, Train 0.6758, Val 0.6271, Test 0.5839

RUN #7: seed=512
DOT_PRODUCT
Attention Filter (n=1166243): 0.858 +\- 0.102 [0.269-1.000]
282.5408368110657
Epoch 20:, Train 0.6268, Val 0.6143, Test 0.5634
Epoch 40:, Train 0.6445, Val 0.6192, Test 0.5689
Epoch 60:, Train 0.6529, Val 0.6177, Test 0.5681
Epoch 80:, Train 0.6612, Val 0.6198, Test 0.5622
Epoch 100:, Train 0.6657, Val 0.6277, Test 0.5793
Epoch 120:, Train 0.6683, Val 0.6242, Test 0.5762
Epoch 140:, Train 0.6672, Val 0.6205, Test 0.5645
Epoch 160:, Train 0.6714, Val 0.6265, Test 0.5735
Epoch 180:, Train 0.6718, Val 0.6257, Test 0.5765
Epoch 200:, Train 0.6726, Val 0.6231, Test 0.5683
Epoch 220:, Train 0.6751, Val 0.6235, Test 0.5692
Epoch 240:, Train 0.6736, Val 0.6237, Test 0.5715
Epoch 260:, Train 0.6776, Val 0.6249, Test 0.5719
Epoch 280:, Train 0.6791, Val 0.6237, Test 0.5680
Epoch 300:, Train 0.6751, Val 0.6258, Test 0.5774
BEST: Epoch 100, Train 0.6657, Val 0.6277, Test 0.5793

RUN #8: seed=1024
DOT_PRODUCT
Attention Filter (n=1166243): 0.866 +\- 0.097 [0.261-1.000]
243.83209562301636
Epoch 20:, Train 0.6229, Val 0.6105, Test 0.5620
Epoch 40:, Train 0.6439, Val 0.6187, Test 0.5713
Epoch 60:, Train 0.6569, Val 0.6224, Test 0.5712
Epoch 80:, Train 0.6618, Val 0.6215, Test 0.5683
Epoch 100:, Train 0.6648, Val 0.6218, Test 0.5706
Epoch 120:, Train 0.6696, Val 0.6269, Test 0.5738
Epoch 140:, Train 0.6680, Val 0.6245, Test 0.5750
Epoch 160:, Train 0.6723, Val 0.6270, Test 0.5716
Epoch 180:, Train 0.6724, Val 0.6217, Test 0.5691
Epoch 200:, Train 0.6742, Val 0.6270, Test 0.5809
Epoch 220:, Train 0.6748, Val 0.6257, Test 0.5710
Epoch 240:, Train 0.6751, Val 0.6282, Test 0.5793
Epoch 260:, Train 0.6780, Val 0.6279, Test 0.5696
Epoch 280:, Train 0.6765, Val 0.6239, Test 0.5707
Epoch 300:, Train 0.6737, Val 0.6226, Test 0.5688
BEST: Epoch 240, Train 0.6751, Val 0.6282, Test 0.5793

RUN #9: seed=2048
DOT_PRODUCT
Attention Filter (n=1166243): 0.871 +\- 0.094 [0.242-1.000]
243.88075947761536
Epoch 20:, Train 0.6243, Val 0.6167, Test 0.5747
Epoch 40:, Train 0.6414, Val 0.6157, Test 0.5628
Epoch 60:, Train 0.6560, Val 0.6245, Test 0.5746
Epoch 80:, Train 0.6610, Val 0.6266, Test 0.5733
Epoch 100:, Train 0.6638, Val 0.6163, Test 0.5625
Epoch 120:, Train 0.6636, Val 0.6171, Test 0.5623
Epoch 140:, Train 0.6721, Val 0.6219, Test 0.5693
Epoch 160:, Train 0.6725, Val 0.6200, Test 0.5688
Epoch 180:, Train 0.6704, Val 0.6241, Test 0.5709
Epoch 200:, Train 0.6768, Val 0.6239, Test 0.5704
Epoch 220:, Train 0.6759, Val 0.6252, Test 0.5708
Epoch 240:, Train 0.6735, Val 0.6247, Test 0.5699
Epoch 260:, Train 0.6732, Val 0.6209, Test 0.5691
Epoch 280:, Train 0.6738, Val 0.6235, Test 0.5687
Epoch 300:, Train 0.6747, Val 0.6299, Test 0.5874
BEST: Epoch 300, Train 0.6747, Val 0.6299, Test 0.5874




==================================================
Model Parameters: 531885

Avg. Preaggregation Time (s): 246.8826 +/- 11.9412
Avg. Training Time (epoch) (s): 1.2929 +/- 0.2582
Avg. Inference Time (s): 0.0794 +/- 0.0118

Avg. Training Acc: 0.6732 +/- 0.0043
Avg. Validation Acc: 0.6286 +/- 0.0013
Avg. Test Acc: 0.5818 +/- 0.0050

==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 1 hours 51 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
