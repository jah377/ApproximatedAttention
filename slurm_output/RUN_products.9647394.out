Sun 26 Jun 2022 05:23:54 PM CEST
r32n6.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

**************************************************
================= SIGN ===========================
**************************************************
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='sign', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=True, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 110.1235
Epoch 10:, Train 0.9375, Val 0.9162, Test 0.7204
Epoch 20:, Train 0.9432, Val 0.9214, Test 0.7509
Epoch 30:, Train 0.9405, Val 0.9180, Test 0.7228
Epoch 40:, Train 0.9409, Val 0.9194, Test 0.7229
Epoch 50:, Train 0.9438, Val 0.9218, Test 0.7508
Epoch 60:, Train 0.9440, Val 0.9190, Test 0.7410
Epoch 70:, Train 0.9443, Val 0.9205, Test 0.7575
Epoch 80:, Train 0.9449, Val 0.9198, Test 0.7236
Epoch 90:, Train 0.9457, Val 0.9221, Test 0.7332
Epoch 100:, Train 0.9402, Val 0.9180, Test 0.7304
Epoch 110:, Train 0.9452, Val 0.9207, Test 0.7470
Epoch 120:, Train 0.9452, Val 0.9209, Test 0.7509
Epoch 130:, Train 0.9449, Val 0.9202, Test 0.7382
Epoch 140:, Train 0.9466, Val 0.9212, Test 0.7405
Epoch 150:, Train 0.9478, Val 0.9223, Test 0.7395
Epoch 160:, Train 0.9470, Val 0.9237, Test 0.7449
Epoch 170:, Train 0.9481, Val 0.9234, Test 0.7453
Epoch 180:, Train 0.9473, Val 0.9216, Test 0.7478
Epoch 190:, Train 0.9489, Val 0.9234, Test 0.7525
Epoch 200:, Train 0.9478, Val 0.9211, Test 0.7491
Epoch 210:, Train 0.9490, Val 0.9222, Test 0.7478
Epoch 220:, Train 0.9495, Val 0.9243, Test 0.7558
Epoch 230:, Train 0.9504, Val 0.9230, Test 0.7561
Epoch 240:, Train 0.9491, Val 0.9243, Test 0.7489
Epoch 250:, Train 0.9495, Val 0.9238, Test 0.7478
Epoch 260:, Train 0.9497, Val 0.9236, Test 0.7499
Epoch 270:, Train 0.9489, Val 0.9235, Test 0.7492
Epoch 280:, Train 0.9512, Val 0.9235, Test 0.7364
Epoch 290:, Train 0.9507, Val 0.9254, Test 0.7569
Epoch 300:, Train 0.9492, Val 0.9216, Test 0.7440
BEST: Epoch 290, Train 0.9507, Val 0.9254, Test 0.7569

RUN #1: seed=4
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.1505
Epoch 10:, Train 0.9357, Val 0.9171, Test 0.7515
Epoch 20:, Train 0.9403, Val 0.9191, Test 0.7404
Epoch 30:, Train 0.9429, Val 0.9213, Test 0.7295
Epoch 40:, Train 0.9434, Val 0.9204, Test 0.7352
Epoch 50:, Train 0.9441, Val 0.9206, Test 0.7538
Epoch 60:, Train 0.9442, Val 0.9180, Test 0.7263
Epoch 70:, Train 0.9426, Val 0.9198, Test 0.7539
Epoch 80:, Train 0.9448, Val 0.9208, Test 0.7354
Epoch 90:, Train 0.9445, Val 0.9198, Test 0.7191
Epoch 100:, Train 0.9431, Val 0.9194, Test 0.7405
Epoch 110:, Train 0.9462, Val 0.9236, Test 0.7403
Epoch 120:, Train 0.9449, Val 0.9214, Test 0.7493
Epoch 130:, Train 0.9464, Val 0.9226, Test 0.7635
Epoch 140:, Train 0.9475, Val 0.9226, Test 0.7488
Epoch 150:, Train 0.9472, Val 0.9231, Test 0.7466
Epoch 160:, Train 0.9476, Val 0.9227, Test 0.7527
Epoch 170:, Train 0.9485, Val 0.9236, Test 0.7690
Epoch 180:, Train 0.9449, Val 0.9219, Test 0.7597
Epoch 190:, Train 0.9485, Val 0.9227, Test 0.7402
Epoch 200:, Train 0.9484, Val 0.9244, Test 0.7498
Epoch 210:, Train 0.9486, Val 0.9246, Test 0.7543
Epoch 220:, Train 0.9431, Val 0.9176, Test 0.7372
Epoch 230:, Train 0.9490, Val 0.9232, Test 0.7511
Epoch 240:, Train 0.9481, Val 0.9216, Test 0.7537
Epoch 250:, Train 0.9501, Val 0.9232, Test 0.7439
Epoch 260:, Train 0.9486, Val 0.9238, Test 0.7401
Epoch 270:, Train 0.9504, Val 0.9246, Test 0.7565
Epoch 280:, Train 0.9506, Val 0.9239, Test 0.7527
Epoch 290:, Train 0.9513, Val 0.9253, Test 0.7547
Epoch 300:, Train 0.9493, Val 0.9235, Test 0.7437
BEST: Epoch 290, Train 0.9513, Val 0.9253, Test 0.7547

RUN #2: seed=8
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.1001
Epoch 10:, Train 0.9388, Val 0.9190, Test 0.7217
Epoch 20:, Train 0.9326, Val 0.9083, Test 0.7123
Epoch 30:, Train 0.9426, Val 0.9217, Test 0.7463
Epoch 40:, Train 0.9429, Val 0.9197, Test 0.7477
Epoch 50:, Train 0.9433, Val 0.9213, Test 0.7433
Epoch 60:, Train 0.9436, Val 0.9190, Test 0.7442
Epoch 70:, Train 0.9437, Val 0.9205, Test 0.7365
Epoch 80:, Train 0.9427, Val 0.9196, Test 0.7312
Epoch 90:, Train 0.9458, Val 0.9205, Test 0.7349
Epoch 100:, Train 0.9440, Val 0.9189, Test 0.7197
Epoch 110:, Train 0.9458, Val 0.9216, Test 0.7389
Epoch 120:, Train 0.9469, Val 0.9226, Test 0.7505
Epoch 130:, Train 0.9467, Val 0.9231, Test 0.7550
Epoch 140:, Train 0.9469, Val 0.9216, Test 0.7461
Epoch 150:, Train 0.9474, Val 0.9234, Test 0.7514
Epoch 160:, Train 0.9462, Val 0.9228, Test 0.7490
Epoch 170:, Train 0.9496, Val 0.9220, Test 0.7475
Epoch 180:, Train 0.9474, Val 0.9213, Test 0.7479
Epoch 190:, Train 0.9485, Val 0.9224, Test 0.7469
Epoch 200:, Train 0.9494, Val 0.9247, Test 0.7633
Epoch 210:, Train 0.9480, Val 0.9232, Test 0.7510
Epoch 220:, Train 0.9501, Val 0.9250, Test 0.7501
Epoch 230:, Train 0.9484, Val 0.9224, Test 0.7398
Epoch 240:, Train 0.9498, Val 0.9242, Test 0.7494
Epoch 250:, Train 0.9496, Val 0.9251, Test 0.7508
Epoch 260:, Train 0.9513, Val 0.9248, Test 0.7516
Epoch 270:, Train 0.9506, Val 0.9245, Test 0.7566
Epoch 280:, Train 0.9483, Val 0.9233, Test 0.7549
Epoch 290:, Train 0.9508, Val 0.9248, Test 0.7535
Epoch 300:, Train 0.9510, Val 0.9252, Test 0.7592
BEST: Epoch 300, Train 0.9510, Val 0.9252, Test 0.7592

RUN #3: seed=42
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0830
Epoch 10:, Train 0.9370, Val 0.9184, Test 0.7481
Epoch 20:, Train 0.9444, Val 0.9222, Test 0.7511
Epoch 30:, Train 0.9395, Val 0.9180, Test 0.7518
Epoch 40:, Train 0.9414, Val 0.9194, Test 0.7431
Epoch 50:, Train 0.9407, Val 0.9176, Test 0.7472
Epoch 60:, Train 0.9433, Val 0.9198, Test 0.7524
Epoch 70:, Train 0.9426, Val 0.9190, Test 0.7450
Epoch 80:, Train 0.9446, Val 0.9201, Test 0.7396
Epoch 90:, Train 0.9441, Val 0.9197, Test 0.7350
Epoch 100:, Train 0.9465, Val 0.9226, Test 0.7465
Epoch 110:, Train 0.9459, Val 0.9213, Test 0.7535
Epoch 120:, Train 0.9445, Val 0.9194, Test 0.7434
Epoch 130:, Train 0.9473, Val 0.9240, Test 0.7626
Epoch 140:, Train 0.9463, Val 0.9201, Test 0.7317
Epoch 150:, Train 0.9474, Val 0.9224, Test 0.7438
Epoch 160:, Train 0.9496, Val 0.9249, Test 0.7569
Epoch 170:, Train 0.9485, Val 0.9245, Test 0.7498
Epoch 180:, Train 0.9477, Val 0.9233, Test 0.7543
Epoch 190:, Train 0.9483, Val 0.9239, Test 0.7495
Epoch 200:, Train 0.9497, Val 0.9240, Test 0.7498
Epoch 210:, Train 0.9484, Val 0.9246, Test 0.7562
Epoch 220:, Train 0.9496, Val 0.9235, Test 0.7478
Epoch 230:, Train 0.9491, Val 0.9226, Test 0.7624
Epoch 240:, Train 0.9502, Val 0.9245, Test 0.7441
Epoch 250:, Train 0.9481, Val 0.9247, Test 0.7355
Epoch 260:, Train 0.9496, Val 0.9235, Test 0.7428
Epoch 270:, Train 0.9498, Val 0.9239, Test 0.7557
Epoch 280:, Train 0.9510, Val 0.9263, Test 0.7532
Epoch 290:, Train 0.9493, Val 0.9227, Test 0.7349
Epoch 300:, Train 0.9510, Val 0.9239, Test 0.7617
BEST: Epoch 280, Train 0.9510, Val 0.9263, Test 0.7532

RUN #4: seed=64
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0793
Epoch 10:, Train 0.9376, Val 0.9177, Test 0.7392
Epoch 20:, Train 0.9397, Val 0.9173, Test 0.7176
Epoch 30:, Train 0.9379, Val 0.9144, Test 0.7280
Epoch 40:, Train 0.9452, Val 0.9228, Test 0.7449
Epoch 50:, Train 0.9409, Val 0.9178, Test 0.7352
Epoch 60:, Train 0.9427, Val 0.9196, Test 0.7480
Epoch 70:, Train 0.9442, Val 0.9216, Test 0.7411
Epoch 80:, Train 0.9446, Val 0.9207, Test 0.7432
Epoch 90:, Train 0.9449, Val 0.9221, Test 0.7492
Epoch 100:, Train 0.9468, Val 0.9198, Test 0.7280
Epoch 110:, Train 0.9458, Val 0.9205, Test 0.7369
Epoch 120:, Train 0.9436, Val 0.9178, Test 0.7446
Epoch 130:, Train 0.9456, Val 0.9219, Test 0.7601
Epoch 140:, Train 0.9454, Val 0.9188, Test 0.7505
Epoch 150:, Train 0.9458, Val 0.9218, Test 0.7412
Epoch 160:, Train 0.9482, Val 0.9237, Test 0.7589
Epoch 170:, Train 0.9471, Val 0.9212, Test 0.7494
Epoch 180:, Train 0.9482, Val 0.9200, Test 0.7456
Epoch 190:, Train 0.9485, Val 0.9240, Test 0.7614
Epoch 200:, Train 0.9484, Val 0.9227, Test 0.7446
Epoch 210:, Train 0.9489, Val 0.9222, Test 0.7451
Epoch 220:, Train 0.9491, Val 0.9250, Test 0.7517
Epoch 230:, Train 0.9487, Val 0.9220, Test 0.7512
Epoch 240:, Train 0.9502, Val 0.9254, Test 0.7459
Epoch 250:, Train 0.9494, Val 0.9251, Test 0.7456
Epoch 260:, Train 0.9484, Val 0.9237, Test 0.7601
Epoch 270:, Train 0.9501, Val 0.9220, Test 0.7420
Epoch 280:, Train 0.9518, Val 0.9255, Test 0.7567
Epoch 290:, Train 0.9495, Val 0.9229, Test 0.7450
Epoch 300:, Train 0.9499, Val 0.9250, Test 0.7610
BEST: Epoch 280, Train 0.9518, Val 0.9255, Test 0.7567

RUN #5: seed=128
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.1112
Epoch 10:, Train 0.9381, Val 0.9190, Test 0.7352
Epoch 20:, Train 0.9428, Val 0.9216, Test 0.7445
Epoch 30:, Train 0.9434, Val 0.9218, Test 0.7425
Epoch 40:, Train 0.9428, Val 0.9215, Test 0.7393
Epoch 50:, Train 0.9447, Val 0.9200, Test 0.7382
Epoch 60:, Train 0.9428, Val 0.9216, Test 0.7481
Epoch 70:, Train 0.9428, Val 0.9200, Test 0.7298
Epoch 80:, Train 0.9441, Val 0.9224, Test 0.7485
Epoch 90:, Train 0.9467, Val 0.9213, Test 0.7449
Epoch 100:, Train 0.9439, Val 0.9209, Test 0.7470
Epoch 110:, Train 0.9460, Val 0.9226, Test 0.7526
Epoch 120:, Train 0.9449, Val 0.9192, Test 0.7361
Epoch 130:, Train 0.9469, Val 0.9213, Test 0.7600
Epoch 140:, Train 0.9469, Val 0.9233, Test 0.7561
Epoch 150:, Train 0.9460, Val 0.9211, Test 0.7537
Epoch 160:, Train 0.9491, Val 0.9228, Test 0.7470
Epoch 170:, Train 0.9479, Val 0.9231, Test 0.7448
Epoch 180:, Train 0.9496, Val 0.9232, Test 0.7581
Epoch 190:, Train 0.9494, Val 0.9235, Test 0.7487
Epoch 200:, Train 0.9487, Val 0.9214, Test 0.7369
Epoch 210:, Train 0.9503, Val 0.9238, Test 0.7490
Epoch 220:, Train 0.9495, Val 0.9231, Test 0.7406
Epoch 230:, Train 0.9489, Val 0.9230, Test 0.7494
Epoch 240:, Train 0.9513, Val 0.9244, Test 0.7524
Epoch 250:, Train 0.9489, Val 0.9225, Test 0.7502
Epoch 260:, Train 0.9509, Val 0.9247, Test 0.7485
Epoch 270:, Train 0.9487, Val 0.9223, Test 0.7338
Epoch 280:, Train 0.9501, Val 0.9224, Test 0.7450
Epoch 290:, Train 0.9512, Val 0.9236, Test 0.7544
Epoch 300:, Train 0.9492, Val 0.9239, Test 0.7491
BEST: Epoch 260, Train 0.9509, Val 0.9247, Test 0.7485

RUN #6: seed=256
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0688
Epoch 10:, Train 0.9396, Val 0.9179, Test 0.7419
Epoch 20:, Train 0.9414, Val 0.9199, Test 0.7529
Epoch 30:, Train 0.9438, Val 0.9193, Test 0.7395
Epoch 40:, Train 0.9437, Val 0.9210, Test 0.7425
Epoch 50:, Train 0.9424, Val 0.9192, Test 0.7374
Epoch 60:, Train 0.9452, Val 0.9230, Test 0.7463
Epoch 70:, Train 0.9443, Val 0.9214, Test 0.7520
Epoch 80:, Train 0.9400, Val 0.9177, Test 0.7415
Epoch 90:, Train 0.9443, Val 0.9210, Test 0.7384
Epoch 100:, Train 0.9457, Val 0.9216, Test 0.7309
Epoch 110:, Train 0.9449, Val 0.9224, Test 0.7424
Epoch 120:, Train 0.9454, Val 0.9216, Test 0.7462
Epoch 130:, Train 0.9446, Val 0.9225, Test 0.7488
Epoch 140:, Train 0.9462, Val 0.9209, Test 0.7502
Epoch 150:, Train 0.9460, Val 0.9223, Test 0.7394
Epoch 160:, Train 0.9477, Val 0.9239, Test 0.7427
Epoch 170:, Train 0.9480, Val 0.9240, Test 0.7562
Epoch 180:, Train 0.9483, Val 0.9225, Test 0.7520
Epoch 190:, Train 0.9462, Val 0.9194, Test 0.7433
Epoch 200:, Train 0.9486, Val 0.9220, Test 0.7509
Epoch 210:, Train 0.9483, Val 0.9228, Test 0.7415
Epoch 220:, Train 0.9479, Val 0.9232, Test 0.7559
Epoch 230:, Train 0.9499, Val 0.9241, Test 0.7521
Epoch 240:, Train 0.9491, Val 0.9237, Test 0.7697
Epoch 250:, Train 0.9496, Val 0.9233, Test 0.7497
Epoch 260:, Train 0.9505, Val 0.9246, Test 0.7627
Epoch 270:, Train 0.9490, Val 0.9230, Test 0.7555
Epoch 280:, Train 0.9502, Val 0.9241, Test 0.7439
Epoch 290:, Train 0.9490, Val 0.9235, Test 0.7497
Epoch 300:, Train 0.9489, Val 0.9234, Test 0.7552
BEST: Epoch 260, Train 0.9505, Val 0.9246, Test 0.7627

RUN #7: seed=512
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.0766
Epoch 10:, Train 0.9371, Val 0.9165, Test 0.7366
Epoch 20:, Train 0.9421, Val 0.9206, Test 0.7480
Epoch 30:, Train 0.9408, Val 0.9182, Test 0.7333
Epoch 40:, Train 0.9396, Val 0.9162, Test 0.7396
Epoch 50:, Train 0.9446, Val 0.9214, Test 0.7368
Epoch 60:, Train 0.9452, Val 0.9194, Test 0.7383
Epoch 70:, Train 0.9439, Val 0.9211, Test 0.7445
Epoch 80:, Train 0.9450, Val 0.9213, Test 0.7525
Epoch 90:, Train 0.9467, Val 0.9230, Test 0.7523
Epoch 100:, Train 0.9440, Val 0.9199, Test 0.7506
Epoch 110:, Train 0.9471, Val 0.9236, Test 0.7454
Epoch 120:, Train 0.9463, Val 0.9219, Test 0.7366
Epoch 130:, Train 0.9465, Val 0.9228, Test 0.7458
Epoch 140:, Train 0.9461, Val 0.9225, Test 0.7637
Epoch 150:, Train 0.9475, Val 0.9213, Test 0.7432
Epoch 160:, Train 0.9466, Val 0.9214, Test 0.7337
Epoch 170:, Train 0.9483, Val 0.9224, Test 0.7402
Epoch 180:, Train 0.9492, Val 0.9239, Test 0.7590
Epoch 190:, Train 0.9478, Val 0.9218, Test 0.7515
Epoch 200:, Train 0.9468, Val 0.9200, Test 0.7385
Epoch 210:, Train 0.9487, Val 0.9225, Test 0.7384
Epoch 220:, Train 0.9507, Val 0.9244, Test 0.7562
Epoch 230:, Train 0.9481, Val 0.9235, Test 0.7513
Epoch 240:, Train 0.9495, Val 0.9252, Test 0.7579
Epoch 250:, Train 0.9493, Val 0.9234, Test 0.7457
Epoch 260:, Train 0.9497, Val 0.9219, Test 0.7601
Epoch 270:, Train 0.9513, Val 0.9235, Test 0.7491
Epoch 280:, Train 0.9503, Val 0.9241, Test 0.7469
Epoch 290:, Train 0.9507, Val 0.9242, Test 0.7504
Epoch 300:, Train 0.9495, Val 0.9236, Test 0.7486
BEST: Epoch 240, Train 0.9495, Val 0.9252, Test 0.7579

RUN #8: seed=1024
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.1004
Epoch 10:, Train 0.9358, Val 0.9173, Test 0.7211
Epoch 20:, Train 0.9410, Val 0.9192, Test 0.7344
Epoch 30:, Train 0.9429, Val 0.9173, Test 0.7225
Epoch 40:, Train 0.9409, Val 0.9184, Test 0.7311
Epoch 50:, Train 0.9446, Val 0.9215, Test 0.7356
Epoch 60:, Train 0.9440, Val 0.9208, Test 0.7426
Epoch 70:, Train 0.9408, Val 0.9147, Test 0.7305
Epoch 80:, Train 0.9429, Val 0.9170, Test 0.7117
Epoch 90:, Train 0.9445, Val 0.9210, Test 0.7358
Epoch 100:, Train 0.9423, Val 0.9172, Test 0.7355
Epoch 110:, Train 0.9436, Val 0.9197, Test 0.7457
Epoch 120:, Train 0.9441, Val 0.9189, Test 0.7223
Epoch 130:, Train 0.9443, Val 0.9234, Test 0.7472
Epoch 140:, Train 0.9473, Val 0.9221, Test 0.7484
Epoch 150:, Train 0.9460, Val 0.9210, Test 0.7447
Epoch 160:, Train 0.9488, Val 0.9244, Test 0.7510
Epoch 170:, Train 0.9487, Val 0.9227, Test 0.7578
Epoch 180:, Train 0.9468, Val 0.9227, Test 0.7449
Epoch 190:, Train 0.9484, Val 0.9242, Test 0.7499
Epoch 200:, Train 0.9473, Val 0.9238, Test 0.7562
Epoch 210:, Train 0.9478, Val 0.9218, Test 0.7626
Epoch 220:, Train 0.9456, Val 0.9221, Test 0.7465
Epoch 230:, Train 0.9493, Val 0.9231, Test 0.7514
Epoch 240:, Train 0.9495, Val 0.9252, Test 0.7568
Epoch 250:, Train 0.9504, Val 0.9238, Test 0.7632
Epoch 260:, Train 0.9481, Val 0.9238, Test 0.7542
Epoch 270:, Train 0.9485, Val 0.9234, Test 0.7506
Epoch 280:, Train 0.9502, Val 0.9235, Test 0.7547
Epoch 290:, Train 0.9497, Val 0.9242, Test 0.7582
Epoch 300:, Train 0.9504, Val 0.9251, Test 0.7556
BEST: Epoch 240, Train 0.9495, Val 0.9252, Test 0.7568

RUN #9: seed=2048
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.1071
Epoch 10:, Train 0.9352, Val 0.9155, Test 0.7331
Epoch 20:, Train 0.9401, Val 0.9192, Test 0.7525
Epoch 30:, Train 0.9433, Val 0.9203, Test 0.7415
Epoch 40:, Train 0.9431, Val 0.9191, Test 0.7552
Epoch 50:, Train 0.9422, Val 0.9200, Test 0.7362
Epoch 60:, Train 0.9427, Val 0.9168, Test 0.7443
Epoch 70:, Train 0.9449, Val 0.9227, Test 0.7558
Epoch 80:, Train 0.9438, Val 0.9201, Test 0.7366
Epoch 90:, Train 0.9451, Val 0.9211, Test 0.7376
Epoch 100:, Train 0.9458, Val 0.9222, Test 0.7408
Epoch 110:, Train 0.9444, Val 0.9241, Test 0.7537
Epoch 120:, Train 0.9457, Val 0.9227, Test 0.7515
Epoch 130:, Train 0.9476, Val 0.9220, Test 0.7478
Epoch 140:, Train 0.9450, Val 0.9191, Test 0.7347
Epoch 150:, Train 0.9483, Val 0.9239, Test 0.7514
Epoch 160:, Train 0.9471, Val 0.9224, Test 0.7515
Epoch 170:, Train 0.9480, Val 0.9221, Test 0.7509
Epoch 180:, Train 0.9476, Val 0.9225, Test 0.7539
Epoch 190:, Train 0.9487, Val 0.9224, Test 0.7321
Epoch 200:, Train 0.9494, Val 0.9245, Test 0.7424
Epoch 210:, Train 0.9476, Val 0.9215, Test 0.7525
Epoch 220:, Train 0.9490, Val 0.9223, Test 0.7550
Epoch 230:, Train 0.9492, Val 0.9225, Test 0.7559
Epoch 240:, Train 0.9492, Val 0.9245, Test 0.7537
Epoch 250:, Train 0.9492, Val 0.9241, Test 0.7520
Epoch 260:, Train 0.9492, Val 0.9230, Test 0.7538
Epoch 270:, Train 0.9492, Val 0.9235, Test 0.7578
Epoch 280:, Train 0.9488, Val 0.9228, Test 0.7536
Epoch 290:, Train 0.9503, Val 0.9251, Test 0.7468
Epoch 300:, Train 0.9497, Val 0.9238, Test 0.7578
BEST: Epoch 290, Train 0.9503, Val 0.9251, Test 0.7468




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 0.0000 +/- 0.0000
Avg. Preaggregation Time (s): 109.2001 +/- 0.3086
Avg. Training Time (epoch) (s): 4.3361 +/- 0.0542
Avg. Inference Time (s): 1.3198 +/- 0.0137

Avg. Training Acc: 0.9507 +/- 0.0007
Avg. Validation Acc: 0.9252 +/- 0.0004
Avg. Test Acc: 0.7553 +/- 0.0045

**************************************************

**************************************************
================= SIGN+CS ========================
**************************************************
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='cosine', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=4, BATCH_SIZE=16384, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=2, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=2, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 1.979e-05
convert to csr_matrix: 2.66
calc min-max per row: 0.7328
vectorization: 1.734
Total Normalization: 6.6463
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 281.8574
Epoch 10:, Train 0.9216, Val 0.8990, Test 0.7273
Epoch 20:, Train 0.9426, Val 0.9085, Test 0.7556
Epoch 30:, Train 0.9470, Val 0.9096, Test 0.7512
Epoch 40:, Train 0.9533, Val 0.9134, Test 0.7607
Epoch 50:, Train 0.9560, Val 0.9143, Test 0.7652
Epoch 60:, Train 0.9582, Val 0.9135, Test 0.7669
Epoch 70:, Train 0.9596, Val 0.9148, Test 0.7656
Epoch 80:, Train 0.9622, Val 0.9159, Test 0.7639
Epoch 90:, Train 0.9619, Val 0.9108, Test 0.7582
Epoch 100:, Train 0.9642, Val 0.9140, Test 0.7564
Epoch 110:, Train 0.9628, Val 0.9121, Test 0.7575
Epoch 120:, Train 0.9636, Val 0.9123, Test 0.7557
Epoch 130:, Train 0.9639, Val 0.9125, Test 0.7545
Epoch 140:, Train 0.9651, Val 0.9139, Test 0.7638
Epoch 150:, Train 0.9656, Val 0.9121, Test 0.7570
Epoch 160:, Train 0.9666, Val 0.9134, Test 0.7586
Epoch 170:, Train 0.9671, Val 0.9122, Test 0.7554
Epoch 180:, Train 0.9698, Val 0.9163, Test 0.7641
Epoch 190:, Train 0.9702, Val 0.9141, Test 0.7687
Epoch 200:, Train 0.9710, Val 0.9164, Test 0.7652
Epoch 210:, Train 0.9686, Val 0.9157, Test 0.7593
Epoch 220:, Train 0.9721, Val 0.9149, Test 0.7608
Epoch 230:, Train 0.9707, Val 0.9135, Test 0.7545
Epoch 240:, Train 0.9713, Val 0.9164, Test 0.7634
Epoch 250:, Train 0.9721, Val 0.9170, Test 0.7657
Epoch 260:, Train 0.9729, Val 0.9142, Test 0.7593
Epoch 270:, Train 0.9742, Val 0.9161, Test 0.7659
Epoch 280:, Train 0.9718, Val 0.9137, Test 0.7608
Epoch 290:, Train 0.9710, Val 0.9133, Test 0.7613
Epoch 300:, Train 0.9747, Val 0.9154, Test 0.7652
BEST: Epoch 250, Train 0.9721, Val 0.9170, Test 0.7657

RUN #1: seed=4
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.217e-05
convert to csr_matrix: 2.536
calc min-max per row: 0.722
vectorization: 1.663
Total Normalization: 6.4494
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 282.2932
Epoch 10:, Train 0.9241, Val 0.9003, Test 0.7175
Epoch 20:, Train 0.9433, Val 0.9071, Test 0.7498
Epoch 30:, Train 0.9506, Val 0.9129, Test 0.7592
Epoch 40:, Train 0.9530, Val 0.9123, Test 0.7541
Epoch 50:, Train 0.9568, Val 0.9153, Test 0.7558
Epoch 60:, Train 0.9560, Val 0.9128, Test 0.7572
Epoch 70:, Train 0.9587, Val 0.9161, Test 0.7636
Epoch 80:, Train 0.9606, Val 0.9149, Test 0.7617
Epoch 90:, Train 0.9627, Val 0.9165, Test 0.7552
Epoch 100:, Train 0.9636, Val 0.9159, Test 0.7619
Epoch 110:, Train 0.9630, Val 0.9108, Test 0.7536
Epoch 120:, Train 0.9641, Val 0.9124, Test 0.7567
Epoch 130:, Train 0.9653, Val 0.9108, Test 0.7532
Epoch 140:, Train 0.9659, Val 0.9131, Test 0.7584
Epoch 150:, Train 0.9669, Val 0.9152, Test 0.7613
Epoch 160:, Train 0.9687, Val 0.9159, Test 0.7637
Epoch 170:, Train 0.9675, Val 0.9125, Test 0.7510
Epoch 180:, Train 0.9678, Val 0.9157, Test 0.7524
Epoch 190:, Train 0.9687, Val 0.9143, Test 0.7553
Epoch 200:, Train 0.9683, Val 0.9161, Test 0.7630
Epoch 210:, Train 0.9699, Val 0.9146, Test 0.7603
Epoch 220:, Train 0.9689, Val 0.9132, Test 0.7543
Epoch 230:, Train 0.9701, Val 0.9152, Test 0.7595
Epoch 240:, Train 0.9694, Val 0.9161, Test 0.7573
Epoch 250:, Train 0.9706, Val 0.9174, Test 0.7643
Epoch 260:, Train 0.9714, Val 0.9150, Test 0.7559
Epoch 270:, Train 0.9702, Val 0.9124, Test 0.7533
Epoch 280:, Train 0.9722, Val 0.9148, Test 0.7653
Epoch 290:, Train 0.9717, Val 0.9157, Test 0.7683
Epoch 300:, Train 0.9721, Val 0.9152, Test 0.7621
BEST: Epoch 250, Train 0.9706, Val 0.9174, Test 0.7643

RUN #2: seed=8
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.623e-05
convert to csr_matrix: 2.529
calc min-max per row: 0.7222
vectorization: 1.652
Total Normalization: 6.4209
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 280.3463
Epoch 10:, Train 0.9250, Val 0.9009, Test 0.7184
Epoch 20:, Train 0.9440, Val 0.9107, Test 0.7428
Epoch 30:, Train 0.9499, Val 0.9116, Test 0.7505
Epoch 40:, Train 0.9536, Val 0.9107, Test 0.7535
Epoch 50:, Train 0.9539, Val 0.9106, Test 0.7577
Epoch 60:, Train 0.9582, Val 0.9126, Test 0.7649
Epoch 70:, Train 0.9592, Val 0.9118, Test 0.7560
Epoch 80:, Train 0.9612, Val 0.9150, Test 0.7655
Epoch 90:, Train 0.9629, Val 0.9153, Test 0.7623
Epoch 100:, Train 0.9640, Val 0.9152, Test 0.7601
Epoch 110:, Train 0.9622, Val 0.9119, Test 0.7553
Epoch 120:, Train 0.9647, Val 0.9113, Test 0.7584
Epoch 130:, Train 0.9655, Val 0.9155, Test 0.7550
Epoch 140:, Train 0.9653, Val 0.9161, Test 0.7618
Epoch 150:, Train 0.9661, Val 0.9167, Test 0.7618
Epoch 160:, Train 0.9655, Val 0.9169, Test 0.7566
Epoch 170:, Train 0.9673, Val 0.9173, Test 0.7567
Epoch 180:, Train 0.9668, Val 0.9146, Test 0.7610
Epoch 190:, Train 0.9685, Val 0.9168, Test 0.7579
Epoch 200:, Train 0.9703, Val 0.9115, Test 0.7539
Epoch 210:, Train 0.9695, Val 0.9145, Test 0.7561
Epoch 220:, Train 0.9698, Val 0.9134, Test 0.7573
Epoch 230:, Train 0.9714, Val 0.9134, Test 0.7580
Epoch 240:, Train 0.9706, Val 0.9135, Test 0.7546
Epoch 250:, Train 0.9706, Val 0.9159, Test 0.7558
Epoch 260:, Train 0.9695, Val 0.9167, Test 0.7620
Epoch 270:, Train 0.9721, Val 0.9172, Test 0.7628
Epoch 280:, Train 0.9718, Val 0.9133, Test 0.7572
Epoch 290:, Train 0.9695, Val 0.9152, Test 0.7632
Epoch 300:, Train 0.9719, Val 0.9156, Test 0.7631
BEST: Epoch 170, Train 0.9673, Val 0.9173, Test 0.7567

RUN #3: seed=42
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 3.552e-05
convert to csr_matrix: 2.529
calc min-max per row: 0.7468
vectorization: 1.635
Total Normalization: 6.4398
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 281.8148
Epoch 10:, Train 0.9130, Val 0.8924, Test 0.7114
Epoch 20:, Train 0.9439, Val 0.9077, Test 0.7552
Epoch 30:, Train 0.9502, Val 0.9097, Test 0.7527
Epoch 40:, Train 0.9524, Val 0.9095, Test 0.7502
Epoch 50:, Train 0.9554, Val 0.9129, Test 0.7544
Epoch 60:, Train 0.9567, Val 0.9131, Test 0.7545
Epoch 70:, Train 0.9608, Val 0.9132, Test 0.7619
Epoch 80:, Train 0.9630, Val 0.9148, Test 0.7635
Epoch 90:, Train 0.9643, Val 0.9150, Test 0.7575
Epoch 100:, Train 0.9631, Val 0.9120, Test 0.7552
Epoch 110:, Train 0.9628, Val 0.9108, Test 0.7448
Epoch 120:, Train 0.9675, Val 0.9135, Test 0.7551
Epoch 130:, Train 0.9651, Val 0.9137, Test 0.7521
Epoch 140:, Train 0.9684, Val 0.9146, Test 0.7581
Epoch 150:, Train 0.9697, Val 0.9161, Test 0.7648
Epoch 160:, Train 0.9684, Val 0.9123, Test 0.7569
Epoch 170:, Train 0.9684, Val 0.9123, Test 0.7533
Epoch 180:, Train 0.9701, Val 0.9150, Test 0.7615
Epoch 190:, Train 0.9706, Val 0.9147, Test 0.7586
Epoch 200:, Train 0.9697, Val 0.9135, Test 0.7552
Epoch 210:, Train 0.9720, Val 0.9122, Test 0.7546
Epoch 220:, Train 0.9726, Val 0.9153, Test 0.7573
Epoch 230:, Train 0.9740, Val 0.9161, Test 0.7646
Epoch 240:, Train 0.9711, Val 0.9166, Test 0.7550
Epoch 250:, Train 0.9726, Val 0.9122, Test 0.7552
Epoch 260:, Train 0.9738, Val 0.9154, Test 0.7628
Epoch 270:, Train 0.9731, Val 0.9148, Test 0.7662
Epoch 280:, Train 0.9731, Val 0.9174, Test 0.7627
Epoch 290:, Train 0.9749, Val 0.9153, Test 0.7578
Epoch 300:, Train 0.9704, Val 0.9127, Test 0.7538
BEST: Epoch 280, Train 0.9731, Val 0.9174, Test 0.7627

RUN #4: seed=64
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.718e-05
convert to csr_matrix: 2.533
calc min-max per row: 0.7316
vectorization: 1.637
Total Normalization: 6.4236
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 280.7989
Epoch 10:, Train 0.9219, Val 0.8975, Test 0.7174
Epoch 20:, Train 0.9439, Val 0.9095, Test 0.7466
Epoch 30:, Train 0.9475, Val 0.9109, Test 0.7570
Epoch 40:, Train 0.9538, Val 0.9154, Test 0.7638
Epoch 50:, Train 0.9537, Val 0.9091, Test 0.7468
Epoch 60:, Train 0.9574, Val 0.9125, Test 0.7562
Epoch 70:, Train 0.9595, Val 0.9148, Test 0.7542
Epoch 80:, Train 0.9620, Val 0.9145, Test 0.7661
Epoch 90:, Train 0.9623, Val 0.9128, Test 0.7590
Epoch 100:, Train 0.9664, Val 0.9172, Test 0.7682
Epoch 110:, Train 0.9631, Val 0.9144, Test 0.7638
Epoch 120:, Train 0.9637, Val 0.9142, Test 0.7639
Epoch 130:, Train 0.9655, Val 0.9125, Test 0.7579
Epoch 140:, Train 0.9678, Val 0.9139, Test 0.7549
Epoch 150:, Train 0.9659, Val 0.9144, Test 0.7547
Epoch 160:, Train 0.9672, Val 0.9167, Test 0.7612
Epoch 170:, Train 0.9667, Val 0.9126, Test 0.7547
Epoch 180:, Train 0.9672, Val 0.9132, Test 0.7569
Epoch 190:, Train 0.9709, Val 0.9165, Test 0.7578
Epoch 200:, Train 0.9688, Val 0.9115, Test 0.7580
Epoch 210:, Train 0.9694, Val 0.9129, Test 0.7583
Epoch 220:, Train 0.9700, Val 0.9125, Test 0.7544
Epoch 230:, Train 0.9698, Val 0.9148, Test 0.7565
Epoch 240:, Train 0.9692, Val 0.9145, Test 0.7591
Epoch 250:, Train 0.9724, Val 0.9156, Test 0.7666
Epoch 260:, Train 0.9717, Val 0.9143, Test 0.7640
Epoch 270:, Train 0.9709, Val 0.9154, Test 0.7641
Epoch 280:, Train 0.9715, Val 0.9148, Test 0.7549
Epoch 290:, Train 0.9722, Val 0.9124, Test 0.7548
Epoch 300:, Train 0.9710, Val 0.9169, Test 0.7602
BEST: Epoch 100, Train 0.9664, Val 0.9172, Test 0.7682

RUN #5: seed=128
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.694e-05
convert to csr_matrix: 2.656
calc min-max per row: 0.7454
vectorization: 1.737
Total Normalization: 6.6940
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 261.9409
Epoch 10:, Train 0.9223, Val 0.9002, Test 0.7257
Epoch 20:, Train 0.9435, Val 0.9090, Test 0.7438
Epoch 30:, Train 0.9492, Val 0.9106, Test 0.7651
Epoch 40:, Train 0.9537, Val 0.9127, Test 0.7547
Epoch 50:, Train 0.9569, Val 0.9133, Test 0.7632
Epoch 60:, Train 0.9584, Val 0.9141, Test 0.7598
Epoch 70:, Train 0.9606, Val 0.9156, Test 0.7648
Epoch 80:, Train 0.9639, Val 0.9154, Test 0.7611
Epoch 90:, Train 0.9656, Val 0.9147, Test 0.7640
Epoch 100:, Train 0.9648, Val 0.9157, Test 0.7580
Epoch 110:, Train 0.9678, Val 0.9163, Test 0.7627
Epoch 120:, Train 0.9683, Val 0.9169, Test 0.7593
Epoch 130:, Train 0.9679, Val 0.9149, Test 0.7633
Epoch 140:, Train 0.9688, Val 0.9152, Test 0.7569
Epoch 150:, Train 0.9715, Val 0.9159, Test 0.7614
Epoch 160:, Train 0.9709, Val 0.9162, Test 0.7564
Epoch 170:, Train 0.9699, Val 0.9167, Test 0.7667
Epoch 180:, Train 0.9721, Val 0.9127, Test 0.7597
Epoch 190:, Train 0.9694, Val 0.9138, Test 0.7588
Epoch 200:, Train 0.9723, Val 0.9151, Test 0.7551
Epoch 210:, Train 0.9710, Val 0.9144, Test 0.7547
Epoch 220:, Train 0.9706, Val 0.9121, Test 0.7521
Epoch 230:, Train 0.9730, Val 0.9141, Test 0.7615
Epoch 240:, Train 0.9723, Val 0.9139, Test 0.7659
Epoch 250:, Train 0.9728, Val 0.9147, Test 0.7684
Epoch 260:, Train 0.9726, Val 0.9157, Test 0.7607
Epoch 270:, Train 0.9750, Val 0.9163, Test 0.7617
Epoch 280:, Train 0.9723, Val 0.9120, Test 0.7516
Epoch 290:, Train 0.9731, Val 0.9158, Test 0.7594
Epoch 300:, Train 0.9748, Val 0.9161, Test 0.7615
BEST: Epoch 120, Train 0.9683, Val 0.9169, Test 0.7593

RUN #6: seed=256
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.718e-05
convert to csr_matrix: 2.659
calc min-max per row: 0.747
vectorization: 1.736
Total Normalization: 6.7006
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 279.8248
Epoch 10:, Train 0.9196, Val 0.8971, Test 0.7149
Epoch 20:, Train 0.9413, Val 0.9069, Test 0.7313
Epoch 30:, Train 0.9515, Val 0.9139, Test 0.7558
Epoch 40:, Train 0.9537, Val 0.9131, Test 0.7476
Epoch 50:, Train 0.9563, Val 0.9141, Test 0.7619
Epoch 60:, Train 0.9570, Val 0.9133, Test 0.7511
Epoch 70:, Train 0.9584, Val 0.9134, Test 0.7567
Epoch 80:, Train 0.9603, Val 0.9130, Test 0.7613
Epoch 90:, Train 0.9614, Val 0.9134, Test 0.7554
Epoch 100:, Train 0.9626, Val 0.9115, Test 0.7655
Epoch 110:, Train 0.9627, Val 0.9131, Test 0.7573
Epoch 120:, Train 0.9652, Val 0.9143, Test 0.7561
Epoch 130:, Train 0.9663, Val 0.9154, Test 0.7590
Epoch 140:, Train 0.9649, Val 0.9145, Test 0.7547
Epoch 150:, Train 0.9665, Val 0.9153, Test 0.7667
Epoch 160:, Train 0.9692, Val 0.9158, Test 0.7679
Epoch 170:, Train 0.9691, Val 0.9133, Test 0.7566
Epoch 180:, Train 0.9681, Val 0.9136, Test 0.7575
Epoch 190:, Train 0.9664, Val 0.9152, Test 0.7569
Epoch 200:, Train 0.9677, Val 0.9124, Test 0.7560
Epoch 210:, Train 0.9690, Val 0.9156, Test 0.7635
Epoch 220:, Train 0.9711, Val 0.9161, Test 0.7607
Epoch 230:, Train 0.9706, Val 0.9121, Test 0.7568
Epoch 240:, Train 0.9706, Val 0.9157, Test 0.7607
Epoch 250:, Train 0.9704, Val 0.9149, Test 0.7586
Epoch 260:, Train 0.9688, Val 0.9138, Test 0.7581
Epoch 270:, Train 0.9707, Val 0.9168, Test 0.7658
Epoch 280:, Train 0.9702, Val 0.9157, Test 0.7602
Epoch 290:, Train 0.9700, Val 0.9133, Test 0.7580
Epoch 300:, Train 0.9720, Val 0.9147, Test 0.7599
BEST: Epoch 270, Train 0.9707, Val 0.9168, Test 0.7658

RUN #7: seed=512
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.575e-05
convert to csr_matrix: 2.664
calc min-max per row: 0.7215
vectorization: 1.731
Total Normalization: 6.6623
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 281.3240
Epoch 10:, Train 0.9216, Val 0.9002, Test 0.7259
Epoch 20:, Train 0.9421, Val 0.9083, Test 0.7498
Epoch 30:, Train 0.9492, Val 0.9086, Test 0.7473
Epoch 40:, Train 0.9522, Val 0.9135, Test 0.7554
Epoch 50:, Train 0.9548, Val 0.9127, Test 0.7589
Epoch 60:, Train 0.9588, Val 0.9128, Test 0.7629
Epoch 70:, Train 0.9589, Val 0.9123, Test 0.7575
Epoch 80:, Train 0.9612, Val 0.9148, Test 0.7633
Epoch 90:, Train 0.9636, Val 0.9148, Test 0.7531
Epoch 100:, Train 0.9622, Val 0.9123, Test 0.7605
Epoch 110:, Train 0.9641, Val 0.9152, Test 0.7599
Epoch 120:, Train 0.9657, Val 0.9133, Test 0.7608
Epoch 130:, Train 0.9636, Val 0.9131, Test 0.7498
Epoch 140:, Train 0.9652, Val 0.9147, Test 0.7615
Epoch 150:, Train 0.9670, Val 0.9159, Test 0.7662
Epoch 160:, Train 0.9688, Val 0.9161, Test 0.7554
Epoch 170:, Train 0.9694, Val 0.9167, Test 0.7612
Epoch 180:, Train 0.9692, Val 0.9171, Test 0.7663
Epoch 190:, Train 0.9687, Val 0.9153, Test 0.7564
Epoch 200:, Train 0.9690, Val 0.9149, Test 0.7617
Epoch 210:, Train 0.9685, Val 0.9148, Test 0.7613
Epoch 220:, Train 0.9708, Val 0.9178, Test 0.7624
Epoch 230:, Train 0.9721, Val 0.9162, Test 0.7546
Epoch 240:, Train 0.9708, Val 0.9138, Test 0.7512
Epoch 250:, Train 0.9735, Val 0.9162, Test 0.7571
Epoch 260:, Train 0.9733, Val 0.9136, Test 0.7609
Epoch 270:, Train 0.9735, Val 0.9167, Test 0.7615
Epoch 280:, Train 0.9603, Val 0.9009, Test 0.7318
Epoch 290:, Train 0.9729, Val 0.9134, Test 0.7553
Epoch 300:, Train 0.9745, Val 0.9145, Test 0.7588
BEST: Epoch 220, Train 0.9708, Val 0.9178, Test 0.7624

RUN #8: seed=1024
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.098e-05
convert to csr_matrix: 2.646
calc min-max per row: 0.7336
vectorization: 1.737
Total Normalization: 6.6792
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 279.1525
Epoch 10:, Train 0.9222, Val 0.8990, Test 0.7262
Epoch 20:, Train 0.9430, Val 0.9088, Test 0.7523
Epoch 30:, Train 0.9487, Val 0.9093, Test 0.7466
Epoch 40:, Train 0.9513, Val 0.9130, Test 0.7571
Epoch 50:, Train 0.9556, Val 0.9118, Test 0.7587
Epoch 60:, Train 0.9558, Val 0.9128, Test 0.7565
Epoch 70:, Train 0.9597, Val 0.9154, Test 0.7636
Epoch 80:, Train 0.9601, Val 0.9132, Test 0.7547
Epoch 90:, Train 0.9630, Val 0.9163, Test 0.7608
Epoch 100:, Train 0.9625, Val 0.9134, Test 0.7590
Epoch 110:, Train 0.9646, Val 0.9157, Test 0.7618
Epoch 120:, Train 0.9611, Val 0.9115, Test 0.7475
Epoch 130:, Train 0.9628, Val 0.9098, Test 0.7565
Epoch 140:, Train 0.9643, Val 0.9121, Test 0.7577
Epoch 150:, Train 0.9680, Val 0.9160, Test 0.7613
Epoch 160:, Train 0.9666, Val 0.9109, Test 0.7568
Epoch 170:, Train 0.9647, Val 0.9141, Test 0.7571
Epoch 180:, Train 0.9683, Val 0.9161, Test 0.7604
Epoch 190:, Train 0.9674, Val 0.9131, Test 0.7566
Epoch 200:, Train 0.9687, Val 0.9135, Test 0.7559
Epoch 210:, Train 0.9697, Val 0.9166, Test 0.7605
Epoch 220:, Train 0.9675, Val 0.9139, Test 0.7615
Epoch 230:, Train 0.9696, Val 0.9139, Test 0.7588
Epoch 240:, Train 0.9704, Val 0.9150, Test 0.7618
Epoch 250:, Train 0.9702, Val 0.9120, Test 0.7616
Epoch 260:, Train 0.9712, Val 0.9169, Test 0.7610
Epoch 270:, Train 0.9686, Val 0.9131, Test 0.7546
Epoch 280:, Train 0.9708, Val 0.9167, Test 0.7602
Epoch 290:, Train 0.9709, Val 0.9150, Test 0.7611
Epoch 300:, Train 0.9717, Val 0.9107, Test 0.7553
BEST: Epoch 260, Train 0.9712, Val 0.9169, Test 0.7610

RUN #9: seed=2048
Attn Summary:
len(r): 121619682
len(c): 121619682
len(v): 121619682
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.384e-05
convert to csr_matrix: 2.529
calc min-max per row: 0.7326
vectorization: 1.636
Total Normalization: 6.4197
COSINE
Attention Filter (n=121619682): 0.396 +\- 0.925 [-4046.922-3691.750]
Total Transformation Time: 280.2025
Epoch 10:, Train 0.9235, Val 0.9011, Test 0.7185
Epoch 20:, Train 0.9426, Val 0.9090, Test 0.7436
Epoch 30:, Train 0.9523, Val 0.9126, Test 0.7611
Epoch 40:, Train 0.9538, Val 0.9133, Test 0.7672
Epoch 50:, Train 0.9538, Val 0.9096, Test 0.7516
Epoch 60:, Train 0.9578, Val 0.9127, Test 0.7575
Epoch 70:, Train 0.9606, Val 0.9150, Test 0.7644
Epoch 80:, Train 0.9601, Val 0.9120, Test 0.7587
Epoch 90:, Train 0.9605, Val 0.9132, Test 0.7530
Epoch 100:, Train 0.9642, Val 0.9166, Test 0.7653
Epoch 110:, Train 0.9657, Val 0.9139, Test 0.7541
Epoch 120:, Train 0.9657, Val 0.9130, Test 0.7586
Epoch 130:, Train 0.9653, Val 0.9129, Test 0.7574
Epoch 140:, Train 0.9654, Val 0.9166, Test 0.7629
Epoch 150:, Train 0.9644, Val 0.9124, Test 0.7562
Epoch 160:, Train 0.9665, Val 0.9138, Test 0.7592
Epoch 170:, Train 0.9696, Val 0.9135, Test 0.7596
Epoch 180:, Train 0.9688, Val 0.9163, Test 0.7622
Epoch 190:, Train 0.9679, Val 0.9126, Test 0.7587
Epoch 200:, Train 0.9705, Val 0.9167, Test 0.7652
Epoch 210:, Train 0.9676, Val 0.9128, Test 0.7604
Epoch 220:, Train 0.9689, Val 0.9134, Test 0.7513
Epoch 230:, Train 0.9714, Val 0.9165, Test 0.7603
Epoch 240:, Train 0.9702, Val 0.9166, Test 0.7599
Epoch 250:, Train 0.9705, Val 0.9156, Test 0.7584
Epoch 260:, Train 0.9728, Val 0.9167, Test 0.7648
Epoch 270:, Train 0.9724, Val 0.9151, Test 0.7614
Epoch 280:, Train 0.9740, Val 0.9160, Test 0.7637
Epoch 290:, Train 0.9737, Val 0.9163, Test 0.7567
Epoch 300:, Train 0.9734, Val 0.9138, Test 0.7628
BEST: Epoch 200, Train 0.9705, Val 0.9167, Test 0.7652




==================================================
Model Parameters: 8422454

Avg. Filter Time (s): 150.6883 +/- 5.7305
Avg. Preaggregation Time (s): 278.9555 +/- 5.7491
Avg. Training Time (epoch) (s): 2.7263 +/- 0.1151
Avg. Inference Time (s): 0.2556 +/- 0.0130

Avg. Training Acc: 0.9701 +/- 0.0020
Avg. Validation Acc: 0.9171 +/- 0.0003
Avg. Test Acc: 0.7631 +/- 0.0033

**************************************************

**************************************************
================= SIGN+SHA =======================
**************************************************
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=4, BATCH_SIZE=8192, LEARNING_RATE=0.001, WEIGHT_DECAY=1e-07, INCEPTION_LAYERS=2, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=2, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.2, NODE_DROPOUT=0.5, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0003807349130511284
coalesce scoo: 1.121e-05
convert to csr_matrix: 2.696
calc min-max per row: 0.754
vectorization: 1.767
Normalization Time: 6.7930
DOT_PRODUCT
Attention Filter (n=122947251): 0.151 +\- 0.234 [0.000-1.000]
Total Transformation Time: 240.3440
Epoch 10:, Train 0.8920, Val 0.8747, Test 0.7093
Epoch 20:, Train 0.9180, Val 0.8902, Test 0.7369
Epoch 30:, Train 0.9351, Val 0.9002, Test 0.7496
Epoch 40:, Train 0.9426, Val 0.9021, Test 0.7526
Epoch 50:, Train 0.9473, Val 0.9017, Test 0.7605
Epoch 60:, Train 0.9538, Val 0.9055, Test 0.7636
Epoch 70:, Train 0.9550, Val 0.9048, Test 0.7622
Epoch 80:, Train 0.9606, Val 0.9078, Test 0.7635
Epoch 90:, Train 0.9638, Val 0.9079, Test 0.7668
Epoch 100:, Train 0.9662, Val 0.9078, Test 0.7680
Epoch 110:, Train 0.9690, Val 0.9086, Test 0.7700
Epoch 120:, Train 0.9707, Val 0.9100, Test 0.7697
Epoch 130:, Train 0.9728, Val 0.9093, Test 0.7703
Epoch 140:, Train 0.9755, Val 0.9103, Test 0.7688
Epoch 150:, Train 0.9762, Val 0.9102, Test 0.7753
Epoch 160:, Train 0.9767, Val 0.9088, Test 0.7677
Epoch 170:, Train 0.9775, Val 0.9072, Test 0.7719
Epoch 180:, Train 0.9787, Val 0.9082, Test 0.7689
Epoch 190:, Train 0.9799, Val 0.9082, Test 0.7690
Epoch 200:, Train 0.9815, Val 0.9101, Test 0.7742
Epoch 210:, Train 0.9813, Val 0.9083, Test 0.7710
Epoch 220:, Train 0.9838, Val 0.9105, Test 0.7703
Epoch 230:, Train 0.9842, Val 0.9087, Test 0.7725
Epoch 240:, Train 0.9841, Val 0.9104, Test 0.7762
Epoch 250:, Train 0.9856, Val 0.9102, Test 0.7707
Epoch 260:, Train 0.9865, Val 0.9105, Test 0.7747
Epoch 270:, Train 0.9859, Val 0.9083, Test 0.7750
Epoch 280:, Train 0.9868, Val 0.9100, Test 0.7718
Epoch 290:, Train 0.9877, Val 0.9107, Test 0.7743
Epoch 300:, Train 0.9884, Val 0.9112, Test 0.7736
BEST: Epoch 300, Train 0.9884, Val 0.9112, Test 0.7736

RUN #1: seed=4
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004695733543485403
coalesce scoo: 1.335e-05
convert to csr_matrix: 2.691
calc min-max per row: 0.7251
vectorization: 1.76
Normalization Time: 6.7291
DOT_PRODUCT
Attention Filter (n=122825229): 0.152 +\- 0.232 [0.000-1.000]
Total Transformation Time: 242.4219
Epoch 10:, Train 0.8877, Val 0.8696, Test 0.7129
Epoch 20:, Train 0.9208, Val 0.8915, Test 0.7413
Epoch 30:, Train 0.9329, Val 0.8966, Test 0.7527
Epoch 40:, Train 0.9410, Val 0.8996, Test 0.7565
Epoch 50:, Train 0.9486, Val 0.9021, Test 0.7642
Epoch 60:, Train 0.9533, Val 0.9048, Test 0.7653
Epoch 70:, Train 0.9567, Val 0.9056, Test 0.7648
Epoch 80:, Train 0.9608, Val 0.9061, Test 0.7655
Epoch 90:, Train 0.9640, Val 0.9064, Test 0.7684
Epoch 100:, Train 0.9657, Val 0.9069, Test 0.7709
Epoch 110:, Train 0.9684, Val 0.9074, Test 0.7701
Epoch 120:, Train 0.9699, Val 0.9088, Test 0.7736
Epoch 130:, Train 0.9714, Val 0.9085, Test 0.7702
Epoch 140:, Train 0.9743, Val 0.9089, Test 0.7747
Epoch 150:, Train 0.9750, Val 0.9091, Test 0.7701
Epoch 160:, Train 0.9768, Val 0.9098, Test 0.7741
Epoch 170:, Train 0.9780, Val 0.9089, Test 0.7742
Epoch 180:, Train 0.9799, Val 0.9116, Test 0.7750
Epoch 190:, Train 0.9809, Val 0.9097, Test 0.7756
Epoch 200:, Train 0.9806, Val 0.9085, Test 0.7702
Epoch 210:, Train 0.9817, Val 0.9102, Test 0.7746
Epoch 220:, Train 0.9834, Val 0.9098, Test 0.7747
Epoch 230:, Train 0.9839, Val 0.9101, Test 0.7743
Epoch 240:, Train 0.9848, Val 0.9103, Test 0.7767
Epoch 250:, Train 0.9855, Val 0.9104, Test 0.7739
Epoch 260:, Train 0.9862, Val 0.9124, Test 0.7756
Epoch 270:, Train 0.9874, Val 0.9124, Test 0.7772
Epoch 280:, Train 0.9872, Val 0.9119, Test 0.7784
Epoch 290:, Train 0.9878, Val 0.9116, Test 0.7760
Epoch 300:, Train 0.9881, Val 0.9108, Test 0.7785
BEST: Epoch 260, Train 0.9862, Val 0.9124, Test 0.7756

RUN #2: seed=8
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0016792048700153828
coalesce scoo: 1.264e-05
convert to csr_matrix: 2.716
calc min-max per row: 0.7457
vectorization: 1.773
Normalization Time: 6.8049
DOT_PRODUCT
Attention Filter (n=123020289): 0.147 +\- 0.229 [0.000-1.000]
Total Transformation Time: 242.9190
Epoch 10:, Train 0.8901, Val 0.8730, Test 0.7143
Epoch 20:, Train 0.9195, Val 0.8933, Test 0.7444
Epoch 30:, Train 0.9316, Val 0.8957, Test 0.7518
Epoch 40:, Train 0.9399, Val 0.9004, Test 0.7551
Epoch 50:, Train 0.9458, Val 0.9018, Test 0.7579
Epoch 60:, Train 0.9519, Val 0.9051, Test 0.7641
Epoch 70:, Train 0.9578, Val 0.9073, Test 0.7627
Epoch 80:, Train 0.9593, Val 0.9062, Test 0.7630
Epoch 90:, Train 0.9638, Val 0.9072, Test 0.7654
Epoch 100:, Train 0.9661, Val 0.9088, Test 0.7659
Epoch 110:, Train 0.9653, Val 0.9076, Test 0.7634
Epoch 120:, Train 0.9719, Val 0.9091, Test 0.7719
Epoch 130:, Train 0.9716, Val 0.9093, Test 0.7648
Epoch 140:, Train 0.9747, Val 0.9111, Test 0.7716
Epoch 150:, Train 0.9743, Val 0.9092, Test 0.7660
Epoch 160:, Train 0.9769, Val 0.9104, Test 0.7705
Epoch 170:, Train 0.9773, Val 0.9100, Test 0.7676
Epoch 180:, Train 0.9785, Val 0.9093, Test 0.7700
Epoch 190:, Train 0.9797, Val 0.9094, Test 0.7698
Epoch 200:, Train 0.9811, Val 0.9115, Test 0.7710
Epoch 210:, Train 0.9816, Val 0.9109, Test 0.7720
Epoch 220:, Train 0.9827, Val 0.9102, Test 0.7702
Epoch 230:, Train 0.9830, Val 0.9106, Test 0.7717
Epoch 240:, Train 0.9835, Val 0.9102, Test 0.7719
Epoch 250:, Train 0.9853, Val 0.9116, Test 0.7688
Epoch 260:, Train 0.9854, Val 0.9114, Test 0.7699
Epoch 270:, Train 0.9855, Val 0.9114, Test 0.7727
Epoch 280:, Train 0.9872, Val 0.9118, Test 0.7720
Epoch 290:, Train 0.9872, Val 0.9101, Test 0.7698
Epoch 300:, Train 0.9876, Val 0.9112, Test 0.7719
BEST: Epoch 280, Train 0.9872, Val 0.9118, Test 0.7720

RUN #3: seed=42
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0031600971706211567
coalesce scoo: 1.264e-05
convert to csr_matrix: 2.642
calc min-max per row: 0.7326
vectorization: 1.817
Normalization Time: 6.7586
DOT_PRODUCT
Attention Filter (n=123001819): 0.148 +\- 0.229 [0.000-1.000]
Total Transformation Time: 232.2261
Epoch 10:, Train 0.8955, Val 0.8791, Test 0.7115
Epoch 20:, Train 0.9189, Val 0.8904, Test 0.7364
Epoch 30:, Train 0.9314, Val 0.8959, Test 0.7435
Epoch 40:, Train 0.9405, Val 0.8996, Test 0.7551
Epoch 50:, Train 0.9491, Val 0.9051, Test 0.7616
Epoch 60:, Train 0.9517, Val 0.9035, Test 0.7578
Epoch 70:, Train 0.9568, Val 0.9054, Test 0.7615
Epoch 80:, Train 0.9598, Val 0.9062, Test 0.7636
Epoch 90:, Train 0.9619, Val 0.9077, Test 0.7585
Epoch 100:, Train 0.9659, Val 0.9082, Test 0.7660
Epoch 110:, Train 0.9684, Val 0.9083, Test 0.7684
Epoch 120:, Train 0.9701, Val 0.9097, Test 0.7674
Epoch 130:, Train 0.9716, Val 0.9099, Test 0.7659
Epoch 140:, Train 0.9746, Val 0.9108, Test 0.7693
Epoch 150:, Train 0.9760, Val 0.9111, Test 0.7700
Epoch 160:, Train 0.9758, Val 0.9096, Test 0.7676
Epoch 170:, Train 0.9782, Val 0.9105, Test 0.7675
Epoch 180:, Train 0.9798, Val 0.9111, Test 0.7710
Epoch 190:, Train 0.9789, Val 0.9094, Test 0.7695
Epoch 200:, Train 0.9809, Val 0.9109, Test 0.7664
Epoch 210:, Train 0.9814, Val 0.9108, Test 0.7677
Epoch 220:, Train 0.9828, Val 0.9108, Test 0.7666
Epoch 230:, Train 0.9845, Val 0.9132, Test 0.7721
Epoch 240:, Train 0.9840, Val 0.9106, Test 0.7696
Epoch 250:, Train 0.9852, Val 0.9107, Test 0.7694
Epoch 260:, Train 0.9859, Val 0.9114, Test 0.7719
Epoch 270:, Train 0.9860, Val 0.9113, Test 0.7686
Epoch 280:, Train 0.9870, Val 0.9110, Test 0.7724
Epoch 290:, Train 0.9874, Val 0.9109, Test 0.7701
Epoch 300:, Train 0.9881, Val 0.9108, Test 0.7736
BEST: Epoch 230, Train 0.9845, Val 0.9132, Test 0.7721

RUN #4: seed=64
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004785676021128893
coalesce scoo: 1.287e-05
convert to csr_matrix: 2.642
calc min-max per row: 0.7469
vectorization: 1.721
Normalization Time: 6.9687
DOT_PRODUCT
Attention Filter (n=123009438): 0.151 +\- 0.234 [0.000-1.000]
Total Transformation Time: 230.3889
Epoch 10:, Train 0.8890, Val 0.8726, Test 0.7086
Epoch 20:, Train 0.9213, Val 0.8928, Test 0.7358
Epoch 30:, Train 0.9345, Val 0.8980, Test 0.7479
Epoch 40:, Train 0.9398, Val 0.8985, Test 0.7489
Epoch 50:, Train 0.9483, Val 0.9037, Test 0.7576
Epoch 60:, Train 0.9502, Val 0.9020, Test 0.7547
Epoch 70:, Train 0.9566, Val 0.9060, Test 0.7640
Epoch 80:, Train 0.9606, Val 0.9066, Test 0.7644
Epoch 90:, Train 0.9634, Val 0.9088, Test 0.7632
Epoch 100:, Train 0.9659, Val 0.9066, Test 0.7651
Epoch 110:, Train 0.9675, Val 0.9078, Test 0.7678
Epoch 120:, Train 0.9692, Val 0.9090, Test 0.7661
Epoch 130:, Train 0.9700, Val 0.9049, Test 0.7644
Epoch 140:, Train 0.9734, Val 0.9085, Test 0.7683
Epoch 150:, Train 0.9749, Val 0.9092, Test 0.7656
Epoch 160:, Train 0.9768, Val 0.9090, Test 0.7695
Epoch 170:, Train 0.9772, Val 0.9077, Test 0.7636
Epoch 180:, Train 0.9786, Val 0.9086, Test 0.7711
Epoch 190:, Train 0.9799, Val 0.9088, Test 0.7680
Epoch 200:, Train 0.9795, Val 0.9078, Test 0.7702
Epoch 210:, Train 0.9814, Val 0.9088, Test 0.7698
Epoch 220:, Train 0.9823, Val 0.9095, Test 0.7686
Epoch 230:, Train 0.9826, Val 0.9089, Test 0.7691
Epoch 240:, Train 0.9836, Val 0.9095, Test 0.7695
Epoch 250:, Train 0.9848, Val 0.9107, Test 0.7721
Epoch 260:, Train 0.9857, Val 0.9104, Test 0.7736
Epoch 270:, Train 0.9855, Val 0.9097, Test 0.7712
Epoch 280:, Train 0.9866, Val 0.9109, Test 0.7724
Epoch 290:, Train 0.9862, Val 0.9099, Test 0.7719
Epoch 300:, Train 0.9879, Val 0.9115, Test 0.7727
BEST: Epoch 300, Train 0.9879, Val 0.9115, Test 0.7727

RUN #5: seed=128
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00019998301286250353
coalesce scoo: 1.144e-05
convert to csr_matrix: 2.629
calc min-max per row: 0.7502
vectorization: 1.705
Normalization Time: 6.9344
DOT_PRODUCT
Attention Filter (n=122841277): 0.151 +\- 0.233 [0.000-1.000]
Total Transformation Time: 231.9895
Epoch 10:, Train 0.8823, Val 0.8680, Test 0.6957
Epoch 20:, Train 0.9193, Val 0.8909, Test 0.7373
Epoch 30:, Train 0.9330, Val 0.8978, Test 0.7437
Epoch 40:, Train 0.9402, Val 0.9001, Test 0.7523
Epoch 50:, Train 0.9482, Val 0.9035, Test 0.7584
Epoch 60:, Train 0.9537, Val 0.9042, Test 0.7575
Epoch 70:, Train 0.9563, Val 0.9055, Test 0.7596
Epoch 80:, Train 0.9602, Val 0.9067, Test 0.7609
Epoch 90:, Train 0.9634, Val 0.9067, Test 0.7641
Epoch 100:, Train 0.9662, Val 0.9074, Test 0.7646
Epoch 110:, Train 0.9682, Val 0.9075, Test 0.7623
Epoch 120:, Train 0.9703, Val 0.9086, Test 0.7645
Epoch 130:, Train 0.9721, Val 0.9077, Test 0.7673
Epoch 140:, Train 0.9737, Val 0.9087, Test 0.7666
Epoch 150:, Train 0.9748, Val 0.9083, Test 0.7663
Epoch 160:, Train 0.9771, Val 0.9095, Test 0.7682
Epoch 170:, Train 0.9766, Val 0.9083, Test 0.7663
Epoch 180:, Train 0.9793, Val 0.9087, Test 0.7668
Epoch 190:, Train 0.9803, Val 0.9086, Test 0.7661
Epoch 200:, Train 0.9820, Val 0.9114, Test 0.7695
Epoch 210:, Train 0.9819, Val 0.9088, Test 0.7660
Epoch 220:, Train 0.9830, Val 0.9097, Test 0.7659
Epoch 230:, Train 0.9833, Val 0.9089, Test 0.7637
Epoch 240:, Train 0.9846, Val 0.9098, Test 0.7668
Epoch 250:, Train 0.9856, Val 0.9094, Test 0.7691
Epoch 260:, Train 0.9859, Val 0.9102, Test 0.7691
Epoch 270:, Train 0.9851, Val 0.9083, Test 0.7622
Epoch 280:, Train 0.9866, Val 0.9103, Test 0.7677
Epoch 290:, Train 0.9863, Val 0.9088, Test 0.7684
Epoch 300:, Train 0.9875, Val 0.9089, Test 0.7666
BEST: Epoch 200, Train 0.9820, Val 0.9114, Test 0.7695

RUN #6: seed=256
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0025518205948174
coalesce scoo: 1.144e-05
convert to csr_matrix: 2.707
calc min-max per row: 0.7556
vectorization: 1.77
Normalization Time: 6.7600
DOT_PRODUCT
Attention Filter (n=123037660): 0.162 +\- 0.240 [0.000-1.000]
Total Transformation Time: 229.3788
Epoch 10:, Train 0.8926, Val 0.8756, Test 0.7118
Epoch 20:, Train 0.9225, Val 0.8939, Test 0.7369
Epoch 30:, Train 0.9367, Val 0.9002, Test 0.7538
Epoch 40:, Train 0.9425, Val 0.9004, Test 0.7557
Epoch 50:, Train 0.9504, Val 0.9055, Test 0.7638
Epoch 60:, Train 0.9564, Val 0.9067, Test 0.7686
Epoch 70:, Train 0.9602, Val 0.9085, Test 0.7682
Epoch 80:, Train 0.9633, Val 0.9082, Test 0.7712
Epoch 90:, Train 0.9649, Val 0.9066, Test 0.7662
Epoch 100:, Train 0.9673, Val 0.9082, Test 0.7681
Epoch 110:, Train 0.9701, Val 0.9089, Test 0.7714
Epoch 120:, Train 0.9709, Val 0.9085, Test 0.7698
Epoch 130:, Train 0.9736, Val 0.9091, Test 0.7720
Epoch 140:, Train 0.9752, Val 0.9112, Test 0.7739
Epoch 150:, Train 0.9756, Val 0.9082, Test 0.7690
Epoch 160:, Train 0.9780, Val 0.9107, Test 0.7717
Epoch 170:, Train 0.9794, Val 0.9101, Test 0.7709
Epoch 180:, Train 0.9798, Val 0.9101, Test 0.7743
Epoch 190:, Train 0.9819, Val 0.9123, Test 0.7733
Epoch 200:, Train 0.9823, Val 0.9103, Test 0.7712
Epoch 210:, Train 0.9838, Val 0.9109, Test 0.7754
Epoch 220:, Train 0.9841, Val 0.9104, Test 0.7741
Epoch 230:, Train 0.9853, Val 0.9111, Test 0.7759
Epoch 240:, Train 0.9855, Val 0.9106, Test 0.7748
Epoch 250:, Train 0.9859, Val 0.9115, Test 0.7793
Epoch 260:, Train 0.9868, Val 0.9101, Test 0.7769
Epoch 270:, Train 0.9876, Val 0.9121, Test 0.7785
Epoch 280:, Train 0.9883, Val 0.9127, Test 0.7774
Epoch 290:, Train 0.9883, Val 0.9117, Test 0.7757
Epoch 300:, Train 0.9881, Val 0.9096, Test 0.7746
BEST: Epoch 280, Train 0.9883, Val 0.9127, Test 0.7774

RUN #7: seed=512
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.002371214795857668
coalesce scoo: 1.049e-05
convert to csr_matrix: 2.489
calc min-max per row: 0.7301
vectorization: 1.575
Normalization Time: 6.3250
DOT_PRODUCT
Attention Filter (n=122883286): 0.149 +\- 0.230 [0.000-1.000]
Total Transformation Time: 230.6373
Epoch 10:, Train 0.8912, Val 0.8752, Test 0.7083
Epoch 20:, Train 0.9229, Val 0.8958, Test 0.7380
Epoch 30:, Train 0.9333, Val 0.8993, Test 0.7444
Epoch 40:, Train 0.9428, Val 0.9025, Test 0.7537
Epoch 50:, Train 0.9487, Val 0.9049, Test 0.7534
Epoch 60:, Train 0.9534, Val 0.9047, Test 0.7597
Epoch 70:, Train 0.9578, Val 0.9073, Test 0.7616
Epoch 80:, Train 0.9602, Val 0.9070, Test 0.7623
Epoch 90:, Train 0.9607, Val 0.9053, Test 0.7573
Epoch 100:, Train 0.9669, Val 0.9081, Test 0.7641
Epoch 110:, Train 0.9688, Val 0.9088, Test 0.7650
Epoch 120:, Train 0.9705, Val 0.9090, Test 0.7612
Epoch 130:, Train 0.9725, Val 0.9095, Test 0.7678
Epoch 140:, Train 0.9752, Val 0.9116, Test 0.7674
Epoch 150:, Train 0.9764, Val 0.9103, Test 0.7675
Epoch 160:, Train 0.9770, Val 0.9087, Test 0.7646
Epoch 170:, Train 0.9783, Val 0.9095, Test 0.7665
Epoch 180:, Train 0.9802, Val 0.9095, Test 0.7657
Epoch 190:, Train 0.9809, Val 0.9101, Test 0.7669
Epoch 200:, Train 0.9810, Val 0.9098, Test 0.7647
Epoch 210:, Train 0.9818, Val 0.9109, Test 0.7672
Epoch 220:, Train 0.9842, Val 0.9116, Test 0.7675
Epoch 230:, Train 0.9846, Val 0.9109, Test 0.7681
Epoch 240:, Train 0.9850, Val 0.9100, Test 0.7646
Epoch 250:, Train 0.9866, Val 0.9115, Test 0.7708
Epoch 260:, Train 0.9859, Val 0.9098, Test 0.7649
Epoch 270:, Train 0.9869, Val 0.9118, Test 0.7677
Epoch 280:, Train 0.9880, Val 0.9106, Test 0.7690
Epoch 290:, Train 0.9883, Val 0.9112, Test 0.7677
Epoch 300:, Train 0.9888, Val 0.9116, Test 0.7677
BEST: Epoch 270, Train 0.9869, Val 0.9118, Test 0.7677

RUN #8: seed=1024
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.000924520893022418
coalesce scoo: 1.121e-05
convert to csr_matrix: 2.891
calc min-max per row: 0.7507
vectorization: 1.561
Normalization Time: 6.7479
DOT_PRODUCT
Attention Filter (n=122896656): 0.151 +\- 0.233 [0.000-1.000]
Total Transformation Time: 234.1494
Epoch 10:, Train 0.8927, Val 0.8756, Test 0.7103
Epoch 20:, Train 0.9215, Val 0.8933, Test 0.7343
Epoch 30:, Train 0.9325, Val 0.8952, Test 0.7463
Epoch 40:, Train 0.9402, Val 0.8990, Test 0.7552
Epoch 50:, Train 0.9486, Val 0.9034, Test 0.7593
Epoch 60:, Train 0.9528, Val 0.9022, Test 0.7636
Epoch 70:, Train 0.9569, Val 0.9053, Test 0.7668
Epoch 80:, Train 0.9618, Val 0.9069, Test 0.7714
Epoch 90:, Train 0.9632, Val 0.9074, Test 0.7693
Epoch 100:, Train 0.9664, Val 0.9073, Test 0.7692
Epoch 110:, Train 0.9683, Val 0.9069, Test 0.7697
Epoch 120:, Train 0.9704, Val 0.9081, Test 0.7691
Epoch 130:, Train 0.9715, Val 0.9084, Test 0.7673
Epoch 140:, Train 0.9723, Val 0.9077, Test 0.7721
Epoch 150:, Train 0.9735, Val 0.9067, Test 0.7684
Epoch 160:, Train 0.9766, Val 0.9078, Test 0.7761
Epoch 170:, Train 0.9778, Val 0.9112, Test 0.7717
Epoch 180:, Train 0.9795, Val 0.9106, Test 0.7758
Epoch 190:, Train 0.9793, Val 0.9089, Test 0.7723
Epoch 200:, Train 0.9820, Val 0.9093, Test 0.7753
Epoch 210:, Train 0.9817, Val 0.9098, Test 0.7750
Epoch 220:, Train 0.9827, Val 0.9100, Test 0.7718
Epoch 230:, Train 0.9839, Val 0.9116, Test 0.7763
Epoch 240:, Train 0.9851, Val 0.9108, Test 0.7738
Epoch 250:, Train 0.9849, Val 0.9087, Test 0.7733
Epoch 260:, Train 0.9849, Val 0.9097, Test 0.7729
Epoch 270:, Train 0.9856, Val 0.9106, Test 0.7749
Epoch 280:, Train 0.9871, Val 0.9104, Test 0.7736
Epoch 290:, Train 0.9877, Val 0.9107, Test 0.7750
Epoch 300:, Train 0.9884, Val 0.9110, Test 0.7754
BEST: Epoch 230, Train 0.9839, Val 0.9116, Test 0.7763

RUN #9: seed=2048
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00865280069410801
coalesce scoo: 1.097e-05
convert to csr_matrix: 2.402
calc min-max per row: 0.7518
vectorization: 1.766
Normalization Time: 6.5592
DOT_PRODUCT
Attention Filter (n=123018678): 0.153 +\- 0.235 [0.000-1.000]
Total Transformation Time: 240.0994
Epoch 10:, Train 0.8858, Val 0.8679, Test 0.7015
Epoch 20:, Train 0.9209, Val 0.8925, Test 0.7316
Epoch 30:, Train 0.9350, Val 0.8994, Test 0.7458
Epoch 40:, Train 0.9430, Val 0.9027, Test 0.7535
Epoch 50:, Train 0.9475, Val 0.9037, Test 0.7535
Epoch 60:, Train 0.9534, Val 0.9068, Test 0.7606
Epoch 70:, Train 0.9560, Val 0.9064, Test 0.7604
Epoch 80:, Train 0.9601, Val 0.9068, Test 0.7597
Epoch 90:, Train 0.9634, Val 0.9079, Test 0.7617
Epoch 100:, Train 0.9665, Val 0.9096, Test 0.7648
Epoch 110:, Train 0.9677, Val 0.9067, Test 0.7630
Epoch 120:, Train 0.9701, Val 0.9090, Test 0.7630
Epoch 130:, Train 0.9722, Val 0.9091, Test 0.7649
Epoch 140:, Train 0.9737, Val 0.9097, Test 0.7642
Epoch 150:, Train 0.9746, Val 0.9112, Test 0.7675
Epoch 160:, Train 0.9774, Val 0.9102, Test 0.7660
Epoch 170:, Train 0.9783, Val 0.9116, Test 0.7665
Epoch 180:, Train 0.9799, Val 0.9107, Test 0.7667
Epoch 190:, Train 0.9805, Val 0.9110, Test 0.7678
Epoch 200:, Train 0.9798, Val 0.9102, Test 0.7668
Epoch 210:, Train 0.9815, Val 0.9109, Test 0.7699
Epoch 220:, Train 0.9827, Val 0.9109, Test 0.7670
Epoch 230:, Train 0.9835, Val 0.9117, Test 0.7657
Epoch 240:, Train 0.9837, Val 0.9109, Test 0.7652
Epoch 250:, Train 0.9840, Val 0.9095, Test 0.7645
Epoch 260:, Train 0.9861, Val 0.9121, Test 0.7735
Epoch 270:, Train 0.9865, Val 0.9107, Test 0.7699
Epoch 280:, Train 0.9866, Val 0.9109, Test 0.7658
Epoch 290:, Train 0.9877, Val 0.9113, Test 0.7677
Epoch 300:, Train 0.9874, Val 0.9113, Test 0.7646
BEST: Epoch 260, Train 0.9861, Val 0.9121, Test 0.7735




==================================================
Model Parameters: 11069494

Avg. Filter Time (s): 94.9150 +/- 4.2720
Avg. Preaggregation Time (s): 235.4554 +/- 5.0957
Avg. Training Time (epoch) (s): 3.4111 +/- 0.0925
Avg. Inference Time (s): 0.5014 +/- 0.0154

Avg. Training Acc: 0.9862 +/- 0.0020
Avg. Validation Acc: 0.9120 +/- 0.0006
Avg. Test Acc: 0.7730 +/- 0.0028

**************************************************
**************************************************

**************************************************
================= SIGN+MHA =======================
**************************************************
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=4, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.0001, INCEPTION_LAYERS=2, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=4, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.002750938758254051
coalesce scoo: 1.717e-05
convert to csr_matrix: 3.454
calc min-max per row: 0.7729
vectorization: 1.636
Normalization Time: 7.7106
DOT_PRODUCT
Attention Filter (n=123577305): 0.182 +\- 0.255 [0.000-1.000]
Total Transformation Time: 619.5537
Epoch 10:, Train 0.9470, Val 0.9103, Test 0.7613
Epoch 20:, Train 0.9613, Val 0.9126, Test 0.7661
Epoch 30:, Train 0.9686, Val 0.9145, Test 0.7586
Epoch 40:, Train 0.9727, Val 0.9122, Test 0.7611
Epoch 50:, Train 0.9744, Val 0.9113, Test 0.7563
Epoch 60:, Train 0.9766, Val 0.9137, Test 0.7643
Epoch 70:, Train 0.9787, Val 0.9140, Test 0.7598
Epoch 80:, Train 0.9808, Val 0.9154, Test 0.7643
Epoch 90:, Train 0.9827, Val 0.9155, Test 0.7671
Epoch 100:, Train 0.9830, Val 0.9126, Test 0.7563
Epoch 110:, Train 0.9840, Val 0.9136, Test 0.7616
Epoch 120:, Train 0.9850, Val 0.9116, Test 0.7667
Epoch 130:, Train 0.9844, Val 0.9132, Test 0.7561
Epoch 140:, Train 0.9851, Val 0.9137, Test 0.7598
Epoch 150:, Train 0.9854, Val 0.9144, Test 0.7674
Epoch 160:, Train 0.9847, Val 0.9116, Test 0.7625
Epoch 170:, Train 0.9836, Val 0.9100, Test 0.7506
Epoch 180:, Train 0.9858, Val 0.9115, Test 0.7590
Epoch 190:, Train 0.9859, Val 0.9137, Test 0.7582
Epoch 200:, Train 0.9851, Val 0.9148, Test 0.7533
Epoch 210:, Train 0.9866, Val 0.9122, Test 0.7632
Epoch 220:, Train 0.9873, Val 0.9132, Test 0.7642
Epoch 230:, Train 0.9882, Val 0.9149, Test 0.7652
Epoch 240:, Train 0.9876, Val 0.9134, Test 0.7616
Epoch 250:, Train 0.9834, Val 0.9065, Test 0.7490
Epoch 260:, Train 0.9872, Val 0.9138, Test 0.7632
Epoch 270:, Train 0.9877, Val 0.9124, Test 0.7647
Epoch 280:, Train 0.9848, Val 0.9077, Test 0.7496
Epoch 290:, Train 0.9877, Val 0.9143, Test 0.7608
Epoch 300:, Train 0.9871, Val 0.9142, Test 0.7603
BEST: Epoch 90, Train 0.9827, Val 0.9155, Test 0.7671

RUN #1: seed=4
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.006151767447590828
coalesce scoo: 2.098e-05
convert to csr_matrix: 3.242
calc min-max per row: 0.7551
vectorization: 1.767
Normalization Time: 7.5805
DOT_PRODUCT
Attention Filter (n=123590278): 0.182 +\- 0.256 [0.000-1.000]
Total Transformation Time: 566.3400
Epoch 10:, Train 0.9440, Val 0.9040, Test 0.7482
Epoch 20:, Train 0.9625, Val 0.9137, Test 0.7681
Epoch 30:, Train 0.9647, Val 0.9079, Test 0.7558
Epoch 40:, Train 0.9645, Val 0.9048, Test 0.7435
Epoch 50:, Train 0.9768, Val 0.9154, Test 0.7614
Epoch 60:, Train 0.9786, Val 0.9138, Test 0.7542
Epoch 70:, Train 0.9805, Val 0.9136, Test 0.7631
Epoch 80:, Train 0.9816, Val 0.9121, Test 0.7598
Epoch 90:, Train 0.9816, Val 0.9149, Test 0.7697
Epoch 100:, Train 0.9824, Val 0.9137, Test 0.7605
Epoch 110:, Train 0.9799, Val 0.9020, Test 0.7466
Epoch 120:, Train 0.9847, Val 0.9113, Test 0.7554
Epoch 130:, Train 0.9820, Val 0.9078, Test 0.7438
Epoch 140:, Train 0.9846, Val 0.9143, Test 0.7642
Epoch 150:, Train 0.9827, Val 0.9072, Test 0.7476
Epoch 160:, Train 0.9802, Val 0.9049, Test 0.7399
Epoch 170:, Train 0.9868, Val 0.9147, Test 0.7661
Epoch 180:, Train 0.9842, Val 0.9138, Test 0.7610
Epoch 190:, Train 0.9868, Val 0.9128, Test 0.7639
Epoch 200:, Train 0.9857, Val 0.9094, Test 0.7543
Epoch 210:, Train 0.9875, Val 0.9126, Test 0.7575
Epoch 220:, Train 0.9853, Val 0.9144, Test 0.7594
Epoch 230:, Train 0.9871, Val 0.9122, Test 0.7541
Epoch 240:, Train 0.9849, Val 0.9071, Test 0.7445
Epoch 250:, Train 0.9870, Val 0.9132, Test 0.7592
Epoch 260:, Train 0.9852, Val 0.9070, Test 0.7492
Epoch 270:, Train 0.9872, Val 0.9139, Test 0.7560
Epoch 280:, Train 0.9854, Val 0.9076, Test 0.7502
Epoch 290:, Train 0.9869, Val 0.9151, Test 0.7620
Epoch 300:, Train 0.9864, Val 0.9134, Test 0.7615
BEST: Epoch 50, Train 0.9768, Val 0.9154, Test 0.7614

RUN #2: seed=8
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0024782554246485233
coalesce scoo: 1.74e-05
convert to csr_matrix: 3.195
calc min-max per row: 0.7699
vectorization: 1.576
Normalization Time: 8.1487
DOT_PRODUCT
Attention Filter (n=123595488): 0.178 +\- 0.253 [0.000-1.000]
Total Transformation Time: 576.3942
Epoch 10:, Train 0.9462, Val 0.9074, Test 0.7553
Epoch 20:, Train 0.9618, Val 0.9134, Test 0.7678
Epoch 30:, Train 0.9690, Val 0.9110, Test 0.7519
Epoch 40:, Train 0.9732, Val 0.9145, Test 0.7670
Epoch 50:, Train 0.9755, Val 0.9122, Test 0.7680
Epoch 60:, Train 0.9787, Val 0.9143, Test 0.7584
Epoch 70:, Train 0.9808, Val 0.9135, Test 0.7673
Epoch 80:, Train 0.9821, Val 0.9142, Test 0.7625
Epoch 90:, Train 0.9821, Val 0.9150, Test 0.7599
Epoch 100:, Train 0.9831, Val 0.9131, Test 0.7598
Epoch 110:, Train 0.9829, Val 0.9131, Test 0.7625
Epoch 120:, Train 0.9839, Val 0.9116, Test 0.7581
Epoch 130:, Train 0.9842, Val 0.9121, Test 0.7677
Epoch 140:, Train 0.9838, Val 0.9146, Test 0.7664
Epoch 150:, Train 0.9855, Val 0.9142, Test 0.7621
Epoch 160:, Train 0.9856, Val 0.9132, Test 0.7637
Epoch 170:, Train 0.9845, Val 0.9143, Test 0.7722
Epoch 180:, Train 0.9861, Val 0.9141, Test 0.7632
Epoch 190:, Train 0.9858, Val 0.9133, Test 0.7560
Epoch 200:, Train 0.9861, Val 0.9147, Test 0.7610
Epoch 210:, Train 0.9848, Val 0.9135, Test 0.7613
Epoch 220:, Train 0.9862, Val 0.9162, Test 0.7618
Epoch 230:, Train 0.9870, Val 0.9137, Test 0.7630
Epoch 240:, Train 0.9880, Val 0.9154, Test 0.7626
Epoch 250:, Train 0.9872, Val 0.9135, Test 0.7621
Epoch 260:, Train 0.9875, Val 0.9143, Test 0.7606
Epoch 270:, Train 0.9880, Val 0.9125, Test 0.7634
Epoch 280:, Train 0.9874, Val 0.9158, Test 0.7576
Epoch 290:, Train 0.9878, Val 0.9139, Test 0.7595
Epoch 300:, Train 0.9868, Val 0.9140, Test 0.7552
BEST: Epoch 220, Train 0.9862, Val 0.9162, Test 0.7618

RUN #3: seed=42
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004516818560659885
coalesce scoo: 1.907e-05
convert to csr_matrix: 3.102
calc min-max per row: 0.7427
vectorization: 1.571
Normalization Time: 8.0106
DOT_PRODUCT
Attention Filter (n=123586101): 0.182 +\- 0.253 [0.000-1.000]
Total Transformation Time: 576.2716
Epoch 10:, Train 0.9468, Val 0.9103, Test 0.7608
Epoch 20:, Train 0.9611, Val 0.9130, Test 0.7628
Epoch 30:, Train 0.9689, Val 0.9138, Test 0.7710
Epoch 40:, Train 0.9721, Val 0.9129, Test 0.7567
Epoch 50:, Train 0.9756, Val 0.9147, Test 0.7673
Epoch 60:, Train 0.9792, Val 0.9112, Test 0.7526
Epoch 70:, Train 0.9798, Val 0.9155, Test 0.7633
Epoch 80:, Train 0.9811, Val 0.9145, Test 0.7619
Epoch 90:, Train 0.9821, Val 0.9147, Test 0.7583
Epoch 100:, Train 0.9820, Val 0.9113, Test 0.7554
Epoch 110:, Train 0.9830, Val 0.9112, Test 0.7502
Epoch 120:, Train 0.9837, Val 0.9128, Test 0.7600
Epoch 130:, Train 0.9801, Val 0.9071, Test 0.7445
Epoch 140:, Train 0.9851, Val 0.9138, Test 0.7589
Epoch 150:, Train 0.9860, Val 0.9154, Test 0.7595
Epoch 160:, Train 0.9852, Val 0.9152, Test 0.7560
Epoch 170:, Train 0.9853, Val 0.9163, Test 0.7613
Epoch 180:, Train 0.9827, Val 0.9106, Test 0.7497
Epoch 190:, Train 0.9865, Val 0.9140, Test 0.7573
Epoch 200:, Train 0.9868, Val 0.9156, Test 0.7626
Epoch 210:, Train 0.9870, Val 0.9146, Test 0.7579
Epoch 220:, Train 0.9866, Val 0.9134, Test 0.7571
Epoch 230:, Train 0.9874, Val 0.9125, Test 0.7597
Epoch 240:, Train 0.9870, Val 0.9131, Test 0.7572
Epoch 250:, Train 0.9864, Val 0.9139, Test 0.7632
Epoch 260:, Train 0.9874, Val 0.9137, Test 0.7592
Epoch 270:, Train 0.9882, Val 0.9131, Test 0.7548
Epoch 280:, Train 0.9883, Val 0.9128, Test 0.7609
Epoch 290:, Train 0.9876, Val 0.9120, Test 0.7557
Epoch 300:, Train 0.9871, Val 0.9131, Test 0.7585
BEST: Epoch 170, Train 0.9853, Val 0.9163, Test 0.7613

RUN #4: seed=64
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00530599569901824
coalesce scoo: 1.478e-05
convert to csr_matrix: 2.982
calc min-max per row: 0.8507
vectorization: 1.577
Normalization Time: 8.1716
DOT_PRODUCT
Attention Filter (n=123577334): 0.179 +\- 0.254 [0.000-1.000]
Total Transformation Time: 575.0106
Epoch 10:, Train 0.9469, Val 0.9103, Test 0.7594
Epoch 20:, Train 0.9618, Val 0.9119, Test 0.7603
Epoch 30:, Train 0.9699, Val 0.9137, Test 0.7620
Epoch 40:, Train 0.9735, Val 0.9140, Test 0.7668
Epoch 50:, Train 0.9756, Val 0.9109, Test 0.7651
Epoch 60:, Train 0.9792, Val 0.9144, Test 0.7674
Epoch 70:, Train 0.9805, Val 0.9127, Test 0.7606
Epoch 80:, Train 0.9805, Val 0.9145, Test 0.7623
Epoch 90:, Train 0.9819, Val 0.9127, Test 0.7514
Epoch 100:, Train 0.9821, Val 0.9127, Test 0.7639
Epoch 110:, Train 0.9826, Val 0.9098, Test 0.7629
Epoch 120:, Train 0.9839, Val 0.9118, Test 0.7529
Epoch 130:, Train 0.9850, Val 0.9142, Test 0.7622
Epoch 140:, Train 0.9817, Val 0.9081, Test 0.7497
Epoch 150:, Train 0.9836, Val 0.9135, Test 0.7634
Epoch 160:, Train 0.9852, Val 0.9121, Test 0.7614
Epoch 170:, Train 0.9848, Val 0.9084, Test 0.7545
Epoch 180:, Train 0.9853, Val 0.9125, Test 0.7654
Epoch 190:, Train 0.9866, Val 0.9138, Test 0.7687
Epoch 200:, Train 0.9830, Val 0.9148, Test 0.7607
Epoch 210:, Train 0.9850, Val 0.9135, Test 0.7592
Epoch 220:, Train 0.9861, Val 0.9151, Test 0.7608
Epoch 230:, Train 0.9856, Val 0.9114, Test 0.7575
Epoch 240:, Train 0.9843, Val 0.9125, Test 0.7504
Epoch 250:, Train 0.9876, Val 0.9139, Test 0.7597
Epoch 260:, Train 0.9860, Val 0.9112, Test 0.7559
Epoch 270:, Train 0.9871, Val 0.9144, Test 0.7612
Epoch 280:, Train 0.9867, Val 0.9136, Test 0.7627
Epoch 290:, Train 0.9883, Val 0.9127, Test 0.7669
Epoch 300:, Train 0.9880, Val 0.9158, Test 0.7646
BEST: Epoch 300, Train 0.9880, Val 0.9158, Test 0.7646

RUN #5: seed=128
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0013660663971677423
coalesce scoo: 1.979e-05
convert to csr_matrix: 2.971
calc min-max per row: 0.8403
vectorization: 1.779
Normalization Time: 7.8281
DOT_PRODUCT
Attention Filter (n=123597625): 0.179 +\- 0.252 [0.000-1.000]
Total Transformation Time: 569.0658
Epoch 10:, Train 0.9484, Val 0.9109, Test 0.7523
Epoch 20:, Train 0.9620, Val 0.9139, Test 0.7621
Epoch 30:, Train 0.9704, Val 0.9130, Test 0.7613
Epoch 40:, Train 0.9737, Val 0.9141, Test 0.7625
Epoch 50:, Train 0.9733, Val 0.9077, Test 0.7461
Epoch 60:, Train 0.9790, Val 0.9129, Test 0.7638
Epoch 70:, Train 0.9791, Val 0.9139, Test 0.7542
Epoch 80:, Train 0.9799, Val 0.9105, Test 0.7494
Epoch 90:, Train 0.9818, Val 0.9144, Test 0.7596
Epoch 100:, Train 0.9827, Val 0.9134, Test 0.7632
Epoch 110:, Train 0.9819, Val 0.9148, Test 0.7591
Epoch 120:, Train 0.9812, Val 0.9123, Test 0.7542
Epoch 130:, Train 0.9842, Val 0.9133, Test 0.7584
Epoch 140:, Train 0.9845, Val 0.9121, Test 0.7601
Epoch 150:, Train 0.9848, Val 0.9124, Test 0.7580
Epoch 160:, Train 0.9861, Val 0.9141, Test 0.7625
Epoch 170:, Train 0.9854, Val 0.9147, Test 0.7627
Epoch 180:, Train 0.9854, Val 0.9123, Test 0.7546
Epoch 190:, Train 0.9868, Val 0.9144, Test 0.7593
Epoch 200:, Train 0.9845, Val 0.9124, Test 0.7569
Epoch 210:, Train 0.9863, Val 0.9153, Test 0.7575
Epoch 220:, Train 0.9831, Val 0.9093, Test 0.7544
Epoch 230:, Train 0.9857, Val 0.9111, Test 0.7569
Epoch 240:, Train 0.9861, Val 0.9147, Test 0.7634
Epoch 250:, Train 0.9874, Val 0.9163, Test 0.7635
Epoch 260:, Train 0.9860, Val 0.9137, Test 0.7605
Epoch 270:, Train 0.9871, Val 0.9114, Test 0.7543
Epoch 280:, Train 0.9867, Val 0.9145, Test 0.7588
Epoch 290:, Train 0.9887, Val 0.9133, Test 0.7580
Epoch 300:, Train 0.9875, Val 0.9135, Test 0.7594
BEST: Epoch 250, Train 0.9874, Val 0.9163, Test 0.7635

RUN #6: seed=256
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.001952421385794878
coalesce scoo: 1.669e-05
convert to csr_matrix: 3.046
calc min-max per row: 0.8118
vectorization: 1.771
Normalization Time: 8.2619
DOT_PRODUCT
Attention Filter (n=123598013): 0.185 +\- 0.257 [0.000-1.000]
Total Transformation Time: 571.7242
Epoch 10:, Train 0.9479, Val 0.9112, Test 0.7612
Epoch 20:, Train 0.9631, Val 0.9160, Test 0.7660
Epoch 30:, Train 0.9656, Val 0.9106, Test 0.7517
Epoch 40:, Train 0.9715, Val 0.9104, Test 0.7438
Epoch 50:, Train 0.9734, Val 0.9118, Test 0.7572
Epoch 60:, Train 0.9780, Val 0.9166, Test 0.7643
Epoch 70:, Train 0.9800, Val 0.9151, Test 0.7578
Epoch 80:, Train 0.9808, Val 0.9123, Test 0.7526
Epoch 90:, Train 0.9827, Val 0.9169, Test 0.7649
Epoch 100:, Train 0.9827, Val 0.9152, Test 0.7619
Epoch 110:, Train 0.9830, Val 0.9141, Test 0.7609
Epoch 120:, Train 0.9844, Val 0.9165, Test 0.7574
Epoch 130:, Train 0.9843, Val 0.9123, Test 0.7546
Epoch 140:, Train 0.9851, Val 0.9134, Test 0.7612
Epoch 150:, Train 0.9837, Val 0.9088, Test 0.7514
Epoch 160:, Train 0.9821, Val 0.9091, Test 0.7480
Epoch 170:, Train 0.9863, Val 0.9151, Test 0.7626
Epoch 180:, Train 0.9858, Val 0.9142, Test 0.7517
Epoch 190:, Train 0.9839, Val 0.9140, Test 0.7503
Epoch 200:, Train 0.9874, Val 0.9139, Test 0.7598
Epoch 210:, Train 0.9834, Val 0.9142, Test 0.7525
Epoch 220:, Train 0.9868, Val 0.9123, Test 0.7501
Epoch 230:, Train 0.9865, Val 0.9110, Test 0.7492
Epoch 240:, Train 0.9869, Val 0.9130, Test 0.7495
Epoch 250:, Train 0.9852, Val 0.9142, Test 0.7564
Epoch 260:, Train 0.9875, Val 0.9177, Test 0.7617
Epoch 270:, Train 0.9870, Val 0.9106, Test 0.7460
Epoch 280:, Train 0.9877, Val 0.9160, Test 0.7677
Epoch 290:, Train 0.9880, Val 0.9150, Test 0.7591
Epoch 300:, Train 0.9860, Val 0.9125, Test 0.7508
BEST: Epoch 260, Train 0.9875, Val 0.9177, Test 0.7617

RUN #7: seed=512
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.005771292373538017
coalesce scoo: 1.717e-05
convert to csr_matrix: 2.966
calc min-max per row: 0.7636
vectorization: 1.568
Normalization Time: 7.5949
DOT_PRODUCT
Attention Filter (n=123589343): 0.180 +\- 0.253 [0.000-1.000]
Total Transformation Time: 573.1836
Epoch 10:, Train 0.9478, Val 0.9110, Test 0.7506
Epoch 20:, Train 0.9628, Val 0.9150, Test 0.7695
Epoch 30:, Train 0.9686, Val 0.9144, Test 0.7586
Epoch 40:, Train 0.9698, Val 0.9071, Test 0.7467
Epoch 50:, Train 0.9762, Val 0.9139, Test 0.7645
Epoch 60:, Train 0.9786, Val 0.9135, Test 0.7639
Epoch 70:, Train 0.9804, Val 0.9156, Test 0.7619
Epoch 80:, Train 0.9804, Val 0.9128, Test 0.7566
Epoch 90:, Train 0.9806, Val 0.9132, Test 0.7568
Epoch 100:, Train 0.9837, Val 0.9149, Test 0.7630
Epoch 110:, Train 0.9829, Val 0.9142, Test 0.7606
Epoch 120:, Train 0.9842, Val 0.9157, Test 0.7621
Epoch 130:, Train 0.9839, Val 0.9135, Test 0.7617
Epoch 140:, Train 0.9834, Val 0.9086, Test 0.7541
Epoch 150:, Train 0.9847, Val 0.9145, Test 0.7608
Epoch 160:, Train 0.9846, Val 0.9138, Test 0.7627
Epoch 170:, Train 0.9856, Val 0.9153, Test 0.7635
Epoch 180:, Train 0.9854, Val 0.9132, Test 0.7647
Epoch 190:, Train 0.9853, Val 0.9107, Test 0.7527
Epoch 200:, Train 0.9858, Val 0.9155, Test 0.7600
Epoch 210:, Train 0.9849, Val 0.9130, Test 0.7559
Epoch 220:, Train 0.9869, Val 0.9141, Test 0.7554
Epoch 230:, Train 0.9860, Val 0.9146, Test 0.7669
Epoch 240:, Train 0.9859, Val 0.9147, Test 0.7654
Epoch 250:, Train 0.9864, Val 0.9145, Test 0.7624
Epoch 260:, Train 0.9867, Val 0.9107, Test 0.7564
Epoch 270:, Train 0.9869, Val 0.9143, Test 0.7554
Epoch 280:, Train 0.9874, Val 0.9118, Test 0.7559
Epoch 290:, Train 0.9882, Val 0.9111, Test 0.7623
Epoch 300:, Train 0.9871, Val 0.9105, Test 0.7626
BEST: Epoch 120, Train 0.9842, Val 0.9157, Test 0.7621

RUN #8: seed=1024
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0017024658154696226
coalesce scoo: 1.621e-05
convert to csr_matrix: 2.977
calc min-max per row: 0.8657
vectorization: 1.583
Normalization Time: 8.0055
DOT_PRODUCT
Attention Filter (n=123576447): 0.180 +\- 0.255 [0.000-1.000]
Total Transformation Time: 570.4850
Epoch 10:, Train 0.9482, Val 0.9115, Test 0.7630
Epoch 20:, Train 0.9633, Val 0.9140, Test 0.7587
Epoch 30:, Train 0.9688, Val 0.9117, Test 0.7594
Epoch 40:, Train 0.9732, Val 0.9126, Test 0.7675
Epoch 50:, Train 0.9742, Val 0.9122, Test 0.7632
Epoch 60:, Train 0.9776, Val 0.9140, Test 0.7658
Epoch 70:, Train 0.9802, Val 0.9126, Test 0.7615
Epoch 80:, Train 0.9810, Val 0.9124, Test 0.7620
Epoch 90:, Train 0.9825, Val 0.9119, Test 0.7580
Epoch 100:, Train 0.9816, Val 0.9111, Test 0.7560
Epoch 110:, Train 0.9817, Val 0.9118, Test 0.7531
Epoch 120:, Train 0.9847, Val 0.9153, Test 0.7616
Epoch 130:, Train 0.9849, Val 0.9159, Test 0.7666
Epoch 140:, Train 0.9833, Val 0.9115, Test 0.7519
Epoch 150:, Train 0.9857, Val 0.9128, Test 0.7601
Epoch 160:, Train 0.9849, Val 0.9146, Test 0.7532
Epoch 170:, Train 0.9863, Val 0.9140, Test 0.7611
Epoch 180:, Train 0.9844, Val 0.9146, Test 0.7637
Epoch 190:, Train 0.9864, Val 0.9133, Test 0.7615
Epoch 200:, Train 0.9864, Val 0.9124, Test 0.7679
Epoch 210:, Train 0.9870, Val 0.9132, Test 0.7726
Epoch 220:, Train 0.9871, Val 0.9141, Test 0.7613
Epoch 230:, Train 0.9865, Val 0.9132, Test 0.7585
Epoch 240:, Train 0.9864, Val 0.9121, Test 0.7517
Epoch 250:, Train 0.9864, Val 0.9127, Test 0.7644
Epoch 260:, Train 0.9873, Val 0.9140, Test 0.7557
Epoch 270:, Train 0.9857, Val 0.9140, Test 0.7591
Epoch 280:, Train 0.9873, Val 0.9115, Test 0.7566
Epoch 290:, Train 0.9844, Val 0.9064, Test 0.7446
Epoch 300:, Train 0.9854, Val 0.9140, Test 0.7542
BEST: Epoch 130, Train 0.9849, Val 0.9159, Test 0.7666

RUN #9: seed=2048
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0056320615112781525
coalesce scoo: 1.931e-05
convert to csr_matrix: 3.05
calc min-max per row: 0.7649
vectorization: 1.574
Normalization Time: 8.9417
DOT_PRODUCT
Attention Filter (n=123580491): 0.183 +\- 0.255 [0.000-1.000]
Total Transformation Time: 571.6950
Epoch 10:, Train 0.9491, Val 0.9100, Test 0.7620
Epoch 20:, Train 0.9616, Val 0.9136, Test 0.7678
Epoch 30:, Train 0.9696, Val 0.9121, Test 0.7595
Epoch 40:, Train 0.9729, Val 0.9145, Test 0.7660
Epoch 50:, Train 0.9743, Val 0.9129, Test 0.7618
Epoch 60:, Train 0.9792, Val 0.9127, Test 0.7625
Epoch 70:, Train 0.9782, Val 0.9141, Test 0.7614
Epoch 80:, Train 0.9824, Val 0.9145, Test 0.7638
Epoch 90:, Train 0.9822, Val 0.9142, Test 0.7627
Epoch 100:, Train 0.9837, Val 0.9152, Test 0.7645
Epoch 110:, Train 0.9841, Val 0.9140, Test 0.7635
Epoch 120:, Train 0.9834, Val 0.9141, Test 0.7686
Epoch 130:, Train 0.9842, Val 0.9136, Test 0.7618
Epoch 140:, Train 0.9841, Val 0.9114, Test 0.7541
Epoch 150:, Train 0.9848, Val 0.9151, Test 0.7623
Epoch 160:, Train 0.9854, Val 0.9119, Test 0.7568
Epoch 170:, Train 0.9853, Val 0.9142, Test 0.7648
Epoch 180:, Train 0.9855, Val 0.9135, Test 0.7602
Epoch 190:, Train 0.9871, Val 0.9147, Test 0.7649
Epoch 200:, Train 0.9869, Val 0.9165, Test 0.7642
Epoch 210:, Train 0.9872, Val 0.9159, Test 0.7618
Epoch 220:, Train 0.9871, Val 0.9135, Test 0.7619
Epoch 230:, Train 0.9864, Val 0.9137, Test 0.7645
Epoch 240:, Train 0.9873, Val 0.9159, Test 0.7688
Epoch 250:, Train 0.9871, Val 0.9141, Test 0.7643
Epoch 260:, Train 0.9877, Val 0.9128, Test 0.7528
Epoch 270:, Train 0.9870, Val 0.9134, Test 0.7563
Epoch 280:, Train 0.9877, Val 0.9153, Test 0.7607
Epoch 290:, Train 0.9875, Val 0.9106, Test 0.7524
Epoch 300:, Train 0.9870, Val 0.9132, Test 0.7605
BEST: Epoch 200, Train 0.9869, Val 0.9165, Test 0.7642




==================================================
Model Parameters: 8686134

Avg. Filter Time (s): 436.7965 +/- 13.7593
Avg. Preaggregation Time (s): 576.9724 +/- 14.5094
Avg. Training Time (epoch) (s): 4.1796 +/- 0.1259
Avg. Inference Time (s): 1.9632 +/- 0.0163

Avg. Training Acc: 0.9850 +/- 0.0032
Avg. Validation Acc: 0.9161 +/- 0.0006
Avg. Test Acc: 0.7634 +/- 0.0020

**************************************************

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 22 hours 13 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
