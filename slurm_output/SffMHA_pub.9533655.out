Thu 16 Jun 2022 03:51:19 AM CEST
r32n5.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4


==================================================
dataset: pubmed
method: bayes
model: SIGNff_MHA
iterations: 100
run_trial: false
config: SIGNff_MHA.yaml
train_file: hps_SIGNff_DPA.py
project_name: sffMHA_pubmed
method: bayes
metric:
  goal: minimize
  name: val_loss
parameters:
  ATTN_HEADS:
    distribution: int_uniform
    max: 5
    min: 2
  BATCH_NORMALIZATION:
    value: 1
  BATCH_SIZE:
    values:
    - 64
    - 128
    - 256
    - 512
    - 1024
  CLASSIFICATION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  CLASSIFICATION_UNITS:
    values:
    - 64
    - 128
    - 256
    - 512
  DATASET:
    value: pubmed
  DPA_NORMALIZATION:
    values:
    - 0
    - 1
  EPOCHS:
    value: 300
  FEATURE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  HOPS:
    values:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
  INCEPTION_LAYERS:
    distribution: int_uniform
    max: 3
    min: 1
  INCEPTION_UNITS:
    values:
    - 64
    - 128
    - 256
    - 512
  LEARNING_RATE:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
  LR_PATIENCE:
    value: 5
  NODE_DROPOUT:
    values:
    - 0.0
    - 0.1
    - 0.2
    - 0.3
    - 0.4
    - 0.5
    - 0.6
    - 0.7
  SEED:
    value: 42
  TERMINATION_PATIENCE:
    value: 10
  TRANSFORMATION:
    value: dot_product
  WEIGHT_DECAY:
    values:
    - 1.0
    - 0.1
    - 0.01
    - 0.001
    - 0.0001
    - 1.0e-05
    - 1.0e-06
    - 1.0e-07
program: hps_SIGNff_DPA.py

wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_035207-2q0itsmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-pine-93
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/2q0itsmw
wandb: Starting wandb agent \U0001f575\ufe0f
2022-06-16 03:52:16,041 - wandb.wandb_agent - INFO - Running runs: []
2022-06-16 03:52:16,327 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 03:52:16,328 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 0
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 03:52:16,335 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=0 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 03:52:21,345 - wandb.wandb_agent - INFO - Running runs: ['9m6j5rqf']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_035220-9m6j5rqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-1
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/9m6j5rqf
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k0_dot_product_norm1_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86856
wandb:    train_loss 9610.78139
wandb: training_time 1.02288
wandb:        val_f1 0.846
wandb:      val_loss 10210.12213
wandb: 
wandb: Synced helpful-sweep-1: https://wandb.ai/jah377/sffMHA_pubmed/runs/9m6j5rqf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_035220-9m6j5rqf/logs
2022-06-16 04:01:56,453 - wandb.wandb_agent - INFO - Cleaning up finished run: 9m6j5rqf
2022-06-16 04:01:56,770 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:01:56,771 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 04:01:56,780 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 04:02:01,789 - wandb.wandb_agent - INFO - Running runs: ['mvw3kdxl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_040201-mvw3kdxl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-2
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/mvw3kdxl
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm1_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90994
wandb:    train_loss 0.27617
wandb: training_time 1.43179
wandb:        val_f1 0.896
wandb:      val_loss 0.29321
wandb: 
wandb: Synced devoted-sweep-2: https://wandb.ai/jah377/sffMHA_pubmed/runs/mvw3kdxl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_040201-mvw3kdxl/logs
2022-06-16 04:13:32,684 - wandb.wandb_agent - INFO - Cleaning up finished run: mvw3kdxl
2022-06-16 04:13:33,211 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:13:33,212 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 04:13:33,219 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 04:13:38,233 - wandb.wandb_agent - INFO - Running runs: ['zsi0gret']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_041338-zsi0gret
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-3
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/zsi0gret
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k1_dot_product_norm1_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.99433
wandb:    train_loss 0.02724
wandb: training_time 2.00576
wandb:        val_f1 0.908
wandb:      val_loss 0.27983
wandb: 
wandb: Synced pious-sweep-3: https://wandb.ai/jah377/sffMHA_pubmed/runs/zsi0gret
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_041338-zsi0gret/logs
2022-06-16 04:29:59,469 - wandb.wandb_agent - INFO - Cleaning up finished run: zsi0gret
2022-06-16 04:29:59,839 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:29:59,839 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 04:29:59,846 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 04:30:04,857 - wandb.wandb_agent - INFO - Running runs: ['zyssrv4v']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_043004-zyssrv4v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-4
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/zyssrv4v
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k1_dot_product_norm0_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96704
wandb:    train_loss 0.10974
wandb: training_time 1.41498
wandb:        val_f1 0.918
wandb:      val_loss 0.24354
wandb: 
wandb: Synced fast-sweep-4: https://wandb.ai/jah377/sffMHA_pubmed/runs/zyssrv4v
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_043004-zyssrv4v/logs
2022-06-16 04:42:55,562 - wandb.wandb_agent - INFO - Cleaning up finished run: zyssrv4v
2022-06-16 04:42:55,987 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:42:55,988 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 04:42:55,997 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 04:43:01,009 - wandb.wandb_agent - INFO - Running runs: ['nkbbpja1']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_044301-nkbbpja1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-5
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/nkbbpja1
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm1_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8799
wandb:    train_loss 0.34401
wandb: training_time 2.12286
wandb:        val_f1 0.894
wandb:      val_loss 0.32849
wandb: 
wandb: Synced lively-sweep-5: https://wandb.ai/jah377/sffMHA_pubmed/runs/nkbbpja1
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_044301-nkbbpja1/logs
2022-06-16 04:59:16,451 - wandb.wandb_agent - INFO - Cleaning up finished run: nkbbpja1
2022-06-16 04:59:16,837 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 04:59:16,837 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 04:59:16,846 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 04:59:21,859 - wandb.wandb_agent - INFO - Running runs: ['we64wwz2']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_045921-we64wwz2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-6
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/we64wwz2
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm0_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91384
wandb:    train_loss 0.2362
wandb: training_time 1.35906
wandb:        val_f1 0.908
wandb:      val_loss 0.27493
wandb: 
wandb: Synced earnest-sweep-6: https://wandb.ai/jah377/sffMHA_pubmed/runs/we64wwz2
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_045921-we64wwz2/logs
2022-06-16 05:11:13,493 - wandb.wandb_agent - INFO - Cleaning up finished run: we64wwz2
2022-06-16 05:11:14,267 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:11:14,267 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 05:11:14,274 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 05:11:19,288 - wandb.wandb_agent - INFO - Running runs: ['iqlxvfd8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_051119-iqlxvfd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-7
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/iqlxvfd8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95125
wandb:    train_loss 0.13213
wandb: training_time 1.57696
wandb:        val_f1 0.926
wandb:      val_loss 0.23517
wandb: 
wandb: Synced golden-sweep-7: https://wandb.ai/jah377/sffMHA_pubmed/runs/iqlxvfd8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_051119-iqlxvfd8/logs
2022-06-16 05:23:20,219 - wandb.wandb_agent - INFO - Cleaning up finished run: iqlxvfd8
2022-06-16 05:23:20,664 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:23:20,665 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 05:23:20,674 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 05:23:25,685 - wandb.wandb_agent - INFO - Running runs: ['72sjc8yl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_052325-72sjc8yl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-8
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/72sjc8yl
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm0_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96264
wandb:    train_loss 0.09679
wandb: training_time 1.58445
wandb:        val_f1 0.922
wandb:      val_loss 0.24729
wandb: 
wandb: Synced confused-sweep-8: https://wandb.ai/jah377/sffMHA_pubmed/runs/72sjc8yl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_052325-72sjc8yl/logs
2022-06-16 05:36:23,974 - wandb.wandb_agent - INFO - Cleaning up finished run: 72sjc8yl
2022-06-16 05:36:24,378 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:36:24,378 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 05:36:24,385 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 05:36:29,398 - wandb.wandb_agent - INFO - Running runs: ['1r9qouqv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_053629-1r9qouqv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-9
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/1r9qouqv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm0_heads4.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97849
wandb:    train_loss 0.06505
wandb: training_time 1.07455
wandb:        val_f1 0.918
wandb:      val_loss 0.26762
wandb: 
wandb: Synced golden-sweep-9: https://wandb.ai/jah377/sffMHA_pubmed/runs/1r9qouqv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_053629-1r9qouqv/logs
2022-06-16 05:45:52,747 - wandb.wandb_agent - INFO - Cleaning up finished run: 1r9qouqv
2022-06-16 05:45:53,144 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 05:45:53,144 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 05:45:53,152 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 05:45:58,165 - wandb.wandb_agent - INFO - Running runs: ['1nluepw9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_054558-1nluepw9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-10
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/1nluepw9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm1_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.903
wandb:    train_loss 0.26076
wandb: training_time 2.18026
wandb:        val_f1 0.9
wandb:      val_loss 0.27132
wandb: 
wandb: Synced dutiful-sweep-10: https://wandb.ai/jah377/sffMHA_pubmed/runs/1nluepw9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_054558-1nluepw9/logs
2022-06-16 06:02:29,008 - wandb.wandb_agent - INFO - Cleaning up finished run: 1nluepw9
2022-06-16 06:02:29,426 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:02:29,427 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 06:02:29,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 06:02:34,448 - wandb.wandb_agent - INFO - Running runs: ['8mbseaio']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_060234-8mbseaio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-11
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/8mbseaio
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm0_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94482
wandb:    train_loss 0.13669
wandb: training_time 1.94583
wandb:        val_f1 0.91
wandb:      val_loss 0.2529
wandb: 
wandb: Synced major-sweep-11: https://wandb.ai/jah377/sffMHA_pubmed/runs/8mbseaio
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_060234-8mbseaio/logs
2022-06-16 06:17:51,304 - wandb.wandb_agent - INFO - Cleaning up finished run: 8mbseaio
2022-06-16 06:17:51,735 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:17:51,735 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 06:17:51,744 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 06:17:56,757 - wandb.wandb_agent - INFO - Running runs: ['ccdfqc6y']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_061756-ccdfqc6y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-12
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/ccdfqc6y
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91049
wandb:    train_loss 0.23058
wandb: training_time 1.46428
wandb:        val_f1 0.908
wandb:      val_loss 0.25438
wandb: 
wandb: Synced leafy-sweep-12: https://wandb.ai/jah377/sffMHA_pubmed/runs/ccdfqc6y
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_061756-ccdfqc6y/logs
2022-06-16 06:29:07,151 - wandb.wandb_agent - INFO - Cleaning up finished run: ccdfqc6y
2022-06-16 06:29:07,583 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:29:07,584 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 06:29:07,593 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 06:29:12,606 - wandb.wandb_agent - INFO - Running runs: ['n554y2iu']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_062912-n554y2iu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-13
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/n554y2iu
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87137
wandb:    train_loss 0.32784
wandb: training_time 2.43991
wandb:        val_f1 0.89
wandb:      val_loss 0.31276
wandb: 
wandb: Synced lunar-sweep-13: https://wandb.ai/jah377/sffMHA_pubmed/runs/n554y2iu
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_062912-n554y2iu/logs
2022-06-16 06:46:59,515 - wandb.wandb_agent - INFO - Cleaning up finished run: n554y2iu
2022-06-16 06:46:59,899 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 06:46:59,899 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 06:46:59,906 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 06:47:04,920 - wandb.wandb_agent - INFO - Running runs: ['phoiukb8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_064705-phoiukb8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-14
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/phoiukb8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm1_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.91285
wandb:    train_loss 0.22997
wandb: training_time 3.68292
wandb:        val_f1 0.91
wandb:      val_loss 0.2493
wandb: 
wandb: Synced elated-sweep-14: https://wandb.ai/jah377/sffMHA_pubmed/runs/phoiukb8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_064705-phoiukb8/logs
2022-06-16 07:13:27,037 - wandb.wandb_agent - INFO - Cleaning up finished run: phoiukb8
2022-06-16 07:13:27,494 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:13:27,494 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 07:13:27,501 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 07:13:32,513 - wandb.wandb_agent - INFO - Running runs: ['bit0hwpt']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_071332-bit0hwpt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-15
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/bit0hwpt
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89981
wandb:    train_loss 0.26251
wandb: training_time 1.26815
wandb:        val_f1 0.894
wandb:      val_loss 0.27664
wandb: 
wandb: Synced daily-sweep-15: https://wandb.ai/jah377/sffMHA_pubmed/runs/bit0hwpt
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_071332-bit0hwpt/logs
2022-06-16 07:23:25,901 - wandb.wandb_agent - INFO - Cleaning up finished run: bit0hwpt
2022-06-16 07:23:26,426 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:23:26,426 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 2
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 07:23:26,433 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=2 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 07:23:31,447 - wandb.wandb_agent - INFO - Running runs: ['knq7hwfo']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_072331-knq7hwfo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-16
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/knq7hwfo
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm1_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.67826
wandb:    train_loss 0.8024
wandb: training_time 2.08367
wandb:        val_f1 0.668
wandb:      val_loss 0.79886
wandb: 
wandb: Synced exalted-sweep-16: https://wandb.ai/jah377/sffMHA_pubmed/runs/knq7hwfo
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_072331-knq7hwfo/logs
2022-06-16 07:38:55,793 - wandb.wandb_agent - INFO - Cleaning up finished run: knq7hwfo
2022-06-16 07:38:56,201 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:38:56,202 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 07:38:56,210 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 07:39:01,223 - wandb.wandb_agent - INFO - Running runs: ['xet2l3ta']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_073901-xet2l3ta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-17
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/xet2l3ta
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm1_heads4.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87318
wandb:    train_loss 0.33055
wandb: training_time 1.25458
wandb:        val_f1 0.874
wandb:      val_loss 0.32754
wandb: 
wandb: Synced misunderstood-sweep-17: https://wandb.ai/jah377/sffMHA_pubmed/runs/xet2l3ta
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_073901-xet2l3ta/logs
2022-06-16 07:50:10,921 - wandb.wandb_agent - INFO - Cleaning up finished run: xet2l3ta
2022-06-16 07:50:11,406 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 07:50:11,406 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 07:50:11,414 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 07:50:16,427 - wandb.wandb_agent - INFO - Running runs: ['3j44sgtx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_075016-3j44sgtx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-18
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/3j44sgtx
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.93046
wandb:    train_loss 0.18742
wandb: training_time 2.19607
wandb:        val_f1 0.92
wandb:      val_loss 0.23512
wandb: 
wandb: Synced drawn-sweep-18: https://wandb.ai/jah377/sffMHA_pubmed/runs/3j44sgtx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_075016-3j44sgtx/logs
2022-06-16 08:07:31,998 - wandb.wandb_agent - INFO - Cleaning up finished run: 3j44sgtx
2022-06-16 08:07:32,494 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:07:32,494 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 08:07:32,502 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 08:07:37,515 - wandb.wandb_agent - INFO - Running runs: ['y5gqvudx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_080737-y5gqvudx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-19
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/y5gqvudx
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm0_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.75875
wandb:    train_loss 0.85943
wandb: training_time 2.01165
wandb:        val_f1 0.752
wandb:      val_loss 0.86067
wandb: 
wandb: Synced summer-sweep-19: https://wandb.ai/jah377/sffMHA_pubmed/runs/y5gqvudx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_080737-y5gqvudx/logs
2022-06-16 08:24:27,256 - wandb.wandb_agent - INFO - Cleaning up finished run: y5gqvudx
2022-06-16 08:24:27,650 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:24:27,651 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 08:24:27,659 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 08:24:32,672 - wandb.wandb_agent - INFO - Running runs: ['selzkj11']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_082432-selzkj11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-20
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/selzkj11
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.937
wandb:    train_loss 0.17372
wandb: training_time 1.74068
wandb:        val_f1 0.922
wandb:      val_loss 0.22771
wandb: 
wandb: Synced flowing-sweep-20: https://wandb.ai/jah377/sffMHA_pubmed/runs/selzkj11
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_082432-selzkj11/logs
2022-06-16 08:38:52,249 - wandb.wandb_agent - INFO - Cleaning up finished run: selzkj11
2022-06-16 08:38:52,633 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:38:52,634 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 08:38:52,640 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 08:38:57,651 - wandb.wandb_agent - INFO - Running runs: ['6pnf7o9m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_083857-6pnf7o9m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-21
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/6pnf7o9m
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.82213
wandb:    train_loss 0.44075
wandb: training_time 0.64538
wandb:        val_f1 0.826
wandb:      val_loss 0.44686
wandb: 
wandb: Synced glorious-sweep-21: https://wandb.ai/jah377/sffMHA_pubmed/runs/6pnf7o9m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_083857-6pnf7o9m/logs
2022-06-16 08:45:18,813 - wandb.wandb_agent - INFO - Cleaning up finished run: 6pnf7o9m
2022-06-16 08:45:19,228 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 08:45:19,229 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 08:45:19,236 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 08:45:24,249 - wandb.wandb_agent - INFO - Running runs: ['7mddp1a6']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_084524-7mddp1a6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-22
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/7mddp1a6
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm0_heads4.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87506
wandb:    train_loss 0.34905
wandb: training_time 1.90472
wandb:        val_f1 0.898
wandb:      val_loss 0.33776
wandb: 
wandb: Synced classic-sweep-22: https://wandb.ai/jah377/sffMHA_pubmed/runs/7mddp1a6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_084524-7mddp1a6/logs
2022-06-16 09:00:14,471 - wandb.wandb_agent - INFO - Cleaning up finished run: 7mddp1a6
2022-06-16 09:00:18,021 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:00:18,021 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 09:00:18,028 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 09:00:23,042 - wandb.wandb_agent - INFO - Running runs: ['l176j5hx']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_090023-l176j5hx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-23
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/l176j5hx
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm0_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86438
wandb:    train_loss 0.35666
wandb: training_time 4.57421
wandb:        val_f1 0.878
wandb:      val_loss 0.35774
wandb: 
wandb: Synced youthful-sweep-23: https://wandb.ai/jah377/sffMHA_pubmed/runs/l176j5hx
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_090023-l176j5hx/logs
2022-06-16 09:31:23,391 - wandb.wandb_agent - INFO - Cleaning up finished run: l176j5hx
2022-06-16 09:31:23,834 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:31:23,834 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 09:31:23,841 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 09:31:28,855 - wandb.wandb_agent - INFO - Running runs: ['v2jydtjj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_093128-v2jydtjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-24
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/v2jydtjj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86614
wandb:    train_loss 0.35475
wandb: training_time 1.2916
wandb:        val_f1 0.862
wandb:      val_loss 0.35892
wandb: 
wandb: Synced snowy-sweep-24: https://wandb.ai/jah377/sffMHA_pubmed/runs/v2jydtjj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_093128-v2jydtjj/logs
2022-06-16 09:41:52,234 - wandb.wandb_agent - INFO - Cleaning up finished run: v2jydtjj
2022-06-16 09:41:52,762 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:41:52,762 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 09:41:52,771 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 09:41:57,786 - wandb.wandb_agent - INFO - Running runs: ['yqhhgir9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_094157-yqhhgir9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-25
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/yqhhgir9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87792
wandb:    train_loss 0.36229
wandb: training_time 1.43396
wandb:        val_f1 0.884
wandb:      val_loss 0.36218
wandb: 
wandb: Synced ancient-sweep-25: https://wandb.ai/jah377/sffMHA_pubmed/runs/yqhhgir9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_094157-yqhhgir9/logs
2022-06-16 09:54:26,087 - wandb.wandb_agent - INFO - Cleaning up finished run: yqhhgir9
2022-06-16 09:54:26,811 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 09:54:26,811 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 09:54:26,819 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 09:54:31,833 - wandb.wandb_agent - INFO - Running runs: ['446fhboj']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_095431-446fhboj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-26
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/446fhboj
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k1_dot_product_norm1_heads4.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90889
wandb:    train_loss 0.24223
wandb: training_time 2.64576
wandb:        val_f1 0.906
wandb:      val_loss 0.25767
wandb: 
wandb: Synced twilight-sweep-26: https://wandb.ai/jah377/sffMHA_pubmed/runs/446fhboj
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_095431-446fhboj/logs
2022-06-16 10:14:29,326 - wandb.wandb_agent - INFO - Cleaning up finished run: 446fhboj
2022-06-16 10:14:29,798 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:14:29,798 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 10:14:29,807 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 10:14:34,820 - wandb.wandb_agent - INFO - Running runs: ['eveesyf7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_101434-eveesyf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-27
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/eveesyf7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k0_dot_product_norm0_heads4.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85211
wandb:    train_loss 0.39198
wandb: training_time 1.25159
wandb:        val_f1 0.858
wandb:      val_loss 0.39526
wandb: 
wandb: Synced silvery-sweep-27: https://wandb.ai/jah377/sffMHA_pubmed/runs/eveesyf7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_101434-eveesyf7/logs
2022-06-16 10:25:18,813 - wandb.wandb_agent - INFO - Cleaning up finished run: eveesyf7
2022-06-16 10:25:19,316 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:25:19,316 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 10:25:19,324 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 10:25:24,336 - wandb.wandb_agent - INFO - Running runs: ['cnsh9jao']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_102524-cnsh9jao
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-28
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/cnsh9jao
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k1_dot_product_norm0_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8377
wandb:    train_loss 0.51172
wandb: training_time 1.18149
wandb:        val_f1 0.856
wandb:      val_loss 0.49926
wandb: 
wandb: Synced pious-sweep-28: https://wandb.ai/jah377/sffMHA_pubmed/runs/cnsh9jao
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_102524-cnsh9jao/logs
2022-06-16 10:35:48,220 - wandb.wandb_agent - INFO - Cleaning up finished run: cnsh9jao
2022-06-16 10:35:48,635 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:35:48,635 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 10:35:48,642 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 10:35:53,656 - wandb.wandb_agent - INFO - Running runs: ['5tdygb6q']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_103553-5tdygb6q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-29
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/5tdygb6q
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm1_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.78928
wandb:    train_loss 0.79469
wandb: training_time 2.61336
wandb:        val_f1 0.8
wandb:      val_loss 0.78443
wandb: 
wandb: Synced wandering-sweep-29: https://wandb.ai/jah377/sffMHA_pubmed/runs/5tdygb6q
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_103553-5tdygb6q/logs
2022-06-16 10:55:29,176 - wandb.wandb_agent - INFO - Cleaning up finished run: 5tdygb6q
2022-06-16 10:55:29,631 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 10:55:29,631 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 10:55:29,640 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 10:55:34,654 - wandb.wandb_agent - INFO - Running runs: ['j7890zzh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_105534-j7890zzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-30
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/j7890zzh
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm1_heads5.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89024
wandb:    train_loss 0.28602
wandb: training_time 1.21381
wandb:        val_f1 0.894
wandb:      val_loss 0.28195
wandb: 
wandb: Synced cerulean-sweep-30: https://wandb.ai/jah377/sffMHA_pubmed/runs/j7890zzh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_105534-j7890zzh/logs
2022-06-16 11:05:18,348 - wandb.wandb_agent - INFO - Cleaning up finished run: j7890zzh
2022-06-16 11:05:18,779 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:05:18,780 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 11:05:18,787 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 11:05:23,802 - wandb.wandb_agent - INFO - Running runs: ['jipqqqvv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_110523-jipqqqvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-31
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/jipqqqvv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88831
wandb:    train_loss 0.28608
wandb: training_time 2.78165
wandb:        val_f1 0.892
wandb:      val_loss 0.29091
wandb: 
wandb: Synced leafy-sweep-31: https://wandb.ai/jah377/sffMHA_pubmed/runs/jipqqqvv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_110523-jipqqqvv/logs
2022-06-16 11:26:06,074 - wandb.wandb_agent - INFO - Cleaning up finished run: jipqqqvv
2022-06-16 11:26:06,507 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:26:06,508 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 11:26:06,515 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 11:26:11,529 - wandb.wandb_agent - INFO - Running runs: ['6mqv1ey5']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_112611-6mqv1ey5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-32
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/6mqv1ey5
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm0_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90207
wandb:    train_loss 0.24501
wandb: training_time 1.06564
wandb:        val_f1 0.9
wandb:      val_loss 0.26797
wandb: 
wandb: Synced devout-sweep-32: https://wandb.ai/jah377/sffMHA_pubmed/runs/6mqv1ey5
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_112611-6mqv1ey5/logs
2022-06-16 11:35:39,739 - wandb.wandb_agent - INFO - Cleaning up finished run: 6mqv1ey5
2022-06-16 11:35:40,773 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:35:40,773 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 11:35:40,783 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 11:35:45,796 - wandb.wandb_agent - INFO - Running runs: ['a5rf3n80']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_113545-a5rf3n80
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-33
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/a5rf3n80
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 75
wandb:      train_f1 0.87423
wandb:    train_loss 0.34332
wandb: training_time 0.67873
wandb:        val_f1 0.87
wandb:      val_loss 0.34694
wandb: 
wandb: Synced colorful-sweep-33: https://wandb.ai/jah377/sffMHA_pubmed/runs/a5rf3n80
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_113545-a5rf3n80/logs
2022-06-16 11:37:49,335 - wandb.wandb_agent - INFO - Cleaning up finished run: a5rf3n80
2022-06-16 11:37:50,138 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:37:50,138 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 11:37:50,145 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 11:37:55,158 - wandb.wandb_agent - INFO - Running runs: ['2z98ljtn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_113755-2z98ljtn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-34
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/2z98ljtn
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm0_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.52085
wandb:    train_loss 1.07477
wandb: training_time 1.90012
wandb:        val_f1 0.546
wandb:      val_loss 1.0708
wandb: 
wandb: Synced denim-sweep-34: https://wandb.ai/jah377/sffMHA_pubmed/runs/2z98ljtn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_113755-2z98ljtn/logs
2022-06-16 11:52:14,744 - wandb.wandb_agent - INFO - Cleaning up finished run: 2z98ljtn
2022-06-16 11:52:15,385 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 11:52:15,385 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 11:52:15,392 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 11:52:20,406 - wandb.wandb_agent - INFO - Running runs: ['nf5rq9hn']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_115220-nf5rq9hn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-35
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/nf5rq9hn
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.84039
wandb:    train_loss 0.51002
wandb: training_time 1.1707
wandb:        val_f1 0.84
wandb:      val_loss 0.50566
wandb: 
wandb: Synced happy-sweep-35: https://wandb.ai/jah377/sffMHA_pubmed/runs/nf5rq9hn
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_115220-nf5rq9hn/logs
2022-06-16 12:02:18,969 - wandb.wandb_agent - INFO - Cleaning up finished run: nf5rq9hn
2022-06-16 12:02:19,670 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:02:19,670 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 12:02:19,677 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 12:02:24,692 - wandb.wandb_agent - INFO - Running runs: ['kkqrfmnb']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_120224-kkqrfmnb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-36
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/kkqrfmnb
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.94889
wandb:    train_loss 0.15077
wandb: training_time 1.94879
wandb:        val_f1 0.912
wandb:      val_loss 0.23518
wandb: 
wandb: Synced ethereal-sweep-36: https://wandb.ai/jah377/sffMHA_pubmed/runs/kkqrfmnb
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_120224-kkqrfmnb/logs
2022-06-16 12:18:17,605 - wandb.wandb_agent - INFO - Cleaning up finished run: kkqrfmnb
2022-06-16 12:18:18,247 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:18:18,248 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 12:18:18,254 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 12:18:23,268 - wandb.wandb_agent - INFO - Running runs: ['s4o6vshg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_121823-s4o6vshg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-37
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/s4o6vshg
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.79533
wandb:    train_loss 0.55546
wandb: training_time 1.85728
wandb:        val_f1 0.786
wandb:      val_loss 0.55837
wandb: 
wandb: Synced vibrant-sweep-37: https://wandb.ai/jah377/sffMHA_pubmed/runs/s4o6vshg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_121823-s4o6vshg/logs
2022-06-16 12:32:49,427 - wandb.wandb_agent - INFO - Cleaning up finished run: s4o6vshg
2022-06-16 12:32:49,999 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:32:50,000 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 12:32:50,007 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 12:32:55,020 - wandb.wandb_agent - INFO - Running runs: ['kvbrl6ca']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_123255-kvbrl6ca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-38
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/kvbrl6ca
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39503
wandb:    train_loss 1.04028
wandb: training_time 3.36697
wandb:        val_f1 0.388
wandb:      val_loss 1.02682
wandb: 
wandb: Synced classic-sweep-38: https://wandb.ai/jah377/sffMHA_pubmed/runs/kvbrl6ca
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_123255-kvbrl6ca/logs
2022-06-16 12:55:57,434 - wandb.wandb_agent - INFO - Cleaning up finished run: kvbrl6ca
2022-06-16 12:55:57,979 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 12:55:57,979 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 12:55:57,987 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 12:56:03,001 - wandb.wandb_agent - INFO - Running runs: ['dtt0onro']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_125603-dtt0onro
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-39
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/dtt0onro
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39074
wandb:    train_loss 1.09246
wandb: training_time 0.5376
wandb:        val_f1 0.388
wandb:      val_loss 1.09203
wandb: 
wandb: Synced eager-sweep-39: https://wandb.ai/jah377/sffMHA_pubmed/runs/dtt0onro
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_125603-dtt0onro/logs
2022-06-16 13:01:54,781 - wandb.wandb_agent - INFO - Cleaning up finished run: dtt0onro
2022-06-16 13:01:55,459 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:01:55,460 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 13:01:55,466 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 13:02:00,477 - wandb.wandb_agent - INFO - Running runs: ['8ffhzlza']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_130200-8ffhzlza
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run super-sweep-40
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/8ffhzlza
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.20989
wandb:    train_loss 1.1021
wandb: training_time 0.59262
wandb:        val_f1 0.196
wandb:      val_loss 1.10232
wandb: 
wandb: Synced super-sweep-40: https://wandb.ai/jah377/sffMHA_pubmed/runs/8ffhzlza
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_130200-8ffhzlza/logs
2022-06-16 13:08:16,899 - wandb.wandb_agent - INFO - Cleaning up finished run: 8ffhzlza
2022-06-16 13:08:17,694 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:08:17,694 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 13:08:17,703 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 13:08:22,717 - wandb.wandb_agent - INFO - Running runs: ['uqpruh27']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_130822-uqpruh27
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-41
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/uqpruh27
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm0_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87362
wandb:    train_loss 0.36947
wandb: training_time 1.85839
wandb:        val_f1 0.87
wandb:      val_loss 0.36643
wandb: 
wandb: Synced atomic-sweep-41: https://wandb.ai/jah377/sffMHA_pubmed/runs/uqpruh27
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_130822-uqpruh27/logs
2022-06-16 13:24:16,023 - wandb.wandb_agent - INFO - Cleaning up finished run: uqpruh27
2022-06-16 13:24:16,878 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:24:16,879 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 13:24:16,886 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 13:24:21,897 - wandb.wandb_agent - INFO - Running runs: ['6bwrc687']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_132421-6bwrc687
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-42
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/6bwrc687
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.70835
wandb:    train_loss 0.95796
wandb: training_time 2.24201
wandb:        val_f1 0.73
wandb:      val_loss 0.95455
wandb: 
wandb: Synced ruby-sweep-42: https://wandb.ai/jah377/sffMHA_pubmed/runs/6bwrc687
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_132421-6bwrc687/logs
2022-06-16 13:40:46,352 - wandb.wandb_agent - INFO - Cleaning up finished run: 6bwrc687
2022-06-16 13:40:46,998 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 13:40:46,998 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 13:40:47,005 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 13:40:52,019 - wandb.wandb_agent - INFO - Running runs: ['mo2jk282']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_134052-mo2jk282
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-43
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/mo2jk282
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm0_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.77448
wandb:    train_loss 0.73028
wandb: training_time 2.59737
wandb:        val_f1 0.77
wandb:      val_loss 0.73331
wandb: 
wandb: Synced firm-sweep-43: https://wandb.ai/jah377/sffMHA_pubmed/runs/mo2jk282
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_134052-mo2jk282/logs
2022-06-16 14:01:09,433 - wandb.wandb_agent - INFO - Cleaning up finished run: mo2jk282
2022-06-16 14:01:10,183 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:01:10,183 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 14:01:10,190 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 14:01:15,201 - wandb.wandb_agent - INFO - Running runs: ['rp54bhjd']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_140115-rp54bhjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-44
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/rp54bhjd
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm0_heads3.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96099
wandb:    train_loss 0.10568
wandb: training_time 2.2031
wandb:        val_f1 0.924
wandb:      val_loss 0.2627
wandb: 
wandb: Synced iconic-sweep-44: https://wandb.ai/jah377/sffMHA_pubmed/runs/rp54bhjd
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_140115-rp54bhjd/logs
2022-06-16 14:19:08,554 - wandb.wandb_agent - INFO - Cleaning up finished run: rp54bhjd
2022-06-16 14:19:09,105 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:19:09,105 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 14:19:09,112 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 14:19:14,125 - wandb.wandb_agent - INFO - Running runs: ['sz4ovxv7']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_141914-sz4ovxv7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-45
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/sz4ovxv7
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm0_heads5.pth

$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 69
wandb:      train_f1 0.8169
wandb:    train_loss 0.5855
wandb: training_time 1.14795
wandb:        val_f1 0.828
wandb:      val_loss 0.55929
wandb: 
wandb: Synced efficient-sweep-45: https://wandb.ai/jah377/sffMHA_pubmed/runs/sz4ovxv7
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_141914-sz4ovxv7/logs
2022-06-16 14:22:04,188 - wandb.wandb_agent - INFO - Cleaning up finished run: sz4ovxv7
2022-06-16 14:22:04,794 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:22:04,795 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 14:22:04,802 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 14:22:09,815 - wandb.wandb_agent - INFO - Running runs: ['3xvt5082']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_142209-3xvt5082
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-46
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/3xvt5082
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.48125
wandb:    train_loss 1.02431
wandb: training_time 0.6194
wandb:        val_f1 0.456
wandb:      val_loss 1.02646
wandb: 
wandb: Synced fragrant-sweep-46: https://wandb.ai/jah377/sffMHA_pubmed/runs/3xvt5082
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_142209-3xvt5082/logs
2022-06-16 14:28:37,212 - wandb.wandb_agent - INFO - Cleaning up finished run: 3xvt5082
2022-06-16 14:28:37,764 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:28:37,764 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 14:28:37,774 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 14:28:42,787 - wandb.wandb_agent - INFO - Running runs: ['hvdxpccl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_142842-hvdxpccl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-47
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/hvdxpccl
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k5_dot_product_norm1_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4784
wandb:    train_loss 0.99938
wandb: training_time 0.67808
wandb:        val_f1 0.468
wandb:      val_loss 0.99328
wandb: 
wandb: Synced morning-sweep-47: https://wandb.ai/jah377/sffMHA_pubmed/runs/hvdxpccl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_142842-hvdxpccl/logs
2022-06-16 14:35:42,470 - wandb.wandb_agent - INFO - Cleaning up finished run: hvdxpccl
2022-06-16 14:35:43,119 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:35:43,119 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 14:35:43,128 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 14:35:48,142 - wandb.wandb_agent - INFO - Running runs: ['95v8aqp4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_143548-95v8aqp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-48
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/95v8aqp4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8761
wandb:    train_loss 0.35038
wandb: training_time 1.73942
wandb:        val_f1 0.886
wandb:      val_loss 0.34344
wandb: 
wandb: Synced trim-sweep-48: https://wandb.ai/jah377/sffMHA_pubmed/runs/95v8aqp4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_143548-95v8aqp4/logs
2022-06-16 14:50:15,337 - wandb.wandb_agent - INFO - Cleaning up finished run: 95v8aqp4
2022-06-16 14:50:16,459 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 14:50:16,459 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 14:50:16,467 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 14:50:21,477 - wandb.wandb_agent - INFO - Running runs: ['5dkh9654']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_145021-5dkh9654
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-49
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/5dkh9654
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85536
wandb:    train_loss 0.41699
wandb: training_time 2.99561
wandb:        val_f1 0.868
wandb:      val_loss 0.4047
wandb: 
wandb: Synced worldly-sweep-49: https://wandb.ai/jah377/sffMHA_pubmed/runs/5dkh9654
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_145021-5dkh9654/logs
2022-06-16 15:12:26,676 - wandb.wandb_agent - INFO - Cleaning up finished run: 5dkh9654
2022-06-16 15:12:27,382 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:12:27,382 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 15:12:27,390 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 15:12:32,401 - wandb.wandb_agent - INFO - Running runs: ['mykgpcn8']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_151232-mykgpcn8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-50
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/mykgpcn8
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.88614
wandb:    train_loss 0.3024
wandb: training_time 0.41388
wandb:        val_f1 0.894
wandb:      val_loss 0.29364
wandb: 
wandb: Synced treasured-sweep-50: https://wandb.ai/jah377/sffMHA_pubmed/runs/mykgpcn8
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_151232-mykgpcn8/logs
2022-06-16 15:17:26,351 - wandb.wandb_agent - INFO - Cleaning up finished run: mykgpcn8
2022-06-16 15:17:26,886 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:17:26,886 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 15:17:26,895 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 15:17:31,909 - wandb.wandb_agent - INFO - Running runs: ['glwf2svv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_151731-glwf2svv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-51
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/glwf2svv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.79015
wandb:    train_loss 0.66513
wandb: training_time 0.47195
wandb:        val_f1 0.78
wandb:      val_loss 0.66454
wandb: 
wandb: Synced atomic-sweep-51: https://wandb.ai/jah377/sffMHA_pubmed/runs/glwf2svv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_151731-glwf2svv/logs
2022-06-16 15:22:56,922 - wandb.wandb_agent - INFO - Cleaning up finished run: glwf2svv
2022-06-16 15:22:57,442 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:22:57,442 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 15:22:57,451 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 15:23:02,465 - wandb.wandb_agent - INFO - Running runs: ['xsr7nh7c']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_152302-xsr7nh7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-52
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/xsr7nh7c
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.98179
wandb:    train_loss 0.06609
wandb: training_time 2.1483
wandb:        val_f1 0.924
wandb:      val_loss 0.23964
wandb: 
wandb: Synced copper-sweep-52: https://wandb.ai/jah377/sffMHA_pubmed/runs/xsr7nh7c
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_152302-xsr7nh7c/logs
2022-06-16 15:40:08,002 - wandb.wandb_agent - INFO - Cleaning up finished run: xsr7nh7c
2022-06-16 15:40:08,551 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:40:08,551 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 15:40:08,558 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 15:40:13,569 - wandb.wandb_agent - INFO - Running runs: ['5epa6how']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_154013-5epa6how
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-53
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/5epa6how
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k1_dot_product_norm0_heads4.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90741
wandb:    train_loss 0.25375
wandb: training_time 1.74764
wandb:        val_f1 0.898
wandb:      val_loss 0.27809
wandb: 
wandb: Synced polished-sweep-53: https://wandb.ai/jah377/sffMHA_pubmed/runs/5epa6how
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_154013-5epa6how/logs
2022-06-16 15:55:11,976 - wandb.wandb_agent - INFO - Cleaning up finished run: 5epa6how
2022-06-16 15:55:12,695 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 15:55:12,696 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 4
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 15:55:12,704 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=4 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 15:55:17,717 - wandb.wandb_agent - INFO - Running runs: ['1364318b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_155517-1364318b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-54
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/1364318b
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 4, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90454
wandb:    train_loss 0.25133
wandb: training_time 1.37362
wandb:        val_f1 0.894
wandb:      val_loss 0.25612
wandb: 
wandb: Synced honest-sweep-54: https://wandb.ai/jah377/sffMHA_pubmed/runs/1364318b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_155517-1364318b/logs
2022-06-16 16:07:41,144 - wandb.wandb_agent - INFO - Cleaning up finished run: 1364318b
2022-06-16 16:07:41,671 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:07:41,672 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 16:07:41,678 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 16:07:46,693 - wandb.wandb_agent - INFO - Running runs: ['3i4s7vam']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_160746-3i4s7vam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-55
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/3i4s7vam
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39156
wandb:    train_loss 1.08086
wandb: training_time 0.91227
wandb:        val_f1 0.388
wandb:      val_loss 1.08067
wandb: 
wandb: Synced young-sweep-55: https://wandb.ai/jah377/sffMHA_pubmed/runs/3i4s7vam
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_160746-3i4s7vam/logs
2022-06-16 16:16:06,057 - wandb.wandb_agent - INFO - Cleaning up finished run: 3i4s7vam
2022-06-16 16:16:06,804 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:16:06,804 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 16:16:06,812 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 16:16:11,825 - wandb.wandb_agent - INFO - Running runs: ['vc4kfaa0']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_161611-vc4kfaa0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-56
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/vc4kfaa0
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.62594
wandb:    train_loss 0.92039
wandb: training_time 1.38607
wandb:        val_f1 0.648
wandb:      val_loss 0.90921
wandb: 
wandb: Synced neat-sweep-56: https://wandb.ai/jah377/sffMHA_pubmed/runs/vc4kfaa0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_161611-vc4kfaa0/logs
2022-06-16 16:27:11,955 - wandb.wandb_agent - INFO - Cleaning up finished run: vc4kfaa0
2022-06-16 16:27:12,481 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:27:12,481 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 16:27:12,488 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 16:27:17,502 - wandb.wandb_agent - INFO - Running runs: ['ya6kbcv4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_162717-ya6kbcv4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-57
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/ya6kbcv4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.33304
wandb:    train_loss 1.08749
wandb: training_time 0.64298
wandb:        val_f1 0.326
wandb:      val_loss 1.09422
wandb: 
wandb: Synced good-sweep-57: https://wandb.ai/jah377/sffMHA_pubmed/runs/ya6kbcv4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_162717-ya6kbcv4/logs
2022-06-16 16:33:44,529 - wandb.wandb_agent - INFO - Cleaning up finished run: ya6kbcv4
2022-06-16 16:33:45,410 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:33:45,411 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 16:33:45,418 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 16:33:50,431 - wandb.wandb_agent - INFO - Running runs: ['bd7g9y9x']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_163350-bd7g9y9x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-58
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/bd7g9y9x
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39833
wandb:    train_loss 1.08006
wandb: training_time 1.3558
wandb:        val_f1 0.416
wandb:      val_loss 1.07803
wandb: 
wandb: Synced sunny-sweep-58: https://wandb.ai/jah377/sffMHA_pubmed/runs/bd7g9y9x
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_163350-bd7g9y9x/logs
2022-06-16 16:46:26,447 - wandb.wandb_agent - INFO - Cleaning up finished run: bd7g9y9x
2022-06-16 16:46:26,974 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 16:46:26,974 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 16:46:26,981 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 16:46:31,993 - wandb.wandb_agent - INFO - Running runs: ['ug2a9ajm']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_164632-ug2a9ajm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-59
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/ug2a9ajm
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.89767
wandb:    train_loss 0.27951
wandb: training_time 4.25549
wandb:        val_f1 0.9
wandb:      val_loss 0.30049
wandb: 
wandb: Synced royal-sweep-59: https://wandb.ai/jah377/sffMHA_pubmed/runs/ug2a9ajm
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_164632-ug2a9ajm/logs
2022-06-16 17:14:54,398 - wandb.wandb_agent - INFO - Cleaning up finished run: ug2a9ajm
2022-06-16 17:14:54,972 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:14:54,973 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 17:14:54,980 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 17:14:59,993 - wandb.wandb_agent - INFO - Running runs: ['l0xv6dfc']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_171500-l0xv6dfc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-60
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/l0xv6dfc
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39717
wandb:    train_loss 1.06411
wandb: training_time 0.83352
wandb:        val_f1 0.426
wandb:      val_loss 1.05909
wandb: 
wandb: Synced easy-sweep-60: https://wandb.ai/jah377/sffMHA_pubmed/runs/l0xv6dfc
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_171500-l0xv6dfc/logs
2022-06-16 17:22:54,276 - wandb.wandb_agent - INFO - Cleaning up finished run: l0xv6dfc
2022-06-16 17:22:55,150 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:22:55,150 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 17:22:55,158 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 17:23:00,171 - wandb.wandb_agent - INFO - Running runs: ['fnht69in']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_172300-fnht69in
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-61
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/fnht69in
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.51249
wandb:    train_loss 1.07414
wandb: training_time 2.04319
wandb:        val_f1 0.52
wandb:      val_loss 1.07373
wandb: 
wandb: Synced twilight-sweep-61: https://wandb.ai/jah377/sffMHA_pubmed/runs/fnht69in
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_172300-fnht69in/logs
2022-06-16 17:39:23,771 - wandb.wandb_agent - INFO - Cleaning up finished run: fnht69in
2022-06-16 17:39:24,394 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:39:24,394 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 17:39:24,402 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 17:39:29,416 - wandb.wandb_agent - INFO - Running runs: ['nb3j05a4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_173929-nb3j05a4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-62
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/nb3j05a4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.002 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.64734
wandb:    train_loss 0.97466
wandb: training_time 0.82626
wandb:        val_f1 0.648
wandb:      val_loss 0.96691
wandb: 
wandb: Synced snowy-sweep-62: https://wandb.ai/jah377/sffMHA_pubmed/runs/nb3j05a4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_173929-nb3j05a4/logs
2022-06-16 17:47:34,359 - wandb.wandb_agent - INFO - Cleaning up finished run: nb3j05a4
2022-06-16 17:47:34,906 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:47:34,906 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 17:47:34,913 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 17:47:39,925 - wandb.wandb_agent - INFO - Running runs: ['uebhge28']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_174740-uebhge28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-63
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/uebhge28
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.28382
wandb:    train_loss 1.11374
wandb: training_time 0.78397
wandb:        val_f1 0.256
wandb:      val_loss 1.11831
wandb: 
wandb: Synced skilled-sweep-63: https://wandb.ai/jah377/sffMHA_pubmed/runs/uebhge28
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_174740-uebhge28/logs
2022-06-16 17:54:59,005 - wandb.wandb_agent - INFO - Cleaning up finished run: uebhge28
2022-06-16 17:54:59,548 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 17:54:59,549 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 17:54:59,556 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 17:55:04,569 - wandb.wandb_agent - INFO - Running runs: ['jx47f748']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_175504-jx47f748
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-64
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/jx47f748
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.68265
wandb:    train_loss 1.04692
wandb: training_time 0.58611
wandb:        val_f1 0.704
wandb:      val_loss 1.04591
wandb: 
wandb: Synced dashing-sweep-64: https://wandb.ai/jah377/sffMHA_pubmed/runs/jx47f748
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_175504-jx47f748/logs
2022-06-16 18:01:16,605 - wandb.wandb_agent - INFO - Cleaning up finished run: jx47f748
2022-06-16 18:01:17,128 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:01:17,129 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 18:01:17,136 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 18:01:22,150 - wandb.wandb_agent - INFO - Running runs: ['iobonucf']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_180122-iobonucf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-65
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/iobonucf
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39866
wandb:    train_loss 1.09707
wandb: training_time 0.72941
wandb:        val_f1 0.416
wandb:      val_loss 1.09642
wandb: 
wandb: Synced clean-sweep-65: https://wandb.ai/jah377/sffMHA_pubmed/runs/iobonucf
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_180122-iobonucf/logs
2022-06-16 18:08:46,867 - wandb.wandb_agent - INFO - Cleaning up finished run: iobonucf
2022-06-16 18:08:47,467 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:08:47,468 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 18:08:47,475 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 18:08:52,489 - wandb.wandb_agent - INFO - Running runs: ['6bts400u']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_180852-6bts400u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-66
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/6bts400u
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96457
wandb:    train_loss 0.11095
wandb: training_time 2.39471
wandb:        val_f1 0.92
wandb:      val_loss 0.23183
wandb: 
wandb: Synced balmy-sweep-66: https://wandb.ai/jah377/sffMHA_pubmed/runs/6bts400u
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_180852-6bts400u/logs
2022-06-16 18:26:20,147 - wandb.wandb_agent - INFO - Cleaning up finished run: 6bts400u
2022-06-16 18:26:20,762 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:26:20,762 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 256
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 18:26:20,769 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=256 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 18:26:25,781 - wandb.wandb_agent - INFO - Running runs: ['h284ic1m']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_182625-h284ic1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-67
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/h284ic1m
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 256, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 103
wandb:      train_f1 0.39838
wandb:    train_loss 1.07921
wandb: training_time 1.33168
wandb:        val_f1 0.416
wandb:      val_loss 1.07793
wandb: 
wandb: Synced leafy-sweep-67: https://wandb.ai/jah377/sffMHA_pubmed/runs/h284ic1m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_182625-h284ic1m/logs
2022-06-16 18:30:36,719 - wandb.wandb_agent - INFO - Cleaning up finished run: h284ic1m
2022-06-16 18:30:37,365 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:30:37,366 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 18:30:37,373 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 18:30:42,388 - wandb.wandb_agent - INFO - Running runs: ['3c1z1l1p']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_183042-3c1z1l1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-68
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/3c1z1l1p
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k2_dot_product_norm0_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.46237
wandb:    train_loss 1.07868
wandb: training_time 2.15222
wandb:        val_f1 0.452
wandb:      val_loss 1.07845
wandb: 
wandb: Synced crisp-sweep-68: https://wandb.ai/jah377/sffMHA_pubmed/runs/3c1z1l1p
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_183042-3c1z1l1p/logs
2022-06-16 18:48:05,767 - wandb.wandb_agent - INFO - Cleaning up finished run: 3c1z1l1p
2022-06-16 18:48:06,296 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:48:06,296 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 5
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 18:48:06,303 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=5 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 18:48:11,317 - wandb.wandb_agent - INFO - Running runs: ['quv4midl']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_184811-quv4midl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-69
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/quv4midl
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 5, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.26864
wandb:    train_loss 1.12539
wandb: training_time 0.8596
wandb:        val_f1 0.24
wandb:      val_loss 1.12737
wandb: 
wandb: Synced usual-sweep-69: https://wandb.ai/jah377/sffMHA_pubmed/runs/quv4midl
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_184811-quv4midl/logs
2022-06-16 18:55:52,476 - wandb.wandb_agent - INFO - Cleaning up finished run: quv4midl
2022-06-16 18:55:53,193 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 18:55:53,193 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 18:55:53,202 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 18:55:58,216 - wandb.wandb_agent - INFO - Running runs: ['ln4q7xjq']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_185558-ln4q7xjq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-70
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/ln4q7xjq
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.75653
wandb:    train_loss 0.95865
wandb: training_time 0.5579
wandb:        val_f1 0.732
wandb:      val_loss 0.95762
wandb: 
wandb: Synced dazzling-sweep-70: https://wandb.ai/jah377/sffMHA_pubmed/runs/ln4q7xjq
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_185558-ln4q7xjq/logs
2022-06-16 19:01:33,445 - wandb.wandb_agent - INFO - Cleaning up finished run: ln4q7xjq
2022-06-16 19:01:34,228 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:01:34,228 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 19:01:34,235 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 19:01:39,249 - wandb.wandb_agent - INFO - Running runs: ['flnxg041']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_190139-flnxg041
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-71
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/flnxg041
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.83599
wandb:    train_loss 0.51069
wandb: training_time 0.55834
wandb:        val_f1 0.868
wandb:      val_loss 0.49021
wandb: 
wandb: Synced sweepy-sweep-71: https://wandb.ai/jah377/sffMHA_pubmed/runs/flnxg041
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_190139-flnxg041/logs
2022-06-16 19:07:35,546 - wandb.wandb_agent - INFO - Cleaning up finished run: flnxg041
2022-06-16 19:07:36,192 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:07:36,193 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 19:07:36,202 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 19:07:41,216 - wandb.wandb_agent - INFO - Running runs: ['a8t5g9yh']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_190741-a8t5g9yh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-72
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/a8t5g9yh
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.86724
wandb:    train_loss 0.37939
wandb: training_time 1.05059
wandb:        val_f1 0.86
wandb:      val_loss 0.37515
wandb: 
wandb: Synced legendary-sweep-72: https://wandb.ai/jah377/sffMHA_pubmed/runs/a8t5g9yh
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_190741-a8t5g9yh/logs
2022-06-16 19:16:59,418 - wandb.wandb_agent - INFO - Cleaning up finished run: a8t5g9yh
2022-06-16 19:16:59,894 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:16:59,895 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 19:16:59,902 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 19:17:04,915 - wandb.wandb_agent - INFO - Running runs: ['n1lxszth']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_191704-n1lxszth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-73
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/n1lxszth
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39108
wandb:    train_loss 1.08714
wandb: training_time 0.41409
wandb:        val_f1 0.388
wandb:      val_loss 1.08596
wandb: 
wandb: Synced polar-sweep-73: https://wandb.ai/jah377/sffMHA_pubmed/runs/n1lxszth
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_191704-n1lxszth/logs
2022-06-16 19:21:43,970 - wandb.wandb_agent - INFO - Cleaning up finished run: n1lxszth
2022-06-16 19:21:45,179 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:21:45,179 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 512
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 19:21:45,187 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=512 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 19:21:50,200 - wandb.wandb_agent - INFO - Running runs: ['t4n5f3pr']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_192150-t4n5f3pr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-74
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/t4n5f3pr
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 512, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65179
wandb:    train_loss 1.00193
wandb: training_time 0.7668
wandb:        val_f1 0.652
wandb:      val_loss 0.99414
wandb: 
wandb: Synced eager-sweep-74: https://wandb.ai/jah377/sffMHA_pubmed/runs/t4n5f3pr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_192150-t4n5f3pr/logs
2022-06-16 19:29:04,317 - wandb.wandb_agent - INFO - Cleaning up finished run: t4n5f3pr
2022-06-16 19:29:05,314 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:29:05,315 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 19:29:05,323 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 19:29:10,333 - wandb.wandb_agent - INFO - Running runs: ['mwvqp80n']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_192910-mwvqp80n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-75
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/mwvqp80n
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
$$$ EARLY STOPPING TRIGGERED $$$
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 39
wandb:      train_f1 0.39827
wandb:    train_loss 1.08347
wandb: training_time 1.48123
wandb:        val_f1 0.416
wandb:      val_loss 1.08146
wandb: 
wandb: Synced dauntless-sweep-75: https://wandb.ai/jah377/sffMHA_pubmed/runs/mwvqp80n
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_192910-mwvqp80n/logs
2022-06-16 19:30:59,375 - wandb.wandb_agent - INFO - Cleaning up finished run: mwvqp80n
2022-06-16 19:31:00,138 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:31:00,138 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 3
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 19:31:00,145 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=3 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 19:31:05,159 - wandb.wandb_agent - INFO - Running runs: ['h6l8hzfg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_193105-h6l8hzfg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-76
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/h6l8hzfg
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 3, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39233
wandb:    train_loss 1.05042
wandb: training_time 3.37801
wandb:        val_f1 0.388
wandb:      val_loss 1.03411
wandb: 
wandb: Synced fast-sweep-76: https://wandb.ai/jah377/sffMHA_pubmed/runs/h6l8hzfg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_193105-h6l8hzfg/logs
2022-06-16 19:55:10,793 - wandb.wandb_agent - INFO - Cleaning up finished run: h6l8hzfg
2022-06-16 19:55:11,351 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 19:55:11,352 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 19:55:11,360 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 19:55:16,374 - wandb.wandb_agent - INFO - Running runs: ['wo8yiaks']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_195516-wo8yiaks
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-77
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/wo8yiaks
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k3_dot_product_norm1_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39178
wandb:    train_loss 1.0937
wandb: training_time 1.70109
wandb:        val_f1 0.388
wandb:      val_loss 1.09358
wandb: 
wandb: Synced noble-sweep-77: https://wandb.ai/jah377/sffMHA_pubmed/runs/wo8yiaks
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_195516-wo8yiaks/logs
2022-06-16 20:10:05,645 - wandb.wandb_agent - INFO - Cleaning up finished run: wo8yiaks
2022-06-16 20:10:06,182 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:10:06,183 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 20:10:06,189 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 20:10:11,204 - wandb.wandb_agent - INFO - Running runs: ['dc61ib6b']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_201011-dc61ib6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-78
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/dc61ib6b
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96094
wandb:    train_loss 0.11917
wandb: training_time 2.26732
wandb:        val_f1 0.912
wandb:      val_loss 0.27676
wandb: 
wandb: Synced soft-sweep-78: https://wandb.ai/jah377/sffMHA_pubmed/runs/dc61ib6b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_201011-dc61ib6b/logs
2022-06-16 20:28:23,259 - wandb.wandb_agent - INFO - Cleaning up finished run: dc61ib6b
2022-06-16 20:28:23,747 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:28:23,748 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 20:28:23,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 20:28:28,769 - wandb.wandb_agent - INFO - Running runs: ['4ycbzx6l']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_202828-4ycbzx6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-79
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/4ycbzx6l
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39849
wandb:    train_loss 1.08356
wandb: training_time 0.32313
wandb:        val_f1 0.416
wandb:      val_loss 1.08161
wandb: 
wandb: Synced woven-sweep-79: https://wandb.ai/jah377/sffMHA_pubmed/runs/4ycbzx6l
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_202828-4ycbzx6l/logs
2022-06-16 20:32:38,311 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ycbzx6l
2022-06-16 20:32:38,815 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:32:38,815 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 20:32:38,822 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
2022-06-16 20:32:43,833 - wandb.wandb_agent - INFO - Running runs: ['3ocbkbvg']
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_203243-3ocbkbvg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-80
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/3ocbkbvg
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.96594
wandb:    train_loss 0.12889
wandb: training_time 0.70158
wandb:        val_f1 0.912
wandb:      val_loss 0.22928
wandb: 
wandb: Synced prime-sweep-80: https://wandb.ai/jah377/sffMHA_pubmed/runs/3ocbkbvg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_203243-3ocbkbvg/logs
2022-06-16 20:39:45,128 - wandb.wandb_agent - INFO - Cleaning up finished run: 3ocbkbvg
2022-06-16 20:39:45,719 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:39:45,720 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.2
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 20:39:45,727 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.2 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 20:39:50,740 - wandb.wandb_agent - INFO - Running runs: ['cnaujw9r']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_203950-cnaujw9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-81
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/cnaujw9r
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.2, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.8739
wandb:    train_loss 0.35286
wandb: training_time 1.70279
wandb:        val_f1 0.868
wandb:      val_loss 0.35205
wandb: 
wandb: Synced swept-sweep-81: https://wandb.ai/jah377/sffMHA_pubmed/runs/cnaujw9r
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_203950-cnaujw9r/logs
2022-06-16 20:54:10,381 - wandb.wandb_agent - INFO - Cleaning up finished run: cnaujw9r
2022-06-16 20:54:10,965 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 20:54:10,965 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 2
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 20:54:10,972 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=2 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 20:54:15,986 - wandb.wandb_agent - INFO - Running runs: ['wk00481o']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_205416-wk00481o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-82
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/wk00481o
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.40988
wandb:    train_loss 1.08828
wandb: training_time 2.83589
wandb:        val_f1 0.408
wandb:      val_loss 1.09447
wandb: 
wandb: Synced olive-sweep-82: https://wandb.ai/jah377/sffMHA_pubmed/runs/wk00481o
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_205416-wk00481o/logs
2022-06-16 21:15:14,418 - wandb.wandb_agent - INFO - Cleaning up finished run: wk00481o
2022-06-16 21:15:15,006 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:15:15,006 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.01
2022-06-16 21:15:15,013 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.01
Using backend: pytorch
2022-06-16 21:15:20,027 - wandb.wandb_agent - INFO - Running runs: ['fdt0f74w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_211520-fdt0f74w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-83
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/fdt0f74w
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.01, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.85893
wandb:    train_loss 0.39677
wandb: training_time 2.56898
wandb:        val_f1 0.86
wandb:      val_loss 0.40538
wandb: 
wandb: Synced hopeful-sweep-83: https://wandb.ai/jah377/sffMHA_pubmed/runs/fdt0f74w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_211520-fdt0f74w/logs
2022-06-16 21:35:11,405 - wandb.wandb_agent - INFO - Cleaning up finished run: fdt0f74w
2022-06-16 21:35:12,091 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:35:12,091 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 21:35:12,098 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 21:35:17,109 - wandb.wandb_agent - INFO - Running runs: ['tw4qh9if']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_213517-tw4qh9if
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-84
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/tw4qh9if
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.58236
wandb:    train_loss 1.08209
wandb: training_time 1.26205
wandb:        val_f1 0.576
wandb:      val_loss 1.08157
wandb: 
wandb: Synced charmed-sweep-84: https://wandb.ai/jah377/sffMHA_pubmed/runs/tw4qh9if
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_213517-tw4qh9if/logs
2022-06-16 21:45:25,510 - wandb.wandb_agent - INFO - Cleaning up finished run: tw4qh9if
2022-06-16 21:45:26,101 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:45:26,101 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 21:45:26,109 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 21:45:31,123 - wandb.wandb_agent - INFO - Running runs: ['3e7gdz83']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_214531-3e7gdz83
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-85
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/3e7gdz83
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.87852
wandb:    train_loss 0.34413
wandb: training_time 1.4896
wandb:        val_f1 0.896
wandb:      val_loss 0.33426
wandb: 
wandb: Synced dry-sweep-85: https://wandb.ai/jah377/sffMHA_pubmed/runs/3e7gdz83
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_214531-3e7gdz83/logs
2022-06-16 21:57:42,599 - wandb.wandb_agent - INFO - Cleaning up finished run: 3e7gdz83
2022-06-16 21:57:43,126 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 21:57:43,127 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 21:57:43,134 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 21:57:48,145 - wandb.wandb_agent - INFO - Running runs: ['6qo5lgce']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_215748-6qo5lgce
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-86
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/6qo5lgce
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.90036
wandb:    train_loss 0.31337
wandb: training_time 0.79609
wandb:        val_f1 0.904
wandb:      val_loss 0.31666
wandb: 
wandb: Synced eager-sweep-86: https://wandb.ai/jah377/sffMHA_pubmed/runs/6qo5lgce
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_215748-6qo5lgce/logs
2022-06-16 22:05:16,509 - wandb.wandb_agent - INFO - Cleaning up finished run: 6qo5lgce
2022-06-16 22:05:17,040 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:05:17,040 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 0
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 22:05:17,048 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=0 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 22:05:22,062 - wandb.wandb_agent - INFO - Running runs: ['qsjw16vg']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_220522-qsjw16vg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-87
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/qsjw16vg
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k0_dot_product_norm0_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.2666
wandb:    train_loss 1.11768
wandb: training_time 0.35592
wandb:        val_f1 0.262
wandb:      val_loss 1.11802
wandb: 
wandb: Synced stellar-sweep-87: https://wandb.ai/jah377/sffMHA_pubmed/runs/qsjw16vg
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_220522-qsjw16vg/logs
2022-06-16 22:09:49,985 - wandb.wandb_agent - INFO - Cleaning up finished run: qsjw16vg
2022-06-16 22:09:50,831 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:09:50,831 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 22:09:50,839 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 22:09:55,853 - wandb.wandb_agent - INFO - Running runs: ['rn0ywan4']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_220955-rn0ywan4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-88
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/rn0ywan4
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.30562
wandb:    train_loss 1.10142
wandb: training_time 0.62117
wandb:        val_f1 0.358
wandb:      val_loss 1.10122
wandb: 
wandb: Synced dainty-sweep-88: https://wandb.ai/jah377/sffMHA_pubmed/runs/rn0ywan4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_220955-rn0ywan4/logs
2022-06-16 22:16:30,258 - wandb.wandb_agent - INFO - Cleaning up finished run: rn0ywan4
2022-06-16 22:16:30,778 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:16:30,779 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.0001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.1
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 22:16:30,786 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.0001 --LR_PATIENCE=5 --NODE_DROPOUT=0.1 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 22:16:35,800 - wandb.wandb_agent - INFO - Running runs: ['k3obgse9']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_221635-k3obgse9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-89
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/k3obgse9
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 0.0001, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.1, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}

TRANSFORMED FILE: data/pubmed_k4_dot_product_norm1_heads2.pth

wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97964
wandb:    train_loss 0.0696
wandb: training_time 2.16211
wandb:        val_f1 0.922
wandb:      val_loss 0.25436
wandb: 
wandb: Synced playful-sweep-89: https://wandb.ai/jah377/sffMHA_pubmed/runs/k3obgse9
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_221635-k3obgse9/logs
2022-06-16 22:34:15,562 - wandb.wandb_agent - INFO - Cleaning up finished run: k3obgse9
2022-06-16 22:34:18,773 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:34:18,773 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 22:34:18,782 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 22:34:23,793 - wandb.wandb_agent - INFO - Running runs: ['8j9cf82n']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_223423-8j9cf82n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-90
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/8j9cf82n
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.33197
wandb:    train_loss 1.11009
wandb: training_time 0.45598
wandb:        val_f1 0.334
wandb:      val_loss 1.11468
wandb: 
wandb: Synced comfy-sweep-90: https://wandb.ai/jah377/sffMHA_pubmed/runs/8j9cf82n
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_223423-8j9cf82n/logs
2022-06-16 22:39:38,310 - wandb.wandb_agent - INFO - Cleaning up finished run: 8j9cf82n
2022-06-16 22:39:40,597 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:39:40,597 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.5
	HOPS: 5
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.001
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.2
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.0001
2022-06-16 22:39:40,604 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.5 --HOPS=5 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.001 --LR_PATIENCE=5 --NODE_DROPOUT=0.2 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.0001
Using backend: pytorch
2022-06-16 22:39:45,619 - wandb.wandb_agent - INFO - Running runs: ['bbb8pl9w']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_223945-bbb8pl9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-91
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/bbb8pl9w
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 5, 'BATCH_SIZE': 256, 'LEARNING_RATE': 0.001, 'WEIGHT_DECAY': 0.0001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.5, 'NODE_DROPOUT': 0.2, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.95428
wandb:    train_loss 0.12324
wandb: training_time 0.83406
wandb:        val_f1 0.91
wandb:      val_loss 0.24225
wandb: 
wandb: Synced neat-sweep-91: https://wandb.ai/jah377/sffMHA_pubmed/runs/bbb8pl9w
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_223945-bbb8pl9w/logs
2022-06-16 22:47:35,897 - wandb.wandb_agent - INFO - Cleaning up finished run: bbb8pl9w
2022-06-16 22:47:36,368 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:47:36,368 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 0
	INCEPTION_LAYERS: 2
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.7
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 22:47:36,375 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=0 --INCEPTION_LAYERS=2 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.7 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 22:47:41,389 - wandb.wandb_agent - INFO - Running runs: ['bi0szf95']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_224741-bi0szf95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-sweep-92
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/bi0szf95
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 0, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 2, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.7, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.003 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39552
wandb:    train_loss 1.02466
wandb: training_time 0.74703
wandb:        val_f1 0.39
wandb:      val_loss 1.01244
wandb: 
wandb: Synced trim-sweep-92: https://wandb.ai/jah377/sffMHA_pubmed/runs/bi0szf95
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_224741-bi0szf95/logs
2022-06-16 22:54:28,494 - wandb.wandb_agent - INFO - Cleaning up finished run: bi0szf95
2022-06-16 22:54:30,036 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 22:54:30,037 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.4
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.3
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-05
2022-06-16 22:54:30,044 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.4 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.3 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-05
Using backend: pytorch
2022-06-16 22:54:35,059 - wandb.wandb_agent - INFO - Running runs: ['0r664uwv']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_225435-0r664uwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-93
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/0r664uwv
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1e-05, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.4, 'NODE_DROPOUT': 0.3, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.4
wandb:    train_loss 1.09067
wandb: training_time 0.47671
wandb:        val_f1 0.39
wandb:      val_loss 1.0931
wandb: 
wandb: Synced hardy-sweep-93: https://wandb.ai/jah377/sffMHA_pubmed/runs/0r664uwv
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_225435-0r664uwv/logs
2022-06-16 23:00:04,897 - wandb.wandb_agent - INFO - Cleaning up finished run: 0r664uwv
2022-06-16 23:00:05,428 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:00:05,429 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 512
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.7
	HOPS: 1
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 23:00:05,438 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=512 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.7 --HOPS=1 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 23:00:10,451 - wandb.wandb_agent - INFO - Running runs: ['1napiopw']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_230010-1napiopw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-94
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/1napiopw
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 1, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 512, 'FEATURE_DROPOUT': 0.7, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39183
wandb:    train_loss 1.08212
wandb: training_time 0.38619
wandb:        val_f1 0.402
wandb:      val_loss 1.07706
wandb: 
wandb: Synced kind-sweep-94: https://wandb.ai/jah377/sffMHA_pubmed/runs/1napiopw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_230010-1napiopw/logs
2022-06-16 23:04:38,680 - wandb.wandb_agent - INFO - Cleaning up finished run: 1napiopw
2022-06-16 23:04:39,180 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:04:39,181 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.1
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 23:04:39,189 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.1 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 23:04:44,204 - wandb.wandb_agent - INFO - Running runs: ['afvvk82s']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_230444-afvvk82s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-95
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/afvvk82s
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 128, 'LEARNING_RATE': 0.1, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39838
wandb:    train_loss 1.06415
wandb: training_time 1.42508
wandb:        val_f1 0.416
wandb:      val_loss 1.05757
wandb: 
wandb: Synced charmed-sweep-95: https://wandb.ai/jah377/sffMHA_pubmed/runs/afvvk82s
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_230444-afvvk82s/logs
2022-06-16 23:16:20,059 - wandb.wandb_agent - INFO - Cleaning up finished run: afvvk82s
2022-06-16 23:16:20,673 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:16:20,674 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 512
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.6
	HOPS: 3
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 128
	LEARNING_RATE: 1e-05
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.6
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.001
2022-06-16 23:16:20,681 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=512 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.6 --HOPS=3 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=128 --LEARNING_RATE=1e-05 --LR_PATIENCE=5 --NODE_DROPOUT=0.6 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.001
Using backend: pytorch
2022-06-16 23:16:25,695 - wandb.wandb_agent - INFO - Running runs: ['gi0zgr98']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_231625-gi0zgr98
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-96
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/gi0zgr98
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 3, 'BATCH_SIZE': 512, 'LEARNING_RATE': 1e-05, 'WEIGHT_DECAY': 0.001, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 128, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.6, 'NODE_DROPOUT': 0.6, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.78225
wandb:    train_loss 0.77767
wandb: training_time 0.44696
wandb:        val_f1 0.792
wandb:      val_loss 0.77356
wandb: 
wandb: Synced rural-sweep-96: https://wandb.ai/jah377/sffMHA_pubmed/runs/gi0zgr98
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_231625-gi0zgr98/logs
2022-06-16 23:21:39,869 - wandb.wandb_agent - INFO - Cleaning up finished run: gi0zgr98
2022-06-16 23:21:40,453 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:21:40,454 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 3
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 256
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 64
	DATASET: pubmed
	DPA_NORMALIZATION: 1
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-07
	LR_PATIENCE: 5
	NODE_DROPOUT: 0
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1
2022-06-16 23:21:40,461 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=3 --BATCH_NORMALIZATION=1 --BATCH_SIZE=256 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=64 --DATASET=pubmed --DPA_NORMALIZATION=1 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-07 --LR_PATIENCE=5 --NODE_DROPOUT=0 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1
Using backend: pytorch
2022-06-16 23:21:45,475 - wandb.wandb_agent - INFO - Running runs: ['pb0aqk3e']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_232145-pb0aqk3e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-97
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/pb0aqk3e
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 256, 'LEARNING_RATE': 1e-07, 'WEIGHT_DECAY': 1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 64, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 3, 'DPA_NORMALIZATION': 1, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.39305
wandb:    train_loss 1.10875
wandb: training_time 0.78702
wandb:        val_f1 0.372
wandb:      val_loss 1.11118
wandb: 
wandb: Synced legendary-sweep-97: https://wandb.ai/jah377/sffMHA_pubmed/runs/pb0aqk3e
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_232145-pb0aqk3e/logs
2022-06-16 23:29:34,367 - wandb.wandb_agent - INFO - Cleaning up finished run: pb0aqk3e
2022-06-16 23:29:34,883 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:29:34,883 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 128
	CLASSIFICATION_LAYERS: 2
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.3
	HOPS: 2
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.4
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 0.1
2022-06-16 23:29:34,890 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=128 --CLASSIFICATION_LAYERS=2 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.3 --HOPS=2 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.4 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=0.1
Using backend: pytorch
2022-06-16 23:29:39,904 - wandb.wandb_agent - INFO - Running runs: ['ayzh0f5j']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_232939-ayzh0f5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-98
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/ayzh0f5j
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 2, 'BATCH_SIZE': 128, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 0.1, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 2, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.3, 'NODE_DROPOUT': 0.4, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.82812
wandb:    train_loss 0.52166
wandb: training_time 1.25917
wandb:        val_f1 0.81
wandb:      val_loss 0.52937
wandb: 
wandb: Synced northern-sweep-98: https://wandb.ai/jah377/sffMHA_pubmed/runs/ayzh0f5j
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_232939-ayzh0f5j/logs
2022-06-16 23:39:22,396 - wandb.wandb_agent - INFO - Cleaning up finished run: ayzh0f5j
2022-06-16 23:39:22,908 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:39:22,909 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 1024
	CLASSIFICATION_LAYERS: 3
	CLASSIFICATION_UNITS: 256
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 0.01
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-06
2022-06-16 23:39:22,918 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=1024 --CLASSIFICATION_LAYERS=3 --CLASSIFICATION_UNITS=256 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=0.01 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-06
Using backend: pytorch
2022-06-16 23:39:27,932 - wandb.wandb_agent - INFO - Running runs: ['zrpzw60h']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_233928-zrpzw60h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-99
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/zrpzw60h
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 1024, 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 1e-06, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 3, 'CLASSIFICATION_UNITS': 256, 'FEATURE_DROPOUT': 0, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.97076
wandb:    train_loss 0.09283
wandb: training_time 0.44637
wandb:        val_f1 0.916
wandb:      val_loss 0.28881
wandb: 
wandb: Synced hopeful-sweep-99: https://wandb.ai/jah377/sffMHA_pubmed/runs/zrpzw60h
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_233928-zrpzw60h/logs
2022-06-16 23:44:26,502 - wandb.wandb_agent - INFO - Cleaning up finished run: zrpzw60h
2022-06-16 23:44:27,422 - wandb.wandb_agent - INFO - Agent received command: run
2022-06-16 23:44:27,423 - wandb.wandb_agent - INFO - Agent starting run with config:
	ATTN_HEADS: 2
	BATCH_NORMALIZATION: 1
	BATCH_SIZE: 64
	CLASSIFICATION_LAYERS: 1
	CLASSIFICATION_UNITS: 128
	DATASET: pubmed
	DPA_NORMALIZATION: 0
	EPOCHS: 300
	FEATURE_DROPOUT: 0.1
	HOPS: 4
	INCEPTION_LAYERS: 1
	INCEPTION_UNITS: 64
	LEARNING_RATE: 1e-06
	LR_PATIENCE: 5
	NODE_DROPOUT: 0.5
	SEED: 42
	TERMINATION_PATIENCE: 10
	TRANSFORMATION: dot_product
	WEIGHT_DECAY: 1e-07
2022-06-16 23:44:27,430 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python hps_SIGNff_DPA.py --ATTN_HEADS=2 --BATCH_NORMALIZATION=1 --BATCH_SIZE=64 --CLASSIFICATION_LAYERS=1 --CLASSIFICATION_UNITS=128 --DATASET=pubmed --DPA_NORMALIZATION=0 --EPOCHS=300 --FEATURE_DROPOUT=0.1 --HOPS=4 --INCEPTION_LAYERS=1 --INCEPTION_UNITS=64 --LEARNING_RATE=1e-06 --LR_PATIENCE=5 --NODE_DROPOUT=0.5 --SEED=42 --TERMINATION_PATIENCE=10 --TRANSFORMATION=dot_product --WEIGHT_DECAY=1e-07
Using backend: pytorch
2022-06-16 23:44:32,445 - wandb.wandb_agent - INFO - Running runs: ['fs2gtcdy']
wandb: Currently logged in as: jah377. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.12.18 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.16
wandb: Run data is saved locally in /scratch/sffMHA_pubmed/wandb/run-20220616_234432-fs2gtcdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-100
wandb:  View project at https://wandb.ai/jah377/sffMHA_pubmed
wandb:  View sweep at https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb:  View run at https://wandb.ai/jah377/sffMHA_pubmed/runs/fs2gtcdy
{'DATASET': 'pubmed', 'SEED': 42, 'EPOCHS': 300, 'HOPS': 4, 'BATCH_SIZE': 64, 'LEARNING_RATE': 1e-06, 'WEIGHT_DECAY': 1e-07, 'INCEPTION_LAYERS': 1, 'INCEPTION_UNITS': 64, 'CLASSIFICATION_LAYERS': 1, 'CLASSIFICATION_UNITS': 128, 'FEATURE_DROPOUT': 0.1, 'NODE_DROPOUT': 0.5, 'BATCH_NORMALIZATION': 1, 'ATTN_HEADS': 2, 'DPA_NORMALIZATION': 0, 'LR_PATIENCE': 5, 'TERMINATION_PATIENCE': 10, 'TRANSFORMATION': 'dot_product'}
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run summary:
wandb:         epoch 300
wandb:      train_f1 0.65443
wandb:    train_loss 0.97764
wandb: training_time 1.88819
wandb:        val_f1 0.668
wandb:      val_loss 0.96953
wandb: 
wandb: Synced balmy-sweep-100: https://wandb.ai/jah377/sffMHA_pubmed/runs/fs2gtcdy
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_234432-fs2gtcdy/logs
2022-06-16 23:59:55,416 - wandb.wandb_agent - INFO - Cleaning up finished run: fs2gtcdy
wandb: Terminating and syncing runs. Press ctrl-c to kill.
Create sweep with ID: 4qbzkios
Sweep URL: https://wandb.ai/jah377/sffMHA_pubmed/sweeps/4qbzkios
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: \ 0.001 MB of 0.001 MB uploaded (0.000 MB deduped)wandb: | 0.001 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: / 0.001 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: - 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: \ 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: | 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: / 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: - 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: \ 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: | 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: / 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb: - 0.268 MB of 0.268 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: Synced dashing-pine-93: https://wandb.ai/jah377/sffMHA_pubmed/runs/2q0itsmw
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220616_035207-2q0itsmw/logs
==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 20 hours 08 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
