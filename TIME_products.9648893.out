Mon 27 Jun 2022 05:42:51 PM CEST
r32n7.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
================= SIGN ===========================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='sign', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=True, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.4661
Epoch 10:, Train 0.9380, Val 0.9158, Test 0.7179
Epoch 20:, Train 0.9425, Val 0.9202, Test 0.7417
Epoch 30:, Train 0.9419, Val 0.9196, Test 0.7414
Epoch 40:, Train 0.9409, Val 0.9196, Test 0.7250
Epoch 50:, Train 0.9448, Val 0.9212, Test 0.7471
Epoch 60:, Train 0.9431, Val 0.9175, Test 0.7436
Epoch 70:, Train 0.9433, Val 0.9204, Test 0.7451
Epoch 80:, Train 0.9432, Val 0.9189, Test 0.7128
Epoch 90:, Train 0.9455, Val 0.9216, Test 0.7381
Epoch 100:, Train 0.9419, Val 0.9200, Test 0.7384
Epoch 110:, Train 0.9445, Val 0.9181, Test 0.7406
Epoch 120:, Train 0.9451, Val 0.9220, Test 0.7422
Epoch 130:, Train 0.9459, Val 0.9230, Test 0.7511
Epoch 140:, Train 0.9455, Val 0.9215, Test 0.7494
Epoch 150:, Train 0.9472, Val 0.9218, Test 0.7409
Epoch 160:, Train 0.9475, Val 0.9224, Test 0.7455
Epoch 170:, Train 0.9479, Val 0.9228, Test 0.7488
Epoch 180:, Train 0.9476, Val 0.9215, Test 0.7375
Epoch 190:, Train 0.9484, Val 0.9234, Test 0.7479
Epoch 200:, Train 0.9469, Val 0.9218, Test 0.7430
Epoch 210:, Train 0.9499, Val 0.9239, Test 0.7547
Epoch 220:, Train 0.9477, Val 0.9235, Test 0.7631
Epoch 230:, Train 0.9495, Val 0.9243, Test 0.7504
Epoch 240:, Train 0.9484, Val 0.9229, Test 0.7453
Epoch 250:, Train 0.9484, Val 0.9237, Test 0.7506
Epoch 260:, Train 0.9505, Val 0.9237, Test 0.7561
Epoch 270:, Train 0.9487, Val 0.9236, Test 0.7543
Epoch 280:, Train 0.9519, Val 0.9245, Test 0.7466
Epoch 290:, Train 0.9513, Val 0.9242, Test 0.7596
Epoch 300:, Train 0.9489, Val 0.9225, Test 0.7513
BEST: Epoch 280, Train 0.9519, Val 0.9245, Test 0.7466

RUN #1: seed=4
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.2399
Epoch 10:, Train 0.9351, Val 0.9161, Test 0.7566
Epoch 20:, Train 0.9408, Val 0.9169, Test 0.7417
Epoch 30:, Train 0.9423, Val 0.9200, Test 0.7393
Epoch 40:, Train 0.9434, Val 0.9199, Test 0.7426
Epoch 50:, Train 0.9427, Val 0.9185, Test 0.7448
Epoch 60:, Train 0.9438, Val 0.9198, Test 0.7228
Epoch 70:, Train 0.9421, Val 0.9170, Test 0.7345
Epoch 80:, Train 0.9441, Val 0.9216, Test 0.7485
Epoch 90:, Train 0.9443, Val 0.9194, Test 0.7299
Epoch 100:, Train 0.9437, Val 0.9196, Test 0.7399
Epoch 110:, Train 0.9470, Val 0.9225, Test 0.7337
Epoch 120:, Train 0.9464, Val 0.9225, Test 0.7432
Epoch 130:, Train 0.9472, Val 0.9210, Test 0.7600
Epoch 140:, Train 0.9464, Val 0.9205, Test 0.7388
Epoch 150:, Train 0.9404, Val 0.9160, Test 0.7345
Epoch 160:, Train 0.9484, Val 0.9215, Test 0.7551
Epoch 170:, Train 0.9479, Val 0.9208, Test 0.7717
Epoch 180:, Train 0.9475, Val 0.9223, Test 0.7455
Epoch 190:, Train 0.9474, Val 0.9231, Test 0.7439
Epoch 200:, Train 0.9479, Val 0.9243, Test 0.7534
Epoch 210:, Train 0.9483, Val 0.9240, Test 0.7488
Epoch 220:, Train 0.9484, Val 0.9226, Test 0.7511
Epoch 230:, Train 0.9494, Val 0.9234, Test 0.7578
Epoch 240:, Train 0.9496, Val 0.9222, Test 0.7554
Epoch 250:, Train 0.9492, Val 0.9233, Test 0.7550
Epoch 260:, Train 0.9472, Val 0.9233, Test 0.7488
Epoch 270:, Train 0.9496, Val 0.9251, Test 0.7637
Epoch 280:, Train 0.9502, Val 0.9240, Test 0.7506
Epoch 290:, Train 0.9503, Val 0.9222, Test 0.7509
Epoch 300:, Train 0.9494, Val 0.9245, Test 0.7393
BEST: Epoch 270, Train 0.9496, Val 0.9251, Test 0.7637

RUN #2: seed=8
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.6931
Epoch 10:, Train 0.9382, Val 0.9186, Test 0.7263
Epoch 20:, Train 0.9385, Val 0.9157, Test 0.7262
Epoch 30:, Train 0.9398, Val 0.9185, Test 0.7513
Epoch 40:, Train 0.9426, Val 0.9188, Test 0.7443
Epoch 50:, Train 0.9435, Val 0.9214, Test 0.7517
Epoch 60:, Train 0.9437, Val 0.9219, Test 0.7409
Epoch 70:, Train 0.9438, Val 0.9193, Test 0.7341
Epoch 80:, Train 0.9456, Val 0.9210, Test 0.7455
Epoch 90:, Train 0.9436, Val 0.9182, Test 0.7303
Epoch 100:, Train 0.9454, Val 0.9218, Test 0.7394
Epoch 110:, Train 0.9431, Val 0.9177, Test 0.7424
Epoch 120:, Train 0.9477, Val 0.9242, Test 0.7465
Epoch 130:, Train 0.9482, Val 0.9239, Test 0.7427
Epoch 140:, Train 0.9473, Val 0.9238, Test 0.7523
Epoch 150:, Train 0.9451, Val 0.9208, Test 0.7416
Epoch 160:, Train 0.9466, Val 0.9223, Test 0.7431
Epoch 170:, Train 0.9472, Val 0.9216, Test 0.7448
Epoch 180:, Train 0.9477, Val 0.9218, Test 0.7482
Epoch 190:, Train 0.9492, Val 0.9235, Test 0.7516
Epoch 200:, Train 0.9493, Val 0.9239, Test 0.7560
Epoch 210:, Train 0.9485, Val 0.9254, Test 0.7562
Epoch 220:, Train 0.9500, Val 0.9241, Test 0.7528
Epoch 230:, Train 0.9502, Val 0.9249, Test 0.7479
Epoch 240:, Train 0.9504, Val 0.9253, Test 0.7555
Epoch 250:, Train 0.9500, Val 0.9239, Test 0.7523
Epoch 260:, Train 0.9512, Val 0.9251, Test 0.7571
Epoch 270:, Train 0.9505, Val 0.9264, Test 0.7660
Epoch 280:, Train 0.9504, Val 0.9241, Test 0.7581
Epoch 290:, Train 0.9498, Val 0.9230, Test 0.7493
Epoch 300:, Train 0.9508, Val 0.9248, Test 0.7578
BEST: Epoch 270, Train 0.9505, Val 0.9264, Test 0.7660

RUN #3: seed=42
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.7005
Epoch 10:, Train 0.9363, Val 0.9168, Test 0.7479
Epoch 20:, Train 0.9396, Val 0.9192, Test 0.7425
Epoch 30:, Train 0.9401, Val 0.9180, Test 0.7516
Epoch 40:, Train 0.9436, Val 0.9212, Test 0.7415
Epoch 50:, Train 0.9438, Val 0.9222, Test 0.7460
Epoch 60:, Train 0.9436, Val 0.9190, Test 0.7350
Epoch 70:, Train 0.9435, Val 0.9189, Test 0.7523
Epoch 80:, Train 0.9465, Val 0.9214, Test 0.7411
Epoch 90:, Train 0.9420, Val 0.9164, Test 0.7293
Epoch 100:, Train 0.9465, Val 0.9223, Test 0.7455
Epoch 110:, Train 0.9445, Val 0.9201, Test 0.7285
Epoch 120:, Train 0.9471, Val 0.9222, Test 0.7416
Epoch 130:, Train 0.9471, Val 0.9223, Test 0.7456
Epoch 140:, Train 0.9444, Val 0.9179, Test 0.7199
Epoch 150:, Train 0.9462, Val 0.9228, Test 0.7421
Epoch 160:, Train 0.9483, Val 0.9233, Test 0.7509
Epoch 170:, Train 0.9473, Val 0.9230, Test 0.7574
Epoch 180:, Train 0.9486, Val 0.9246, Test 0.7560
Epoch 190:, Train 0.9485, Val 0.9226, Test 0.7476
Epoch 200:, Train 0.9498, Val 0.9245, Test 0.7473
Epoch 210:, Train 0.9487, Val 0.9235, Test 0.7594
Epoch 220:, Train 0.9505, Val 0.9235, Test 0.7468
Epoch 230:, Train 0.9494, Val 0.9230, Test 0.7674
Epoch 240:, Train 0.9512, Val 0.9238, Test 0.7483
Epoch 250:, Train 0.9507, Val 0.9247, Test 0.7456
Epoch 260:, Train 0.9488, Val 0.9242, Test 0.7627
Epoch 270:, Train 0.9500, Val 0.9246, Test 0.7511
Epoch 280:, Train 0.9494, Val 0.9240, Test 0.7468
Epoch 290:, Train 0.9491, Val 0.9231, Test 0.7476
Epoch 300:, Train 0.9507, Val 0.9242, Test 0.7600
BEST: Epoch 250, Train 0.9507, Val 0.9247, Test 0.7456

RUN #4: seed=64
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.4469
Epoch 10:, Train 0.9386, Val 0.9193, Test 0.7385
Epoch 20:, Train 0.9409, Val 0.9196, Test 0.7382
Epoch 30:, Train 0.9431, Val 0.9211, Test 0.7485
Epoch 40:, Train 0.9444, Val 0.9199, Test 0.7423
Epoch 50:, Train 0.9450, Val 0.9200, Test 0.7456
Epoch 60:, Train 0.9424, Val 0.9184, Test 0.7427
Epoch 70:, Train 0.9451, Val 0.9213, Test 0.7431
Epoch 80:, Train 0.9440, Val 0.9209, Test 0.7425
Epoch 90:, Train 0.9455, Val 0.9209, Test 0.7386
Epoch 100:, Train 0.9458, Val 0.9224, Test 0.7293
Epoch 110:, Train 0.9465, Val 0.9222, Test 0.7432
Epoch 120:, Train 0.9451, Val 0.9204, Test 0.7426
Epoch 130:, Train 0.9474, Val 0.9234, Test 0.7558
Epoch 140:, Train 0.9463, Val 0.9221, Test 0.7586
Epoch 150:, Train 0.9468, Val 0.9220, Test 0.7632
Epoch 160:, Train 0.9477, Val 0.9231, Test 0.7516
Epoch 170:, Train 0.9479, Val 0.9219, Test 0.7485
Epoch 180:, Train 0.9489, Val 0.9233, Test 0.7536
Epoch 190:, Train 0.9496, Val 0.9255, Test 0.7570
Epoch 200:, Train 0.9492, Val 0.9229, Test 0.7596
Epoch 210:, Train 0.9489, Val 0.9244, Test 0.7463
Epoch 220:, Train 0.9495, Val 0.9240, Test 0.7567
Epoch 230:, Train 0.9498, Val 0.9230, Test 0.7448
Epoch 240:, Train 0.9491, Val 0.9227, Test 0.7506
Epoch 250:, Train 0.9501, Val 0.9245, Test 0.7487
Epoch 260:, Train 0.9489, Val 0.9238, Test 0.7575
Epoch 270:, Train 0.9496, Val 0.9212, Test 0.7422
Epoch 280:, Train 0.9515, Val 0.9246, Test 0.7546
Epoch 290:, Train 0.9499, Val 0.9244, Test 0.7394
Epoch 300:, Train 0.9508, Val 0.9246, Test 0.7508
BEST: Epoch 190, Train 0.9496, Val 0.9255, Test 0.7570

RUN #5: seed=128
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 110.3491
Epoch 10:, Train 0.9387, Val 0.9192, Test 0.7380
Epoch 20:, Train 0.9432, Val 0.9221, Test 0.7422
Epoch 30:, Train 0.9418, Val 0.9206, Test 0.7376
Epoch 40:, Train 0.9409, Val 0.9180, Test 0.7109
Epoch 50:, Train 0.9451, Val 0.9215, Test 0.7426
Epoch 60:, Train 0.9430, Val 0.9202, Test 0.7357
Epoch 70:, Train 0.9428, Val 0.9198, Test 0.7317
Epoch 80:, Train 0.9448, Val 0.9241, Test 0.7390
Epoch 90:, Train 0.9445, Val 0.9197, Test 0.7488
Epoch 100:, Train 0.9455, Val 0.9205, Test 0.7374
Epoch 110:, Train 0.9455, Val 0.9216, Test 0.7580
Epoch 120:, Train 0.9472, Val 0.9209, Test 0.7396
Epoch 130:, Train 0.9461, Val 0.9201, Test 0.7471
Epoch 140:, Train 0.9457, Val 0.9207, Test 0.7455
Epoch 150:, Train 0.9481, Val 0.9226, Test 0.7566
Epoch 160:, Train 0.9483, Val 0.9235, Test 0.7412
Epoch 170:, Train 0.9492, Val 0.9223, Test 0.7523
Epoch 180:, Train 0.9485, Val 0.9237, Test 0.7506
Epoch 190:, Train 0.9489, Val 0.9238, Test 0.7487
Epoch 200:, Train 0.9493, Val 0.9238, Test 0.7508
Epoch 210:, Train 0.9482, Val 0.9222, Test 0.7413
Epoch 220:, Train 0.9499, Val 0.9233, Test 0.7475
Epoch 230:, Train 0.9493, Val 0.9224, Test 0.7377
Epoch 240:, Train 0.9500, Val 0.9249, Test 0.7495
Epoch 250:, Train 0.9486, Val 0.9215, Test 0.7576
Epoch 260:, Train 0.9501, Val 0.9235, Test 0.7513
Epoch 270:, Train 0.9507, Val 0.9246, Test 0.7486
Epoch 280:, Train 0.9498, Val 0.9230, Test 0.7507
Epoch 290:, Train 0.9494, Val 0.9207, Test 0.7585
Epoch 300:, Train 0.9500, Val 0.9239, Test 0.7466
BEST: Epoch 240, Train 0.9500, Val 0.9249, Test 0.7495

RUN #6: seed=256
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.5515
Epoch 10:, Train 0.9390, Val 0.9163, Test 0.7290
Epoch 20:, Train 0.9379, Val 0.9178, Test 0.7486
Epoch 30:, Train 0.9439, Val 0.9185, Test 0.7586
Epoch 40:, Train 0.9440, Val 0.9200, Test 0.7398
Epoch 50:, Train 0.9421, Val 0.9164, Test 0.7279
Epoch 60:, Train 0.9453, Val 0.9216, Test 0.7471
Epoch 70:, Train 0.9418, Val 0.9164, Test 0.7288
Epoch 80:, Train 0.9425, Val 0.9205, Test 0.7591
Epoch 90:, Train 0.9453, Val 0.9231, Test 0.7400
Epoch 100:, Train 0.9464, Val 0.9223, Test 0.7399
Epoch 110:, Train 0.9440, Val 0.9202, Test 0.7354
Epoch 120:, Train 0.9450, Val 0.9214, Test 0.7435
Epoch 130:, Train 0.9461, Val 0.9228, Test 0.7507
Epoch 140:, Train 0.9466, Val 0.9233, Test 0.7551
Epoch 150:, Train 0.9457, Val 0.9200, Test 0.7289
Epoch 160:, Train 0.9475, Val 0.9239, Test 0.7476
Epoch 170:, Train 0.9481, Val 0.9239, Test 0.7591
Epoch 180:, Train 0.9491, Val 0.9243, Test 0.7566
Epoch 190:, Train 0.9466, Val 0.9221, Test 0.7520
Epoch 200:, Train 0.9500, Val 0.9230, Test 0.7544
Epoch 210:, Train 0.9490, Val 0.9236, Test 0.7456
Epoch 220:, Train 0.9488, Val 0.9213, Test 0.7549
Epoch 230:, Train 0.9499, Val 0.9241, Test 0.7429
Epoch 240:, Train 0.9492, Val 0.9248, Test 0.7612
Epoch 250:, Train 0.9512, Val 0.9242, Test 0.7561
Epoch 260:, Train 0.9498, Val 0.9250, Test 0.7535
Epoch 270:, Train 0.9505, Val 0.9236, Test 0.7528
Epoch 280:, Train 0.9492, Val 0.9240, Test 0.7419
Epoch 290:, Train 0.9492, Val 0.9237, Test 0.7466
Epoch 300:, Train 0.9505, Val 0.9241, Test 0.7525
BEST: Epoch 260, Train 0.9498, Val 0.9250, Test 0.7535

RUN #7: seed=512
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.3315
Epoch 10:, Train 0.9376, Val 0.9169, Test 0.7321
Epoch 20:, Train 0.9405, Val 0.9191, Test 0.7658
Epoch 30:, Train 0.9409, Val 0.9177, Test 0.7360
Epoch 40:, Train 0.9392, Val 0.9159, Test 0.7451
Epoch 50:, Train 0.9450, Val 0.9214, Test 0.7370
Epoch 60:, Train 0.9447, Val 0.9195, Test 0.7429
Epoch 70:, Train 0.9441, Val 0.9214, Test 0.7472
Epoch 80:, Train 0.9455, Val 0.9223, Test 0.7653
Epoch 90:, Train 0.9451, Val 0.9226, Test 0.7394
Epoch 100:, Train 0.9458, Val 0.9213, Test 0.7373
Epoch 110:, Train 0.9448, Val 0.9210, Test 0.7439
Epoch 120:, Train 0.9463, Val 0.9215, Test 0.7417
Epoch 130:, Train 0.9449, Val 0.9211, Test 0.7545
Epoch 140:, Train 0.9477, Val 0.9221, Test 0.7507
Epoch 150:, Train 0.9478, Val 0.9221, Test 0.7343
Epoch 160:, Train 0.9475, Val 0.9229, Test 0.7409
Epoch 170:, Train 0.9454, Val 0.9199, Test 0.7309
Epoch 180:, Train 0.9474, Val 0.9231, Test 0.7535
Epoch 190:, Train 0.9496, Val 0.9236, Test 0.7525
Epoch 200:, Train 0.9486, Val 0.9248, Test 0.7528
Epoch 210:, Train 0.9489, Val 0.9244, Test 0.7488
Epoch 220:, Train 0.9504, Val 0.9246, Test 0.7493
Epoch 230:, Train 0.9478, Val 0.9227, Test 0.7584
Epoch 240:, Train 0.9496, Val 0.9239, Test 0.7577
Epoch 250:, Train 0.9490, Val 0.9248, Test 0.7446
Epoch 260:, Train 0.9495, Val 0.9238, Test 0.7558
Epoch 270:, Train 0.9501, Val 0.9231, Test 0.7460
Epoch 280:, Train 0.9507, Val 0.9233, Test 0.7499
Epoch 290:, Train 0.9492, Val 0.9228, Test 0.7439
Epoch 300:, Train 0.9494, Val 0.9233, Test 0.7409
BEST: Epoch 200, Train 0.9486, Val 0.9248, Test 0.7528

RUN #8: seed=1024
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.9806
Epoch 10:, Train 0.9364, Val 0.9167, Test 0.7189
Epoch 20:, Train 0.9406, Val 0.9175, Test 0.7371
Epoch 30:, Train 0.9454, Val 0.9215, Test 0.7381
Epoch 40:, Train 0.9452, Val 0.9226, Test 0.7323
Epoch 50:, Train 0.9445, Val 0.9199, Test 0.7390
Epoch 60:, Train 0.9452, Val 0.9210, Test 0.7358
Epoch 70:, Train 0.9411, Val 0.9167, Test 0.7357
Epoch 80:, Train 0.9451, Val 0.9216, Test 0.7437
Epoch 90:, Train 0.9441, Val 0.9227, Test 0.7394
Epoch 100:, Train 0.9460, Val 0.9203, Test 0.7377
Epoch 110:, Train 0.9442, Val 0.9185, Test 0.7243
Epoch 120:, Train 0.9436, Val 0.9190, Test 0.7272
Epoch 130:, Train 0.9469, Val 0.9233, Test 0.7399
Epoch 140:, Train 0.9475, Val 0.9223, Test 0.7428
Epoch 150:, Train 0.9454, Val 0.9212, Test 0.7423
Epoch 160:, Train 0.9480, Val 0.9242, Test 0.7431
Epoch 170:, Train 0.9487, Val 0.9236, Test 0.7526
Epoch 180:, Train 0.9470, Val 0.9224, Test 0.7471
Epoch 190:, Train 0.9490, Val 0.9228, Test 0.7506
Epoch 200:, Train 0.9478, Val 0.9240, Test 0.7552
Epoch 210:, Train 0.9488, Val 0.9231, Test 0.7593
Epoch 220:, Train 0.9484, Val 0.9229, Test 0.7519
Epoch 230:, Train 0.9497, Val 0.9256, Test 0.7533
Epoch 240:, Train 0.9489, Val 0.9246, Test 0.7635
Epoch 250:, Train 0.9501, Val 0.9248, Test 0.7600
Epoch 260:, Train 0.9501, Val 0.9241, Test 0.7530
Epoch 270:, Train 0.9494, Val 0.9231, Test 0.7492
Epoch 280:, Train 0.9505, Val 0.9247, Test 0.7513
Epoch 290:, Train 0.9495, Val 0.9241, Test 0.7588
Epoch 300:, Train 0.9500, Val 0.9235, Test 0.7476
BEST: Epoch 230, Train 0.9497, Val 0.9256, Test 0.7533

RUN #9: seed=2048
SIGN
Attention Filter (n=123718152): 1.000 +\- 0.001 [1.000-2.000]
Total Transformation Time: 109.6873
Epoch 10:, Train 0.9359, Val 0.9151, Test 0.7237
Epoch 20:, Train 0.9431, Val 0.9204, Test 0.7393
Epoch 30:, Train 0.9418, Val 0.9199, Test 0.7405
Epoch 40:, Train 0.9423, Val 0.9210, Test 0.7501
Epoch 50:, Train 0.9429, Val 0.9196, Test 0.7265
Epoch 60:, Train 0.9426, Val 0.9193, Test 0.7401
Epoch 70:, Train 0.9426, Val 0.9192, Test 0.7445
Epoch 80:, Train 0.9452, Val 0.9229, Test 0.7461
Epoch 90:, Train 0.9446, Val 0.9205, Test 0.7225
Epoch 100:, Train 0.9471, Val 0.9212, Test 0.7463
Epoch 110:, Train 0.9451, Val 0.9219, Test 0.7457
Epoch 120:, Train 0.9459, Val 0.9207, Test 0.7439
Epoch 130:, Train 0.9469, Val 0.9219, Test 0.7529
Epoch 140:, Train 0.9473, Val 0.9218, Test 0.7494
Epoch 150:, Train 0.9476, Val 0.9226, Test 0.7539
Epoch 160:, Train 0.9473, Val 0.9195, Test 0.7386
Epoch 170:, Train 0.9475, Val 0.9244, Test 0.7468
Epoch 180:, Train 0.9483, Val 0.9240, Test 0.7563
Epoch 190:, Train 0.9501, Val 0.9239, Test 0.7415
Epoch 200:, Train 0.9496, Val 0.9243, Test 0.7480
Epoch 210:, Train 0.9480, Val 0.9222, Test 0.7516
Epoch 220:, Train 0.9488, Val 0.9240, Test 0.7502
Epoch 230:, Train 0.9488, Val 0.9223, Test 0.7423
Epoch 240:, Train 0.9492, Val 0.9228, Test 0.7461
Epoch 250:, Train 0.9496, Val 0.9257, Test 0.7428
Epoch 260:, Train 0.9489, Val 0.9238, Test 0.7596
Epoch 270:, Train 0.9495, Val 0.9234, Test 0.7454
Epoch 280:, Train 0.9514, Val 0.9230, Test 0.7559
Epoch 290:, Train 0.9495, Val 0.9233, Test 0.7540
Epoch 300:, Train 0.9500, Val 0.9228, Test 0.7504
BEST: Epoch 250, Train 0.9496, Val 0.9257, Test 0.7428




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 0.0000 +/- 0.0000
Avg. Preaggregation Time (s): 109.6446 +/- 0.3095
Avg. Training Time (epoch) (s): 4.5343 +/- 3.5985
Avg. Inference Time (s): 1.3197 +/- 0.0163

Avg. Training Acc: 0.9500 +/- 0.0008
Avg. Validation Acc: 0.9252 +/- 0.0005
Avg. Test Acc: 0.7531 +/- 0.0072

==================================================

==================================================
================= SIGN+CS ========================
==================================================
Using backend: pytorch
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='cosine', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.67e-05
convert to csr_matrix: 2.938
calc min-max per row: 0.7552
vectorization: 1.769
Total Normalization: 6.9958
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 263.3105
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #1: seed=4
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.575e-05
convert to csr_matrix: 2.695
calc min-max per row: 0.7567
vectorization: 1.764
Total Normalization: 6.7613
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 263.7026
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #2: seed=8
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.027e-05
convert to csr_matrix: 2.7
calc min-max per row: 0.7312
vectorization: 1.764
Total Normalization: 6.7305
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 263.0519
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #3: seed=42
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.694e-05
convert to csr_matrix: 2.715
calc min-max per row: 0.7542
vectorization: 1.763
Total Normalization: 6.7544
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 244.4531
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #4: seed=64
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.718e-05
convert to csr_matrix: 2.708
calc min-max per row: 0.755
vectorization: 1.767
Total Normalization: 6.7684
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 244.2333
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #5: seed=128
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.646e-05
convert to csr_matrix: 2.7
calc min-max per row: 0.765
vectorization: 1.76
Total Normalization: 6.7690
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 245.7401
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #6: seed=256
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 1.955e-05
convert to csr_matrix: 2.684
calc min-max per row: 0.7371
vectorization: 1.761
Total Normalization: 6.6878
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 255.3524
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #7: seed=512
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.694e-05
convert to csr_matrix: 2.694
calc min-max per row: 0.7525
vectorization: 1.759
Total Normalization: 6.7152
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 259.7513
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #8: seed=1024
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.05e-05
convert to csr_matrix: 2.678
calc min-max per row: 0.7375
vectorization: 1.754
Total Normalization: 6.6633
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 260.0624
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
/scratch/TIME_products/utils.py:147: RuntimeWarning: divide by zero encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
/scratch/TIME_products/utils.py:147: RuntimeWarning: invalid value encountered in true_divide
  value=torch.tensor((v-min_m)/(max_m-min_m)),
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455

RUN #9: seed=2048
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.21465368568897247
coalesce scoo: 2.456e-05
convert to csr_matrix: 2.686
calc min-max per row: 0.7541
vectorization: 1.76
Total Normalization: 6.7072
COSINE
Attention Filter (n=122799606): nan +\- nan [nan-nan]
Total Transformation Time: 242.0821
Epoch 10:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 20:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 30:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 40:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 50:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 60:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 70:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 80:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 90:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 100:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 110:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 120:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 130:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 140:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 150:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 160:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 170:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 180:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 190:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 200:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 210:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 220:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 230:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 240:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 250:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 260:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 270:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 280:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 290:, Train 0.0576, Val 0.0583, Test 0.0455
Epoch 300:, Train 0.0576, Val 0.0583, Test 0.0455
BEST: Epoch 10, Train 0.0576, Val 0.0583, Test 0.0455




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 145.0249 +/- 8.7832
Avg. Preaggregation Time (s): 254.1740 +/- 8.5493
Avg. Training Time (epoch) (s): 4.2642 +/- 0.0583
Avg. Inference Time (s): 1.3178 +/- 0.0186

Avg. Training Acc: 0.0576 +/- 0.0000
Avg. Validation Acc: 0.0583 +/- 0.0000
Avg. Test Acc: 0.0455 +/- 0.0000

==================================================

==================================================
================= SIGN+SHA =======================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0003807349130511284
coalesce scoo: 1.645e-05
convert to csr_matrix: 2.684
calc min-max per row: 0.7302
vectorization: 1.751
Normalization Time: 6.6835
DOT_PRODUCT
Attention Filter (n=122947251): 0.151 +\- 0.234 [0.000-1.000]
Total Transformation Time: 215.7212
Epoch 10:, Train 0.9038, Val 0.8804, Test 0.7046
Epoch 20:, Train 0.9241, Val 0.8929, Test 0.7349
Epoch 30:, Train 0.9235, Val 0.8918, Test 0.7350
Epoch 40:, Train 0.9239, Val 0.8899, Test 0.7322
Epoch 50:, Train 0.9274, Val 0.8958, Test 0.7337
Epoch 60:, Train 0.9266, Val 0.8925, Test 0.7353
Epoch 70:, Train 0.9348, Val 0.9005, Test 0.7410
Epoch 80:, Train 0.9281, Val 0.8922, Test 0.7348
Epoch 90:, Train 0.9323, Val 0.8967, Test 0.7349
Epoch 100:, Train 0.9367, Val 0.8989, Test 0.7473
Epoch 110:, Train 0.9322, Val 0.8945, Test 0.7400
Epoch 120:, Train 0.9308, Val 0.8953, Test 0.7299
Epoch 130:, Train 0.9311, Val 0.8914, Test 0.7335
Epoch 140:, Train 0.9343, Val 0.8967, Test 0.7490
Epoch 150:, Train 0.9338, Val 0.8979, Test 0.7489
Epoch 160:, Train 0.9321, Val 0.8957, Test 0.7377
Epoch 170:, Train 0.9367, Val 0.8961, Test 0.7455
Epoch 180:, Train 0.9338, Val 0.8964, Test 0.7353
Epoch 190:, Train 0.9305, Val 0.8927, Test 0.7437
Epoch 200:, Train 0.9290, Val 0.8919, Test 0.7353
Epoch 210:, Train 0.9354, Val 0.8995, Test 0.7438
Epoch 220:, Train 0.9363, Val 0.8957, Test 0.7423
Epoch 230:, Train 0.9355, Val 0.8987, Test 0.7441
Epoch 240:, Train 0.9369, Val 0.8990, Test 0.7441
Epoch 250:, Train 0.9370, Val 0.9002, Test 0.7439
Epoch 260:, Train 0.9298, Val 0.8903, Test 0.7209
Epoch 270:, Train 0.9369, Val 0.9000, Test 0.7413
Epoch 280:, Train 0.9361, Val 0.8978, Test 0.7358
Epoch 290:, Train 0.9347, Val 0.8989, Test 0.7430
Epoch 300:, Train 0.9357, Val 0.8954, Test 0.7441
BEST: Epoch 70, Train 0.9348, Val 0.9005, Test 0.7410

RUN #1: seed=4
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004695733543485403
coalesce scoo: 1.669e-05
convert to csr_matrix: 2.677
calc min-max per row: 0.7505
vectorization: 1.76
Normalization Time: 6.7025
DOT_PRODUCT
Attention Filter (n=122825229): 0.152 +\- 0.232 [0.000-1.000]
Total Transformation Time: 218.9751
Epoch 10:, Train 0.9064, Val 0.8827, Test 0.7174
Epoch 20:, Train 0.9175, Val 0.8879, Test 0.7231
Epoch 30:, Train 0.9245, Val 0.8937, Test 0.7314
Epoch 40:, Train 0.9267, Val 0.8948, Test 0.7362
Epoch 50:, Train 0.9282, Val 0.8948, Test 0.7428
Epoch 60:, Train 0.9317, Val 0.8957, Test 0.7459
Epoch 70:, Train 0.9325, Val 0.8953, Test 0.7478
Epoch 80:, Train 0.9317, Val 0.8971, Test 0.7421
Epoch 90:, Train 0.9321, Val 0.8954, Test 0.7445
Epoch 100:, Train 0.9325, Val 0.8953, Test 0.7417
Epoch 110:, Train 0.9354, Val 0.8993, Test 0.7541
Epoch 120:, Train 0.9274, Val 0.8909, Test 0.7394
Epoch 130:, Train 0.9327, Val 0.8942, Test 0.7432
Epoch 140:, Train 0.9371, Val 0.8997, Test 0.7437
Epoch 150:, Train 0.9329, Val 0.8958, Test 0.7423
Epoch 160:, Train 0.9372, Val 0.9000, Test 0.7444
Epoch 170:, Train 0.9362, Val 0.8973, Test 0.7482
Epoch 180:, Train 0.9348, Val 0.8969, Test 0.7483
Epoch 190:, Train 0.9369, Val 0.9005, Test 0.7512
Epoch 200:, Train 0.9375, Val 0.9001, Test 0.7513
Epoch 210:, Train 0.9349, Val 0.8968, Test 0.7500
Epoch 220:, Train 0.9356, Val 0.8975, Test 0.7494
Epoch 230:, Train 0.9363, Val 0.8966, Test 0.7455
Epoch 240:, Train 0.9302, Val 0.8927, Test 0.7404
Epoch 250:, Train 0.9371, Val 0.8971, Test 0.7440
Epoch 260:, Train 0.9354, Val 0.8960, Test 0.7413
Epoch 270:, Train 0.9329, Val 0.8935, Test 0.7386
Epoch 280:, Train 0.9375, Val 0.8983, Test 0.7514
Epoch 290:, Train 0.9385, Val 0.9005, Test 0.7470
Epoch 300:, Train 0.9370, Val 0.8991, Test 0.7455
BEST: Epoch 190, Train 0.9369, Val 0.9005, Test 0.7512

RUN #2: seed=8
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0016792048700153828
coalesce scoo: 1.717e-05
convert to csr_matrix: 2.682
calc min-max per row: 0.7249
vectorization: 1.752
Normalization Time: 6.6484
DOT_PRODUCT
Attention Filter (n=123020289): 0.147 +\- 0.229 [0.000-1.000]
Total Transformation Time: 212.6680
Epoch 10:, Train 0.9130, Val 0.8886, Test 0.7251
Epoch 20:, Train 0.9235, Val 0.8939, Test 0.7355
Epoch 30:, Train 0.9247, Val 0.8927, Test 0.7283
Epoch 40:, Train 0.9190, Val 0.8858, Test 0.7328
Epoch 50:, Train 0.9262, Val 0.8936, Test 0.7313
Epoch 60:, Train 0.9326, Val 0.8975, Test 0.7476
Epoch 70:, Train 0.9305, Val 0.8932, Test 0.7387
Epoch 80:, Train 0.9338, Val 0.8993, Test 0.7456
Epoch 90:, Train 0.9223, Val 0.8871, Test 0.7289
Epoch 100:, Train 0.9248, Val 0.8906, Test 0.7363
Epoch 110:, Train 0.9313, Val 0.8923, Test 0.7369
Epoch 120:, Train 0.9285, Val 0.8899, Test 0.7248
Epoch 130:, Train 0.9317, Val 0.8967, Test 0.7415
Epoch 140:, Train 0.9315, Val 0.8925, Test 0.7398
Epoch 150:, Train 0.9347, Val 0.8982, Test 0.7430
Epoch 160:, Train 0.9352, Val 0.8979, Test 0.7409
Epoch 170:, Train 0.9333, Val 0.8966, Test 0.7477
Epoch 180:, Train 0.9341, Val 0.8955, Test 0.7376
Epoch 190:, Train 0.9328, Val 0.8949, Test 0.7326
Epoch 200:, Train 0.9318, Val 0.8941, Test 0.7450
Epoch 210:, Train 0.9331, Val 0.8950, Test 0.7395
Epoch 220:, Train 0.9321, Val 0.8960, Test 0.7383
Epoch 230:, Train 0.9371, Val 0.8997, Test 0.7441
Epoch 240:, Train 0.9372, Val 0.8990, Test 0.7436
Epoch 250:, Train 0.9307, Val 0.8928, Test 0.7390
Epoch 260:, Train 0.9354, Val 0.8970, Test 0.7381
Epoch 270:, Train 0.9311, Val 0.8933, Test 0.7387
Epoch 280:, Train 0.9373, Val 0.8982, Test 0.7430
Epoch 290:, Train 0.9334, Val 0.8945, Test 0.7369
Epoch 300:, Train 0.9352, Val 0.8965, Test 0.7478
BEST: Epoch 230, Train 0.9371, Val 0.8997, Test 0.7441

RUN #3: seed=42
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0031600971706211567
coalesce scoo: 1.669e-05
convert to csr_matrix: 2.697
calc min-max per row: 0.747
vectorization: 1.767
Normalization Time: 6.7257
DOT_PRODUCT
Attention Filter (n=123001819): 0.148 +\- 0.229 [0.000-1.000]
Total Transformation Time: 206.6038
Epoch 10:, Train 0.9121, Val 0.8864, Test 0.7266
Epoch 20:, Train 0.9216, Val 0.8937, Test 0.7262
Epoch 30:, Train 0.9248, Val 0.8940, Test 0.7276
Epoch 40:, Train 0.9308, Val 0.8980, Test 0.7363
Epoch 50:, Train 0.9284, Val 0.8944, Test 0.7316
Epoch 60:, Train 0.9278, Val 0.8938, Test 0.7365
Epoch 70:, Train 0.9315, Val 0.8956, Test 0.7431
Epoch 80:, Train 0.9264, Val 0.8916, Test 0.7256
Epoch 90:, Train 0.9323, Val 0.8970, Test 0.7394
Epoch 100:, Train 0.9261, Val 0.8899, Test 0.7350
Epoch 110:, Train 0.9377, Val 0.8989, Test 0.7455
Epoch 120:, Train 0.9278, Val 0.8916, Test 0.7346
Epoch 130:, Train 0.9317, Val 0.8933, Test 0.7326
Epoch 140:, Train 0.9343, Val 0.8987, Test 0.7376
Epoch 150:, Train 0.9331, Val 0.8966, Test 0.7448
Epoch 160:, Train 0.9362, Val 0.9007, Test 0.7465
Epoch 170:, Train 0.9366, Val 0.8993, Test 0.7493
Epoch 180:, Train 0.9331, Val 0.8932, Test 0.7414
Epoch 190:, Train 0.9302, Val 0.8914, Test 0.7393
Epoch 200:, Train 0.9371, Val 0.8981, Test 0.7478
Epoch 210:, Train 0.9316, Val 0.8947, Test 0.7387
Epoch 220:, Train 0.9307, Val 0.8925, Test 0.7398
Epoch 230:, Train 0.9369, Val 0.9003, Test 0.7435
Epoch 240:, Train 0.9357, Val 0.8975, Test 0.7457
Epoch 250:, Train 0.9371, Val 0.8985, Test 0.7430
Epoch 260:, Train 0.9378, Val 0.8980, Test 0.7493
Epoch 270:, Train 0.9355, Val 0.8985, Test 0.7339
Epoch 280:, Train 0.9384, Val 0.9003, Test 0.7423
Epoch 290:, Train 0.9384, Val 0.9018, Test 0.7508
Epoch 300:, Train 0.9384, Val 0.9007, Test 0.7484
BEST: Epoch 290, Train 0.9384, Val 0.9018, Test 0.7508

RUN #4: seed=64
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004785676021128893
coalesce scoo: 1.502e-05
convert to csr_matrix: 2.484
calc min-max per row: 0.7467
vectorization: 1.567
Normalization Time: 6.7336
DOT_PRODUCT
Attention Filter (n=123009438): 0.151 +\- 0.234 [0.000-1.000]
Total Transformation Time: 207.1019
Epoch 10:, Train 0.9138, Val 0.8854, Test 0.7248
Epoch 20:, Train 0.9218, Val 0.8908, Test 0.7364
Epoch 30:, Train 0.9230, Val 0.8898, Test 0.7287
Epoch 40:, Train 0.9256, Val 0.8903, Test 0.7302
Epoch 50:, Train 0.9293, Val 0.8924, Test 0.7479
Epoch 60:, Train 0.9280, Val 0.8922, Test 0.7384
Epoch 70:, Train 0.9295, Val 0.8915, Test 0.7293
Epoch 80:, Train 0.9261, Val 0.8882, Test 0.7277
Epoch 90:, Train 0.9291, Val 0.8915, Test 0.7287
Epoch 100:, Train 0.9303, Val 0.8934, Test 0.7347
Epoch 110:, Train 0.9343, Val 0.8970, Test 0.7475
Epoch 120:, Train 0.9358, Val 0.8964, Test 0.7342
Epoch 130:, Train 0.9269, Val 0.8869, Test 0.7313
Epoch 140:, Train 0.9342, Val 0.8937, Test 0.7476
Epoch 150:, Train 0.9387, Val 0.8977, Test 0.7429
Epoch 160:, Train 0.9338, Val 0.8952, Test 0.7398
Epoch 170:, Train 0.9352, Val 0.8933, Test 0.7358
Epoch 180:, Train 0.9358, Val 0.8942, Test 0.7402
Epoch 190:, Train 0.9367, Val 0.8978, Test 0.7427
Epoch 200:, Train 0.9386, Val 0.8983, Test 0.7487
Epoch 210:, Train 0.9361, Val 0.8944, Test 0.7344
Epoch 220:, Train 0.9354, Val 0.8945, Test 0.7399
Epoch 230:, Train 0.9355, Val 0.8943, Test 0.7343
Epoch 240:, Train 0.9354, Val 0.8952, Test 0.7410
Epoch 250:, Train 0.9376, Val 0.8965, Test 0.7426
Epoch 260:, Train 0.9377, Val 0.8976, Test 0.7481
Epoch 270:, Train 0.9302, Val 0.8899, Test 0.7366
Epoch 280:, Train 0.9321, Val 0.8908, Test 0.7385
Epoch 290:, Train 0.9386, Val 0.8987, Test 0.7531
Epoch 300:, Train 0.9341, Val 0.8918, Test 0.7296
BEST: Epoch 290, Train 0.9386, Val 0.8987, Test 0.7531

RUN #5: seed=128
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00019998301286250353
coalesce scoo: 1.597e-05
convert to csr_matrix: 2.703
calc min-max per row: 0.7485
vectorization: 1.753
Normalization Time: 6.7358
DOT_PRODUCT
Attention Filter (n=122841277): 0.151 +\- 0.233 [0.000-1.000]
Total Transformation Time: 206.0009
Epoch 10:, Train 0.9040, Val 0.8750, Test 0.7011
Epoch 20:, Train 0.9110, Val 0.8814, Test 0.7096
Epoch 30:, Train 0.9203, Val 0.8889, Test 0.7244
Epoch 40:, Train 0.9188, Val 0.8873, Test 0.7306
Epoch 50:, Train 0.9230, Val 0.8914, Test 0.7346
Epoch 60:, Train 0.9235, Val 0.8913, Test 0.7297
Epoch 70:, Train 0.9280, Val 0.8949, Test 0.7252
Epoch 80:, Train 0.9287, Val 0.8916, Test 0.7397
Epoch 90:, Train 0.9318, Val 0.8973, Test 0.7355
Epoch 100:, Train 0.9331, Val 0.8964, Test 0.7363
Epoch 110:, Train 0.9275, Val 0.8935, Test 0.7318
Epoch 120:, Train 0.9339, Val 0.8956, Test 0.7348
Epoch 130:, Train 0.9324, Val 0.8974, Test 0.7422
Epoch 140:, Train 0.9348, Val 0.9013, Test 0.7403
Epoch 150:, Train 0.9324, Val 0.8958, Test 0.7374
Epoch 160:, Train 0.9366, Val 0.9006, Test 0.7512
Epoch 170:, Train 0.9323, Val 0.8939, Test 0.7287
Epoch 180:, Train 0.9328, Val 0.8946, Test 0.7228
Epoch 190:, Train 0.9331, Val 0.8965, Test 0.7339
Epoch 200:, Train 0.9314, Val 0.8947, Test 0.7327
Epoch 210:, Train 0.9355, Val 0.8975, Test 0.7442
Epoch 220:, Train 0.9334, Val 0.8968, Test 0.7373
Epoch 230:, Train 0.9262, Val 0.8922, Test 0.7211
Epoch 240:, Train 0.9359, Val 0.8987, Test 0.7346
Epoch 250:, Train 0.9280, Val 0.8926, Test 0.7265
Epoch 260:, Train 0.9370, Val 0.8977, Test 0.7385
Epoch 270:, Train 0.9309, Val 0.8932, Test 0.7325
Epoch 280:, Train 0.9337, Val 0.8946, Test 0.7394
Epoch 290:, Train 0.9350, Val 0.9001, Test 0.7459
Epoch 300:, Train 0.9342, Val 0.8962, Test 0.7351
BEST: Epoch 140, Train 0.9348, Val 0.9013, Test 0.7403

RUN #6: seed=256
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0025518205948174
coalesce scoo: 1.502e-05
convert to csr_matrix: 2.481
calc min-max per row: 0.7299
vectorization: 1.556
Normalization Time: 6.2676
DOT_PRODUCT
Attention Filter (n=123037660): 0.162 +\- 0.240 [0.000-1.000]
Total Transformation Time: 211.2971
Epoch 10:, Train 0.9111, Val 0.8852, Test 0.7204
Epoch 20:, Train 0.9224, Val 0.8932, Test 0.7213
Epoch 30:, Train 0.9265, Val 0.8957, Test 0.7345
Epoch 40:, Train 0.9253, Val 0.8911, Test 0.7336
Epoch 50:, Train 0.9288, Val 0.8941, Test 0.7403
Epoch 60:, Train 0.9296, Val 0.8958, Test 0.7478
Epoch 70:, Train 0.9306, Val 0.8933, Test 0.7348
Epoch 80:, Train 0.9349, Val 0.8989, Test 0.7441
Epoch 90:, Train 0.9370, Val 0.8993, Test 0.7479
Epoch 100:, Train 0.9351, Val 0.8974, Test 0.7429
Epoch 110:, Train 0.9350, Val 0.8992, Test 0.7442
Epoch 120:, Train 0.9369, Val 0.8999, Test 0.7446
Epoch 130:, Train 0.9384, Val 0.9007, Test 0.7441
Epoch 140:, Train 0.9357, Val 0.8977, Test 0.7442
Epoch 150:, Train 0.9345, Val 0.8954, Test 0.7381
Epoch 160:, Train 0.9377, Val 0.8994, Test 0.7391
Epoch 170:, Train 0.9387, Val 0.8988, Test 0.7506
Epoch 180:, Train 0.9364, Val 0.8954, Test 0.7419
Epoch 190:, Train 0.9333, Val 0.8940, Test 0.7356
Epoch 200:, Train 0.9387, Val 0.8990, Test 0.7467
Epoch 210:, Train 0.9365, Val 0.9006, Test 0.7505
Epoch 220:, Train 0.9379, Val 0.8987, Test 0.7420
Epoch 230:, Train 0.9368, Val 0.8976, Test 0.7463
Epoch 240:, Train 0.9393, Val 0.8979, Test 0.7381
Epoch 250:, Train 0.9381, Val 0.8986, Test 0.7411
Epoch 260:, Train 0.9355, Val 0.8975, Test 0.7427
Epoch 270:, Train 0.9315, Val 0.8951, Test 0.7410
Epoch 280:, Train 0.9376, Val 0.8974, Test 0.7450
Epoch 290:, Train 0.9412, Val 0.9012, Test 0.7512
Epoch 300:, Train 0.9398, Val 0.8995, Test 0.7442
BEST: Epoch 290, Train 0.9412, Val 0.9012, Test 0.7512

RUN #7: seed=512
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.002371214795857668
coalesce scoo: 1.407e-05
convert to csr_matrix: 2.701
calc min-max per row: 0.7261
vectorization: 1.755
Normalization Time: 6.6941
DOT_PRODUCT
Attention Filter (n=122883286): 0.149 +\- 0.230 [0.000-1.000]
Total Transformation Time: 208.8283
Epoch 10:, Train 0.9118, Val 0.8838, Test 0.7208
Epoch 20:, Train 0.9212, Val 0.8903, Test 0.7189
Epoch 30:, Train 0.9265, Val 0.8941, Test 0.7306
Epoch 40:, Train 0.9272, Val 0.8948, Test 0.7385
Epoch 50:, Train 0.9272, Val 0.8948, Test 0.7354
Epoch 60:, Train 0.9294, Val 0.8919, Test 0.7375
Epoch 70:, Train 0.9318, Val 0.8966, Test 0.7425
Epoch 80:, Train 0.9315, Val 0.8949, Test 0.7333
Epoch 90:, Train 0.9343, Val 0.8972, Test 0.7384
Epoch 100:, Train 0.9365, Val 0.8988, Test 0.7409
Epoch 110:, Train 0.9358, Val 0.8988, Test 0.7451
Epoch 120:, Train 0.9350, Val 0.8980, Test 0.7405
Epoch 130:, Train 0.9332, Val 0.8992, Test 0.7396
Epoch 140:, Train 0.9345, Val 0.8980, Test 0.7437
Epoch 150:, Train 0.9302, Val 0.8925, Test 0.7367
Epoch 160:, Train 0.9382, Val 0.9004, Test 0.7396
Epoch 170:, Train 0.9364, Val 0.8990, Test 0.7416
Epoch 180:, Train 0.9380, Val 0.8997, Test 0.7421
Epoch 190:, Train 0.9359, Val 0.8988, Test 0.7430
Epoch 200:, Train 0.9381, Val 0.8995, Test 0.7449
Epoch 210:, Train 0.9349, Val 0.8970, Test 0.7390
Epoch 220:, Train 0.9354, Val 0.8946, Test 0.7340
Epoch 230:, Train 0.9396, Val 0.9011, Test 0.7431
Epoch 240:, Train 0.9396, Val 0.9001, Test 0.7412
Epoch 250:, Train 0.9382, Val 0.8985, Test 0.7424
Epoch 260:, Train 0.9378, Val 0.8992, Test 0.7449
Epoch 270:, Train 0.9390, Val 0.8988, Test 0.7421
Epoch 280:, Train 0.9378, Val 0.8993, Test 0.7498
Epoch 290:, Train 0.9387, Val 0.8993, Test 0.7446
Epoch 300:, Train 0.9398, Val 0.9009, Test 0.7493
BEST: Epoch 230, Train 0.9396, Val 0.9011, Test 0.7431

RUN #8: seed=1024
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.000924520893022418
coalesce scoo: 1.407e-05
convert to csr_matrix: 2.683
calc min-max per row: 0.7285
vectorization: 1.68
Normalization Time: 6.6049
DOT_PRODUCT
Attention Filter (n=122896656): 0.151 +\- 0.233 [0.000-1.000]
Total Transformation Time: 205.5320
Epoch 10:, Train 0.9085, Val 0.8819, Test 0.7207
Epoch 20:, Train 0.9106, Val 0.8831, Test 0.7163
Epoch 30:, Train 0.9240, Val 0.8903, Test 0.7289
Epoch 40:, Train 0.9228, Val 0.8893, Test 0.7351
Epoch 50:, Train 0.9251, Val 0.8913, Test 0.7355
Epoch 60:, Train 0.9286, Val 0.8919, Test 0.7359
Epoch 70:, Train 0.9271, Val 0.8900, Test 0.7322
Epoch 80:, Train 0.9290, Val 0.8923, Test 0.7392
Epoch 90:, Train 0.9279, Val 0.8918, Test 0.7271
Epoch 100:, Train 0.9324, Val 0.8966, Test 0.7371
Epoch 110:, Train 0.9286, Val 0.8928, Test 0.7305
Epoch 120:, Train 0.9319, Val 0.8937, Test 0.7357
Epoch 130:, Train 0.9295, Val 0.8906, Test 0.7373
Epoch 140:, Train 0.9305, Val 0.8945, Test 0.7364
Epoch 150:, Train 0.9338, Val 0.8939, Test 0.7384
Epoch 160:, Train 0.9309, Val 0.8917, Test 0.7341
Epoch 170:, Train 0.9337, Val 0.8960, Test 0.7376
Epoch 180:, Train 0.9337, Val 0.8964, Test 0.7432
Epoch 190:, Train 0.9358, Val 0.8984, Test 0.7450
Epoch 200:, Train 0.9298, Val 0.8925, Test 0.7348
Epoch 210:, Train 0.9367, Val 0.8983, Test 0.7455
Epoch 220:, Train 0.9363, Val 0.8969, Test 0.7425
Epoch 230:, Train 0.9387, Val 0.8974, Test 0.7406
Epoch 240:, Train 0.9298, Val 0.8898, Test 0.7270
Epoch 250:, Train 0.9336, Val 0.8940, Test 0.7324
Epoch 260:, Train 0.9323, Val 0.8942, Test 0.7294
Epoch 270:, Train 0.9377, Val 0.8970, Test 0.7416
Epoch 280:, Train 0.9346, Val 0.8976, Test 0.7384
Epoch 290:, Train 0.9348, Val 0.8962, Test 0.7370
Epoch 300:, Train 0.9364, Val 0.8970, Test 0.7443
BEST: Epoch 190, Train 0.9358, Val 0.8984, Test 0.7450

RUN #9: seed=2048
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00865280069410801
coalesce scoo: 1.359e-05
convert to csr_matrix: 2.573
calc min-max per row: 0.7256
vectorization: 1.661
Normalization Time: 6.4869
DOT_PRODUCT
Attention Filter (n=123018678): 0.153 +\- 0.235 [0.000-1.000]
Total Transformation Time: 207.4420
Epoch 10:, Train 0.9094, Val 0.8841, Test 0.7170
Epoch 20:, Train 0.9046, Val 0.8793, Test 0.7127
Epoch 30:, Train 0.9266, Val 0.8936, Test 0.7418
Epoch 40:, Train 0.9191, Val 0.8857, Test 0.7261
Epoch 50:, Train 0.9227, Val 0.8886, Test 0.7143
Epoch 60:, Train 0.9313, Val 0.8972, Test 0.7344
Epoch 70:, Train 0.9326, Val 0.8981, Test 0.7414
Epoch 80:, Train 0.9278, Val 0.8904, Test 0.7303
Epoch 90:, Train 0.9306, Val 0.8919, Test 0.7315
Epoch 100:, Train 0.9308, Val 0.8959, Test 0.7321
Epoch 110:, Train 0.9311, Val 0.8904, Test 0.7308
Epoch 120:, Train 0.9340, Val 0.8984, Test 0.7417
Epoch 130:, Train 0.9325, Val 0.8948, Test 0.7334
Epoch 140:, Train 0.9318, Val 0.8922, Test 0.7369
Epoch 150:, Train 0.9322, Val 0.8966, Test 0.7376
Epoch 160:, Train 0.9304, Val 0.8937, Test 0.7308
Epoch 170:, Train 0.9352, Val 0.8981, Test 0.7395
Epoch 180:, Train 0.9315, Val 0.8938, Test 0.7342
Epoch 190:, Train 0.9362, Val 0.8969, Test 0.7443
Epoch 200:, Train 0.9373, Val 0.8965, Test 0.7327
Epoch 210:, Train 0.9364, Val 0.8972, Test 0.7370
Epoch 220:, Train 0.9361, Val 0.8974, Test 0.7427
Epoch 230:, Train 0.9315, Val 0.8926, Test 0.7405
Epoch 240:, Train 0.9309, Val 0.8887, Test 0.7275
Epoch 250:, Train 0.9322, Val 0.8937, Test 0.7331
Epoch 260:, Train 0.9333, Val 0.8933, Test 0.7371
Epoch 270:, Train 0.9345, Val 0.8949, Test 0.7388
Epoch 280:, Train 0.9371, Val 0.8971, Test 0.7388
Epoch 290:, Train 0.9353, Val 0.8957, Test 0.7348
Epoch 300:, Train 0.9351, Val 0.8958, Test 0.7361
BEST: Epoch 120, Train 0.9340, Val 0.8984, Test 0.7417




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 94.6057 +/- 4.4748
Avg. Preaggregation Time (s): 210.0170 +/- 4.3114
Avg. Training Time (epoch) (s): 4.4447 +/- 0.0766
Avg. Inference Time (s): 1.2787 +/- 0.0229

Avg. Training Acc: 0.9371 +/- 0.0022
Avg. Validation Acc: 0.9001 +/- 0.0012
Avg. Test Acc: 0.7461 +/- 0.0046

==================================================

==================================================
================= SIGN+MHA =======================
==================================================
Using backend: pytorch

===== PRODUCTS =====

Namespace(DATASET='products', ATTN_FILTER='dot_product', EPOCHS=300, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=3, BATCH_SIZE=4096, LEARNING_RATE=0.01, WEIGHT_DECAY=1e-05, INCEPTION_LAYERS=3, INCEPTION_UNITS=1024, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=1024, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.4, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=4, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.002750938758254051
coalesce scoo: 2.217e-05
convert to csr_matrix: 3.248
calc min-max per row: 0.7646
vectorization: 1.56
Normalization Time: 7.4035
DOT_PRODUCT
Attention Filter (n=123577305): 0.182 +\- 0.255 [0.000-1.000]
Total Transformation Time: 593.8539
Epoch 10:, Train 0.9179, Val 0.8953, Test 0.7195
Epoch 20:, Train 0.9274, Val 0.8988, Test 0.7304
Epoch 30:, Train 0.9283, Val 0.8985, Test 0.7384
Epoch 40:, Train 0.9293, Val 0.9000, Test 0.7365
Epoch 50:, Train 0.9306, Val 0.8991, Test 0.7345
Epoch 60:, Train 0.9363, Val 0.9034, Test 0.7536
Epoch 70:, Train 0.9375, Val 0.9040, Test 0.7411
Epoch 80:, Train 0.9367, Val 0.9032, Test 0.7460
Epoch 90:, Train 0.9387, Val 0.9082, Test 0.7518
Epoch 100:, Train 0.9401, Val 0.9072, Test 0.7542
Epoch 110:, Train 0.9361, Val 0.9029, Test 0.7447
Epoch 120:, Train 0.9399, Val 0.9071, Test 0.7505
Epoch 130:, Train 0.9410, Val 0.9079, Test 0.7542
Epoch 140:, Train 0.9397, Val 0.9075, Test 0.7437
Epoch 150:, Train 0.9390, Val 0.9043, Test 0.7501
Epoch 160:, Train 0.9407, Val 0.9076, Test 0.7495
Epoch 170:, Train 0.9357, Val 0.9034, Test 0.7517
Epoch 180:, Train 0.9398, Val 0.9096, Test 0.7621
Epoch 190:, Train 0.9415, Val 0.9057, Test 0.7519
Epoch 200:, Train 0.9398, Val 0.9061, Test 0.7607
Epoch 210:, Train 0.9415, Val 0.9083, Test 0.7550
Epoch 220:, Train 0.9412, Val 0.9075, Test 0.7511
Epoch 230:, Train 0.9399, Val 0.9044, Test 0.7458
Epoch 240:, Train 0.9424, Val 0.9078, Test 0.7564
Epoch 250:, Train 0.9425, Val 0.9092, Test 0.7538
Epoch 260:, Train 0.9424, Val 0.9076, Test 0.7551
Epoch 270:, Train 0.9315, Val 0.8986, Test 0.7398
Epoch 280:, Train 0.9432, Val 0.9080, Test 0.7507
Epoch 290:, Train 0.9415, Val 0.9057, Test 0.7467
Epoch 300:, Train 0.9423, Val 0.9077, Test 0.7547
BEST: Epoch 180, Train 0.9398, Val 0.9096, Test 0.7621

RUN #1: seed=4
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.006151767447590828
coalesce scoo: 2.146e-05
convert to csr_matrix: 3.385
calc min-max per row: 0.7686
vectorization: 1.769
Normalization Time: 7.7646
DOT_PRODUCT
Attention Filter (n=123590278): 0.182 +\- 0.256 [0.000-1.000]
Total Transformation Time: 570.5920
Epoch 10:, Train 0.9187, Val 0.8952, Test 0.7199
Epoch 20:, Train 0.9268, Val 0.8998, Test 0.7256
Epoch 30:, Train 0.9299, Val 0.8992, Test 0.7419
Epoch 40:, Train 0.9231, Val 0.8963, Test 0.7271
Epoch 50:, Train 0.9343, Val 0.9015, Test 0.7450
Epoch 60:, Train 0.9235, Val 0.8932, Test 0.7345
Epoch 70:, Train 0.9355, Val 0.9043, Test 0.7532
Epoch 80:, Train 0.9381, Val 0.9054, Test 0.7510
Epoch 90:, Train 0.9384, Val 0.9042, Test 0.7476
Epoch 100:, Train 0.9371, Val 0.9059, Test 0.7436
Epoch 110:, Train 0.9382, Val 0.9040, Test 0.7498
Epoch 120:, Train 0.9383, Val 0.9072, Test 0.7461
Epoch 130:, Train 0.9318, Val 0.8975, Test 0.7429
Epoch 140:, Train 0.9313, Val 0.8979, Test 0.7337
Epoch 150:, Train 0.9331, Val 0.8968, Test 0.7373
Epoch 160:, Train 0.9352, Val 0.9036, Test 0.7471
Epoch 170:, Train 0.9397, Val 0.9061, Test 0.7452
Epoch 180:, Train 0.9415, Val 0.9072, Test 0.7450
Epoch 190:, Train 0.9404, Val 0.9070, Test 0.7500
Epoch 200:, Train 0.9325, Val 0.8966, Test 0.7410
Epoch 210:, Train 0.9399, Val 0.9064, Test 0.7517
Epoch 220:, Train 0.9406, Val 0.9065, Test 0.7458
Epoch 230:, Train 0.9430, Val 0.9090, Test 0.7589
Epoch 240:, Train 0.9437, Val 0.9088, Test 0.7547
Epoch 250:, Train 0.9398, Val 0.9012, Test 0.7415
Epoch 260:, Train 0.9152, Val 0.8863, Test 0.7185
Epoch 270:, Train 0.9393, Val 0.9047, Test 0.7486
Epoch 280:, Train 0.9350, Val 0.8954, Test 0.7439
Epoch 290:, Train 0.9243, Val 0.8919, Test 0.7314
Epoch 300:, Train 0.9419, Val 0.9056, Test 0.7483
BEST: Epoch 230, Train 0.9430, Val 0.9090, Test 0.7589

RUN #2: seed=8
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0024782554246485233
coalesce scoo: 2.074e-05
convert to csr_matrix: 3.11
calc min-max per row: 0.7899
vectorization: 1.77
Normalization Time: 7.8175
DOT_PRODUCT
Attention Filter (n=123595488): 0.178 +\- 0.253 [0.000-1.000]
Total Transformation Time: 551.2882
Epoch 10:, Train 0.9024, Val 0.8785, Test 0.7114
Epoch 20:, Train 0.9204, Val 0.8904, Test 0.7244
Epoch 30:, Train 0.9289, Val 0.8997, Test 0.7385
Epoch 40:, Train 0.9316, Val 0.9016, Test 0.7474
Epoch 50:, Train 0.9306, Val 0.9004, Test 0.7462
Epoch 60:, Train 0.9354, Val 0.9033, Test 0.7502
Epoch 70:, Train 0.9272, Val 0.8984, Test 0.7427
Epoch 80:, Train 0.9372, Val 0.9033, Test 0.7487
Epoch 90:, Train 0.9349, Val 0.9022, Test 0.7489
Epoch 100:, Train 0.9385, Val 0.9037, Test 0.7513
Epoch 110:, Train 0.9390, Val 0.9072, Test 0.7564
Epoch 120:, Train 0.9396, Val 0.9077, Test 0.7557
Epoch 130:, Train 0.9394, Val 0.9062, Test 0.7517
Epoch 140:, Train 0.9399, Val 0.9083, Test 0.7530
Epoch 150:, Train 0.9420, Val 0.9073, Test 0.7611
Epoch 160:, Train 0.9408, Val 0.9075, Test 0.7525
Epoch 170:, Train 0.9403, Val 0.9075, Test 0.7627
Epoch 180:, Train 0.9361, Val 0.9003, Test 0.7423
Epoch 190:, Train 0.9366, Val 0.9015, Test 0.7465
Epoch 200:, Train 0.9388, Val 0.9028, Test 0.7559
Epoch 210:, Train 0.9414, Val 0.9092, Test 0.7536
Epoch 220:, Train 0.9379, Val 0.9035, Test 0.7453
Epoch 230:, Train 0.9370, Val 0.9032, Test 0.7564
Epoch 240:, Train 0.9415, Val 0.9090, Test 0.7525
Epoch 250:, Train 0.9420, Val 0.9062, Test 0.7536
Epoch 260:, Train 0.9422, Val 0.9080, Test 0.7517
Epoch 270:, Train 0.9431, Val 0.9076, Test 0.7616
Epoch 280:, Train 0.9400, Val 0.9066, Test 0.7557
Epoch 290:, Train 0.9399, Val 0.9049, Test 0.7542
Epoch 300:, Train 0.9389, Val 0.9058, Test 0.7535
BEST: Epoch 210, Train 0.9414, Val 0.9092, Test 0.7536

RUN #3: seed=42
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.004516818560659885
coalesce scoo: 2.193e-05
convert to csr_matrix: 3.12
calc min-max per row: 0.7932
vectorization: 1.993
Normalization Time: 7.6917
DOT_PRODUCT
Attention Filter (n=123586101): 0.182 +\- 0.253 [0.000-1.000]
Total Transformation Time: 552.7762
Epoch 10:, Train 0.9167, Val 0.8948, Test 0.7185
Epoch 20:, Train 0.9112, Val 0.8858, Test 0.7193
Epoch 30:, Train 0.9150, Val 0.8904, Test 0.7253
Epoch 40:, Train 0.9320, Val 0.9032, Test 0.7384
Epoch 50:, Train 0.9280, Val 0.8987, Test 0.7435
Epoch 60:, Train 0.9369, Val 0.9052, Test 0.7484
Epoch 70:, Train 0.9343, Val 0.9053, Test 0.7521
Epoch 80:, Train 0.9356, Val 0.9070, Test 0.7494
Epoch 90:, Train 0.9393, Val 0.9069, Test 0.7449
Epoch 100:, Train 0.9322, Val 0.9014, Test 0.7405
Epoch 110:, Train 0.9407, Val 0.9104, Test 0.7556
Epoch 120:, Train 0.9371, Val 0.9047, Test 0.7535
Epoch 130:, Train 0.9369, Val 0.9045, Test 0.7431
Epoch 140:, Train 0.9380, Val 0.9041, Test 0.7545
Epoch 150:, Train 0.9417, Val 0.9077, Test 0.7525
Epoch 160:, Train 0.9415, Val 0.9068, Test 0.7516
Epoch 170:, Train 0.9394, Val 0.9070, Test 0.7448
Epoch 180:, Train 0.9419, Val 0.9070, Test 0.7535
Epoch 190:, Train 0.9421, Val 0.9081, Test 0.7493
Epoch 200:, Train 0.9350, Val 0.9023, Test 0.7382
Epoch 210:, Train 0.9411, Val 0.9063, Test 0.7541
Epoch 220:, Train 0.9380, Val 0.9078, Test 0.7518
Epoch 230:, Train 0.9411, Val 0.9061, Test 0.7468
Epoch 240:, Train 0.9420, Val 0.9084, Test 0.7559
Epoch 250:, Train 0.9306, Val 0.8992, Test 0.7437
Epoch 260:, Train 0.9384, Val 0.9033, Test 0.7417
Epoch 270:, Train 0.9407, Val 0.9084, Test 0.7611
Epoch 280:, Train 0.9426, Val 0.9079, Test 0.7534
Epoch 290:, Train 0.9385, Val 0.9027, Test 0.7387
Epoch 300:, Train 0.9435, Val 0.9092, Test 0.7487
BEST: Epoch 110, Train 0.9407, Val 0.9104, Test 0.7556

RUN #4: seed=64
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.00530599569901824
coalesce scoo: 3.242e-05
convert to csr_matrix: 3.348
calc min-max per row: 0.7666
vectorization: 1.569
Normalization Time: 8.5435
DOT_PRODUCT
Attention Filter (n=123577334): 0.179 +\- 0.254 [0.000-1.000]
Total Transformation Time: 558.3653
Epoch 10:, Train 0.9182, Val 0.8964, Test 0.7219
Epoch 20:, Train 0.9275, Val 0.9000, Test 0.7448
Epoch 30:, Train 0.9287, Val 0.9011, Test 0.7482
Epoch 40:, Train 0.9340, Val 0.8997, Test 0.7501
Epoch 50:, Train 0.9301, Val 0.8997, Test 0.7397
Epoch 60:, Train 0.9336, Val 0.9031, Test 0.7447
Epoch 70:, Train 0.9263, Val 0.8994, Test 0.7486
Epoch 80:, Train 0.9297, Val 0.8983, Test 0.7363
Epoch 90:, Train 0.9351, Val 0.9010, Test 0.7416
Epoch 100:, Train 0.9392, Val 0.9052, Test 0.7472
Epoch 110:, Train 0.9383, Val 0.9040, Test 0.7520
Epoch 120:, Train 0.9395, Val 0.9074, Test 0.7443
Epoch 130:, Train 0.9353, Val 0.9009, Test 0.7436
Epoch 140:, Train 0.9354, Val 0.9015, Test 0.7449
Epoch 150:, Train 0.9403, Val 0.9067, Test 0.7506
Epoch 160:, Train 0.9367, Val 0.9041, Test 0.7446
Epoch 170:, Train 0.9406, Val 0.9084, Test 0.7531
Epoch 180:, Train 0.9394, Val 0.9065, Test 0.7573
Epoch 190:, Train 0.9354, Val 0.9008, Test 0.7444
Epoch 200:, Train 0.9407, Val 0.9024, Test 0.7525
Epoch 210:, Train 0.9374, Val 0.8986, Test 0.7486
Epoch 220:, Train 0.9391, Val 0.9065, Test 0.7510
Epoch 230:, Train 0.9411, Val 0.9067, Test 0.7535
Epoch 240:, Train 0.9434, Val 0.9094, Test 0.7521
Epoch 250:, Train 0.9411, Val 0.9071, Test 0.7556
Epoch 260:, Train 0.9428, Val 0.9075, Test 0.7537
Epoch 270:, Train 0.9355, Val 0.9003, Test 0.7410
Epoch 280:, Train 0.9431, Val 0.9066, Test 0.7581
Epoch 290:, Train 0.9437, Val 0.9082, Test 0.7565
Epoch 300:, Train 0.9394, Val 0.9072, Test 0.7535
BEST: Epoch 240, Train 0.9434, Val 0.9094, Test 0.7521

RUN #5: seed=128
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0013660663971677423
coalesce scoo: 2.217e-05
convert to csr_matrix: 3.126
calc min-max per row: 0.7717
vectorization: 1.784
Normalization Time: 8.0957
DOT_PRODUCT
Attention Filter (n=123597625): 0.179 +\- 0.252 [0.000-1.000]
Total Transformation Time: 554.8305
Epoch 10:, Train 0.9117, Val 0.8893, Test 0.7165
Epoch 20:, Train 0.9278, Val 0.9009, Test 0.7391
Epoch 30:, Train 0.9279, Val 0.9012, Test 0.7323
Epoch 40:, Train 0.9349, Val 0.9044, Test 0.7461
Epoch 50:, Train 0.9330, Val 0.9015, Test 0.7351
Epoch 60:, Train 0.9331, Val 0.9018, Test 0.7387
Epoch 70:, Train 0.9362, Val 0.9055, Test 0.7467
Epoch 80:, Train 0.9390, Val 0.9085, Test 0.7499
Epoch 90:, Train 0.9394, Val 0.9069, Test 0.7504
Epoch 100:, Train 0.9373, Val 0.9028, Test 0.7394
Epoch 110:, Train 0.9399, Val 0.9077, Test 0.7573
Epoch 120:, Train 0.9376, Val 0.9054, Test 0.7467
Epoch 130:, Train 0.9397, Val 0.9074, Test 0.7524
Epoch 140:, Train 0.9405, Val 0.9075, Test 0.7514
Epoch 150:, Train 0.9385, Val 0.9071, Test 0.7446
Epoch 160:, Train 0.9392, Val 0.9060, Test 0.7498
Epoch 170:, Train 0.9368, Val 0.9032, Test 0.7395
Epoch 180:, Train 0.9436, Val 0.9091, Test 0.7538
Epoch 190:, Train 0.9414, Val 0.9071, Test 0.7479
Epoch 200:, Train 0.9389, Val 0.9056, Test 0.7453
Epoch 210:, Train 0.9423, Val 0.9099, Test 0.7558
Epoch 220:, Train 0.9381, Val 0.9067, Test 0.7470
Epoch 230:, Train 0.9332, Val 0.8985, Test 0.7391
Epoch 240:, Train 0.9413, Val 0.9076, Test 0.7557
Epoch 250:, Train 0.9390, Val 0.9052, Test 0.7421
Epoch 260:, Train 0.9407, Val 0.9042, Test 0.7500
Epoch 270:, Train 0.9417, Val 0.9073, Test 0.7495
Epoch 280:, Train 0.9407, Val 0.9072, Test 0.7549
Epoch 290:, Train 0.9416, Val 0.9072, Test 0.7625
Epoch 300:, Train 0.9387, Val 0.9059, Test 0.7469
BEST: Epoch 210, Train 0.9423, Val 0.9099, Test 0.7558

RUN #6: seed=256
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.001952421385794878
coalesce scoo: 4.649e-05
convert to csr_matrix: 3.36
calc min-max per row: 0.8374
vectorization: 1.76
Normalization Time: 8.8762
DOT_PRODUCT
Attention Filter (n=123598013): 0.185 +\- 0.257 [0.000-1.000]
Total Transformation Time: 563.5644
Epoch 10:, Train 0.9234, Val 0.9000, Test 0.7288
Epoch 20:, Train 0.9266, Val 0.9002, Test 0.7358
Epoch 30:, Train 0.9273, Val 0.9013, Test 0.7325
Epoch 40:, Train 0.9318, Val 0.9034, Test 0.7375
Epoch 50:, Train 0.9331, Val 0.9046, Test 0.7409
Epoch 60:, Train 0.9334, Val 0.9043, Test 0.7329
Epoch 70:, Train 0.9358, Val 0.9054, Test 0.7472
Epoch 80:, Train 0.9331, Val 0.9030, Test 0.7421
Epoch 90:, Train 0.9290, Val 0.8963, Test 0.7455
Epoch 100:, Train 0.9394, Val 0.9073, Test 0.7471
Epoch 110:, Train 0.9338, Val 0.9015, Test 0.7371
Epoch 120:, Train 0.9339, Val 0.9040, Test 0.7519
Epoch 130:, Train 0.9417, Val 0.9100, Test 0.7496
Epoch 140:, Train 0.9400, Val 0.9053, Test 0.7525
Epoch 150:, Train 0.9354, Val 0.9048, Test 0.7521
Epoch 160:, Train 0.9355, Val 0.9052, Test 0.7481
Epoch 170:, Train 0.9392, Val 0.9074, Test 0.7502
Epoch 180:, Train 0.9394, Val 0.9044, Test 0.7488
Epoch 190:, Train 0.9422, Val 0.9071, Test 0.7508
Epoch 200:, Train 0.9358, Val 0.9036, Test 0.7507
Epoch 210:, Train 0.9368, Val 0.9018, Test 0.7577
Epoch 220:, Train 0.9415, Val 0.9067, Test 0.7511
Epoch 230:, Train 0.9404, Val 0.9080, Test 0.7525
Epoch 240:, Train 0.9372, Val 0.9044, Test 0.7431
Epoch 250:, Train 0.9403, Val 0.9081, Test 0.7537
Epoch 260:, Train 0.9401, Val 0.9060, Test 0.7487
Epoch 270:, Train 0.9415, Val 0.9095, Test 0.7464
Epoch 280:, Train 0.9405, Val 0.9065, Test 0.7504
Epoch 290:, Train 0.9423, Val 0.9074, Test 0.7520
Epoch 300:, Train 0.9435, Val 0.9089, Test 0.7594
BEST: Epoch 130, Train 0.9417, Val 0.9100, Test 0.7496

RUN #7: seed=512
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.005771292373538017
coalesce scoo: 5.102e-05
convert to csr_matrix: 3.266
calc min-max per row: 0.7682
vectorization: 1.962
Normalization Time: 8.7601
DOT_PRODUCT
Attention Filter (n=123589343): 0.180 +\- 0.253 [0.000-1.000]
Total Transformation Time: 563.7099
Epoch 10:, Train 0.9072, Val 0.8870, Test 0.7143
Epoch 20:, Train 0.9263, Val 0.8991, Test 0.7280
Epoch 30:, Train 0.9311, Val 0.9043, Test 0.7489
Epoch 40:, Train 0.9281, Val 0.8980, Test 0.7341
Epoch 50:, Train 0.9322, Val 0.9033, Test 0.7318
Epoch 60:, Train 0.9375, Val 0.9087, Test 0.7540
Epoch 70:, Train 0.9337, Val 0.9015, Test 0.7421
Epoch 80:, Train 0.9319, Val 0.9012, Test 0.7335
Epoch 90:, Train 0.9359, Val 0.9032, Test 0.7479
Epoch 100:, Train 0.9322, Val 0.8989, Test 0.7324
Epoch 110:, Train 0.9406, Val 0.9058, Test 0.7582
Epoch 120:, Train 0.9352, Val 0.9011, Test 0.7474
Epoch 130:, Train 0.9356, Val 0.9021, Test 0.7534
Epoch 140:, Train 0.9394, Val 0.9069, Test 0.7499
Epoch 150:, Train 0.9410, Val 0.9083, Test 0.7414
Epoch 160:, Train 0.9370, Val 0.9012, Test 0.7452
Epoch 170:, Train 0.9426, Val 0.9082, Test 0.7604
Epoch 180:, Train 0.9420, Val 0.9086, Test 0.7533
Epoch 190:, Train 0.9426, Val 0.9087, Test 0.7546
Epoch 200:, Train 0.9396, Val 0.9077, Test 0.7476
Epoch 210:, Train 0.9386, Val 0.9031, Test 0.7416
Epoch 220:, Train 0.9409, Val 0.9075, Test 0.7610
Epoch 230:, Train 0.9427, Val 0.9078, Test 0.7585
Epoch 240:, Train 0.9391, Val 0.9041, Test 0.7495
Epoch 250:, Train 0.9424, Val 0.9081, Test 0.7451
Epoch 260:, Train 0.9432, Val 0.9090, Test 0.7533
Epoch 270:, Train 0.9398, Val 0.9060, Test 0.7450
Epoch 280:, Train 0.9416, Val 0.9077, Test 0.7548
Epoch 290:, Train 0.9419, Val 0.9078, Test 0.7460
Epoch 300:, Train 0.9437, Val 0.9088, Test 0.7548
BEST: Epoch 260, Train 0.9432, Val 0.9090, Test 0.7533

RUN #8: seed=1024
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0017024658154696226
coalesce scoo: 2.098e-05
convert to csr_matrix: 3.185
calc min-max per row: 0.7686
vectorization: 1.752
Normalization Time: 8.6707
DOT_PRODUCT
Attention Filter (n=123576447): 0.180 +\- 0.255 [0.000-1.000]
Total Transformation Time: 562.6072
Epoch 10:, Train 0.9124, Val 0.8896, Test 0.7171
Epoch 20:, Train 0.9217, Val 0.8955, Test 0.7394
Epoch 30:, Train 0.9229, Val 0.8953, Test 0.7293
Epoch 40:, Train 0.9284, Val 0.9009, Test 0.7344
Epoch 50:, Train 0.9341, Val 0.9054, Test 0.7438
Epoch 60:, Train 0.9330, Val 0.9022, Test 0.7405
Epoch 70:, Train 0.9352, Val 0.9050, Test 0.7498
Epoch 80:, Train 0.9349, Val 0.9032, Test 0.7504
Epoch 90:, Train 0.9383, Val 0.9059, Test 0.7405
Epoch 100:, Train 0.9348, Val 0.9022, Test 0.7477
Epoch 110:, Train 0.9366, Val 0.9033, Test 0.7432
Epoch 120:, Train 0.9301, Val 0.8963, Test 0.7345
Epoch 130:, Train 0.9311, Val 0.8992, Test 0.7333
Epoch 140:, Train 0.9398, Val 0.9066, Test 0.7528
Epoch 150:, Train 0.9355, Val 0.9048, Test 0.7431
Epoch 160:, Train 0.9385, Val 0.9052, Test 0.7486
Epoch 170:, Train 0.9393, Val 0.9068, Test 0.7458
Epoch 180:, Train 0.9399, Val 0.9062, Test 0.7543
Epoch 190:, Train 0.9374, Val 0.9031, Test 0.7403
Epoch 200:, Train 0.9409, Val 0.9069, Test 0.7461
Epoch 210:, Train 0.9396, Val 0.9052, Test 0.7492
Epoch 220:, Train 0.9417, Val 0.9067, Test 0.7467
Epoch 230:, Train 0.9400, Val 0.9056, Test 0.7420
Epoch 240:, Train 0.9370, Val 0.9039, Test 0.7370
Epoch 250:, Train 0.9421, Val 0.9068, Test 0.7457
Epoch 260:, Train 0.9434, Val 0.9081, Test 0.7620
Epoch 270:, Train 0.9376, Val 0.9013, Test 0.7365
Epoch 280:, Train 0.9423, Val 0.9088, Test 0.7498
Epoch 290:, Train 0.9413, Val 0.9040, Test 0.7540
Epoch 300:, Train 0.9425, Val 0.9068, Test 0.7493
BEST: Epoch 280, Train 0.9423, Val 0.9088, Test 0.7498

RUN #9: seed=2048
Attn Summary:
len(r): 123718152
len(c): 123718152
len(v): 123718152
dtype(v): torch.FloatTensor, 0.0056320615112781525
coalesce scoo: 4.888e-05
convert to csr_matrix: 3.286
calc min-max per row: 0.771
vectorization: 1.574
Normalization Time: 8.1928
DOT_PRODUCT
Attention Filter (n=123580491): 0.183 +\- 0.255 [0.000-1.000]
Total Transformation Time: 565.0469
Epoch 10:, Train 0.9217, Val 0.8971, Test 0.7265
Epoch 20:, Train 0.9199, Val 0.8932, Test 0.7307
Epoch 30:, Train 0.9328, Val 0.9039, Test 0.7431
Epoch 40:, Train 0.9370, Val 0.9063, Test 0.7486
Epoch 50:, Train 0.9337, Val 0.9029, Test 0.7473
Epoch 60:, Train 0.9324, Val 0.9011, Test 0.7423
Epoch 70:, Train 0.9365, Val 0.9038, Test 0.7482
Epoch 80:, Train 0.9364, Val 0.9054, Test 0.7393
Epoch 90:, Train 0.9376, Val 0.9044, Test 0.7441
Epoch 100:, Train 0.9367, Val 0.9052, Test 0.7456
Epoch 110:, Train 0.9419, Val 0.9076, Test 0.7609
Epoch 120:, Train 0.9363, Val 0.9038, Test 0.7405
Epoch 130:, Train 0.9380, Val 0.9038, Test 0.7545
Epoch 140:, Train 0.9420, Val 0.9069, Test 0.7519
Epoch 150:, Train 0.9412, Val 0.9075, Test 0.7562
Epoch 160:, Train 0.9411, Val 0.9069, Test 0.7521
Epoch 170:, Train 0.9408, Val 0.9052, Test 0.7502
Epoch 180:, Train 0.9381, Val 0.9049, Test 0.7542
Epoch 190:, Train 0.9417, Val 0.9073, Test 0.7553
Epoch 200:, Train 0.9390, Val 0.9036, Test 0.7450
Epoch 210:, Train 0.9422, Val 0.9084, Test 0.7478
Epoch 220:, Train 0.9408, Val 0.9056, Test 0.7452
Epoch 230:, Train 0.9429, Val 0.9085, Test 0.7584
Epoch 240:, Train 0.9402, Val 0.9066, Test 0.7537
Epoch 250:, Train 0.9424, Val 0.9086, Test 0.7560
Epoch 260:, Train 0.9379, Val 0.9021, Test 0.7512
Epoch 270:, Train 0.9418, Val 0.9070, Test 0.7645
Epoch 280:, Train 0.9445, Val 0.9096, Test 0.7554
Epoch 290:, Train 0.9411, Val 0.9076, Test 0.7536
Epoch 300:, Train 0.9427, Val 0.9076, Test 0.7603
BEST: Epoch 280, Train 0.9445, Val 0.9096, Test 0.7554




==================================================
Model Parameters: 14124085

Avg. Filter Time (s): 441.5854 +/- 12.8868
Avg. Preaggregation Time (s): 563.6635 +/- 11.5771
Avg. Training Time (epoch) (s): 4.6149 +/- 0.1153
Avg. Inference Time (s): 1.2672 +/- 0.0143

Avg. Training Acc: 0.9422 +/- 0.0013
Avg. Validation Acc: 0.9095 +/- 0.0005
Avg. Test Acc: 0.7546 +/- 0.0037

==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 25 hours 20 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
