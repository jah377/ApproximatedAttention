{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from general.utils import set_seeds, standardize_dataset\n",
    "\n",
    "\n",
    "class Args(Dataset):\n",
    "    def __init__(self, seed, dataset, num_heads):\n",
    "        self.seed = seed\n",
    "        self.dataset = dataset.lower()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "\n",
    "args = Args(\n",
    "    seed=42,\n",
    "    dataset='arxiv',\n",
    "    num_heads=4,\n",
    ")\n",
    "\n",
    "set_seeds(args.seed)\n",
    "path = f'data/{args.dataset}/{args.dataset}_sign_k0.pth'\n",
    "data = standardize_dataset(torch.load(path), args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions\n",
    "num_nodes = int(data.num_nodes)\n",
    "num_feats = int(data.num_features)\n",
    "num_edges = int(data.num_edges)\n",
    "num_heads = int(args.num_heads)\n",
    "\n",
    "# dot product\n",
    "out_shape = (num_heads, num_nodes,\n",
    "                    num_nodes)  # attn shape (w/head)\n",
    "d_k = num_feats * num_heads  # hidden dim\n",
    "scale = 1.0/np.sqrt(num_feats)  # scaling factor per head\n",
    "qk_lin = nn.Linear(num_feats, 2*d_k)\n",
    "\n",
    "# compute linear layer\n",
    "qk = qk_lin(data.x)\n",
    "\n",
    "# separate attention heads\n",
    "sep_heads = 'L (h hdim) -> L h hdim'\n",
    "qk = rearrange(\n",
    "    qk, sep_heads,\n",
    "    h=num_heads, hdim=2*num_feats\n",
    ")\n",
    "\n",
    "# separate q and k matrices\n",
    "sep_qk = 'L h (split hdim) -> split h L hdim'\n",
    "q, k = rearrange(qk, sep_qk, split=2)\n",
    "del qk\n",
    "\n",
    "# calculate block dot product attention (Q x K^T)/sqrt(dk)\n",
    "k = k.permute([0, 2, 1])  # h L hdim -> h hdim L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = q, k\n",
    "edge_index = data.edge_index\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# compute dotproduct in batches, across heads\n",
    "h_idx = torch.tensor(range(num_heads))\n",
    "values = torch.zeros(size=(1, num_edges*num_heads))\n",
    "\n",
    "start, end = 0, num_heads\n",
    "for i in range(num_edges):\n",
    "    r_idx, c_idx = edge_index[:, i]\n",
    "    A_node = A[:, r_idx, :].unsqueeze(dim=1).to(device)  # to gpu\n",
    "    B_node = B[:, :, c_idx].unsqueeze(dim=2).to(device)  # to gpu\n",
    "\n",
    "    values[0, start:end] = A_node.matmul(B_node).detach().flatten().cpu()\n",
    "    start += num_heads\n",
    "    end += num_heads\n",
    "\n",
    "h_idx = h_idx.repeat(num_edges)\n",
    "r_idx = edge_index[0].repeat_interleave(num_heads)\n",
    "c_idx = edge_index[1].repeat_interleave(num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.08 GB: 100%|██████████| 81/81 [00:10<00:00,  7.48it/s]\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/<built-in method title of str object at 0x15248e7cd3b0>/arxiv.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 10672.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2004.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import os\n",
    "import numpy as np\n",
    "from einops import rearrange, reduce\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_sparse import SparseTensor\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from general.utils import set_seeds, download_data, standardize_data\n",
    "\n",
    "class Args(Dataset):\n",
    "    def __init__(self, seed, dataset, num_heads):\n",
    "        self.seed = seed\n",
    "        self.dataset = dataset.lower()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "args = Args(\n",
    "    seed=42,\n",
    "    dataset='arxiv',\n",
    "    num_heads=4\n",
    ")\n",
    "\n",
    "data = download_data(args.dataset, K=1)\n",
    "data = standardize_data(data, args.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ..., 169145, 169148, 169251])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = q, k\n",
    "edge_index = data.edge_index\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "values = torch.zeros(size=(1,num_edges*num_heads))\n",
    "start,end = 0, num_heads\n",
    "\n",
    "for i in range(num_edges):\n",
    "    r_idx, c_idx = edge_index[:, i]\n",
    "\n",
    "    A_node = A[:, r_idx, :].to(device)  # to gpu\n",
    "    B_node = B[:, :, c_idx].to(device)  # to gpu  \n",
    "\n",
    "    values[0, start:end] = A_node[:, None, :].matmul(\n",
    "        B_node[:, :, None]).flatten().cpu().detach()\n",
    "\n",
    "    start += num_heads\n",
    "    end += num_heads\n",
    "\n",
    "h_index = torch.tensor(range(num_heads)).repeat(1,num_edges).flatten()\n",
    "r_idx, c_idx = edge_index.repeat_interleave(num_heads, dim=1)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "number of dimensions must be sparse_dim (3) + dense_dim (1), but got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jharris/Desktop/approx_attention/test.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=0'>1</a>\u001b[0m h_idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mrange\u001b[39m(num_heads))\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, num_edges)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=1'>2</a>\u001b[0m r_idx, c_idx \u001b[39m=\u001b[39m edge_index\u001b[39m.\u001b[39mrepeat_interleave(num_heads, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=3'>4</a>\u001b[0m torch\u001b[39m.\u001b[39;49msparse_coo_tensor(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=4'>5</a>\u001b[0m             indices\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mstack([\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=5'>6</a>\u001b[0m                 h_idx,  \u001b[39m# h_idx\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=6'>7</a>\u001b[0m                 r_idx,  \u001b[39m# r_idx\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=7'>8</a>\u001b[0m                 c_idx,  \u001b[39m# c_idx\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=8'>9</a>\u001b[0m             ])\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mLongTensor),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=9'>10</a>\u001b[0m             values\u001b[39m=\u001b[39;49mvalues\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mFloatTensor),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=10'>11</a>\u001b[0m             size\u001b[39m=\u001b[39;49mout_shape,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/jharris/Desktop/approx_attention/test.ipynb#ch0000021vscode-remote?line=11'>12</a>\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dimensions must be sparse_dim (3) + dense_dim (1), but got 3"
     ]
    }
   ],
   "source": [
    "h_idx = torch.tensor(range(num_heads)).repeat(1, num_edges).flatten()\n",
    "r_idx, c_idx = edge_index.repeat_interleave(num_heads, dim=1)\n",
    "\n",
    "torch.sparse_coo_tensor(\n",
    "            indices=torch.stack([\n",
    "                h_idx,  # h_idx\n",
    "                r_idx,  # r_idx\n",
    "                c_idx,  # c_idx\n",
    "            ]).type(torch.LongTensor),\n",
    "            values=values.type(torch.FloatTensor),\n",
    "            size=out_shape,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(c_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    1,    2,  ...,    1,    2,    3],\n",
       "        [   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633,  633,  633,  ..., 2706, 2706, 2706]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([\n",
    "                h_idx,  # h_idx\n",
    "                r_idx,  # r_idx\n",
    "                c_idx,  # c_idx\n",
    "            ])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = torch.randn(100, 128)\n",
    "input2 = torch.randn(100, 128)\n",
    "output = F.cosine_similarity(input1, input2, dim=0)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _batch_slices(num_edges, batch_size):\n",
    "    \"\"\"Generator that yields slice objects for indexing into \n",
    "    sequential blocks of an array along a particular axis\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while True:\n",
    "        yield slice(count, count + int(batch_size), 1)\n",
    "        count += int(batch_size)\n",
    "        if count >= int(num_edges):\n",
    "            break\n",
    "\n",
    "\n",
    "values = torch.tensor(range(data.num_edges)).cpu()\n",
    "\n",
    "for batch in _batch_slices(num_edges, cs_batch_slice):\n",
    "    edges = edge_index[:, batch]  # edge_idx -> node_idx\n",
    "    A = data.x[edges[0]].to(device)\n",
    "    B = data.x[edges[1]].to(device)\n",
    "    values[batch] = F.cosine_similarity(A,B, dim=1).cpu()\n",
    "\n",
    "    del A, B\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1433])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[edges[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(data.x[edges[0]], data.x[edges[1]], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10556])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "677f2394079a7e8b3a41116e0563f7f6e6b4c638366ce750dc9b1c63938d42b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('CPU_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
