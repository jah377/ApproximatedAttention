Tue 28 Jun 2022 08:07:03 PM CEST
r30n7.lisa.surfsara.nl
uid=55639(jharris) gid=55199(jharris) groups=55199(jharris),46457(lisa_uva_gpu),50488(ssh_forwarding)
/home/jharris/Desktop/approx_attention
/home/jharris/Desktop/approx_attention/venvs/GPU_venv/bin/python

Check if packages installed correctly
Torch: 1.11.0+cu113
PyG: 2.0.4

==================================================
================= SIGN ===========================
==================================================
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='sign', EPOCHS=200, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.001, INCEPTION_LAYERS=1, INCEPTION_UNITS=128, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=True, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4938
Total Transformation Time: 0.8929
Epoch 10:, Train 0.6202, Val 0.5898, Test 0.5297
Epoch 20:, Train 0.6379, Val 0.5961, Test 0.5359
Epoch 30:, Train 0.6493, Val 0.5986, Test 0.5342
Epoch 40:, Train 0.6587, Val 0.5989, Test 0.5367
Epoch 50:, Train 0.6665, Val 0.6035, Test 0.5426
Epoch 60:, Train 0.6708, Val 0.6044, Test 0.5450
Epoch 70:, Train 0.6729, Val 0.5999, Test 0.5292
Epoch 80:, Train 0.6746, Val 0.6013, Test 0.5305
Epoch 90:, Train 0.6816, Val 0.5975, Test 0.5277
Epoch 100:, Train 0.6830, Val 0.6027, Test 0.5336
Epoch 110:, Train 0.6831, Val 0.6016, Test 0.5404
Epoch 120:, Train 0.6860, Val 0.6020, Test 0.5308
Epoch 130:, Train 0.6846, Val 0.5995, Test 0.5342
Epoch 140:, Train 0.6868, Val 0.6064, Test 0.5461
Epoch 150:, Train 0.6918, Val 0.6037, Test 0.5360
Epoch 160:, Train 0.6922, Val 0.6016, Test 0.5393
Epoch 170:, Train 0.6907, Val 0.6082, Test 0.5411
Epoch 180:, Train 0.6928, Val 0.6054, Test 0.5453
Epoch 190:, Train 0.6950, Val 0.6075, Test 0.5414
Epoch 200:, Train 0.6957, Val 0.6059, Test 0.5407
BEST: Epoch 170, Train 0.6907, Val 0.6082, Test 0.5411

RUN #1: seed=4
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4851
Total Transformation Time: 0.8651
Epoch 10:, Train 0.6198, Val 0.5904, Test 0.5320
Epoch 20:, Train 0.6380, Val 0.6005, Test 0.5435
Epoch 30:, Train 0.6505, Val 0.5984, Test 0.5332
Epoch 40:, Train 0.6602, Val 0.6035, Test 0.5412
Epoch 50:, Train 0.6655, Val 0.5974, Test 0.5293
Epoch 60:, Train 0.6736, Val 0.6014, Test 0.5349
Epoch 70:, Train 0.6758, Val 0.6018, Test 0.5390
Epoch 80:, Train 0.6786, Val 0.6023, Test 0.5330
Epoch 90:, Train 0.6788, Val 0.6020, Test 0.5382
Epoch 100:, Train 0.6837, Val 0.6011, Test 0.5349
Epoch 110:, Train 0.6841, Val 0.6017, Test 0.5330
Epoch 120:, Train 0.6882, Val 0.6097, Test 0.5531
Epoch 130:, Train 0.6879, Val 0.6011, Test 0.5305
Epoch 140:, Train 0.6903, Val 0.6019, Test 0.5327
Epoch 150:, Train 0.6879, Val 0.6095, Test 0.5519
Epoch 160:, Train 0.6896, Val 0.6035, Test 0.5371
Epoch 170:, Train 0.6926, Val 0.6053, Test 0.5400
Epoch 180:, Train 0.6948, Val 0.6053, Test 0.5384
Epoch 190:, Train 0.6949, Val 0.6051, Test 0.5412
Epoch 200:, Train 0.6947, Val 0.6060, Test 0.5449
BEST: Epoch 120, Train 0.6882, Val 0.6097, Test 0.5531

RUN #2: seed=8
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4902
Total Transformation Time: 0.8686
Epoch 10:, Train 0.6214, Val 0.5904, Test 0.5292
Epoch 20:, Train 0.6358, Val 0.5971, Test 0.5423
Epoch 30:, Train 0.6464, Val 0.5984, Test 0.5373
Epoch 40:, Train 0.6595, Val 0.6055, Test 0.5459
Epoch 50:, Train 0.6640, Val 0.6004, Test 0.5435
Epoch 60:, Train 0.6704, Val 0.6011, Test 0.5352
Epoch 70:, Train 0.6730, Val 0.6039, Test 0.5431
Epoch 80:, Train 0.6775, Val 0.6035, Test 0.5346
Epoch 90:, Train 0.6818, Val 0.6078, Test 0.5451
Epoch 100:, Train 0.6835, Val 0.6047, Test 0.5439
Epoch 110:, Train 0.6853, Val 0.6059, Test 0.5399
Epoch 120:, Train 0.6890, Val 0.6051, Test 0.5434
Epoch 130:, Train 0.6896, Val 0.6058, Test 0.5375
Epoch 140:, Train 0.6873, Val 0.6040, Test 0.5357
Epoch 150:, Train 0.6916, Val 0.6016, Test 0.5352
Epoch 160:, Train 0.6944, Val 0.6054, Test 0.5343
Epoch 170:, Train 0.6914, Val 0.6023, Test 0.5353
Epoch 180:, Train 0.6939, Val 0.6042, Test 0.5437
Epoch 190:, Train 0.6942, Val 0.6076, Test 0.5478
Epoch 200:, Train 0.6904, Val 0.6007, Test 0.5253
BEST: Epoch 90, Train 0.6818, Val 0.6078, Test 0.5451

RUN #3: seed=42
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4870
Total Transformation Time: 0.8648
Epoch 10:, Train 0.6217, Val 0.5941, Test 0.5353
Epoch 20:, Train 0.6368, Val 0.5923, Test 0.5246
Epoch 30:, Train 0.6505, Val 0.6022, Test 0.5400
Epoch 40:, Train 0.6575, Val 0.5988, Test 0.5372
Epoch 50:, Train 0.6620, Val 0.6002, Test 0.5392
Epoch 60:, Train 0.6689, Val 0.6040, Test 0.5417
Epoch 70:, Train 0.6743, Val 0.6012, Test 0.5360
Epoch 80:, Train 0.6748, Val 0.5972, Test 0.5253
Epoch 90:, Train 0.6811, Val 0.6053, Test 0.5438
Epoch 100:, Train 0.6841, Val 0.6042, Test 0.5391
Epoch 110:, Train 0.6882, Val 0.6090, Test 0.5426
Epoch 120:, Train 0.6881, Val 0.6089, Test 0.5467
Epoch 130:, Train 0.6884, Val 0.6066, Test 0.5418
Epoch 140:, Train 0.6901, Val 0.6061, Test 0.5447
Epoch 150:, Train 0.6903, Val 0.6058, Test 0.5450
Epoch 160:, Train 0.6918, Val 0.6030, Test 0.5388
Epoch 170:, Train 0.6934, Val 0.6090, Test 0.5487
Epoch 180:, Train 0.6942, Val 0.6041, Test 0.5362
Epoch 190:, Train 0.6926, Val 0.6043, Test 0.5369
Epoch 200:, Train 0.6950, Val 0.6073, Test 0.5475
BEST: Epoch 110, Train 0.6882, Val 0.6090, Test 0.5426

RUN #4: seed=64
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4917
Total Transformation Time: 0.8714
Epoch 10:, Train 0.6210, Val 0.5931, Test 0.5418
Epoch 20:, Train 0.6372, Val 0.5905, Test 0.5186
Epoch 30:, Train 0.6473, Val 0.5987, Test 0.5493
Epoch 40:, Train 0.6565, Val 0.5994, Test 0.5332
Epoch 50:, Train 0.6637, Val 0.5957, Test 0.5241
Epoch 60:, Train 0.6686, Val 0.5962, Test 0.5287
Epoch 70:, Train 0.6745, Val 0.5984, Test 0.5362
Epoch 80:, Train 0.6800, Val 0.6050, Test 0.5460
Epoch 90:, Train 0.6826, Val 0.6015, Test 0.5369
Epoch 100:, Train 0.6791, Val 0.6002, Test 0.5320
Epoch 110:, Train 0.6868, Val 0.6080, Test 0.5461
Epoch 120:, Train 0.6866, Val 0.6052, Test 0.5441
Epoch 130:, Train 0.6867, Val 0.6045, Test 0.5424
Epoch 140:, Train 0.6863, Val 0.6042, Test 0.5331
Epoch 150:, Train 0.6926, Val 0.6016, Test 0.5344
Epoch 160:, Train 0.6918, Val 0.6066, Test 0.5440
Epoch 170:, Train 0.6901, Val 0.6035, Test 0.5407
Epoch 180:, Train 0.6938, Val 0.6058, Test 0.5363
Epoch 190:, Train 0.6933, Val 0.6016, Test 0.5364
Epoch 200:, Train 0.6954, Val 0.6071, Test 0.5395
BEST: Epoch 110, Train 0.6868, Val 0.6080, Test 0.5461

RUN #5: seed=128
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4873
Total Transformation Time: 0.8677
Epoch 10:, Train 0.6155, Val 0.5845, Test 0.5268
Epoch 20:, Train 0.6370, Val 0.5888, Test 0.5223
Epoch 30:, Train 0.6507, Val 0.5944, Test 0.5262
Epoch 40:, Train 0.6599, Val 0.5961, Test 0.5337
Epoch 50:, Train 0.6675, Val 0.6041, Test 0.5440
Epoch 60:, Train 0.6723, Val 0.6041, Test 0.5416
Epoch 70:, Train 0.6755, Val 0.5957, Test 0.5250
Epoch 80:, Train 0.6769, Val 0.6037, Test 0.5447
Epoch 90:, Train 0.6835, Val 0.6030, Test 0.5438
Epoch 100:, Train 0.6844, Val 0.6068, Test 0.5445
Epoch 110:, Train 0.6866, Val 0.6035, Test 0.5330
Epoch 120:, Train 0.6811, Val 0.6052, Test 0.5363
Epoch 130:, Train 0.6919, Val 0.6030, Test 0.5341
Epoch 140:, Train 0.6895, Val 0.6027, Test 0.5445
Epoch 150:, Train 0.6889, Val 0.6001, Test 0.5379
Epoch 160:, Train 0.6908, Val 0.6070, Test 0.5394
Epoch 170:, Train 0.6913, Val 0.6015, Test 0.5380
Epoch 180:, Train 0.6935, Val 0.6032, Test 0.5354
Epoch 190:, Train 0.6938, Val 0.6071, Test 0.5423
Epoch 200:, Train 0.6944, Val 0.6071, Test 0.5457
BEST: Epoch 200, Train 0.6944, Val 0.6071, Test 0.5457

RUN #6: seed=256
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4859
Total Transformation Time: 0.8662
Epoch 10:, Train 0.6195, Val 0.5845, Test 0.5191
Epoch 20:, Train 0.6368, Val 0.5942, Test 0.5319
Epoch 30:, Train 0.6512, Val 0.5966, Test 0.5325
Epoch 40:, Train 0.6600, Val 0.6041, Test 0.5418
Epoch 50:, Train 0.6652, Val 0.5974, Test 0.5259
Epoch 60:, Train 0.6701, Val 0.6009, Test 0.5385
Epoch 70:, Train 0.6740, Val 0.6033, Test 0.5373
Epoch 80:, Train 0.6756, Val 0.6011, Test 0.5324
Epoch 90:, Train 0.6822, Val 0.6024, Test 0.5358
Epoch 100:, Train 0.6829, Val 0.6037, Test 0.5403
Epoch 110:, Train 0.6868, Val 0.6066, Test 0.5414
Epoch 120:, Train 0.6848, Val 0.6024, Test 0.5302
Epoch 130:, Train 0.6875, Val 0.6058, Test 0.5432
Epoch 140:, Train 0.6909, Val 0.6032, Test 0.5421
Epoch 150:, Train 0.6897, Val 0.6058, Test 0.5390
Epoch 160:, Train 0.6917, Val 0.6029, Test 0.5344
Epoch 170:, Train 0.6940, Val 0.6060, Test 0.5411
Epoch 180:, Train 0.6925, Val 0.6070, Test 0.5472
Epoch 190:, Train 0.6962, Val 0.6035, Test 0.5329
Epoch 200:, Train 0.6951, Val 0.6074, Test 0.5411
BEST: Epoch 200, Train 0.6951, Val 0.6074, Test 0.5411

RUN #7: seed=512
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4879
Total Transformation Time: 0.8640
Epoch 10:, Train 0.6198, Val 0.5882, Test 0.5317
Epoch 20:, Train 0.6382, Val 0.5910, Test 0.5215
Epoch 30:, Train 0.6449, Val 0.5976, Test 0.5339
Epoch 40:, Train 0.6596, Val 0.6051, Test 0.5400
Epoch 50:, Train 0.6651, Val 0.6044, Test 0.5409
Epoch 60:, Train 0.6708, Val 0.6035, Test 0.5419
Epoch 70:, Train 0.6749, Val 0.6028, Test 0.5332
Epoch 80:, Train 0.6756, Val 0.5938, Test 0.5334
Epoch 90:, Train 0.6806, Val 0.5965, Test 0.5374
Epoch 100:, Train 0.6837, Val 0.6056, Test 0.5419
Epoch 110:, Train 0.6825, Val 0.6097, Test 0.5444
Epoch 120:, Train 0.6854, Val 0.6077, Test 0.5440
Epoch 130:, Train 0.6882, Val 0.6039, Test 0.5355
Epoch 140:, Train 0.6904, Val 0.5987, Test 0.5340
Epoch 150:, Train 0.6899, Val 0.6069, Test 0.5387
Epoch 160:, Train 0.6940, Val 0.6080, Test 0.5464
Epoch 170:, Train 0.6927, Val 0.6040, Test 0.5398
Epoch 180:, Train 0.6950, Val 0.6035, Test 0.5377
Epoch 190:, Train 0.6949, Val 0.6047, Test 0.5405
Epoch 200:, Train 0.6938, Val 0.6058, Test 0.5388
BEST: Epoch 110, Train 0.6825, Val 0.6097, Test 0.5444

RUN #8: seed=1024
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4895
Total Transformation Time: 0.8601
Epoch 10:, Train 0.6203, Val 0.5941, Test 0.5369
Epoch 20:, Train 0.6372, Val 0.5896, Test 0.5216
Epoch 30:, Train 0.6509, Val 0.6058, Test 0.5480
Epoch 40:, Train 0.6594, Val 0.6000, Test 0.5301
Epoch 50:, Train 0.6660, Val 0.6070, Test 0.5443
Epoch 60:, Train 0.6684, Val 0.5965, Test 0.5257
Epoch 70:, Train 0.6762, Val 0.6080, Test 0.5434
Epoch 80:, Train 0.6782, Val 0.6016, Test 0.5317
Epoch 90:, Train 0.6808, Val 0.6029, Test 0.5345
Epoch 100:, Train 0.6834, Val 0.6058, Test 0.5416
Epoch 110:, Train 0.6832, Val 0.6020, Test 0.5349
Epoch 120:, Train 0.6843, Val 0.6000, Test 0.5287
Epoch 130:, Train 0.6892, Val 0.6054, Test 0.5383
Epoch 140:, Train 0.6904, Val 0.6031, Test 0.5374
Epoch 150:, Train 0.6917, Val 0.6028, Test 0.5301
Epoch 160:, Train 0.6950, Val 0.6067, Test 0.5413
Epoch 170:, Train 0.6930, Val 0.6059, Test 0.5385
Epoch 180:, Train 0.6936, Val 0.6067, Test 0.5405
Epoch 190:, Train 0.6975, Val 0.6044, Test 0.5430
Epoch 200:, Train 0.6964, Val 0.6082, Test 0.5502
BEST: Epoch 200, Train 0.6964, Val 0.6082, Test 0.5502

RUN #9: seed=2048
SIGN
Attention Filter (n=1166243): 1.000 +\- 0.000 [1.000-1.000]
Filter Time: 0.0000
Diffusion Time: 0.4936
Total Transformation Time: 0.8671
Epoch 10:, Train 0.6219, Val 0.5905, Test 0.5253
Epoch 20:, Train 0.6390, Val 0.5982, Test 0.5412
Epoch 30:, Train 0.6503, Val 0.5969, Test 0.5397
Epoch 40:, Train 0.6604, Val 0.5934, Test 0.5185
Epoch 50:, Train 0.6668, Val 0.5997, Test 0.5400
Epoch 60:, Train 0.6714, Val 0.6045, Test 0.5429
Epoch 70:, Train 0.6761, Val 0.6056, Test 0.5408
Epoch 80:, Train 0.6787, Val 0.6027, Test 0.5316
Epoch 90:, Train 0.6775, Val 0.6014, Test 0.5324
Epoch 100:, Train 0.6850, Val 0.6011, Test 0.5350
Epoch 110:, Train 0.6853, Val 0.6061, Test 0.5467
Epoch 120:, Train 0.6868, Val 0.6032, Test 0.5463
Epoch 130:, Train 0.6909, Val 0.6067, Test 0.5392
Epoch 140:, Train 0.6897, Val 0.6010, Test 0.5391
Epoch 150:, Train 0.6907, Val 0.6026, Test 0.5393
Epoch 160:, Train 0.6948, Val 0.6087, Test 0.5484
Epoch 170:, Train 0.6938, Val 0.6057, Test 0.5373
Epoch 180:, Train 0.6943, Val 0.6029, Test 0.5408
Epoch 190:, Train 0.6961, Val 0.6028, Test 0.5412
Epoch 200:, Train 0.6900, Val 0.6039, Test 0.5386
BEST: Epoch 160, Train 0.6948, Val 0.6087, Test 0.5484




==================================================
Model Parameters: 531885

Avg. Filter Time (s): 0.0000 +/- 0.0000
Avg. Diffusion Time (s): 0.4892 +/- 0.0029
Avg. Preaggregation Time (s): 0.8688 +/- 0.0085
Avg. Training Time (epoch) (s): 1.1078 +/- 0.0885
Avg. Inference Time (s): 0.0767 +/- 0.0121

Avg. Training Acc: 0.6899 +/- 0.0050
Avg. Validation Acc: 0.6084 +/- 0.0008
Avg. Test Acc: 0.5458 +/- 0.0037

==================================================

==================================================
================= SIGN+CS ========================
==================================================
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='cosine', EPOCHS=200, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.001, INCEPTION_LAYERS=1, INCEPTION_UNITS=128, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=2, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.693e-05
convert to csr_matrix: 0.02553
calc min-max per row: 0.03578
vectorization: 0.02124
Total Normalization: 0.0995
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.7470
Diffusion Time: 0.4418
Total Transformation Time: 2.5679
Epoch 10:, Train 0.6011, Val 0.6020, Test 0.5569
Epoch 20:, Train 0.6243, Val 0.6111, Test 0.5632
Epoch 30:, Train 0.6363, Val 0.6139, Test 0.5610
Epoch 40:, Train 0.6455, Val 0.6178, Test 0.5687
Epoch 50:, Train 0.6500, Val 0.6231, Test 0.5765
Epoch 60:, Train 0.6549, Val 0.6210, Test 0.5733
Epoch 70:, Train 0.6554, Val 0.6209, Test 0.5703
Epoch 80:, Train 0.6603, Val 0.6232, Test 0.5708
Epoch 90:, Train 0.6605, Val 0.6182, Test 0.5628
Epoch 100:, Train 0.6626, Val 0.6223, Test 0.5677
Epoch 110:, Train 0.6683, Val 0.6259, Test 0.5763
Epoch 120:, Train 0.6676, Val 0.6205, Test 0.5674
Epoch 130:, Train 0.6686, Val 0.6245, Test 0.5738
Epoch 140:, Train 0.6663, Val 0.6187, Test 0.5669
Epoch 150:, Train 0.6686, Val 0.6218, Test 0.5673
Epoch 160:, Train 0.6695, Val 0.6301, Test 0.5768
Epoch 170:, Train 0.6707, Val 0.6273, Test 0.5757
Epoch 180:, Train 0.6673, Val 0.6233, Test 0.5733
Epoch 190:, Train 0.6712, Val 0.6192, Test 0.5615
Epoch 200:, Train 0.6739, Val 0.6295, Test 0.5855
BEST: Epoch 160, Train 0.6695, Val 0.6301, Test 0.5768

RUN #1: seed=4
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.502e-05
convert to csr_matrix: 0.02433
calc min-max per row: 0.03361
vectorization: 0.02036
Total Normalization: 0.0947
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.6984
Diffusion Time: 0.4381
Total Transformation Time: 2.5048
Epoch 10:, Train 0.6047, Val 0.6081, Test 0.5658
Epoch 20:, Train 0.6249, Val 0.6195, Test 0.5722
Epoch 30:, Train 0.6359, Val 0.6155, Test 0.5636
Epoch 40:, Train 0.6444, Val 0.6162, Test 0.5619
Epoch 50:, Train 0.6524, Val 0.6225, Test 0.5714
Epoch 60:, Train 0.6540, Val 0.6157, Test 0.5591
Epoch 70:, Train 0.6603, Val 0.6198, Test 0.5689
Epoch 80:, Train 0.6633, Val 0.6244, Test 0.5715
Epoch 90:, Train 0.6635, Val 0.6212, Test 0.5707
Epoch 100:, Train 0.6690, Val 0.6245, Test 0.5714
Epoch 110:, Train 0.6674, Val 0.6210, Test 0.5661
Epoch 120:, Train 0.6690, Val 0.6231, Test 0.5739
Epoch 130:, Train 0.6694, Val 0.6249, Test 0.5730
Epoch 140:, Train 0.6700, Val 0.6267, Test 0.5745
Epoch 150:, Train 0.6725, Val 0.6239, Test 0.5729
Epoch 160:, Train 0.6700, Val 0.6247, Test 0.5736
Epoch 170:, Train 0.6732, Val 0.6265, Test 0.5745
Epoch 180:, Train 0.6746, Val 0.6196, Test 0.5672
Epoch 190:, Train 0.6736, Val 0.6242, Test 0.5717
Epoch 200:, Train 0.6737, Val 0.6264, Test 0.5723
BEST: Epoch 140, Train 0.6700, Val 0.6267, Test 0.5745

RUN #2: seed=8
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.788e-05
convert to csr_matrix: 0.02469
calc min-max per row: 0.03409
vectorization: 0.02042
Total Normalization: 0.0951
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.7098
Diffusion Time: 0.4355
Total Transformation Time: 2.5123
Epoch 10:, Train 0.6064, Val 0.6070, Test 0.5616
Epoch 20:, Train 0.6224, Val 0.6139, Test 0.5725
Epoch 30:, Train 0.6353, Val 0.6206, Test 0.5780
Epoch 40:, Train 0.6400, Val 0.6178, Test 0.5710
Epoch 50:, Train 0.6475, Val 0.6214, Test 0.5770
Epoch 60:, Train 0.6563, Val 0.6275, Test 0.5709
Epoch 70:, Train 0.6555, Val 0.6167, Test 0.5633
Epoch 80:, Train 0.6605, Val 0.6209, Test 0.5654
Epoch 90:, Train 0.6614, Val 0.6240, Test 0.5681
Epoch 100:, Train 0.6673, Val 0.6274, Test 0.5795
Epoch 110:, Train 0.6674, Val 0.6210, Test 0.5639
Epoch 120:, Train 0.6687, Val 0.6280, Test 0.5786
Epoch 130:, Train 0.6685, Val 0.6215, Test 0.5611
Epoch 140:, Train 0.6629, Val 0.6242, Test 0.5700
Epoch 150:, Train 0.6678, Val 0.6225, Test 0.5721
Epoch 160:, Train 0.6694, Val 0.6176, Test 0.5631
Epoch 170:, Train 0.6701, Val 0.6223, Test 0.5628
Epoch 180:, Train 0.6724, Val 0.6232, Test 0.5679
Epoch 190:, Train 0.6744, Val 0.6281, Test 0.5845
Epoch 200:, Train 0.6720, Val 0.6236, Test 0.5639
BEST: Epoch 190, Train 0.6744, Val 0.6281, Test 0.5845

RUN #3: seed=42
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.669e-05
convert to csr_matrix: 0.02459
calc min-max per row: 0.0336
vectorization: 0.02077
Total Normalization: 0.0952
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.7007
Diffusion Time: 0.4401
Total Transformation Time: 2.5084
Epoch 10:, Train 0.6064, Val 0.6096, Test 0.5654
Epoch 20:, Train 0.6216, Val 0.6095, Test 0.5572
Epoch 30:, Train 0.6376, Val 0.6197, Test 0.5688
Epoch 40:, Train 0.6472, Val 0.6132, Test 0.5579
Epoch 50:, Train 0.6504, Val 0.6195, Test 0.5687
Epoch 60:, Train 0.6524, Val 0.6203, Test 0.5726
Epoch 70:, Train 0.6607, Val 0.6222, Test 0.5753
Epoch 80:, Train 0.6586, Val 0.6169, Test 0.5622
Epoch 90:, Train 0.6634, Val 0.6226, Test 0.5746
Epoch 100:, Train 0.6653, Val 0.6207, Test 0.5682
Epoch 110:, Train 0.6645, Val 0.6264, Test 0.5724
Epoch 120:, Train 0.6671, Val 0.6288, Test 0.5866
Epoch 130:, Train 0.6664, Val 0.6189, Test 0.5695
Epoch 140:, Train 0.6731, Val 0.6271, Test 0.5803
Epoch 150:, Train 0.6734, Val 0.6296, Test 0.5814
Epoch 160:, Train 0.6671, Val 0.6211, Test 0.5670
Epoch 170:, Train 0.6715, Val 0.6232, Test 0.5750
Epoch 180:, Train 0.6738, Val 0.6208, Test 0.5662
Epoch 190:, Train 0.6719, Val 0.6230, Test 0.5662
Epoch 200:, Train 0.6715, Val 0.6226, Test 0.5663
BEST: Epoch 150, Train 0.6734, Val 0.6296, Test 0.5814

RUN #4: seed=64
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.431e-05
convert to csr_matrix: 0.02415
calc min-max per row: 0.03359
vectorization: 0.02053
Total Normalization: 0.0943
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.7110
Diffusion Time: 0.4368
Total Transformation Time: 2.5153
Epoch 10:, Train 0.6050, Val 0.6072, Test 0.5676
Epoch 20:, Train 0.6235, Val 0.6077, Test 0.5558
Epoch 30:, Train 0.6330, Val 0.6149, Test 0.5668
Epoch 40:, Train 0.6426, Val 0.6221, Test 0.5743
Epoch 50:, Train 0.6509, Val 0.6212, Test 0.5704
Epoch 60:, Train 0.6538, Val 0.6235, Test 0.5721
Epoch 70:, Train 0.6617, Val 0.6214, Test 0.5718
Epoch 80:, Train 0.6615, Val 0.6248, Test 0.5690
Epoch 90:, Train 0.6623, Val 0.6193, Test 0.5624
Epoch 100:, Train 0.6626, Val 0.6172, Test 0.5695
Epoch 110:, Train 0.6675, Val 0.6247, Test 0.5781
Epoch 120:, Train 0.6681, Val 0.6238, Test 0.5746
Epoch 130:, Train 0.6693, Val 0.6212, Test 0.5679
Epoch 140:, Train 0.6702, Val 0.6254, Test 0.5773
Epoch 150:, Train 0.6730, Val 0.6265, Test 0.5760
Epoch 160:, Train 0.6719, Val 0.6211, Test 0.5664
Epoch 170:, Train 0.6719, Val 0.6210, Test 0.5726
Epoch 180:, Train 0.6708, Val 0.6259, Test 0.5745
Epoch 190:, Train 0.6715, Val 0.6210, Test 0.5608
Epoch 200:, Train 0.6744, Val 0.6257, Test 0.5770
BEST: Epoch 150, Train 0.6730, Val 0.6265, Test 0.5760

RUN #5: seed=128
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.526e-05
convert to csr_matrix: 0.02452
calc min-max per row: 0.03404
vectorization: 0.02037
Total Normalization: 0.0953
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.6864
Diffusion Time: 0.4371
Total Transformation Time: 2.4907
Epoch 10:, Train 0.6014, Val 0.5995, Test 0.5610
Epoch 20:, Train 0.6202, Val 0.6066, Test 0.5624
Epoch 30:, Train 0.6335, Val 0.6117, Test 0.5678
Epoch 40:, Train 0.6455, Val 0.6170, Test 0.5635
Epoch 50:, Train 0.6483, Val 0.6210, Test 0.5815
Epoch 60:, Train 0.6547, Val 0.6245, Test 0.5757
Epoch 70:, Train 0.6577, Val 0.6261, Test 0.5774
Epoch 80:, Train 0.6583, Val 0.6211, Test 0.5712
Epoch 90:, Train 0.6648, Val 0.6258, Test 0.5844
Epoch 100:, Train 0.6635, Val 0.6200, Test 0.5680
Epoch 110:, Train 0.6683, Val 0.6229, Test 0.5714
Epoch 120:, Train 0.6658, Val 0.6240, Test 0.5741
Epoch 130:, Train 0.6709, Val 0.6240, Test 0.5715
Epoch 140:, Train 0.6669, Val 0.6239, Test 0.5767
Epoch 150:, Train 0.6696, Val 0.6220, Test 0.5720
Epoch 160:, Train 0.6715, Val 0.6185, Test 0.5623
Epoch 170:, Train 0.6726, Val 0.6220, Test 0.5737
Epoch 180:, Train 0.6733, Val 0.6247, Test 0.5830
Epoch 190:, Train 0.6734, Val 0.6234, Test 0.5783
Epoch 200:, Train 0.6718, Val 0.6224, Test 0.5788
BEST: Epoch 70, Train 0.6577, Val 0.6261, Test 0.5774

RUN #6: seed=256
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.574e-05
convert to csr_matrix: 0.02424
calc min-max per row: 0.03361
vectorization: 0.02046
Total Normalization: 0.0946
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.6998
Diffusion Time: 0.4370
Total Transformation Time: 2.5031
Epoch 10:, Train 0.6079, Val 0.6054, Test 0.5570
Epoch 20:, Train 0.6224, Val 0.6139, Test 0.5701
Epoch 30:, Train 0.6363, Val 0.6135, Test 0.5627
Epoch 40:, Train 0.6455, Val 0.6185, Test 0.5686
Epoch 50:, Train 0.6508, Val 0.6218, Test 0.5709
Epoch 60:, Train 0.6554, Val 0.6216, Test 0.5719
Epoch 70:, Train 0.6589, Val 0.6238, Test 0.5732
Epoch 80:, Train 0.6598, Val 0.6198, Test 0.5682
Epoch 90:, Train 0.6637, Val 0.6229, Test 0.5710
Epoch 100:, Train 0.6649, Val 0.6272, Test 0.5791
Epoch 110:, Train 0.6667, Val 0.6227, Test 0.5719
Epoch 120:, Train 0.6638, Val 0.6179, Test 0.5600
Epoch 130:, Train 0.6680, Val 0.6233, Test 0.5711
Epoch 140:, Train 0.6685, Val 0.6276, Test 0.5791
Epoch 150:, Train 0.6695, Val 0.6214, Test 0.5742
Epoch 160:, Train 0.6695, Val 0.6253, Test 0.5693
Epoch 170:, Train 0.6715, Val 0.6243, Test 0.5712
Epoch 180:, Train 0.6738, Val 0.6262, Test 0.5777
Epoch 190:, Train 0.6723, Val 0.6250, Test 0.5654
Epoch 200:, Train 0.6748, Val 0.6260, Test 0.5726
BEST: Epoch 140, Train 0.6685, Val 0.6276, Test 0.5791

RUN #7: seed=512
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.335e-05
convert to csr_matrix: 0.0239
calc min-max per row: 0.0335
vectorization: 0.02063
Total Normalization: 0.0938
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.7180
Diffusion Time: 0.4403
Total Transformation Time: 2.5245
Epoch 10:, Train 0.6037, Val 0.6063, Test 0.5659
Epoch 20:, Train 0.6252, Val 0.6048, Test 0.5480
Epoch 30:, Train 0.6314, Val 0.6159, Test 0.5628
Epoch 40:, Train 0.6405, Val 0.6169, Test 0.5684
Epoch 50:, Train 0.6507, Val 0.6247, Test 0.5792
Epoch 60:, Train 0.6553, Val 0.6198, Test 0.5615
Epoch 70:, Train 0.6584, Val 0.6243, Test 0.5691
Epoch 80:, Train 0.6617, Val 0.6268, Test 0.5791
Epoch 90:, Train 0.6626, Val 0.6183, Test 0.5614
Epoch 100:, Train 0.6633, Val 0.6211, Test 0.5650
Epoch 110:, Train 0.6645, Val 0.6215, Test 0.5708
Epoch 120:, Train 0.6680, Val 0.6261, Test 0.5735
Epoch 130:, Train 0.6700, Val 0.6288, Test 0.5772
Epoch 140:, Train 0.6691, Val 0.6257, Test 0.5754
Epoch 150:, Train 0.6733, Val 0.6203, Test 0.5665
Epoch 160:, Train 0.6748, Val 0.6280, Test 0.5780
Epoch 170:, Train 0.6730, Val 0.6292, Test 0.5796
Epoch 180:, Train 0.6726, Val 0.6255, Test 0.5720
Epoch 190:, Train 0.6731, Val 0.6223, Test 0.5665
Epoch 200:, Train 0.6721, Val 0.6260, Test 0.5743
BEST: Epoch 170, Train 0.6730, Val 0.6292, Test 0.5796

RUN #8: seed=1024
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.764e-05
convert to csr_matrix: 0.02469
calc min-max per row: 0.03365
vectorization: 0.02036
Total Normalization: 0.0945
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.6860
Diffusion Time: 0.4350
Total Transformation Time: 2.4876
Epoch 10:, Train 0.6035, Val 0.6093, Test 0.5719
Epoch 20:, Train 0.6210, Val 0.6091, Test 0.5585
Epoch 30:, Train 0.6352, Val 0.6200, Test 0.5791
Epoch 40:, Train 0.6464, Val 0.6234, Test 0.5698
Epoch 50:, Train 0.6528, Val 0.6229, Test 0.5717
Epoch 60:, Train 0.6516, Val 0.6190, Test 0.5735
Epoch 70:, Train 0.6574, Val 0.6260, Test 0.5868
Epoch 80:, Train 0.6604, Val 0.6225, Test 0.5751
Epoch 90:, Train 0.6638, Val 0.6212, Test 0.5706
Epoch 100:, Train 0.6649, Val 0.6226, Test 0.5745
Epoch 110:, Train 0.6650, Val 0.6188, Test 0.5653
Epoch 120:, Train 0.6693, Val 0.6222, Test 0.5700
Epoch 130:, Train 0.6682, Val 0.6213, Test 0.5669
Epoch 140:, Train 0.6671, Val 0.6223, Test 0.5735
Epoch 150:, Train 0.6691, Val 0.6191, Test 0.5666
Epoch 160:, Train 0.6767, Val 0.6251, Test 0.5718
Epoch 170:, Train 0.6696, Val 0.6263, Test 0.5706
Epoch 180:, Train 0.6683, Val 0.6238, Test 0.5733
Epoch 190:, Train 0.6730, Val 0.6245, Test 0.5745
Epoch 200:, Train 0.6722, Val 0.6258, Test 0.5824
BEST: Epoch 170, Train 0.6696, Val 0.6263, Test 0.5706

RUN #9: seed=2048
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.8158443570137024
coalesce scoo: 1.407e-05
convert to csr_matrix: 0.02414
calc min-max per row: 0.03354
vectorization: 0.02078
Total Normalization: 0.0945
COSINE
Attention Filter (n=1166243): 0.919 +\- 0.073 [0.303-1.000]
Filter Time: 1.6892
Diffusion Time: 0.4358
Total Transformation Time: 2.4898
Epoch 10:, Train 0.6064, Val 0.6069, Test 0.5672
Epoch 20:, Train 0.6267, Val 0.6189, Test 0.5779
Epoch 30:, Train 0.6354, Val 0.6160, Test 0.5733
Epoch 40:, Train 0.6402, Val 0.6174, Test 0.5669
Epoch 50:, Train 0.6505, Val 0.6214, Test 0.5796
Epoch 60:, Train 0.6550, Val 0.6217, Test 0.5681
Epoch 70:, Train 0.6585, Val 0.6238, Test 0.5754
Epoch 80:, Train 0.6598, Val 0.6236, Test 0.5702
Epoch 90:, Train 0.6643, Val 0.6247, Test 0.5731
Epoch 100:, Train 0.6657, Val 0.6242, Test 0.5708
Epoch 110:, Train 0.6671, Val 0.6258, Test 0.5784
Epoch 120:, Train 0.6674, Val 0.6235, Test 0.5744
Epoch 130:, Train 0.6697, Val 0.6214, Test 0.5653
Epoch 140:, Train 0.6690, Val 0.6174, Test 0.5653
Epoch 150:, Train 0.6675, Val 0.6163, Test 0.5561
Epoch 160:, Train 0.6707, Val 0.6267, Test 0.5811
Epoch 170:, Train 0.6742, Val 0.6284, Test 0.5789
Epoch 180:, Train 0.6724, Val 0.6179, Test 0.5640
Epoch 190:, Train 0.6726, Val 0.6243, Test 0.5747
Epoch 200:, Train 0.6715, Val 0.6222, Test 0.5737
BEST: Epoch 170, Train 0.6742, Val 0.6284, Test 0.5789




==================================================
Model Parameters: 531885

Avg. Filter Time (s): 1.7046 +/- 0.0174
Avg. Diffusion Time (s): 0.4377 +/- 0.0022
Avg. Preaggregation Time (s): 2.5104 +/- 0.0223
Avg. Training Time (epoch) (s): 1.1084 +/- 0.0862
Avg. Inference Time (s): 0.0765 +/- 0.0076

Avg. Training Acc: 0.6703 +/- 0.0047
Avg. Validation Acc: 0.6279 +/- 0.0014
Avg. Test Acc: 0.5779 +/- 0.0036

==================================================

==================================================
================= SIGN+SHA =======================
==================================================
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='dot_product', EPOCHS=200, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.001, INCEPTION_LAYERS=1, INCEPTION_UNITS=128, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=1, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5304709672927856
coalesce scoo: 1.025e-05
convert to csr_matrix: 0.02431
calc min-max per row: 0.03359
vectorization: 0.02042
Normalization Time: 0.0959
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.100 [0.256-1.000]
Filter Time: 1.1467
Diffusion Time: 0.4425
Total Transformation Time: 1.9876
Epoch 10:, Train 0.6074, Val 0.6058, Test 0.5588
Epoch 20:, Train 0.6250, Val 0.6102, Test 0.5590
Epoch 30:, Train 0.6361, Val 0.6155, Test 0.5664
Epoch 40:, Train 0.6464, Val 0.6239, Test 0.5741
Epoch 50:, Train 0.6509, Val 0.6226, Test 0.5727
Epoch 60:, Train 0.6525, Val 0.6162, Test 0.5638
Epoch 70:, Train 0.6567, Val 0.6255, Test 0.5794
Epoch 80:, Train 0.6641, Val 0.6226, Test 0.5711
Epoch 90:, Train 0.6619, Val 0.6216, Test 0.5687
Epoch 100:, Train 0.6665, Val 0.6217, Test 0.5681
Epoch 110:, Train 0.6652, Val 0.6264, Test 0.5760
Epoch 120:, Train 0.6681, Val 0.6212, Test 0.5691
Epoch 130:, Train 0.6691, Val 0.6217, Test 0.5674
Epoch 140:, Train 0.6713, Val 0.6280, Test 0.5746
Epoch 150:, Train 0.6725, Val 0.6240, Test 0.5730
Epoch 160:, Train 0.6709, Val 0.6275, Test 0.5762
Epoch 170:, Train 0.6772, Val 0.6230, Test 0.5675
Epoch 180:, Train 0.6741, Val 0.6249, Test 0.5669
Epoch 190:, Train 0.6741, Val 0.6222, Test 0.5693
Epoch 200:, Train 0.6741, Val 0.6243, Test 0.5725
BEST: Epoch 140, Train 0.6713, Val 0.6280, Test 0.5746

RUN #1: seed=4
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4955138564109802
coalesce scoo: 8.821e-06
convert to csr_matrix: 0.02407
calc min-max per row: 0.03375
vectorization: 0.0206
Normalization Time: 0.0938
DOT_PRODUCT
Attention Filter (n=1166243): 0.872 +\- 0.093 [0.203-1.000]
Filter Time: 1.0784
Diffusion Time: 0.4208
Total Transformation Time: 1.8632
Epoch 10:, Train 0.6041, Val 0.6111, Test 0.5748
Epoch 20:, Train 0.6234, Val 0.6098, Test 0.5627
Epoch 30:, Train 0.6360, Val 0.6146, Test 0.5642
Epoch 40:, Train 0.6445, Val 0.6159, Test 0.5654
Epoch 50:, Train 0.6477, Val 0.6216, Test 0.5752
Epoch 60:, Train 0.6535, Val 0.6206, Test 0.5676
Epoch 70:, Train 0.6577, Val 0.6218, Test 0.5731
Epoch 80:, Train 0.6593, Val 0.6138, Test 0.5628
Epoch 90:, Train 0.6630, Val 0.6160, Test 0.5620
Epoch 100:, Train 0.6660, Val 0.6209, Test 0.5623
Epoch 110:, Train 0.6655, Val 0.6248, Test 0.5755
Epoch 120:, Train 0.6700, Val 0.6218, Test 0.5686
Epoch 130:, Train 0.6661, Val 0.6182, Test 0.5602
Epoch 140:, Train 0.6669, Val 0.6182, Test 0.5673
Epoch 150:, Train 0.6712, Val 0.6266, Test 0.5745
Epoch 160:, Train 0.6697, Val 0.6277, Test 0.5835
Epoch 170:, Train 0.6716, Val 0.6218, Test 0.5711
Epoch 180:, Train 0.6728, Val 0.6250, Test 0.5745
Epoch 190:, Train 0.6756, Val 0.6211, Test 0.5674
Epoch 200:, Train 0.6711, Val 0.6187, Test 0.5685
BEST: Epoch 160, Train 0.6697, Val 0.6277, Test 0.5835

RUN #2: seed=8
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5231907963752747
coalesce scoo: 8.821e-06
convert to csr_matrix: 0.02446
calc min-max per row: 0.0336
vectorization: 0.0204
Normalization Time: 0.0939
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.210-1.000]
Filter Time: 1.0893
Diffusion Time: 0.4373
Total Transformation Time: 1.8861
Epoch 10:, Train 0.6016, Val 0.5962, Test 0.5474
Epoch 20:, Train 0.6219, Val 0.6142, Test 0.5704
Epoch 30:, Train 0.6376, Val 0.6156, Test 0.5646
Epoch 40:, Train 0.6443, Val 0.6205, Test 0.5733
Epoch 50:, Train 0.6489, Val 0.6210, Test 0.5707
Epoch 60:, Train 0.6549, Val 0.6248, Test 0.5679
Epoch 70:, Train 0.6592, Val 0.6203, Test 0.5673
Epoch 80:, Train 0.6610, Val 0.6217, Test 0.5674
Epoch 90:, Train 0.6608, Val 0.6236, Test 0.5783
Epoch 100:, Train 0.6643, Val 0.6212, Test 0.5678
Epoch 110:, Train 0.6635, Val 0.6195, Test 0.5675
Epoch 120:, Train 0.6668, Val 0.6242, Test 0.5736
Epoch 130:, Train 0.6692, Val 0.6246, Test 0.5743
Epoch 140:, Train 0.6708, Val 0.6239, Test 0.5700
Epoch 150:, Train 0.6727, Val 0.6202, Test 0.5636
Epoch 160:, Train 0.6710, Val 0.6243, Test 0.5764
Epoch 170:, Train 0.6692, Val 0.6205, Test 0.5736
Epoch 180:, Train 0.6716, Val 0.6270, Test 0.5784
Epoch 190:, Train 0.6745, Val 0.6256, Test 0.5751
Epoch 200:, Train 0.6709, Val 0.6231, Test 0.5732
BEST: Epoch 180, Train 0.6716, Val 0.6270, Test 0.5784

RUN #3: seed=42
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5119524598121643
coalesce scoo: 8.821e-06
convert to csr_matrix: 0.02362
calc min-max per row: 0.03352
vectorization: 0.0204
Normalization Time: 0.0924
DOT_PRODUCT
Attention Filter (n=1166243): 0.851 +\- 0.109 [0.270-1.000]
Filter Time: 1.0909
Diffusion Time: 0.4323
Total Transformation Time: 1.8897
Epoch 10:, Train 0.6027, Val 0.6052, Test 0.5646
Epoch 20:, Train 0.6240, Val 0.6112, Test 0.5723
Epoch 30:, Train 0.6360, Val 0.6139, Test 0.5676
Epoch 40:, Train 0.6424, Val 0.6171, Test 0.5619
Epoch 50:, Train 0.6487, Val 0.6217, Test 0.5762
Epoch 60:, Train 0.6564, Val 0.6165, Test 0.5621
Epoch 70:, Train 0.6581, Val 0.6228, Test 0.5722
Epoch 80:, Train 0.6570, Val 0.6202, Test 0.5684
Epoch 90:, Train 0.6625, Val 0.6227, Test 0.5686
Epoch 100:, Train 0.6638, Val 0.6239, Test 0.5749
Epoch 110:, Train 0.6652, Val 0.6239, Test 0.5730
Epoch 120:, Train 0.6674, Val 0.6255, Test 0.5805
Epoch 130:, Train 0.6680, Val 0.6245, Test 0.5763
Epoch 140:, Train 0.6714, Val 0.6299, Test 0.5898
Epoch 150:, Train 0.6691, Val 0.6212, Test 0.5636
Epoch 160:, Train 0.6695, Val 0.6283, Test 0.5782
Epoch 170:, Train 0.6727, Val 0.6207, Test 0.5685
Epoch 180:, Train 0.6747, Val 0.6275, Test 0.5818
Epoch 190:, Train 0.6692, Val 0.6227, Test 0.5613
Epoch 200:, Train 0.6739, Val 0.6210, Test 0.5729
BEST: Epoch 140, Train 0.6714, Val 0.6299, Test 0.5898

RUN #4: seed=64
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5308823585510254
coalesce scoo: 9.775e-06
convert to csr_matrix: 0.02418
calc min-max per row: 0.03374
vectorization: 0.02052
Normalization Time: 0.0949
DOT_PRODUCT
Attention Filter (n=1166243): 0.863 +\- 0.099 [0.275-1.000]
Filter Time: 1.0880
Diffusion Time: 0.4366
Total Transformation Time: 1.8974
Epoch 10:, Train 0.6038, Val 0.6056, Test 0.5639
Epoch 20:, Train 0.6229, Val 0.6163, Test 0.5720
Epoch 30:, Train 0.6404, Val 0.6224, Test 0.5698
Epoch 40:, Train 0.6456, Val 0.6154, Test 0.5661
Epoch 50:, Train 0.6541, Val 0.6235, Test 0.5700
Epoch 60:, Train 0.6530, Val 0.6213, Test 0.5712
Epoch 70:, Train 0.6571, Val 0.6262, Test 0.5814
Epoch 80:, Train 0.6602, Val 0.6194, Test 0.5619
Epoch 90:, Train 0.6637, Val 0.6279, Test 0.5778
Epoch 100:, Train 0.6681, Val 0.6268, Test 0.5755
Epoch 110:, Train 0.6680, Val 0.6258, Test 0.5707
Epoch 120:, Train 0.6692, Val 0.6231, Test 0.5734
Epoch 130:, Train 0.6678, Val 0.6260, Test 0.5744
Epoch 140:, Train 0.6715, Val 0.6254, Test 0.5752
Epoch 150:, Train 0.6709, Val 0.6249, Test 0.5759
Epoch 160:, Train 0.6723, Val 0.6216, Test 0.5653
Epoch 170:, Train 0.6678, Val 0.6202, Test 0.5682
Epoch 180:, Train 0.6756, Val 0.6228, Test 0.5682
Epoch 190:, Train 0.6725, Val 0.6265, Test 0.5758
Epoch 200:, Train 0.6740, Val 0.6216, Test 0.5664
BEST: Epoch 90, Train 0.6637, Val 0.6279, Test 0.5778

RUN #5: seed=128
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.48565471172332764
coalesce scoo: 9.298e-06
convert to csr_matrix: 0.02406
calc min-max per row: 0.03375
vectorization: 0.0205
Normalization Time: 0.0960
DOT_PRODUCT
Attention Filter (n=1166243): 0.876 +\- 0.092 [0.280-1.000]
Filter Time: 1.0939
Diffusion Time: 0.4390
Total Transformation Time: 1.9028
Epoch 10:, Train 0.6044, Val 0.6057, Test 0.5633
Epoch 20:, Train 0.6266, Val 0.6184, Test 0.5689
Epoch 30:, Train 0.6372, Val 0.6184, Test 0.5671
Epoch 40:, Train 0.6460, Val 0.6236, Test 0.5787
Epoch 50:, Train 0.6514, Val 0.6254, Test 0.5779
Epoch 60:, Train 0.6549, Val 0.6225, Test 0.5752
Epoch 70:, Train 0.6563, Val 0.6242, Test 0.5746
Epoch 80:, Train 0.6624, Val 0.6235, Test 0.5749
Epoch 90:, Train 0.6616, Val 0.6217, Test 0.5718
Epoch 100:, Train 0.6638, Val 0.6192, Test 0.5640
Epoch 110:, Train 0.6647, Val 0.6211, Test 0.5621
Epoch 120:, Train 0.6678, Val 0.6196, Test 0.5682
Epoch 130:, Train 0.6677, Val 0.6231, Test 0.5687
Epoch 140:, Train 0.6717, Val 0.6270, Test 0.5720
Epoch 150:, Train 0.6694, Val 0.6266, Test 0.5792
Epoch 160:, Train 0.6720, Val 0.6250, Test 0.5700
Epoch 170:, Train 0.6713, Val 0.6186, Test 0.5611
Epoch 180:, Train 0.6683, Val 0.6278, Test 0.5776
Epoch 190:, Train 0.6733, Val 0.6255, Test 0.5748
Epoch 200:, Train 0.6741, Val 0.6192, Test 0.5676
BEST: Epoch 180, Train 0.6683, Val 0.6278, Test 0.5776

RUN #6: seed=256
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5099418759346008
coalesce scoo: 9.298e-06
convert to csr_matrix: 0.02445
calc min-max per row: 0.03382
vectorization: 0.02045
Normalization Time: 0.0965
DOT_PRODUCT
Attention Filter (n=1166243): 0.864 +\- 0.098 [0.294-1.000]
Filter Time: 1.0983
Diffusion Time: 0.4378
Total Transformation Time: 1.9073
Epoch 10:, Train 0.6053, Val 0.6024, Test 0.5581
Epoch 20:, Train 0.6239, Val 0.6091, Test 0.5655
Epoch 30:, Train 0.6372, Val 0.6191, Test 0.5657
Epoch 40:, Train 0.6445, Val 0.6256, Test 0.5735
Epoch 50:, Train 0.6491, Val 0.6153, Test 0.5592
Epoch 60:, Train 0.6535, Val 0.6186, Test 0.5606
Epoch 70:, Train 0.6579, Val 0.6202, Test 0.5689
Epoch 80:, Train 0.6618, Val 0.6194, Test 0.5695
Epoch 90:, Train 0.6628, Val 0.6222, Test 0.5755
Epoch 100:, Train 0.6661, Val 0.6286, Test 0.5844
Epoch 110:, Train 0.6674, Val 0.6194, Test 0.5693
Epoch 120:, Train 0.6665, Val 0.6197, Test 0.5690
Epoch 130:, Train 0.6690, Val 0.6232, Test 0.5757
Epoch 140:, Train 0.6701, Val 0.6275, Test 0.5779
Epoch 150:, Train 0.6735, Val 0.6246, Test 0.5742
Epoch 160:, Train 0.6736, Val 0.6262, Test 0.5723
Epoch 170:, Train 0.6726, Val 0.6243, Test 0.5718
Epoch 180:, Train 0.6723, Val 0.6237, Test 0.5745
Epoch 190:, Train 0.6729, Val 0.6240, Test 0.5727
Epoch 200:, Train 0.6722, Val 0.6265, Test 0.5755
BEST: Epoch 100, Train 0.6661, Val 0.6286, Test 0.5844

RUN #7: seed=512
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5254026651382446
coalesce scoo: 7.153e-06
convert to csr_matrix: 0.02442
calc min-max per row: 0.03359
vectorization: 0.02047
Normalization Time: 0.0963
DOT_PRODUCT
Attention Filter (n=1166243): 0.858 +\- 0.102 [0.269-1.000]
Filter Time: 1.0946
Diffusion Time: 0.4387
Total Transformation Time: 1.9029
Epoch 10:, Train 0.6061, Val 0.6067, Test 0.5610
Epoch 20:, Train 0.6201, Val 0.6075, Test 0.5577
Epoch 30:, Train 0.6343, Val 0.6169, Test 0.5714
Epoch 40:, Train 0.6416, Val 0.6180, Test 0.5720
Epoch 50:, Train 0.6496, Val 0.6222, Test 0.5748
Epoch 60:, Train 0.6489, Val 0.6137, Test 0.5600
Epoch 70:, Train 0.6556, Val 0.6223, Test 0.5711
Epoch 80:, Train 0.6595, Val 0.6124, Test 0.5547
Epoch 90:, Train 0.6633, Val 0.6181, Test 0.5668
Epoch 100:, Train 0.6651, Val 0.6233, Test 0.5761
Epoch 110:, Train 0.6699, Val 0.6247, Test 0.5696
Epoch 120:, Train 0.6712, Val 0.6284, Test 0.5766
Epoch 130:, Train 0.6680, Val 0.6202, Test 0.5679
Epoch 140:, Train 0.6707, Val 0.6261, Test 0.5737
Epoch 150:, Train 0.6706, Val 0.6223, Test 0.5702
Epoch 160:, Train 0.6727, Val 0.6302, Test 0.5826
Epoch 170:, Train 0.6732, Val 0.6238, Test 0.5694
Epoch 180:, Train 0.6744, Val 0.6241, Test 0.5764
Epoch 190:, Train 0.6729, Val 0.6263, Test 0.5808
Epoch 200:, Train 0.6766, Val 0.6219, Test 0.5664
BEST: Epoch 160, Train 0.6727, Val 0.6302, Test 0.5826

RUN #8: seed=1024
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.45444992184638977
coalesce scoo: 7.153e-06
convert to csr_matrix: 0.02354
calc min-max per row: 0.03401
vectorization: 0.02047
Normalization Time: 0.0953
DOT_PRODUCT
Attention Filter (n=1166243): 0.866 +\- 0.097 [0.261-1.000]
Filter Time: 1.0914
Diffusion Time: 0.4387
Total Transformation Time: 1.9038
Epoch 10:, Train 0.5989, Val 0.5965, Test 0.5538
Epoch 20:, Train 0.6211, Val 0.6116, Test 0.5641
Epoch 30:, Train 0.6305, Val 0.6099, Test 0.5554
Epoch 40:, Train 0.6434, Val 0.6229, Test 0.5806
Epoch 50:, Train 0.6468, Val 0.6204, Test 0.5670
Epoch 60:, Train 0.6541, Val 0.6239, Test 0.5774
Epoch 70:, Train 0.6589, Val 0.6215, Test 0.5719
Epoch 80:, Train 0.6598, Val 0.6189, Test 0.5672
Epoch 90:, Train 0.6642, Val 0.6222, Test 0.5735
Epoch 100:, Train 0.6644, Val 0.6266, Test 0.5832
Epoch 110:, Train 0.6657, Val 0.6266, Test 0.5797
Epoch 120:, Train 0.6680, Val 0.6232, Test 0.5693
Epoch 130:, Train 0.6702, Val 0.6225, Test 0.5712
Epoch 140:, Train 0.6695, Val 0.6269, Test 0.5761
Epoch 150:, Train 0.6726, Val 0.6238, Test 0.5704
Epoch 160:, Train 0.6718, Val 0.6239, Test 0.5704
Epoch 170:, Train 0.6752, Val 0.6229, Test 0.5752
Epoch 180:, Train 0.6738, Val 0.6273, Test 0.5793
Epoch 190:, Train 0.6727, Val 0.6255, Test 0.5758
Epoch 200:, Train 0.6737, Val 0.6252, Test 0.5670
BEST: Epoch 180, Train 0.6738, Val 0.6273, Test 0.5793

RUN #9: seed=2048
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4948199987411499
coalesce scoo: 7.391e-06
convert to csr_matrix: 0.02414
calc min-max per row: 0.03483
vectorization: 0.02039
Normalization Time: 0.0957
DOT_PRODUCT
Attention Filter (n=1166243): 0.871 +\- 0.094 [0.242-1.000]
Filter Time: 1.0910
Diffusion Time: 0.4345
Total Transformation Time: 1.8996
Epoch 10:, Train 0.6038, Val 0.6051, Test 0.5640
Epoch 20:, Train 0.6253, Val 0.6156, Test 0.5636
Epoch 30:, Train 0.6279, Val 0.6125, Test 0.5692
Epoch 40:, Train 0.6423, Val 0.6166, Test 0.5654
Epoch 50:, Train 0.6513, Val 0.6243, Test 0.5796
Epoch 60:, Train 0.6545, Val 0.6133, Test 0.5543
Epoch 70:, Train 0.6586, Val 0.6133, Test 0.5595
Epoch 80:, Train 0.6629, Val 0.6205, Test 0.5704
Epoch 90:, Train 0.6622, Val 0.6244, Test 0.5727
Epoch 100:, Train 0.6653, Val 0.6231, Test 0.5703
Epoch 110:, Train 0.6669, Val 0.6221, Test 0.5693
Epoch 120:, Train 0.6690, Val 0.6238, Test 0.5665
Epoch 130:, Train 0.6693, Val 0.6282, Test 0.5768
Epoch 140:, Train 0.6698, Val 0.6281, Test 0.5788
Epoch 150:, Train 0.6701, Val 0.6241, Test 0.5683
Epoch 160:, Train 0.6703, Val 0.6269, Test 0.5820
Epoch 170:, Train 0.6721, Val 0.6259, Test 0.5747
Epoch 180:, Train 0.6772, Val 0.6294, Test 0.5780
Epoch 190:, Train 0.6743, Val 0.6280, Test 0.5800
Epoch 200:, Train 0.6756, Val 0.6296, Test 0.5818
BEST: Epoch 200, Train 0.6756, Val 0.6296, Test 0.5818




==================================================
Model Parameters: 531885

Avg. Filter Time (s): 1.0962 +/- 0.0175
Avg. Diffusion Time (s): 0.4358 +/- 0.0057
Avg. Preaggregation Time (s): 1.9040 +/- 0.0304
Avg. Training Time (epoch) (s): 1.1022 +/- 0.0844
Avg. Inference Time (s): 0.0767 +/- 0.0079

Avg. Training Acc: 0.6704 +/- 0.0034
Avg. Validation Acc: 0.6284 +/- 0.0011
Avg. Test Acc: 0.5810 +/- 0.0041

==================================================

==================================================
================= SIGN+MHA =======================
==================================================
Using backend: pytorch

===== ARXIV =====

Namespace(DATASET='arxiv', ATTN_FILTER='dot_product', EPOCHS=200, EVAL_EVERY=10, RUN_SEEDS=[0, 4, 8, 42, 64, 128, 256, 512, 1024, 2048], HOPS=2, BATCH_SIZE=2048, LEARNING_RATE=0.001, WEIGHT_DECAY=0.001, INCEPTION_LAYERS=1, INCEPTION_UNITS=128, CLASSIFICATION_LAYERS=3, CLASSIFICATION_UNITS=512, FEATURE_DROPOUT=0.1, NODE_DROPOUT=0.3, BATCH_NORMALIZATION=1, FILTER_BATCH_SIZE=100000, ATTN_HEADS=5, ATTN_NORMALIZATION=1, GAT_EPOCHS=10, GAT_BATCH_SIZE=1024, GAT_LEARNING_RATE=0.01, GAT_WEIGHT_DECAY=0.001, GAT_HIDDEN_UNITS=8, GAT_NODE_DROPOUT=0.6, GAT_LAYERS=2, GAT_HEADS_IN=8, GAT_HEADS_OUT=8, GAT_NEIGHBORS=150, GAT_LR_PATIENCE=5)

RUN #0: seed=0
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5139251947402954
coalesce scoo: 9.537e-06
convert to csr_matrix: 0.02446
calc min-max per row: 0.03364
vectorization: 0.02032
Normalization Time: 0.0941
DOT_PRODUCT
Attention Filter (n=1166243): 0.934 +\- 0.049 [0.563-1.000]
Filter Time: 5.2524
Diffusion Time: 0.4376
Total Transformation Time: 6.0688
Epoch 10:, Train 0.6004, Val 0.6008, Test 0.5586
Epoch 20:, Train 0.6229, Val 0.6115, Test 0.5581
Epoch 30:, Train 0.6364, Val 0.6212, Test 0.5704
Epoch 40:, Train 0.6446, Val 0.6188, Test 0.5718
Epoch 50:, Train 0.6511, Val 0.6175, Test 0.5694
Epoch 60:, Train 0.6523, Val 0.6232, Test 0.5735
Epoch 70:, Train 0.6596, Val 0.6239, Test 0.5744
Epoch 80:, Train 0.6613, Val 0.6184, Test 0.5660
Epoch 90:, Train 0.6641, Val 0.6221, Test 0.5719
Epoch 100:, Train 0.6644, Val 0.6202, Test 0.5635
Epoch 110:, Train 0.6650, Val 0.6260, Test 0.5785
Epoch 120:, Train 0.6665, Val 0.6177, Test 0.5628
Epoch 130:, Train 0.6684, Val 0.6239, Test 0.5718
Epoch 140:, Train 0.6717, Val 0.6261, Test 0.5747
Epoch 150:, Train 0.6714, Val 0.6212, Test 0.5713
Epoch 160:, Train 0.6704, Val 0.6210, Test 0.5668
Epoch 170:, Train 0.6720, Val 0.6258, Test 0.5730
Epoch 180:, Train 0.6730, Val 0.6269, Test 0.5683
Epoch 190:, Train 0.6726, Val 0.6228, Test 0.5688
Epoch 200:, Train 0.6733, Val 0.6272, Test 0.5723
BEST: Epoch 200, Train 0.6733, Val 0.6272, Test 0.5723

RUN #1: seed=4
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5025953054428101
coalesce scoo: 2.861e-05
convert to csr_matrix: 0.0263
calc min-max per row: 0.03385
vectorization: 0.0209
Normalization Time: 0.0954
DOT_PRODUCT
Attention Filter (n=1166243): 0.930 +\- 0.053 [0.569-1.000]
Filter Time: 5.2807
Diffusion Time: 0.4374
Total Transformation Time: 6.0796
Epoch 10:, Train 0.6043, Val 0.6077, Test 0.5642
Epoch 20:, Train 0.6242, Val 0.6091, Test 0.5571
Epoch 30:, Train 0.6334, Val 0.6073, Test 0.5519
Epoch 40:, Train 0.6441, Val 0.6207, Test 0.5700
Epoch 50:, Train 0.6500, Val 0.6241, Test 0.5734
Epoch 60:, Train 0.6554, Val 0.6209, Test 0.5705
Epoch 70:, Train 0.6590, Val 0.6188, Test 0.5632
Epoch 80:, Train 0.6614, Val 0.6213, Test 0.5684
Epoch 90:, Train 0.6621, Val 0.6272, Test 0.5797
Epoch 100:, Train 0.6644, Val 0.6230, Test 0.5707
Epoch 110:, Train 0.6669, Val 0.6208, Test 0.5673
Epoch 120:, Train 0.6700, Val 0.6223, Test 0.5705
Epoch 130:, Train 0.6699, Val 0.6271, Test 0.5743
Epoch 140:, Train 0.6703, Val 0.6243, Test 0.5719
Epoch 150:, Train 0.6710, Val 0.6257, Test 0.5726
Epoch 160:, Train 0.6704, Val 0.6249, Test 0.5695
Epoch 170:, Train 0.6719, Val 0.6245, Test 0.5668
Epoch 180:, Train 0.6751, Val 0.6247, Test 0.5786
Epoch 190:, Train 0.6758, Val 0.6264, Test 0.5749
Epoch 200:, Train 0.6747, Val 0.6234, Test 0.5684
BEST: Epoch 90, Train 0.6621, Val 0.6272, Test 0.5797

RUN #2: seed=8
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.491199254989624
coalesce scoo: 1.574e-05
convert to csr_matrix: 0.02457
calc min-max per row: 0.03349
vectorization: 0.02041
Normalization Time: 0.0951
DOT_PRODUCT
Attention Filter (n=1166243): 0.924 +\- 0.056 [0.536-1.000]
Filter Time: 5.1819
Diffusion Time: 0.4347
Total Transformation Time: 5.9791
Epoch 10:, Train 0.6021, Val 0.6070, Test 0.5642
Epoch 20:, Train 0.6243, Val 0.6136, Test 0.5657
Epoch 30:, Train 0.6389, Val 0.6140, Test 0.5601
Epoch 40:, Train 0.6435, Val 0.6210, Test 0.5776
Epoch 50:, Train 0.6488, Val 0.6131, Test 0.5568
Epoch 60:, Train 0.6538, Val 0.6220, Test 0.5766
Epoch 70:, Train 0.6555, Val 0.6201, Test 0.5736
Epoch 80:, Train 0.6610, Val 0.6168, Test 0.5620
Epoch 90:, Train 0.6603, Val 0.6244, Test 0.5788
Epoch 100:, Train 0.6628, Val 0.6202, Test 0.5693
Epoch 110:, Train 0.6671, Val 0.6213, Test 0.5753
Epoch 120:, Train 0.6699, Val 0.6243, Test 0.5717
Epoch 130:, Train 0.6698, Val 0.6232, Test 0.5708
Epoch 140:, Train 0.6691, Val 0.6218, Test 0.5695
Epoch 150:, Train 0.6732, Val 0.6221, Test 0.5639
Epoch 160:, Train 0.6726, Val 0.6309, Test 0.5836
Epoch 170:, Train 0.6728, Val 0.6242, Test 0.5765
Epoch 180:, Train 0.6709, Val 0.6247, Test 0.5730
Epoch 190:, Train 0.6724, Val 0.6246, Test 0.5726
Epoch 200:, Train 0.6736, Val 0.6254, Test 0.5762
BEST: Epoch 160, Train 0.6726, Val 0.6309, Test 0.5836

RUN #3: seed=42
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4875534474849701
coalesce scoo: 1.502e-05
convert to csr_matrix: 0.02375
calc min-max per row: 0.03404
vectorization: 0.02037
Normalization Time: 0.0931
DOT_PRODUCT
Attention Filter (n=1166243): 0.927 +\- 0.055 [0.507-1.000]
Filter Time: 5.1418
Diffusion Time: 0.4245
Total Transformation Time: 5.9279
Epoch 10:, Train 0.6068, Val 0.6082, Test 0.5623
Epoch 20:, Train 0.6250, Val 0.6186, Test 0.5817
Epoch 30:, Train 0.6333, Val 0.6151, Test 0.5691
Epoch 40:, Train 0.6462, Val 0.6222, Test 0.5715
Epoch 50:, Train 0.6545, Val 0.6203, Test 0.5727
Epoch 60:, Train 0.6560, Val 0.6195, Test 0.5598
Epoch 70:, Train 0.6578, Val 0.6185, Test 0.5621
Epoch 80:, Train 0.6619, Val 0.6248, Test 0.5727
Epoch 90:, Train 0.6643, Val 0.6217, Test 0.5714
Epoch 100:, Train 0.6632, Val 0.6156, Test 0.5617
Epoch 110:, Train 0.6661, Val 0.6231, Test 0.5700
Epoch 120:, Train 0.6686, Val 0.6171, Test 0.5602
Epoch 130:, Train 0.6697, Val 0.6268, Test 0.5741
Epoch 140:, Train 0.6679, Val 0.6239, Test 0.5764
Epoch 150:, Train 0.6700, Val 0.6263, Test 0.5739
Epoch 160:, Train 0.6737, Val 0.6268, Test 0.5730
Epoch 170:, Train 0.6735, Val 0.6243, Test 0.5668
Epoch 180:, Train 0.6728, Val 0.6261, Test 0.5766
Epoch 190:, Train 0.6752, Val 0.6257, Test 0.5725
Epoch 200:, Train 0.6740, Val 0.6199, Test 0.5657
BEST: Epoch 130, Train 0.6697, Val 0.6268, Test 0.5741

RUN #4: seed=64
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.544205904006958
coalesce scoo: 1.907e-05
convert to csr_matrix: 0.02362
calc min-max per row: 0.03355
vectorization: 0.02047
Normalization Time: 0.0936
DOT_PRODUCT
Attention Filter (n=1166243): 0.929 +\- 0.052 [0.512-1.000]
Filter Time: 5.1341
Diffusion Time: 0.4246
Total Transformation Time: 5.9215
Epoch 10:, Train 0.6063, Val 0.6075, Test 0.5608
Epoch 20:, Train 0.6261, Val 0.6139, Test 0.5605
Epoch 30:, Train 0.6353, Val 0.6209, Test 0.5728
Epoch 40:, Train 0.6425, Val 0.6175, Test 0.5691
Epoch 50:, Train 0.6502, Val 0.6183, Test 0.5730
Epoch 60:, Train 0.6547, Val 0.6262, Test 0.5710
Epoch 70:, Train 0.6592, Val 0.6249, Test 0.5794
Epoch 80:, Train 0.6609, Val 0.6269, Test 0.5770
Epoch 90:, Train 0.6630, Val 0.6219, Test 0.5743
Epoch 100:, Train 0.6587, Val 0.6211, Test 0.5748
Epoch 110:, Train 0.6641, Val 0.6206, Test 0.5673
Epoch 120:, Train 0.6703, Val 0.6253, Test 0.5708
Epoch 130:, Train 0.6691, Val 0.6225, Test 0.5763
Epoch 140:, Train 0.6719, Val 0.6204, Test 0.5603
Epoch 150:, Train 0.6710, Val 0.6211, Test 0.5663
Epoch 160:, Train 0.6722, Val 0.6235, Test 0.5733
Epoch 170:, Train 0.6757, Val 0.6247, Test 0.5699
Epoch 180:, Train 0.6733, Val 0.6236, Test 0.5711
Epoch 190:, Train 0.6720, Val 0.6281, Test 0.5742
Epoch 200:, Train 0.6750, Val 0.6283, Test 0.5747
BEST: Epoch 200, Train 0.6750, Val 0.6283, Test 0.5747

RUN #5: seed=128
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.5031800270080566
coalesce scoo: 1.836e-05
convert to csr_matrix: 0.02422
calc min-max per row: 0.03366
vectorization: 0.02041
Normalization Time: 0.0934
DOT_PRODUCT
Attention Filter (n=1166243): 0.918 +\- 0.064 [0.530-1.000]
Filter Time: 5.1848
Diffusion Time: 0.4410
Total Transformation Time: 5.9942
Epoch 10:, Train 0.6060, Val 0.6067, Test 0.5679
Epoch 20:, Train 0.6247, Val 0.6129, Test 0.5647
Epoch 30:, Train 0.6353, Val 0.6111, Test 0.5582
Epoch 40:, Train 0.6427, Val 0.6183, Test 0.5708
Epoch 50:, Train 0.6503, Val 0.6183, Test 0.5607
Epoch 60:, Train 0.6565, Val 0.6224, Test 0.5689
Epoch 70:, Train 0.6612, Val 0.6179, Test 0.5652
Epoch 80:, Train 0.6571, Val 0.6190, Test 0.5655
Epoch 90:, Train 0.6618, Val 0.6221, Test 0.5685
Epoch 100:, Train 0.6659, Val 0.6250, Test 0.5752
Epoch 110:, Train 0.6642, Val 0.6199, Test 0.5658
Epoch 120:, Train 0.6678, Val 0.6249, Test 0.5718
Epoch 130:, Train 0.6690, Val 0.6228, Test 0.5701
Epoch 140:, Train 0.6715, Val 0.6189, Test 0.5603
Epoch 150:, Train 0.6709, Val 0.6256, Test 0.5786
Epoch 160:, Train 0.6742, Val 0.6263, Test 0.5740
Epoch 170:, Train 0.6715, Val 0.6184, Test 0.5572
Epoch 180:, Train 0.6725, Val 0.6226, Test 0.5700
Epoch 190:, Train 0.6714, Val 0.6251, Test 0.5711
Epoch 200:, Train 0.6756, Val 0.6278, Test 0.5780
BEST: Epoch 200, Train 0.6756, Val 0.6278, Test 0.5780

RUN #6: seed=256
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4769839346408844
coalesce scoo: 1.836e-05
convert to csr_matrix: 0.02424
calc min-max per row: 0.03355
vectorization: 0.02052
Normalization Time: 0.0945
DOT_PRODUCT
Attention Filter (n=1166243): 0.937 +\- 0.048 [0.556-1.000]
Filter Time: 5.1746
Diffusion Time: 0.4472
Total Transformation Time: 5.9867
Epoch 10:, Train 0.6078, Val 0.6057, Test 0.5591
Epoch 20:, Train 0.6246, Val 0.6115, Test 0.5628
Epoch 30:, Train 0.6359, Val 0.6179, Test 0.5661
Epoch 40:, Train 0.6453, Val 0.6159, Test 0.5615
Epoch 50:, Train 0.6503, Val 0.6219, Test 0.5723
Epoch 60:, Train 0.6556, Val 0.6224, Test 0.5719
Epoch 70:, Train 0.6602, Val 0.6270, Test 0.5783
Epoch 80:, Train 0.6618, Val 0.6229, Test 0.5782
Epoch 90:, Train 0.6644, Val 0.6215, Test 0.5677
Epoch 100:, Train 0.6684, Val 0.6239, Test 0.5728
Epoch 110:, Train 0.6703, Val 0.6301, Test 0.5820
Epoch 120:, Train 0.6677, Val 0.6234, Test 0.5694
Epoch 130:, Train 0.6684, Val 0.6238, Test 0.5744
Epoch 140:, Train 0.6696, Val 0.6228, Test 0.5731
Epoch 150:, Train 0.6710, Val 0.6228, Test 0.5682
Epoch 160:, Train 0.6729, Val 0.6264, Test 0.5740
Epoch 170:, Train 0.6751, Val 0.6276, Test 0.5690
Epoch 180:, Train 0.6749, Val 0.6260, Test 0.5672
Epoch 190:, Train 0.6713, Val 0.6232, Test 0.5631
Epoch 200:, Train 0.6770, Val 0.6263, Test 0.5698
BEST: Epoch 110, Train 0.6703, Val 0.6301, Test 0.5820

RUN #7: seed=512
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4966272711753845
coalesce scoo: 1.192e-05
convert to csr_matrix: 0.02398
calc min-max per row: 0.03368
vectorization: 0.02073
Normalization Time: 0.0936
DOT_PRODUCT
Attention Filter (n=1166243): 0.928 +\- 0.057 [0.520-1.000]
Filter Time: 5.3923
Diffusion Time: 0.4359
Total Transformation Time: 6.1932
Epoch 10:, Train 0.6049, Val 0.6015, Test 0.5539
Epoch 20:, Train 0.6222, Val 0.6123, Test 0.5627
Epoch 30:, Train 0.6312, Val 0.6108, Test 0.5622
Epoch 40:, Train 0.6437, Val 0.6184, Test 0.5664
Epoch 50:, Train 0.6441, Val 0.6200, Test 0.5836
Epoch 60:, Train 0.6536, Val 0.6202, Test 0.5765
Epoch 70:, Train 0.6575, Val 0.6236, Test 0.5758
Epoch 80:, Train 0.6601, Val 0.6178, Test 0.5608
Epoch 90:, Train 0.6596, Val 0.6256, Test 0.5771
Epoch 100:, Train 0.6664, Val 0.6218, Test 0.5700
Epoch 110:, Train 0.6694, Val 0.6262, Test 0.5777
Epoch 120:, Train 0.6696, Val 0.6203, Test 0.5676
Epoch 130:, Train 0.6674, Val 0.6259, Test 0.5817
Epoch 140:, Train 0.6728, Val 0.6223, Test 0.5712
Epoch 150:, Train 0.6684, Val 0.6245, Test 0.5732
Epoch 160:, Train 0.6694, Val 0.6211, Test 0.5706
Epoch 170:, Train 0.6711, Val 0.6237, Test 0.5707
Epoch 180:, Train 0.6729, Val 0.6235, Test 0.5702
Epoch 190:, Train 0.6739, Val 0.6232, Test 0.5697
Epoch 200:, Train 0.6763, Val 0.6258, Test 0.5745
BEST: Epoch 110, Train 0.6694, Val 0.6262, Test 0.5777

RUN #8: seed=1024
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.4767032563686371
coalesce scoo: 1.192e-05
convert to csr_matrix: 0.02391
calc min-max per row: 0.03391
vectorization: 0.0204
Normalization Time: 0.0944
DOT_PRODUCT
Attention Filter (n=1166243): 0.928 +\- 0.054 [0.568-1.000]
Filter Time: 5.3597
Diffusion Time: 0.4727
Total Transformation Time: 6.1982
Epoch 10:, Train 0.6061, Val 0.6066, Test 0.5621
Epoch 20:, Train 0.6259, Val 0.6195, Test 0.5762
Epoch 30:, Train 0.6357, Val 0.6214, Test 0.5776
Epoch 40:, Train 0.6453, Val 0.6210, Test 0.5681
Epoch 50:, Train 0.6493, Val 0.6235, Test 0.5696
Epoch 60:, Train 0.6564, Val 0.6219, Test 0.5695
Epoch 70:, Train 0.6591, Val 0.6185, Test 0.5615
Epoch 80:, Train 0.6607, Val 0.6266, Test 0.5779
Epoch 90:, Train 0.6648, Val 0.6235, Test 0.5687
Epoch 100:, Train 0.6653, Val 0.6234, Test 0.5758
Epoch 110:, Train 0.6664, Val 0.6218, Test 0.5701
Epoch 120:, Train 0.6686, Val 0.6283, Test 0.5800
Epoch 130:, Train 0.6676, Val 0.6199, Test 0.5662
Epoch 140:, Train 0.6729, Val 0.6273, Test 0.5743
Epoch 150:, Train 0.6721, Val 0.6208, Test 0.5621
Epoch 160:, Train 0.6701, Val 0.6259, Test 0.5726
Epoch 170:, Train 0.6713, Val 0.6270, Test 0.5803
Epoch 180:, Train 0.6716, Val 0.6250, Test 0.5658
Epoch 190:, Train 0.6726, Val 0.6174, Test 0.5625
Epoch 200:, Train 0.6739, Val 0.6271, Test 0.5757
BEST: Epoch 120, Train 0.6686, Val 0.6283, Test 0.5800

RUN #9: seed=2048
Attn Summary:
len(r): 1166243
len(c): 1166243
len(v): 1166243
dtype(v): torch.FloatTensor, 0.47441917657852173
coalesce scoo: 1.526e-05
convert to csr_matrix: 0.02379
calc min-max per row: 0.03348
vectorization: 0.02038
Normalization Time: 0.0931
DOT_PRODUCT
Attention Filter (n=1166243): 0.931 +\- 0.052 [0.537-1.000]
Filter Time: 5.1425
Diffusion Time: 0.4334
Total Transformation Time: 5.9429
Epoch 10:, Train 0.6060, Val 0.6052, Test 0.5613
Epoch 20:, Train 0.6227, Val 0.6103, Test 0.5667
Epoch 30:, Train 0.6352, Val 0.6158, Test 0.5599
Epoch 40:, Train 0.6445, Val 0.6177, Test 0.5615
Epoch 50:, Train 0.6504, Val 0.6187, Test 0.5641
Epoch 60:, Train 0.6546, Val 0.6233, Test 0.5722
Epoch 70:, Train 0.6591, Val 0.6215, Test 0.5746
Epoch 80:, Train 0.6603, Val 0.6198, Test 0.5632
Epoch 90:, Train 0.6629, Val 0.6227, Test 0.5769
Epoch 100:, Train 0.6670, Val 0.6224, Test 0.5719
Epoch 110:, Train 0.6668, Val 0.6215, Test 0.5673
Epoch 120:, Train 0.6656, Val 0.6235, Test 0.5707
Epoch 130:, Train 0.6677, Val 0.6240, Test 0.5816
Epoch 140:, Train 0.6666, Val 0.6189, Test 0.5626
Epoch 150:, Train 0.6694, Val 0.6214, Test 0.5703
Epoch 160:, Train 0.6686, Val 0.6265, Test 0.5762
Epoch 170:, Train 0.6717, Val 0.6245, Test 0.5747
Epoch 180:, Train 0.6754, Val 0.6252, Test 0.5731
Epoch 190:, Train 0.6711, Val 0.6260, Test 0.5724
Epoch 200:, Train 0.6764, Val 0.6222, Test 0.5678
BEST: Epoch 160, Train 0.6686, Val 0.6265, Test 0.5762




==================================================
Model Parameters: 531885

Avg. Filter Time (s): 5.2245 +/- 0.0883
Avg. Diffusion Time (s): 0.4389 +/- 0.0130
Avg. Preaggregation Time (s): 6.0292 +/- 0.0972
Avg. Training Time (epoch) (s): 1.1443 +/- 0.4405
Avg. Inference Time (s): 0.0760 +/- 0.0080

Avg. Training Acc: 0.6705 +/- 0.0037
Avg. Validation Acc: 0.6280 +/- 0.0015
Avg. Test Acc: 0.5778 +/- 0.0034

==================================================

++++++++++++++++++++++++++++++++++++++++++++++++++++
TOTAL RUNTIME = 2 hours 49 minutes
++++++++++++++++++++++++++++++++++++++++++++++++++++
